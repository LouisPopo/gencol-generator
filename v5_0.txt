cuda is available
USING : cuda
Done loading data from cached files.
Training ...
     Batch 000 | Loss : 0.6964 | Acc : 0.4893
     Batch 025 | Loss : 0.6926 | Acc : 0.5105
     Batch 050 | Loss : 0.6221 | Acc : 0.7120
     Batch 075 | Loss : 0.5419 | Acc : 0.7773
     Batch 100 | Loss : 0.4207 | Acc : 0.8093
     Batch 125 | Loss : 0.4342 | Acc : 0.7919
     Batch 150 | Loss : 0.3893 | Acc : 0.8193
     Batch 175 | Loss : 0.3392 | Acc : 0.8493
     Batch 200 | Loss : 0.4610 | Acc : 0.8116
     Batch 225 | Loss : 0.4495 | Acc : 0.7821
     Batch 250 | Loss : 0.3973 | Acc : 0.8089
     Batch 275 | Loss : 0.4667 | Acc : 0.7764
     Batch 300 | Loss : 0.3649 | Acc : 0.8279
Epoch 00000 | Train Loss : 0.4799 | Eval Loss : 0.3802 | Train acc : 0.7507 | Eval Acc : 0.8191 | Eval Log. Respected : 0.9988
     Batch 000 | Loss : 0.3385 | Acc : 0.8472
     Batch 025 | Loss : 0.4156 | Acc : 0.7977
     Batch 050 | Loss : 0.3827 | Acc : 0.8191
     Batch 075 | Loss : 0.4361 | Acc : 0.7871
     Batch 100 | Loss : 0.4571 | Acc : 0.7695
     Batch 125 | Loss : 0.3086 | Acc : 0.8554
     Batch 150 | Loss : 0.3745 | Acc : 0.8361
     Batch 175 | Loss : 0.3348 | Acc : 0.8457
     Batch 200 | Loss : 0.3342 | Acc : 0.8635
     Batch 225 | Loss : 0.3415 | Acc : 0.8472
     Batch 250 | Loss : 0.3224 | Acc : 0.8514
     Batch 275 | Loss : 0.3559 | Acc : 0.8376
     Batch 300 | Loss : 0.3758 | Acc : 0.8269
Epoch 00001 | Train Loss : 0.3760 | Eval Loss : 0.3533 | Train acc : 0.8259 | Eval Acc : 0.8333 | Eval Log. Respected : 0.9570
     Batch 000 | Loss : 0.3880 | Acc : 0.8121
     Batch 025 | Loss : 0.3617 | Acc : 0.8291
     Batch 050 | Loss : 0.4004 | Acc : 0.8158
     Batch 075 | Loss : 0.3646 | Acc : 0.8366
     Batch 100 | Loss : 0.3334 | Acc : 0.8557
     Batch 125 | Loss : 0.2838 | Acc : 0.8847
     Batch 150 | Loss : 0.3324 | Acc : 0.8524
     Batch 175 | Loss : 0.3303 | Acc : 0.8478
     Batch 200 | Loss : 0.3294 | Acc : 0.8499
     Batch 225 | Loss : 0.3650 | Acc : 0.8315
     Batch 250 | Loss : 0.3449 | Acc : 0.8406
     Batch 275 | Loss : 0.2894 | Acc : 0.8738
     Batch 300 | Loss : 0.4021 | Acc : 0.8089
Epoch 00002 | Train Loss : 0.3633 | Eval Loss : 0.3431 | Train acc : 0.8329 | Eval Acc : 0.8402 | Eval Log. Respected : 0.9438
     Batch 000 | Loss : 0.2817 | Acc : 0.8770
     Batch 025 | Loss : 0.3153 | Acc : 0.8577
     Batch 050 | Loss : 0.3852 | Acc : 0.8231
     Batch 075 | Loss : 0.3126 | Acc : 0.8651
     Batch 100 | Loss : 0.3297 | Acc : 0.8557
     Batch 125 | Loss : 0.3815 | Acc : 0.8228
     Batch 150 | Loss : 0.2927 | Acc : 0.8713
     Batch 175 | Loss : 0.3069 | Acc : 0.8595
     Batch 200 | Loss : 0.3106 | Acc : 0.8606
     Batch 225 | Loss : 0.3828 | Acc : 0.8193
     Batch 250 | Loss : 0.4115 | Acc : 0.7961
     Batch 275 | Loss : 0.3079 | Acc : 0.8704
     Batch 300 | Loss : 0.3407 | Acc : 0.8462
Epoch 00003 | Train Loss : 0.3534 | Eval Loss : 0.3475 | Train acc : 0.8371 | Eval Acc : 0.8361 | Eval Log. Respected : 0.9441
     Batch 000 | Loss : 0.3157 | Acc : 0.8583
     Batch 025 | Loss : 0.4855 | Acc : 0.7736
     Batch 050 | Loss : 0.4275 | Acc : 0.8031
     Batch 075 | Loss : 0.3217 | Acc : 0.8569
     Batch 100 | Loss : 0.3082 | Acc : 0.8577
     Batch 125 | Loss : 0.3423 | Acc : 0.8402
     Batch 150 | Loss : 0.3695 | Acc : 0.8251
     Batch 175 | Loss : 0.5596 | Acc : 0.7639
     Batch 200 | Loss : 0.3719 | Acc : 0.8228
     Batch 225 | Loss : 0.4323 | Acc : 0.7897
     Batch 250 | Loss : 0.3933 | Acc : 0.8044
     Batch 275 | Loss : 0.3120 | Acc : 0.8568
     Batch 300 | Loss : 0.2804 | Acc : 0.8776
Epoch 00004 | Train Loss : 0.3517 | Eval Loss : 0.3457 | Train acc : 0.8388 | Eval Acc : 0.8395 | Eval Log. Respected : 0.9511
     Batch 000 | Loss : 0.3038 | Acc : 0.8697
     Batch 025 | Loss : 0.3217 | Acc : 0.8556
     Batch 050 | Loss : 0.3302 | Acc : 0.8485
     Batch 075 | Loss : 0.3234 | Acc : 0.8573
     Batch 100 | Loss : 0.3487 | Acc : 0.8357
     Batch 125 | Loss : 0.3856 | Acc : 0.8203
     Batch 150 | Loss : 0.3505 | Acc : 0.8356
     Batch 175 | Loss : 0.3687 | Acc : 0.8370
     Batch 200 | Loss : 0.3184 | Acc : 0.8523
     Batch 225 | Loss : 0.4110 | Acc : 0.8005
     Batch 250 | Loss : 0.3187 | Acc : 0.8534
     Batch 275 | Loss : 0.3719 | Acc : 0.8234
     Batch 300 | Loss : 0.3589 | Acc : 0.8294
Epoch 00005 | Train Loss : 0.3454 | Eval Loss : 0.3482 | Train acc : 0.8410 | Eval Acc : 0.8384 | Eval Log. Respected : 0.9291
     Batch 000 | Loss : 0.3413 | Acc : 0.8404
     Batch 025 | Loss : 0.2998 | Acc : 0.8619
     Batch 050 | Loss : 0.3061 | Acc : 0.8597
     Batch 075 | Loss : 0.3180 | Acc : 0.8500
     Batch 100 | Loss : 0.3781 | Acc : 0.8195
     Batch 125 | Loss : 0.3702 | Acc : 0.8225
     Batch 150 | Loss : 0.3060 | Acc : 0.8667
     Batch 175 | Loss : 0.3252 | Acc : 0.8487
     Batch 200 | Loss : 0.3205 | Acc : 0.8554
     Batch 225 | Loss : 0.3040 | Acc : 0.8572
     Batch 250 | Loss : 0.2713 | Acc : 0.8803
     Batch 275 | Loss : 0.3616 | Acc : 0.8312
     Batch 300 | Loss : 0.3116 | Acc : 0.8590
Epoch 00006 | Train Loss : 0.3418 | Eval Loss : 0.3321 | Train acc : 0.8423 | Eval Acc : 0.8445 | Eval Log. Respected : 0.9312
     Batch 000 | Loss : 0.2951 | Acc : 0.8615
     Batch 025 | Loss : 0.3756 | Acc : 0.8235
     Batch 050 | Loss : 0.3944 | Acc : 0.8140
     Batch 075 | Loss : 0.3620 | Acc : 0.8320
     Batch 100 | Loss : 0.3096 | Acc : 0.8537
     Batch 125 | Loss : 0.2888 | Acc : 0.8682
     Batch 150 | Loss : 0.3016 | Acc : 0.8573
     Batch 175 | Loss : 0.3938 | Acc : 0.8175
     Batch 200 | Loss : 0.2947 | Acc : 0.8654
     Batch 225 | Loss : 0.3020 | Acc : 0.8612
     Batch 250 | Loss : 0.3629 | Acc : 0.8237
     Batch 275 | Loss : 0.3276 | Acc : 0.8501
     Batch 300 | Loss : 0.3344 | Acc : 0.8397
Epoch 00007 | Train Loss : 0.3413 | Eval Loss : 0.3298 | Train acc : 0.8429 | Eval Acc : 0.8445 | Eval Log. Respected : 0.9324
     Batch 000 | Loss : 0.3764 | Acc : 0.8272
     Batch 025 | Loss : 0.3094 | Acc : 0.8703
     Batch 050 | Loss : 0.3713 | Acc : 0.8252
     Batch 075 | Loss : 0.3691 | Acc : 0.8289
     Batch 100 | Loss : 0.4257 | Acc : 0.8088
     Batch 125 | Loss : 0.3315 | Acc : 0.8426
     Batch 150 | Loss : 0.3542 | Acc : 0.8470
     Batch 175 | Loss : 0.3237 | Acc : 0.8532
     Batch 200 | Loss : 0.3176 | Acc : 0.8523
     Batch 225 | Loss : 0.3146 | Acc : 0.8539
     Batch 250 | Loss : 0.3456 | Acc : 0.8453
     Batch 275 | Loss : 0.3157 | Acc : 0.8568
     Batch 300 | Loss : 0.3714 | Acc : 0.8149
Epoch 00008 | Train Loss : 0.3387 | Eval Loss : 0.3317 | Train acc : 0.8442 | Eval Acc : 0.8428 | Eval Log. Respected : 0.9228
     Batch 000 | Loss : 0.3215 | Acc : 0.8494
     Batch 025 | Loss : 0.3253 | Acc : 0.8509
     Batch 050 | Loss : 0.3741 | Acc : 0.8260
     Batch 075 | Loss : 0.2942 | Acc : 0.8660
     Batch 100 | Loss : 0.3635 | Acc : 0.8342
     Batch 125 | Loss : 0.3658 | Acc : 0.8230
     Batch 150 | Loss : 0.3627 | Acc : 0.8343
     Batch 175 | Loss : 0.3193 | Acc : 0.8579
     Batch 200 | Loss : 0.3148 | Acc : 0.8547
     Batch 225 | Loss : 0.3039 | Acc : 0.8622
     Batch 250 | Loss : 0.3063 | Acc : 0.8601
     Batch 275 | Loss : 0.2859 | Acc : 0.8732
     Batch 300 | Loss : 0.3823 | Acc : 0.8214
Epoch 00009 | Train Loss : 0.3365 | Eval Loss : 0.3365 | Train acc : 0.8446 | Eval Acc : 0.8421 | Eval Log. Respected : 0.9307
     Batch 000 | Loss : 0.3902 | Acc : 0.8091
     Batch 025 | Loss : 0.3410 | Acc : 0.8482
     Batch 050 | Loss : 0.3329 | Acc : 0.8460
     Batch 075 | Loss : 0.3274 | Acc : 0.8454
     Batch 100 | Loss : 0.2471 | Acc : 0.8915
     Batch 125 | Loss : 0.3324 | Acc : 0.8457
     Batch 150 | Loss : 0.3111 | Acc : 0.8686
     Batch 175 | Loss : 0.3179 | Acc : 0.8631
     Batch 200 | Loss : 0.3093 | Acc : 0.8647
     Batch 225 | Loss : 0.2858 | Acc : 0.8717
     Batch 250 | Loss : 0.4306 | Acc : 0.8015
     Batch 275 | Loss : 0.3422 | Acc : 0.8351
     Batch 300 | Loss : 0.3463 | Acc : 0.8418
Epoch 00010 | Train Loss : 0.3373 | Eval Loss : 0.3315 | Train acc : 0.8448 | Eval Acc : 0.8442 | Eval Log. Respected : 0.9168
     Batch 000 | Loss : 0.3763 | Acc : 0.8237
     Batch 025 | Loss : 0.3776 | Acc : 0.8215
     Batch 050 | Loss : 0.4283 | Acc : 0.8044
     Batch 075 | Loss : 0.3054 | Acc : 0.8614
     Batch 100 | Loss : 0.4232 | Acc : 0.7983
     Batch 125 | Loss : 0.3691 | Acc : 0.8296
     Batch 150 | Loss : 0.3673 | Acc : 0.8274
     Batch 175 | Loss : 0.2834 | Acc : 0.8707
     Batch 200 | Loss : 0.2977 | Acc : 0.8682
     Batch 225 | Loss : 0.3383 | Acc : 0.8426
     Batch 250 | Loss : 0.4041 | Acc : 0.8201
     Batch 275 | Loss : 0.2972 | Acc : 0.8706
     Batch 300 | Loss : 0.3649 | Acc : 0.8309
Epoch 00011 | Train Loss : 0.3370 | Eval Loss : 0.3377 | Train acc : 0.8448 | Eval Acc : 0.8413 | Eval Log. Respected : 0.9242
     Batch 000 | Loss : 0.3570 | Acc : 0.8292
     Batch 025 | Loss : 0.2880 | Acc : 0.8652
     Batch 050 | Loss : 0.3605 | Acc : 0.8432
     Batch 075 | Loss : 0.3077 | Acc : 0.8615
     Batch 100 | Loss : 0.3647 | Acc : 0.8255
     Batch 125 | Loss : 0.3286 | Acc : 0.8489
     Batch 150 | Loss : 0.3675 | Acc : 0.8247
     Batch 175 | Loss : 0.3083 | Acc : 0.8575
     Batch 200 | Loss : 0.4797 | Acc : 0.7770
     Batch 225 | Loss : 0.3200 | Acc : 0.8581
     Batch 250 | Loss : 0.2876 | Acc : 0.8738
     Batch 275 | Loss : 0.2882 | Acc : 0.8728
     Batch 300 | Loss : 0.3465 | Acc : 0.8381
Epoch 00012 | Train Loss : 0.3364 | Eval Loss : 0.3377 | Train acc : 0.8457 | Eval Acc : 0.8393 | Eval Log. Respected : 0.9287
     Batch 000 | Loss : 0.3541 | Acc : 0.8355
     Batch 025 | Loss : 0.3399 | Acc : 0.8374
     Batch 050 | Loss : 0.3007 | Acc : 0.8607
     Batch 075 | Loss : 0.2884 | Acc : 0.8733
     Batch 100 | Loss : 0.3414 | Acc : 0.8379
     Batch 125 | Loss : 0.3263 | Acc : 0.8474
     Batch 150 | Loss : 0.3555 | Acc : 0.8363
     Batch 175 | Loss : 0.3201 | Acc : 0.8586
     Batch 200 | Loss : 0.3473 | Acc : 0.8384
     Batch 225 | Loss : 0.2866 | Acc : 0.8732
     Batch 250 | Loss : 0.3568 | Acc : 0.8331
     Batch 275 | Loss : 0.3463 | Acc : 0.8325
     Batch 300 | Loss : 0.3219 | Acc : 0.8563
Epoch 00013 | Train Loss : 0.3327 | Eval Loss : 0.3230 | Train acc : 0.8464 | Eval Acc : 0.8477 | Eval Log. Respected : 0.9339
     Batch 000 | Loss : 0.2987 | Acc : 0.8654
     Batch 025 | Loss : 0.4188 | Acc : 0.7965
     Batch 050 | Loss : 0.3404 | Acc : 0.8453
     Batch 075 | Loss : 0.3063 | Acc : 0.8615
     Batch 100 | Loss : 0.2851 | Acc : 0.8691
     Batch 125 | Loss : 0.3253 | Acc : 0.8491
     Batch 150 | Loss : 0.3278 | Acc : 0.8508
     Batch 175 | Loss : 0.3296 | Acc : 0.8495
     Batch 200 | Loss : 0.3367 | Acc : 0.8442
     Batch 225 | Loss : 0.3228 | Acc : 0.8514
     Batch 250 | Loss : 0.3904 | Acc : 0.8179
     Batch 275 | Loss : 0.3218 | Acc : 0.8574
     Batch 300 | Loss : 0.3189 | Acc : 0.8508
Epoch 00014 | Train Loss : 0.3329 | Eval Loss : 0.3225 | Train acc : 0.8468 | Eval Acc : 0.8480 | Eval Log. Respected : 0.9234
     Batch 000 | Loss : 0.3008 | Acc : 0.8596
     Batch 025 | Loss : 0.3498 | Acc : 0.8437
     Batch 050 | Loss : 0.2933 | Acc : 0.8680
     Batch 075 | Loss : 0.2910 | Acc : 0.8686
     Batch 100 | Loss : 0.3094 | Acc : 0.8592
     Batch 125 | Loss : 0.3128 | Acc : 0.8531
     Batch 150 | Loss : 0.3025 | Acc : 0.8571
     Batch 175 | Loss : 0.3014 | Acc : 0.8698
     Batch 200 | Loss : 0.3494 | Acc : 0.8331
     Batch 225 | Loss : 0.3332 | Acc : 0.8426
     Batch 250 | Loss : 0.4043 | Acc : 0.8067
     Batch 275 | Loss : 0.3185 | Acc : 0.8605
     Batch 300 | Loss : 0.3018 | Acc : 0.8594
Epoch 00015 | Train Loss : 0.3324 | Eval Loss : 0.3299 | Train acc : 0.8467 | Eval Acc : 0.8443 | Eval Log. Respected : 0.9385
     Batch 000 | Loss : 0.5180 | Acc : 0.7616
     Batch 025 | Loss : 0.3156 | Acc : 0.8625
     Batch 050 | Loss : 0.3278 | Acc : 0.8501
     Batch 075 | Loss : 0.4387 | Acc : 0.7838
     Batch 100 | Loss : 0.3101 | Acc : 0.8632
     Batch 125 | Loss : 0.2709 | Acc : 0.8826
     Batch 150 | Loss : 0.2537 | Acc : 0.8893
     Batch 175 | Loss : 0.3025 | Acc : 0.8628
     Batch 200 | Loss : 0.3235 | Acc : 0.8514
     Batch 225 | Loss : 0.2826 | Acc : 0.8738
     Batch 250 | Loss : 0.3570 | Acc : 0.8274
     Batch 275 | Loss : 0.2697 | Acc : 0.8793
     Batch 300 | Loss : 0.3710 | Acc : 0.8209
Epoch 00016 | Train Loss : 0.3310 | Eval Loss : 0.3240 | Train acc : 0.8476 | Eval Acc : 0.8474 | Eval Log. Respected : 0.9238
     Batch 000 | Loss : 0.3069 | Acc : 0.8524
     Batch 025 | Loss : 0.3960 | Acc : 0.8120
     Batch 050 | Loss : 0.3357 | Acc : 0.8442
     Batch 075 | Loss : 0.3135 | Acc : 0.8588
     Batch 100 | Loss : 0.3358 | Acc : 0.8448
     Batch 125 | Loss : 0.3089 | Acc : 0.8580
     Batch 150 | Loss : 0.3875 | Acc : 0.8161
     Batch 175 | Loss : 0.3445 | Acc : 0.8329
     Batch 200 | Loss : 0.2704 | Acc : 0.8808
     Batch 225 | Loss : 0.3784 | Acc : 0.8215
     Batch 250 | Loss : 0.3784 | Acc : 0.8233
     Batch 275 | Loss : 0.2660 | Acc : 0.8799
     Batch 300 | Loss : 0.3135 | Acc : 0.8610
Epoch 00017 | Train Loss : 0.3304 | Eval Loss : 0.3273 | Train acc : 0.8477 | Eval Acc : 0.8466 | Eval Log. Respected : 0.9155
     Batch 000 | Loss : 0.3614 | Acc : 0.8356
     Batch 025 | Loss : 0.3011 | Acc : 0.8594
     Batch 050 | Loss : 0.2906 | Acc : 0.8669
     Batch 075 | Loss : 0.2763 | Acc : 0.8791
     Batch 100 | Loss : 0.2768 | Acc : 0.8745
     Batch 125 | Loss : 0.3212 | Acc : 0.8580
     Batch 150 | Loss : 0.2949 | Acc : 0.8627
     Batch 175 | Loss : 0.3319 | Acc : 0.8417
     Batch 200 | Loss : 0.5236 | Acc : 0.7678
     Batch 225 | Loss : 0.3655 | Acc : 0.8347
     Batch 250 | Loss : 0.3015 | Acc : 0.8601
     Batch 275 | Loss : 0.3666 | Acc : 0.8274
     Batch 300 | Loss : 0.3008 | Acc : 0.8721
Epoch 00018 | Train Loss : 0.3300 | Eval Loss : 0.3223 | Train acc : 0.8480 | Eval Acc : 0.8483 | Eval Log. Respected : 0.9366
     Batch 000 | Loss : 0.3592 | Acc : 0.8327
     Batch 025 | Loss : 0.3310 | Acc : 0.8452
     Batch 050 | Loss : 0.3383 | Acc : 0.8446
     Batch 075 | Loss : 0.3796 | Acc : 0.8175
     Batch 100 | Loss : 0.3280 | Acc : 0.8485
     Batch 125 | Loss : 0.4377 | Acc : 0.7978
     Batch 150 | Loss : 0.2665 | Acc : 0.8799
     Batch 175 | Loss : 0.3229 | Acc : 0.8506
     Batch 200 | Loss : 0.2868 | Acc : 0.8709
     Batch 225 | Loss : 0.2909 | Acc : 0.8655
     Batch 250 | Loss : 0.2953 | Acc : 0.8638
     Batch 275 | Loss : 0.3398 | Acc : 0.8385
     Batch 300 | Loss : 0.4592 | Acc : 0.7781
Epoch 00019 | Train Loss : 0.3289 | Eval Loss : 0.3242 | Train acc : 0.8483 | Eval Acc : 0.8466 | Eval Log. Respected : 0.9257
     Batch 000 | Loss : 0.3093 | Acc : 0.8518
     Batch 025 | Loss : 0.4174 | Acc : 0.8063
     Batch 050 | Loss : 0.4164 | Acc : 0.8006
     Batch 075 | Loss : 0.3010 | Acc : 0.8618
     Batch 100 | Loss : 0.2921 | Acc : 0.8657
     Batch 125 | Loss : 0.3174 | Acc : 0.8522
     Batch 150 | Loss : 0.2819 | Acc : 0.8745
     Batch 175 | Loss : 0.3246 | Acc : 0.8434
     Batch 200 | Loss : 0.3363 | Acc : 0.8419
     Batch 225 | Loss : 0.3605 | Acc : 0.8310
     Batch 250 | Loss : 0.3082 | Acc : 0.8582
     Batch 275 | Loss : 0.3102 | Acc : 0.8590
     Batch 300 | Loss : 0.4161 | Acc : 0.8010
Epoch 00020 | Train Loss : 0.3280 | Eval Loss : 0.3236 | Train acc : 0.8492 | Eval Acc : 0.8479 | Eval Log. Respected : 0.9256
     Batch 000 | Loss : 0.3618 | Acc : 0.8270
     Batch 025 | Loss : 0.3267 | Acc : 0.8506
     Batch 050 | Loss : 0.3015 | Acc : 0.8597
     Batch 075 | Loss : 0.2815 | Acc : 0.8714
     Batch 100 | Loss : 0.3708 | Acc : 0.8188
     Batch 125 | Loss : 0.3396 | Acc : 0.8517
     Batch 150 | Loss : 0.3133 | Acc : 0.8538
     Batch 175 | Loss : 0.2883 | Acc : 0.8681
     Batch 200 | Loss : 0.2964 | Acc : 0.8633
     Batch 225 | Loss : 0.3255 | Acc : 0.8517
     Batch 250 | Loss : 0.2747 | Acc : 0.8752
     Batch 275 | Loss : 0.2939 | Acc : 0.8675
     Batch 300 | Loss : 0.3146 | Acc : 0.8545
Epoch 00021 | Train Loss : 0.3276 | Eval Loss : 0.3255 | Train acc : 0.8493 | Eval Acc : 0.8463 | Eval Log. Respected : 0.9218
     Batch 000 | Loss : 0.3428 | Acc : 0.8272
     Batch 025 | Loss : 0.3468 | Acc : 0.8360
     Batch 050 | Loss : 0.2906 | Acc : 0.8697
     Batch 075 | Loss : 0.3444 | Acc : 0.8397
     Batch 100 | Loss : 0.2856 | Acc : 0.8772
     Batch 125 | Loss : 0.3084 | Acc : 0.8592
     Batch 150 | Loss : 0.4573 | Acc : 0.7993
     Batch 175 | Loss : 0.3098 | Acc : 0.8581
     Batch 200 | Loss : 0.3177 | Acc : 0.8483
     Batch 225 | Loss : 0.2960 | Acc : 0.8639
     Batch 250 | Loss : 0.3230 | Acc : 0.8548
     Batch 275 | Loss : 0.2756 | Acc : 0.8820
     Batch 300 | Loss : 0.3356 | Acc : 0.8482
Epoch 00022 | Train Loss : 0.3276 | Eval Loss : 0.3291 | Train acc : 0.8492 | Eval Acc : 0.8434 | Eval Log. Respected : 0.9331
     Batch 000 | Loss : 0.3264 | Acc : 0.8501
     Batch 025 | Loss : 0.2810 | Acc : 0.8799
     Batch 050 | Loss : 0.3435 | Acc : 0.8426
     Batch 075 | Loss : 0.3929 | Acc : 0.8164
     Batch 100 | Loss : 0.2636 | Acc : 0.8784
     Batch 125 | Loss : 0.3159 | Acc : 0.8513
     Batch 150 | Loss : 0.4836 | Acc : 0.7811
     Batch 175 | Loss : 0.3499 | Acc : 0.8324
     Batch 200 | Loss : 0.2981 | Acc : 0.8634
     Batch 225 | Loss : 0.2720 | Acc : 0.8831
     Batch 250 | Loss : 0.3357 | Acc : 0.8437
     Batch 275 | Loss : 0.3193 | Acc : 0.8480
     Batch 300 | Loss : 0.2782 | Acc : 0.8754
Epoch 00023 | Train Loss : 0.3270 | Eval Loss : 0.3266 | Train acc : 0.8494 | Eval Acc : 0.8453 | Eval Log. Respected : 0.9264
     Batch 000 | Loss : 0.2991 | Acc : 0.8618
     Batch 025 | Loss : 0.2473 | Acc : 0.8892
     Batch 050 | Loss : 0.2938 | Acc : 0.8635
     Batch 075 | Loss : 0.2751 | Acc : 0.8722
     Batch 100 | Loss : 0.3418 | Acc : 0.8439
     Batch 125 | Loss : 0.3583 | Acc : 0.8266
     Batch 150 | Loss : 0.3070 | Acc : 0.8605
     Batch 175 | Loss : 0.3560 | Acc : 0.8329
     Batch 200 | Loss : 0.3399 | Acc : 0.8397
     Batch 225 | Loss : 0.2790 | Acc : 0.8727
     Batch 250 | Loss : 0.2850 | Acc : 0.8737
     Batch 275 | Loss : 0.3124 | Acc : 0.8497
     Batch 300 | Loss : 0.3077 | Acc : 0.8580
Epoch 00024 | Train Loss : 0.3256 | Eval Loss : 0.3179 | Train acc : 0.8498 | Eval Acc : 0.8507 | Eval Log. Respected : 0.9408
     Batch 000 | Loss : 0.3256 | Acc : 0.8487
     Batch 025 | Loss : 0.3034 | Acc : 0.8611
     Batch 050 | Loss : 0.2793 | Acc : 0.8732
     Batch 075 | Loss : 0.3876 | Acc : 0.8179
     Batch 100 | Loss : 0.2789 | Acc : 0.8742
     Batch 125 | Loss : 0.2830 | Acc : 0.8703
     Batch 150 | Loss : 0.3046 | Acc : 0.8557
     Batch 175 | Loss : 0.3113 | Acc : 0.8524
     Batch 200 | Loss : 0.2966 | Acc : 0.8646
     Batch 225 | Loss : 0.3286 | Acc : 0.8579
     Batch 250 | Loss : 0.3056 | Acc : 0.8631
     Batch 275 | Loss : 0.3091 | Acc : 0.8534
     Batch 300 | Loss : 0.3668 | Acc : 0.8279
Epoch 00025 | Train Loss : 0.3254 | Eval Loss : 0.3235 | Train acc : 0.8504 | Eval Acc : 0.8484 | Eval Log. Respected : 0.9230
     Batch 000 | Loss : 0.4599 | Acc : 0.7785
     Batch 025 | Loss : 0.2755 | Acc : 0.8797
     Batch 050 | Loss : 0.2969 | Acc : 0.8600
     Batch 075 | Loss : 0.3082 | Acc : 0.8615
     Batch 100 | Loss : 0.3305 | Acc : 0.8436
     Batch 125 | Loss : 0.3293 | Acc : 0.8454
     Batch 150 | Loss : 0.3271 | Acc : 0.8494
     Batch 175 | Loss : 0.2744 | Acc : 0.8788
     Batch 200 | Loss : 0.2684 | Acc : 0.8772
     Batch 225 | Loss : 0.3534 | Acc : 0.8324
     Batch 250 | Loss : 0.3095 | Acc : 0.8554
     Batch 275 | Loss : 0.3721 | Acc : 0.8325
     Batch 300 | Loss : 0.2889 | Acc : 0.8662
Epoch 00026 | Train Loss : 0.3236 | Eval Loss : 0.3184 | Train acc : 0.8507 | Eval Acc : 0.8503 | Eval Log. Respected : 0.9281
     Batch 000 | Loss : 0.3508 | Acc : 0.8335
     Batch 025 | Loss : 0.2644 | Acc : 0.8825
     Batch 050 | Loss : 0.3341 | Acc : 0.8409
     Batch 075 | Loss : 0.3292 | Acc : 0.8469
     Batch 100 | Loss : 0.2747 | Acc : 0.8738
     Batch 125 | Loss : 0.2674 | Acc : 0.8762
     Batch 150 | Loss : 0.2820 | Acc : 0.8790
     Batch 175 | Loss : 0.3270 | Acc : 0.8492
     Batch 200 | Loss : 0.3199 | Acc : 0.8493
     Batch 225 | Loss : 0.3024 | Acc : 0.8634
     Batch 250 | Loss : 0.2965 | Acc : 0.8642
     Batch 275 | Loss : 0.2906 | Acc : 0.8703
     Batch 300 | Loss : 0.3595 | Acc : 0.8324
Epoch 00027 | Train Loss : 0.3231 | Eval Loss : 0.3208 | Train acc : 0.8513 | Eval Acc : 0.8491 | Eval Log. Respected : 0.9424
     Batch 000 | Loss : 0.3184 | Acc : 0.8528
     Batch 025 | Loss : 0.2939 | Acc : 0.8695
     Batch 050 | Loss : 0.3748 | Acc : 0.8163
     Batch 075 | Loss : 0.3510 | Acc : 0.8407
     Batch 100 | Loss : 0.2928 | Acc : 0.8689
     Batch 125 | Loss : 0.3109 | Acc : 0.8548
     Batch 150 | Loss : 0.3022 | Acc : 0.8612
     Batch 175 | Loss : 0.3653 | Acc : 0.8295
     Batch 200 | Loss : 0.3442 | Acc : 0.8406
     Batch 225 | Loss : 0.3134 | Acc : 0.8539
     Batch 250 | Loss : 0.2912 | Acc : 0.8687
     Batch 275 | Loss : 0.2931 | Acc : 0.8655
     Batch 300 | Loss : 0.2475 | Acc : 0.8907
Epoch 00028 | Train Loss : 0.3229 | Eval Loss : 0.3215 | Train acc : 0.8510 | Eval Acc : 0.8494 | Eval Log. Respected : 0.9408
     Batch 000 | Loss : 0.2835 | Acc : 0.8730
     Batch 025 | Loss : 0.2574 | Acc : 0.8862
     Batch 050 | Loss : 0.3556 | Acc : 0.8393
     Batch 075 | Loss : 0.3142 | Acc : 0.8536
     Batch 100 | Loss : 0.3391 | Acc : 0.8431
     Batch 125 | Loss : 0.3453 | Acc : 0.8366
     Batch 150 | Loss : 0.2997 | Acc : 0.8622
     Batch 175 | Loss : 0.3454 | Acc : 0.8362
     Batch 200 | Loss : 0.4034 | Acc : 0.8061
     Batch 225 | Loss : 0.2759 | Acc : 0.8771
     Batch 250 | Loss : 0.3006 | Acc : 0.8618
     Batch 275 | Loss : 0.4350 | Acc : 0.7913
     Batch 300 | Loss : 0.2923 | Acc : 0.8678
Epoch 00029 | Train Loss : 0.3233 | Eval Loss : 0.3180 | Train acc : 0.8509 | Eval Acc : 0.8504 | Eval Log. Respected : 0.9265
     Batch 000 | Loss : 0.2960 | Acc : 0.8650
     Batch 025 | Loss : 0.2809 | Acc : 0.8706
     Batch 050 | Loss : 0.3730 | Acc : 0.8282
     Batch 075 | Loss : 0.2818 | Acc : 0.8747
     Batch 100 | Loss : 0.3037 | Acc : 0.8651
     Batch 125 | Loss : 0.3530 | Acc : 0.8337
     Batch 150 | Loss : 0.2812 | Acc : 0.8764
     Batch 175 | Loss : 0.4428 | Acc : 0.7956
     Batch 200 | Loss : 0.3414 | Acc : 0.8442
     Batch 225 | Loss : 0.2815 | Acc : 0.8854
     Batch 250 | Loss : 0.3183 | Acc : 0.8531
     Batch 275 | Loss : 0.2704 | Acc : 0.8772
     Batch 300 | Loss : 0.3582 | Acc : 0.8339
Epoch 00030 | Train Loss : 0.3220 | Eval Loss : 0.3185 | Train acc : 0.8517 | Eval Acc : 0.8494 | Eval Log. Respected : 0.9280
     Batch 000 | Loss : 0.2783 | Acc : 0.8708
     Batch 025 | Loss : 0.2642 | Acc : 0.8807
     Batch 050 | Loss : 0.3740 | Acc : 0.8230
     Batch 075 | Loss : 0.3619 | Acc : 0.8286
     Batch 100 | Loss : 0.2941 | Acc : 0.8663
     Batch 125 | Loss : 0.2884 | Acc : 0.8661
     Batch 150 | Loss : 0.2875 | Acc : 0.8677
     Batch 175 | Loss : 0.2759 | Acc : 0.8762
     Batch 200 | Loss : 0.2803 | Acc : 0.8689
     Batch 225 | Loss : 0.3772 | Acc : 0.8238
     Batch 250 | Loss : 0.2902 | Acc : 0.8704
     Batch 275 | Loss : 0.3311 | Acc : 0.8420
     Batch 300 | Loss : 0.4266 | Acc : 0.7933
Epoch 00031 | Train Loss : 0.3205 | Eval Loss : 0.3184 | Train acc : 0.8520 | Eval Acc : 0.8498 | Eval Log. Respected : 0.9275
     Batch 000 | Loss : 0.3229 | Acc : 0.8520
     Batch 025 | Loss : 0.2803 | Acc : 0.8731
     Batch 050 | Loss : 0.4092 | Acc : 0.8065
     Batch 075 | Loss : 0.2859 | Acc : 0.8707
     Batch 100 | Loss : 0.4253 | Acc : 0.8077
     Batch 125 | Loss : 0.2584 | Acc : 0.8851
     Batch 150 | Loss : 0.2864 | Acc : 0.8686
     Batch 175 | Loss : 0.4160 | Acc : 0.8035
     Batch 200 | Loss : 0.3637 | Acc : 0.8291
     Batch 225 | Loss : 0.3611 | Acc : 0.8377
     Batch 250 | Loss : 0.3262 | Acc : 0.8488
     Batch 275 | Loss : 0.2940 | Acc : 0.8591
     Batch 300 | Loss : 0.3331 | Acc : 0.8404
Epoch 00032 | Train Loss : 0.3208 | Eval Loss : 0.3213 | Train acc : 0.8521 | Eval Acc : 0.8487 | Eval Log. Respected : 0.9388
     Batch 000 | Loss : 0.2430 | Acc : 0.8931
     Batch 025 | Loss : 0.3302 | Acc : 0.8461
     Batch 050 | Loss : 0.3023 | Acc : 0.8624
     Batch 075 | Loss : 0.3737 | Acc : 0.8234
     Batch 100 | Loss : 0.2673 | Acc : 0.8803
     Batch 125 | Loss : 0.2858 | Acc : 0.8735
     Batch 150 | Loss : 0.3312 | Acc : 0.8474
     Batch 175 | Loss : 0.3290 | Acc : 0.8460
     Batch 200 | Loss : 0.3768 | Acc : 0.8220
     Batch 225 | Loss : 0.2722 | Acc : 0.8816
     Batch 250 | Loss : 0.4983 | Acc : 0.7817
     Batch 275 | Loss : 0.2996 | Acc : 0.8578
     Batch 300 | Loss : 0.2479 | Acc : 0.8923
Epoch 00033 | Train Loss : 0.3206 | Eval Loss : 0.3195 | Train acc : 0.8521 | Eval Acc : 0.8502 | Eval Log. Respected : 0.9391
     Batch 000 | Loss : 0.3278 | Acc : 0.8514
     Batch 025 | Loss : 0.2924 | Acc : 0.8687
     Batch 050 | Loss : 0.3083 | Acc : 0.8564
     Batch 075 | Loss : 0.3408 | Acc : 0.8407
     Batch 100 | Loss : 0.3543 | Acc : 0.8364
     Batch 125 | Loss : 0.3178 | Acc : 0.8536
     Batch 150 | Loss : 0.2978 | Acc : 0.8638
     Batch 175 | Loss : 0.3269 | Acc : 0.8471
     Batch 200 | Loss : 0.2752 | Acc : 0.8747
     Batch 225 | Loss : 0.2909 | Acc : 0.8728
     Batch 250 | Loss : 0.3503 | Acc : 0.8339
     Batch 275 | Loss : 0.3177 | Acc : 0.8563
     Batch 300 | Loss : 0.4440 | Acc : 0.7978
Epoch 00034 | Train Loss : 0.3202 | Eval Loss : 0.3215 | Train acc : 0.8524 | Eval Acc : 0.8482 | Eval Log. Respected : 0.9356
Early Stopping
Testing...
