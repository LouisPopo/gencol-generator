Done loading data from cached files.
Training ...
     Batch 000 | Loss : 0.7875 | Acc : 0.5141
     Batch 025 | Loss : 0.7029 | Acc : 0.5120
     Batch 050 | Loss : 0.6892 | Acc : 0.5420
     Batch 075 | Loss : 0.6894 | Acc : 0.5372
     Batch 100 | Loss : 0.6880 | Acc : 0.5436
     Batch 125 | Loss : 0.6877 | Acc : 0.5472
     Batch 150 | Loss : 0.6897 | Acc : 0.5330
     Batch 175 | Loss : 0.6901 | Acc : 0.5349
     Batch 200 | Loss : 0.6889 | Acc : 0.5367
     Batch 225 | Loss : 0.6863 | Acc : 0.5514
     Batch 250 | Loss : 0.6828 | Acc : 0.5547
     Batch 275 | Loss : 0.6881 | Acc : 0.5375
     Batch 300 | Loss : 0.6836 | Acc : 0.5454
Epoch 00000 | Train Loss : 0.6887 | Eval Loss : 0.6881 | Train acc : 0.5412 | Eval Acc : 0.5382 | Eval Log. Respected : 0.7484
     Batch 000 | Loss : 0.6849 | Acc : 0.5505
     Batch 025 | Loss : 0.6872 | Acc : 0.5424
     Batch 050 | Loss : 0.6863 | Acc : 0.5352
     Batch 075 | Loss : 0.6888 | Acc : 0.5349
     Batch 100 | Loss : 0.6842 | Acc : 0.5466
     Batch 125 | Loss : 0.6840 | Acc : 0.5432
     Batch 150 | Loss : 0.6790 | Acc : 0.5573
     Batch 175 | Loss : 0.6873 | Acc : 0.5347
     Batch 200 | Loss : 0.6826 | Acc : 0.5553
     Batch 225 | Loss : 0.6795 | Acc : 0.5570
     Batch 250 | Loss : 0.6838 | Acc : 0.5364
     Batch 275 | Loss : 0.6875 | Acc : 0.5268
     Batch 300 | Loss : 0.6743 | Acc : 0.5667
Epoch 00001 | Train Loss : 0.6835 | Eval Loss : 0.6892 | Train acc : 0.5457 | Eval Acc : 0.5199 | Eval Log. Respected : 0.3097
     Batch 000 | Loss : 0.6798 | Acc : 0.5478
     Batch 025 | Loss : 0.6785 | Acc : 0.5533
     Batch 050 | Loss : 0.6794 | Acc : 0.5627
     Batch 075 | Loss : 0.6775 | Acc : 0.5600
     Batch 100 | Loss : 0.6827 | Acc : 0.5469
     Batch 125 | Loss : 0.6835 | Acc : 0.5523
     Batch 150 | Loss : 0.6798 | Acc : 0.5574
     Batch 175 | Loss : 0.6792 | Acc : 0.5504
     Batch 200 | Loss : 0.6850 | Acc : 0.5384
     Batch 225 | Loss : 0.6814 | Acc : 0.5604
     Batch 250 | Loss : 0.6738 | Acc : 0.5713
     Batch 275 | Loss : 0.6696 | Acc : 0.5783
     Batch 300 | Loss : 0.6796 | Acc : 0.5661
Epoch 00002 | Train Loss : 0.6813 | Eval Loss : 0.6827 | Train acc : 0.5511 | Eval Acc : 0.5386 | Eval Log. Respected : 0.4504
     Batch 000 | Loss : 0.6856 | Acc : 0.5371
     Batch 025 | Loss : 0.6810 | Acc : 0.5564
     Batch 050 | Loss : 0.6837 | Acc : 0.5486
     Batch 075 | Loss : 0.6799 | Acc : 0.5544
     Batch 100 | Loss : 0.6834 | Acc : 0.5478
     Batch 125 | Loss : 0.6751 | Acc : 0.5590
     Batch 150 | Loss : 0.6839 | Acc : 0.5499
     Batch 175 | Loss : 0.6770 | Acc : 0.5614
     Batch 200 | Loss : 0.6746 | Acc : 0.5702
     Batch 225 | Loss : 0.6720 | Acc : 0.5607
     Batch 250 | Loss : 0.6741 | Acc : 0.5676
     Batch 275 | Loss : 0.6731 | Acc : 0.5560
     Batch 300 | Loss : 0.6769 | Acc : 0.5547
Epoch 00003 | Train Loss : 0.6790 | Eval Loss : 0.6931 | Train acc : 0.5545 | Eval Acc : 0.5366 | Eval Log. Respected : 0.5676
     Batch 000 | Loss : 0.6698 | Acc : 0.5744
     Batch 025 | Loss : 0.6828 | Acc : 0.5459
     Batch 050 | Loss : 0.6673 | Acc : 0.5777
     Batch 075 | Loss : 0.6692 | Acc : 0.5718
     Batch 100 | Loss : 0.6755 | Acc : 0.5600
     Batch 125 | Loss : 0.6813 | Acc : 0.5544
     Batch 150 | Loss : 0.6868 | Acc : 0.5482
     Batch 175 | Loss : 0.6792 | Acc : 0.5538
     Batch 200 | Loss : 0.6933 | Acc : 0.5340
     Batch 225 | Loss : 0.6769 | Acc : 0.5523
     Batch 250 | Loss : 0.6740 | Acc : 0.5638
     Batch 275 | Loss : 0.6702 | Acc : 0.5691
     Batch 300 | Loss : 0.6735 | Acc : 0.5732
Epoch 00004 | Train Loss : 0.6745 | Eval Loss : 0.7628 | Train acc : 0.5620 | Eval Acc : 0.4713 | Eval Log. Respected : 0.6563
     Batch 000 | Loss : 0.6894 | Acc : 0.5414
     Batch 025 | Loss : 0.6758 | Acc : 0.5588
     Batch 050 | Loss : 0.6663 | Acc : 0.5604
     Batch 075 | Loss : 0.6916 | Acc : 0.5576
     Batch 100 | Loss : 0.6680 | Acc : 0.5760
     Batch 125 | Loss : 0.6846 | Acc : 0.5433
     Batch 150 | Loss : 0.6618 | Acc : 0.5835
     Batch 175 | Loss : 0.6519 | Acc : 0.5904
     Batch 200 | Loss : 0.6661 | Acc : 0.5718
     Batch 225 | Loss : 0.6951 | Acc : 0.5182
     Batch 250 | Loss : 0.6846 | Acc : 0.5623
     Batch 275 | Loss : 0.6646 | Acc : 0.5743
     Batch 300 | Loss : 0.6551 | Acc : 0.5755
Epoch 00005 | Train Loss : 0.6728 | Eval Loss : 0.7348 | Train acc : 0.5650 | Eval Acc : 0.5009 | Eval Log. Respected : 0.5717
     Batch 000 | Loss : 0.6415 | Acc : 0.5877
     Batch 025 | Loss : 0.6561 | Acc : 0.5857
     Batch 050 | Loss : 0.6739 | Acc : 0.5679
     Batch 075 | Loss : 0.6750 | Acc : 0.5526
     Batch 100 | Loss : 0.6719 | Acc : 0.5730
     Batch 125 | Loss : 0.6720 | Acc : 0.5613
     Batch 150 | Loss : 0.6753 | Acc : 0.5442
     Batch 175 | Loss : 0.7164 | Acc : 0.4890
     Batch 200 | Loss : 0.6609 | Acc : 0.5833
     Batch 225 | Loss : 0.6682 | Acc : 0.5681
     Batch 250 | Loss : 0.6666 | Acc : 0.5630
     Batch 275 | Loss : 0.6664 | Acc : 0.5775
     Batch 300 | Loss : 0.6839 | Acc : 0.5551
Epoch 00006 | Train Loss : 0.6698 | Eval Loss : 0.7619 | Train acc : 0.5664 | Eval Acc : 0.4711 | Eval Log. Respected : 0.5908
     Batch 000 | Loss : 0.6982 | Acc : 0.5313
     Batch 025 | Loss : 0.6757 | Acc : 0.5749
     Batch 050 | Loss : 0.6917 | Acc : 0.5445
     Batch 075 | Loss : 0.6761 | Acc : 0.5481
     Batch 100 | Loss : 0.6572 | Acc : 0.5783
     Batch 125 | Loss : 0.6626 | Acc : 0.5617
     Batch 150 | Loss : 0.6864 | Acc : 0.5553
     Batch 175 | Loss : 0.6673 | Acc : 0.5716
     Batch 200 | Loss : 0.6921 | Acc : 0.5410
     Batch 225 | Loss : 0.6903 | Acc : 0.5354
     Batch 250 | Loss : 0.6726 | Acc : 0.5672
     Batch 275 | Loss : 0.6715 | Acc : 0.5611
     Batch 300 | Loss : 0.6485 | Acc : 0.5951
Epoch 00007 | Train Loss : 0.6724 | Eval Loss : 0.7421 | Train acc : 0.5645 | Eval Acc : 0.4809 | Eval Log. Respected : 0.5835
     Batch 000 | Loss : 0.6688 | Acc : 0.5677
     Batch 025 | Loss : 0.6716 | Acc : 0.5672
     Batch 050 | Loss : 0.6725 | Acc : 0.5666
     Batch 075 | Loss : 0.6670 | Acc : 0.5752
     Batch 100 | Loss : 0.6678 | Acc : 0.5873
     Batch 125 | Loss : 0.6617 | Acc : 0.5799
     Batch 150 | Loss : 0.6674 | Acc : 0.5697
     Batch 175 | Loss : 0.6752 | Acc : 0.5802
     Batch 200 | Loss : 0.6667 | Acc : 0.5737
     Batch 225 | Loss : 0.6607 | Acc : 0.5714
     Batch 250 | Loss : 0.6649 | Acc : 0.5761
     Batch 275 | Loss : 0.6772 | Acc : 0.5533
     Batch 300 | Loss : 0.6869 | Acc : 0.5307
Epoch 00008 | Train Loss : 0.6700 | Eval Loss : 0.6926 | Train acc : 0.5701 | Eval Acc : 0.5066 | Eval Log. Respected : 0.1455
     Batch 000 | Loss : 0.6853 | Acc : 0.5510
     Batch 025 | Loss : 0.6799 | Acc : 0.5554
     Batch 050 | Loss : 0.6823 | Acc : 0.5472
     Batch 075 | Loss : 0.6739 | Acc : 0.5646
     Batch 100 | Loss : 0.6766 | Acc : 0.5638
     Batch 125 | Loss : 0.6805 | Acc : 0.5573
     Batch 150 | Loss : 0.6789 | Acc : 0.5487
     Batch 175 | Loss : 0.6752 | Acc : 0.5657
     Batch 200 | Loss : 0.6805 | Acc : 0.5547
     Batch 225 | Loss : 0.6715 | Acc : 0.5653
     Batch 250 | Loss : 0.6843 | Acc : 0.5512
     Batch 275 | Loss : 0.6763 | Acc : 0.5611
     Batch 300 | Loss : 0.6750 | Acc : 0.5616
Epoch 00009 | Train Loss : 0.6807 | Eval Loss : 0.7332 | Train acc : 0.5517 | Eval Acc : 0.4593 | Eval Log. Respected : 0.3564
     Batch 000 | Loss : 0.6616 | Acc : 0.5857
     Batch 025 | Loss : 0.6734 | Acc : 0.5726
     Batch 050 | Loss : 0.6895 | Acc : 0.5404
     Batch 075 | Loss : 0.6805 | Acc : 0.5485
     Batch 100 | Loss : 0.6735 | Acc : 0.5649
     Batch 125 | Loss : 0.6762 | Acc : 0.5635
     Batch 150 | Loss : 0.6716 | Acc : 0.5621
     Batch 175 | Loss : 0.7022 | Acc : 0.5265
     Batch 200 | Loss : 0.6667 | Acc : 0.5757
     Batch 225 | Loss : 0.6730 | Acc : 0.5626
     Batch 250 | Loss : 0.6779 | Acc : 0.5555
     Batch 275 | Loss : 0.6605 | Acc : 0.5849
     Batch 300 | Loss : 0.6798 | Acc : 0.5504
Epoch 00010 | Train Loss : 0.6736 | Eval Loss : 0.6718 | Train acc : 0.5653 | Eval Acc : 0.5514 | Eval Log. Respected : 0.4124
     Batch 000 | Loss : 0.6643 | Acc : 0.5801
     Batch 025 | Loss : 0.6731 | Acc : 0.5620
     Batch 050 | Loss : 0.6639 | Acc : 0.5797
     Batch 075 | Loss : 0.6595 | Acc : 0.5710
     Batch 100 | Loss : 0.6911 | Acc : 0.5532
     Batch 125 | Loss : 0.6955 | Acc : 0.5321
     Batch 150 | Loss : 0.6535 | Acc : 0.5811
     Batch 175 | Loss : 0.6746 | Acc : 0.5622
     Batch 200 | Loss : 0.6772 | Acc : 0.5634
     Batch 225 | Loss : 0.6719 | Acc : 0.5669
     Batch 250 | Loss : 0.6901 | Acc : 0.5467
     Batch 275 | Loss : 0.6600 | Acc : 0.5809
     Batch 300 | Loss : 0.6627 | Acc : 0.5803
Epoch 00011 | Train Loss : 0.6700 | Eval Loss : 0.7508 | Train acc : 0.5679 | Eval Acc : 0.4867 | Eval Log. Respected : 0.0002
     Batch 000 | Loss : 0.6885 | Acc : 0.5381
     Batch 025 | Loss : 0.6740 | Acc : 0.5475
     Batch 050 | Loss : 0.6519 | Acc : 0.5835
     Batch 075 | Loss : 0.6818 | Acc : 0.5659
     Batch 100 | Loss : 0.6581 | Acc : 0.5815
     Batch 125 | Loss : 0.6798 | Acc : 0.5406
     Batch 150 | Loss : 0.6498 | Acc : 0.6017
     Batch 175 | Loss : 0.6458 | Acc : 0.6101
     Batch 200 | Loss : 0.6559 | Acc : 0.5892
     Batch 225 | Loss : 0.6404 | Acc : 0.5964
     Batch 250 | Loss : 0.6631 | Acc : 0.5740
     Batch 275 | Loss : 0.6589 | Acc : 0.5743
     Batch 300 | Loss : 0.6494 | Acc : 0.5885
Epoch 00012 | Train Loss : 0.6662 | Eval Loss : 0.7412 | Train acc : 0.5745 | Eval Acc : 0.4986 | Eval Log. Respected : 0.6023
     Batch 000 | Loss : 0.6546 | Acc : 0.5811
     Batch 025 | Loss : 0.6726 | Acc : 0.5641
     Batch 050 | Loss : 0.6609 | Acc : 0.5827
     Batch 075 | Loss : 0.6778 | Acc : 0.5828
     Batch 100 | Loss : 0.6554 | Acc : 0.5849
     Batch 125 | Loss : 0.6716 | Acc : 0.5693
     Batch 150 | Loss : 0.6484 | Acc : 0.5938
     Batch 175 | Loss : 0.6539 | Acc : 0.5816
     Batch 200 | Loss : 0.6439 | Acc : 0.6059
     Batch 225 | Loss : 0.6830 | Acc : 0.5619
     Batch 250 | Loss : 0.6809 | Acc : 0.5622
     Batch 275 | Loss : 0.6571 | Acc : 0.5840
     Batch 300 | Loss : 0.6495 | Acc : 0.5861
Epoch 00013 | Train Loss : 0.6613 | Eval Loss : 0.7414 | Train acc : 0.5828 | Eval Acc : 0.5216 | Eval Log. Respected : 0.6658
     Batch 000 | Loss : 0.6488 | Acc : 0.5953
     Batch 025 | Loss : 0.6394 | Acc : 0.6114
     Batch 050 | Loss : 0.6798 | Acc : 0.5739
     Batch 075 | Loss : 0.6868 | Acc : 0.5574
     Batch 100 | Loss : 0.6525 | Acc : 0.5938
     Batch 125 | Loss : 0.6759 | Acc : 0.5647
     Batch 150 | Loss : 0.6571 | Acc : 0.5799
     Batch 175 | Loss : 0.6367 | Acc : 0.6088
     Batch 200 | Loss : 0.6929 | Acc : 0.5141
     Batch 225 | Loss : 0.6927 | Acc : 0.5141
     Batch 250 | Loss : 0.6926 | Acc : 0.5161
     Batch 275 | Loss : 0.6928 | Acc : 0.5133
     Batch 300 | Loss : 0.6928 | Acc : 0.5135
Epoch 00014 | Train Loss : 0.6746 | Eval Loss : 0.6942 | Train acc : 0.5541 | Eval Acc : 0.4866 | Eval Log. Respected : 0.0000
     Batch 000 | Loss : 0.6929 | Acc : 0.5117
     Batch 025 | Loss : 0.6928 | Acc : 0.5124
     Batch 050 | Loss : 0.6928 | Acc : 0.5141
     Batch 075 | Loss : 0.6929 | Acc : 0.5118
     Batch 100 | Loss : 0.6926 | Acc : 0.5166
     Batch 125 | Loss : 0.6927 | Acc : 0.5151
     Batch 150 | Loss : 0.6930 | Acc : 0.5111
     Batch 175 | Loss : 0.6929 | Acc : 0.5114
     Batch 200 | Loss : 0.6929 | Acc : 0.5108
     Batch 225 | Loss : 0.6928 | Acc : 0.5139
     Batch 250 | Loss : 0.6928 | Acc : 0.5136
     Batch 275 | Loss : 0.6927 | Acc : 0.5143
     Batch 300 | Loss : 0.6929 | Acc : 0.5119
Epoch 00015 | Train Loss : 0.6928 | Eval Loss : 0.6943 | Train acc : 0.5133 | Eval Acc : 0.4866 | Eval Log. Respected : 0.0000
     Batch 000 | Loss : 0.6929 | Acc : 0.5108
     Batch 025 | Loss : 0.6927 | Acc : 0.5141
     Batch 050 | Loss : 0.6928 | Acc : 0.5121
     Batch 075 | Loss : 0.6929 | Acc : 0.5111
     Batch 100 | Loss : 0.6928 | Acc : 0.5127
     Batch 125 | Loss : 0.6927 | Acc : 0.5159
     Batch 150 | Loss : 0.6927 | Acc : 0.5147
     Batch 175 | Loss : 0.6928 | Acc : 0.5134
     Batch 200 | Loss : 0.6927 | Acc : 0.5142
     Batch 225 | Loss : 0.6926 | Acc : 0.5173
     Batch 250 | Loss : 0.6929 | Acc : 0.5109
     Batch 275 | Loss : 0.6929 | Acc : 0.5117
     Batch 300 | Loss : 0.6930 | Acc : 0.5103
Epoch 00016 | Train Loss : 0.6928 | Eval Loss : 0.6944 | Train acc : 0.5134 | Eval Acc : 0.4866 | Eval Log. Respected : 0.0000
     Batch 000 | Loss : 0.6925 | Acc : 0.5175
     Batch 025 | Loss : 0.6929 | Acc : 0.5106
     Batch 050 | Loss : 0.6928 | Acc : 0.5127
     Batch 075 | Loss : 0.6927 | Acc : 0.5152
     Batch 100 | Loss : 0.6925 | Acc : 0.5183
     Batch 125 | Loss : 0.6928 | Acc : 0.5128
     Batch 150 | Loss : 0.6929 | Acc : 0.5108
     Batch 175 | Loss : 0.6929 | Acc : 0.5121
     Batch 200 | Loss : 0.6928 | Acc : 0.5121
     Batch 225 | Loss : 0.6928 | Acc : 0.5134
     Batch 250 | Loss : 0.6928 | Acc : 0.5117
     Batch 275 | Loss : 0.6926 | Acc : 0.5152
     Batch 300 | Loss : 0.6929 | Acc : 0.5104
Epoch 00017 | Train Loss : 0.6928 | Eval Loss : 0.6943 | Train acc : 0.5134 | Eval Acc : 0.4866 | Eval Log. Respected : 0.0000
     Batch 000 | Loss : 0.6929 | Acc : 0.5105
     Batch 025 | Loss : 0.6927 | Acc : 0.5141
     Batch 050 | Loss : 0.6926 | Acc : 0.5163
     Batch 075 | Loss : 0.6928 | Acc : 0.5122
     Batch 100 | Loss : 0.6928 | Acc : 0.5126
     Batch 125 | Loss : 0.6928 | Acc : 0.5129
     Batch 150 | Loss : 0.6927 | Acc : 0.5146
     Batch 175 | Loss : 0.6926 | Acc : 0.5152
     Batch 200 | Loss : 0.6927 | Acc : 0.5153
     Batch 225 | Loss : 0.6927 | Acc : 0.5150
     Batch 250 | Loss : 0.6929 | Acc : 0.5106
     Batch 275 | Loss : 0.6928 | Acc : 0.5127
     Batch 300 | Loss : 0.6930 | Acc : 0.5086
Epoch 00018 | Train Loss : 0.6928 | Eval Loss : 0.6941 | Train acc : 0.5134 | Eval Acc : 0.4866 | Eval Log. Respected : 0.0000
     Batch 000 | Loss : 0.6928 | Acc : 0.5141
     Batch 025 | Loss : 0.6928 | Acc : 0.5125
     Batch 050 | Loss : 0.6929 | Acc : 0.5100
     Batch 075 | Loss : 0.6928 | Acc : 0.5120
     Batch 100 | Loss : 0.6928 | Acc : 0.5115
     Batch 125 | Loss : 0.6928 | Acc : 0.5123
     Batch 150 | Loss : 0.6925 | Acc : 0.5108
     Batch 175 | Loss : 0.6927 | Acc : 0.5150
     Batch 200 | Loss : 0.6929 | Acc : 0.5117
     Batch 225 | Loss : 0.6926 | Acc : 0.5168
     Batch 250 | Loss : 0.6927 | Acc : 0.5153
     Batch 275 | Loss : 0.6929 | Acc : 0.5108
     Batch 300 | Loss : 0.6929 | Acc : 0.5113
Epoch 00019 | Train Loss : 0.6928 | Eval Loss : 0.6944 | Train acc : 0.5134 | Eval Acc : 0.4866 | Eval Log. Respected : 0.0000
     Batch 000 | Loss : 0.6928 | Acc : 0.5134
     Batch 025 | Loss : 0.6925 | Acc : 0.5190
     Batch 050 | Loss : 0.6929 | Acc : 0.5102
     Batch 075 | Loss : 0.6927 | Acc : 0.5142
     Batch 100 | Loss : 0.6921 | Acc : 0.5279
     Batch 125 | Loss : 0.6925 | Acc : 0.5183
     Batch 150 | Loss : 0.6928 | Acc : 0.5121
     Batch 175 | Loss : 0.6929 | Acc : 0.5107
     Batch 200 | Loss : 0.6928 | Acc : 0.5135
     Batch 225 | Loss : 0.6928 | Acc : 0.5123
     Batch 250 | Loss : 0.6928 | Acc : 0.5133
     Batch 275 | Loss : 0.6927 | Acc : 0.5147
     Batch 300 | Loss : 0.6927 | Acc : 0.5157
Epoch 00020 | Train Loss : 0.6928 | Eval Loss : 0.6944 | Train acc : 0.5134 | Eval Acc : 0.4866 | Eval Log. Respected : 0.0000
Early Stopping
Testing...
Test Loss 0.7159 | Test Acc 0.4868 | Test Log. Res. 0.0000
