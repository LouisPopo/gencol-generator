Done loading data from cached files.
Training ...
     Batch 000 | Loss : 0.7134 | Acc : 0.5108
     Batch 025 | Loss : 0.6884 | Acc : 0.5377
     Batch 050 | Loss : 0.6883 | Acc : 0.5389
     Batch 075 | Loss : 0.6820 | Acc : 0.5627
     Batch 100 | Loss : 0.6830 | Acc : 0.5505
     Batch 125 | Loss : 0.6433 | Acc : 0.6311
     Batch 150 | Loss : 0.6233 | Acc : 0.6555
     Batch 175 | Loss : 0.6408 | Acc : 0.6182
     Batch 200 | Loss : 0.6328 | Acc : 0.6496
     Batch 225 | Loss : 0.6089 | Acc : 0.6430
     Batch 250 | Loss : 0.5812 | Acc : 0.6766
     Batch 275 | Loss : 0.5904 | Acc : 0.6753
     Batch 300 | Loss : 0.5881 | Acc : 0.6645
Epoch 00000 | Train Loss : 0.6391 | Eval Loss : 0.5721 | Train acc : 0.6136 | Eval Acc : 0.6817 | Eval Log. Respected : 0.5526
     Batch 000 | Loss : 0.6180 | Acc : 0.6419
     Batch 025 | Loss : 0.5447 | Acc : 0.7090
     Batch 050 | Loss : 0.6064 | Acc : 0.6415
     Batch 075 | Loss : 0.6163 | Acc : 0.6526
     Batch 100 | Loss : 0.5228 | Acc : 0.7322
     Batch 125 | Loss : 0.5396 | Acc : 0.7198
     Batch 150 | Loss : 0.5742 | Acc : 0.6899
     Batch 175 | Loss : 0.5934 | Acc : 0.6658
     Batch 200 | Loss : 0.5264 | Acc : 0.7312
     Batch 225 | Loss : 0.5250 | Acc : 0.7295
     Batch 250 | Loss : 0.5584 | Acc : 0.6998
     Batch 275 | Loss : 0.5375 | Acc : 0.7058
     Batch 300 | Loss : 0.5414 | Acc : 0.7038
Epoch 00001 | Train Loss : 0.5549 | Eval Loss : 0.5183 | Train acc : 0.7024 | Eval Acc : 0.7316 | Eval Log. Respected : 0.6128
     Batch 000 | Loss : 0.4924 | Acc : 0.7494
     Batch 025 | Loss : 0.5204 | Acc : 0.7386
     Batch 050 | Loss : 0.5410 | Acc : 0.7226
     Batch 075 | Loss : 0.5072 | Acc : 0.7456
     Batch 100 | Loss : 0.6185 | Acc : 0.6549
     Batch 125 | Loss : 0.5526 | Acc : 0.7073
     Batch 150 | Loss : 0.5057 | Acc : 0.7388
     Batch 175 | Loss : 0.4714 | Acc : 0.7773
     Batch 200 | Loss : 0.5486 | Acc : 0.7072
     Batch 225 | Loss : 0.4884 | Acc : 0.7587
     Batch 250 | Loss : 0.4985 | Acc : 0.7432
     Batch 275 | Loss : 0.4960 | Acc : 0.7506
     Batch 300 | Loss : 0.5122 | Acc : 0.7393
Epoch 00002 | Train Loss : 0.5337 | Eval Loss : 0.5585 | Train acc : 0.7223 | Eval Acc : 0.7023 | Eval Log. Respected : 0.4759
     Batch 000 | Loss : 0.6180 | Acc : 0.6645
     Batch 025 | Loss : 0.4660 | Acc : 0.7733
     Batch 050 | Loss : 0.5711 | Acc : 0.7027
     Batch 075 | Loss : 0.5079 | Acc : 0.7373
     Batch 100 | Loss : 0.5129 | Acc : 0.7362
     Batch 125 | Loss : 0.4938 | Acc : 0.7519
     Batch 150 | Loss : 0.4871 | Acc : 0.7705
     Batch 175 | Loss : 0.5383 | Acc : 0.7260
     Batch 200 | Loss : 0.4601 | Acc : 0.7878
     Batch 225 | Loss : 0.5014 | Acc : 0.7426
     Batch 250 | Loss : 0.4090 | Acc : 0.8196
     Batch 275 | Loss : 0.5191 | Acc : 0.7239
     Batch 300 | Loss : 0.5093 | Acc : 0.7358
Epoch 00003 | Train Loss : 0.5021 | Eval Loss : 0.4922 | Train acc : 0.7475 | Eval Acc : 0.7494 | Eval Log. Respected : 0.4668
     Batch 000 | Loss : 0.6204 | Acc : 0.6534
     Batch 025 | Loss : 0.5289 | Acc : 0.7390
     Batch 050 | Loss : 0.4276 | Acc : 0.7967
     Batch 075 | Loss : 0.4831 | Acc : 0.7682
     Batch 100 | Loss : 0.6616 | Acc : 0.6273
     Batch 125 | Loss : 0.4418 | Acc : 0.7885
     Batch 150 | Loss : 0.4282 | Acc : 0.8056
     Batch 175 | Loss : 0.4245 | Acc : 0.8077
     Batch 200 | Loss : 0.4367 | Acc : 0.8056
     Batch 225 | Loss : 0.4731 | Acc : 0.7705
     Batch 250 | Loss : 0.5611 | Acc : 0.7108
     Batch 275 | Loss : 0.5070 | Acc : 0.7454
     Batch 300 | Loss : 0.4731 | Acc : 0.7598
Epoch 00004 | Train Loss : 0.4945 | Eval Loss : 0.5325 | Train acc : 0.7521 | Eval Acc : 0.7270 | Eval Log. Respected : 0.5064
     Batch 000 | Loss : 0.4936 | Acc : 0.7615
     Batch 025 | Loss : 0.4301 | Acc : 0.7938
     Batch 050 | Loss : 0.4460 | Acc : 0.7862
     Batch 075 | Loss : 0.4173 | Acc : 0.8116
     Batch 100 | Loss : 0.5014 | Acc : 0.7483
     Batch 125 | Loss : 0.4646 | Acc : 0.7665
     Batch 150 | Loss : 0.5274 | Acc : 0.7271
     Batch 175 | Loss : 0.4847 | Acc : 0.7579
     Batch 200 | Loss : 0.5610 | Acc : 0.7177
     Batch 225 | Loss : 0.4665 | Acc : 0.7666
     Batch 250 | Loss : 0.5084 | Acc : 0.7422
     Batch 275 | Loss : 0.4996 | Acc : 0.7385
     Batch 300 | Loss : 0.4880 | Acc : 0.7432
Epoch 00005 | Train Loss : 0.4860 | Eval Loss : 0.4739 | Train acc : 0.7565 | Eval Acc : 0.7661 | Eval Log. Respected : 0.5316
     Batch 000 | Loss : 0.4021 | Acc : 0.8136
     Batch 025 | Loss : 0.5218 | Acc : 0.7203
     Batch 050 | Loss : 0.4880 | Acc : 0.7558
     Batch 075 | Loss : 0.5356 | Acc : 0.7072
     Batch 100 | Loss : 0.4874 | Acc : 0.7587
     Batch 125 | Loss : 0.4817 | Acc : 0.7783
     Batch 150 | Loss : 0.5413 | Acc : 0.7052
     Batch 175 | Loss : 0.4163 | Acc : 0.8056
     Batch 200 | Loss : 0.4839 | Acc : 0.7545
     Batch 225 | Loss : 0.4316 | Acc : 0.7967
     Batch 250 | Loss : 0.5795 | Acc : 0.6968
     Batch 275 | Loss : 0.4217 | Acc : 0.7983
     Batch 300 | Loss : 0.4253 | Acc : 0.7884
Epoch 00006 | Train Loss : 0.4828 | Eval Loss : 0.4516 | Train acc : 0.7583 | Eval Acc : 0.7743 | Eval Log. Respected : 0.5691
     Batch 000 | Loss : 0.4531 | Acc : 0.7792
     Batch 025 | Loss : 0.5534 | Acc : 0.7033
     Batch 050 | Loss : 0.4913 | Acc : 0.7692
     Batch 075 | Loss : 0.5043 | Acc : 0.7405
     Batch 100 | Loss : 0.4633 | Acc : 0.7759
     Batch 125 | Loss : 0.4405 | Acc : 0.7838
     Batch 150 | Loss : 0.4998 | Acc : 0.7539
     Batch 175 | Loss : 0.4987 | Acc : 0.7448
     Batch 200 | Loss : 0.3972 | Acc : 0.8165
     Batch 225 | Loss : 0.4347 | Acc : 0.7904
     Batch 250 | Loss : 0.4559 | Acc : 0.7814
     Batch 275 | Loss : 0.4273 | Acc : 0.8097
     Batch 300 | Loss : 0.5527 | Acc : 0.7393
Epoch 00007 | Train Loss : 0.4892 | Eval Loss : 0.5449 | Train acc : 0.7540 | Eval Acc : 0.7176 | Eval Log. Respected : 0.5468
     Batch 000 | Loss : 0.5541 | Acc : 0.7034
     Batch 025 | Loss : 0.3925 | Acc : 0.8259
     Batch 050 | Loss : 0.4688 | Acc : 0.7670
     Batch 075 | Loss : 0.5028 | Acc : 0.7444
     Batch 100 | Loss : 0.4091 | Acc : 0.8092
     Batch 125 | Loss : 0.4838 | Acc : 0.7652
     Batch 150 | Loss : 0.4357 | Acc : 0.7983
     Batch 175 | Loss : 0.5655 | Acc : 0.7226
     Batch 200 | Loss : 0.4551 | Acc : 0.7842
     Batch 225 | Loss : 0.4709 | Acc : 0.7593
     Batch 250 | Loss : 0.4686 | Acc : 0.7624
     Batch 275 | Loss : 0.4132 | Acc : 0.8063
     Batch 300 | Loss : 0.4555 | Acc : 0.7811
Epoch 00008 | Train Loss : 0.4838 | Eval Loss : 0.5489 | Train acc : 0.7578 | Eval Acc : 0.7037 | Eval Log. Respected : 0.7111
     Batch 000 | Loss : 0.5665 | Acc : 0.6733
     Batch 025 | Loss : 0.4557 | Acc : 0.7784
     Batch 050 | Loss : 0.5258 | Acc : 0.7196
     Batch 075 | Loss : 0.3966 | Acc : 0.8174
     Batch 100 | Loss : 0.5295 | Acc : 0.7228
     Batch 125 | Loss : 0.4787 | Acc : 0.7812
     Batch 150 | Loss : 0.4694 | Acc : 0.7631
     Batch 175 | Loss : 0.5270 | Acc : 0.7237
     Batch 200 | Loss : 0.4901 | Acc : 0.7500
     Batch 225 | Loss : 0.4683 | Acc : 0.7631
     Batch 250 | Loss : 0.4530 | Acc : 0.7778
     Batch 275 | Loss : 0.4179 | Acc : 0.8121
     Batch 300 | Loss : 0.4533 | Acc : 0.7651
Epoch 00009 | Train Loss : 0.4789 | Eval Loss : 0.5292 | Train acc : 0.7606 | Eval Acc : 0.7285 | Eval Log. Respected : 0.6312
     Batch 000 | Loss : 0.6015 | Acc : 0.6954
     Batch 025 | Loss : 0.4462 | Acc : 0.7729
     Batch 050 | Loss : 0.4428 | Acc : 0.7841
     Batch 075 | Loss : 0.4946 | Acc : 0.7443
     Batch 100 | Loss : 0.5423 | Acc : 0.7152
     Batch 125 | Loss : 0.4147 | Acc : 0.8058
     Batch 150 | Loss : 0.4378 | Acc : 0.7963
     Batch 175 | Loss : 0.4314 | Acc : 0.7921
     Batch 200 | Loss : 0.4488 | Acc : 0.7819
     Batch 225 | Loss : 0.5027 | Acc : 0.7444
     Batch 250 | Loss : 0.5200 | Acc : 0.7308
     Batch 275 | Loss : 0.4494 | Acc : 0.7779
     Batch 300 | Loss : 0.4641 | Acc : 0.7683
Epoch 00010 | Train Loss : 0.4694 | Eval Loss : 0.4884 | Train acc : 0.7667 | Eval Acc : 0.7486 | Eval Log. Respected : 0.6037
     Batch 000 | Loss : 0.4679 | Acc : 0.7613
     Batch 025 | Loss : 0.4291 | Acc : 0.8024
     Batch 050 | Loss : 0.4618 | Acc : 0.7721
     Batch 075 | Loss : 0.4672 | Acc : 0.7667
     Batch 100 | Loss : 0.5286 | Acc : 0.7190
     Batch 125 | Loss : 0.4610 | Acc : 0.7659
     Batch 150 | Loss : 0.4132 | Acc : 0.7990
     Batch 175 | Loss : 0.4096 | Acc : 0.8100
     Batch 200 | Loss : 0.4500 | Acc : 0.7752
     Batch 225 | Loss : 0.4687 | Acc : 0.7685
     Batch 250 | Loss : 0.4318 | Acc : 0.7962
     Batch 275 | Loss : 0.4460 | Acc : 0.7927
     Batch 300 | Loss : 0.4195 | Acc : 0.8097
Epoch 00011 | Train Loss : 0.4662 | Eval Loss : 0.4570 | Train acc : 0.7686 | Eval Acc : 0.7729 | Eval Log. Respected : 0.4630
     Batch 000 | Loss : 0.4455 | Acc : 0.7802
     Batch 025 | Loss : 0.5240 | Acc : 0.7474
     Batch 050 | Loss : 0.3927 | Acc : 0.8236
     Batch 075 | Loss : 0.3849 | Acc : 0.8253
     Batch 100 | Loss : 0.4761 | Acc : 0.7643
     Batch 125 | Loss : 0.4377 | Acc : 0.7920
     Batch 150 | Loss : 0.4363 | Acc : 0.7852
     Batch 175 | Loss : 0.4595 | Acc : 0.7715
     Batch 200 | Loss : 0.5274 | Acc : 0.7290
     Batch 225 | Loss : 0.4092 | Acc : 0.8133
     Batch 250 | Loss : 0.5341 | Acc : 0.7183
     Batch 275 | Loss : 0.6070 | Acc : 0.6952
     Batch 300 | Loss : 0.5360 | Acc : 0.7113
Epoch 00012 | Train Loss : 0.4721 | Eval Loss : 0.4802 | Train acc : 0.7645 | Eval Acc : 0.7601 | Eval Log. Respected : 0.6084
     Batch 000 | Loss : 0.4581 | Acc : 0.7700
     Batch 025 | Loss : 0.4292 | Acc : 0.7919
     Batch 050 | Loss : 0.4158 | Acc : 0.8036
     Batch 075 | Loss : 0.4531 | Acc : 0.7738
     Batch 100 | Loss : 0.5289 | Acc : 0.7218
     Batch 125 | Loss : 0.5074 | Acc : 0.7524
     Batch 150 | Loss : 0.4042 | Acc : 0.8063
     Batch 175 | Loss : 0.4404 | Acc : 0.7933
     Batch 200 | Loss : 0.5848 | Acc : 0.6976
     Batch 225 | Loss : 0.4601 | Acc : 0.7620
     Batch 250 | Loss : 0.5301 | Acc : 0.7315
     Batch 275 | Loss : 0.5511 | Acc : 0.7135
     Batch 300 | Loss : 0.4794 | Acc : 0.7598
Epoch 00013 | Train Loss : 0.4678 | Eval Loss : 0.4470 | Train acc : 0.7668 | Eval Acc : 0.7789 | Eval Log. Respected : 0.6205
     Batch 000 | Loss : 0.4098 | Acc : 0.8092
     Batch 025 | Loss : 0.4169 | Acc : 0.8035
     Batch 050 | Loss : 0.4697 | Acc : 0.7543
     Batch 075 | Loss : 0.4369 | Acc : 0.7865
     Batch 100 | Loss : 0.5963 | Acc : 0.6854
     Batch 125 | Loss : 0.4375 | Acc : 0.7896
     Batch 150 | Loss : 0.3888 | Acc : 0.8200
     Batch 175 | Loss : 0.5733 | Acc : 0.6990
     Batch 200 | Loss : 0.4181 | Acc : 0.8089
     Batch 225 | Loss : 0.4554 | Acc : 0.7741
     Batch 250 | Loss : 0.5058 | Acc : 0.7308
     Batch 275 | Loss : 0.4643 | Acc : 0.7634
     Batch 300 | Loss : 0.5167 | Acc : 0.7378
Epoch 00014 | Train Loss : 0.4580 | Eval Loss : 0.4454 | Train acc : 0.7736 | Eval Acc : 0.7796 | Eval Log. Respected : 0.6213
     Batch 000 | Loss : 0.4651 | Acc : 0.7666
     Batch 025 | Loss : 0.4765 | Acc : 0.7713
     Batch 050 | Loss : 0.4626 | Acc : 0.7655
     Batch 075 | Loss : 0.3758 | Acc : 0.8290
     Batch 100 | Loss : 0.3974 | Acc : 0.8117
     Batch 125 | Loss : 0.4812 | Acc : 0.7611
     Batch 150 | Loss : 0.4735 | Acc : 0.7663
     Batch 175 | Loss : 0.4556 | Acc : 0.7690
     Batch 200 | Loss : 0.3886 | Acc : 0.8139
     Batch 225 | Loss : 0.4152 | Acc : 0.8067
     Batch 250 | Loss : 0.4433 | Acc : 0.7812
     Batch 275 | Loss : 0.4392 | Acc : 0.7943
     Batch 300 | Loss : 0.4247 | Acc : 0.7883
Epoch 00015 | Train Loss : 0.4575 | Eval Loss : 0.4554 | Train acc : 0.7739 | Eval Acc : 0.7751 | Eval Log. Respected : 0.6184
     Batch 000 | Loss : 0.5002 | Acc : 0.7391
     Batch 025 | Loss : 0.4566 | Acc : 0.7657
     Batch 050 | Loss : 0.4933 | Acc : 0.7451
     Batch 075 | Loss : 0.4456 | Acc : 0.7936
     Batch 100 | Loss : 0.5115 | Acc : 0.7358
     Batch 125 | Loss : 0.4127 | Acc : 0.8014
     Batch 150 | Loss : 0.4978 | Acc : 0.7442
     Batch 175 | Loss : 0.4793 | Acc : 0.7525
     Batch 200 | Loss : 0.4020 | Acc : 0.8107
     Batch 225 | Loss : 0.4324 | Acc : 0.7876
     Batch 250 | Loss : 0.4338 | Acc : 0.7943
     Batch 275 | Loss : 0.4756 | Acc : 0.7653
     Batch 300 | Loss : 0.5212 | Acc : 0.7352
Epoch 00016 | Train Loss : 0.4597 | Eval Loss : 0.4427 | Train acc : 0.7732 | Eval Acc : 0.7808 | Eval Log. Respected : 0.4695
     Batch 000 | Loss : 0.4142 | Acc : 0.8059
     Batch 025 | Loss : 0.3784 | Acc : 0.8275
     Batch 050 | Loss : 0.4581 | Acc : 0.7689
     Batch 075 | Loss : 0.5159 | Acc : 0.7429
     Batch 100 | Loss : 0.4076 | Acc : 0.8062
     Batch 125 | Loss : 0.4755 | Acc : 0.7596
     Batch 150 | Loss : 0.4827 | Acc : 0.7500
     Batch 175 | Loss : 0.4698 | Acc : 0.7734
     Batch 200 | Loss : 0.4918 | Acc : 0.7478
     Batch 225 | Loss : 0.4478 | Acc : 0.7938
     Batch 250 | Loss : 0.3957 | Acc : 0.8153
     Batch 275 | Loss : 0.4024 | Acc : 0.8193
     Batch 300 | Loss : 0.4363 | Acc : 0.7951
Epoch 00017 | Train Loss : 0.4574 | Eval Loss : 0.4317 | Train acc : 0.7745 | Eval Acc : 0.7877 | Eval Log. Respected : 0.5257
     Batch 000 | Loss : 0.3810 | Acc : 0.8278
     Batch 025 | Loss : 0.4642 | Acc : 0.7683
     Batch 050 | Loss : 0.4591 | Acc : 0.7660
     Batch 075 | Loss : 0.4788 | Acc : 0.7712
     Batch 100 | Loss : 0.3971 | Acc : 0.8164
     Batch 125 | Loss : 0.4320 | Acc : 0.7926
     Batch 150 | Loss : 0.4847 | Acc : 0.7585
     Batch 175 | Loss : 0.4914 | Acc : 0.7513
     Batch 200 | Loss : 0.4093 | Acc : 0.7949
     Batch 225 | Loss : 0.5621 | Acc : 0.7144
     Batch 250 | Loss : 0.4268 | Acc : 0.8022
     Batch 275 | Loss : 0.3839 | Acc : 0.8257
     Batch 300 | Loss : 0.5221 | Acc : 0.7197
Epoch 00018 | Train Loss : 0.4562 | Eval Loss : 0.4290 | Train acc : 0.7757 | Eval Acc : 0.7874 | Eval Log. Respected : 0.6300
     Batch 000 | Loss : 0.4028 | Acc : 0.8053
     Batch 025 | Loss : 0.4319 | Acc : 0.7921
     Batch 050 | Loss : 0.4389 | Acc : 0.7831
     Batch 075 | Loss : 0.4606 | Acc : 0.7681
     Batch 100 | Loss : 0.4637 | Acc : 0.7695
     Batch 125 | Loss : 0.4870 | Acc : 0.7482
     Batch 150 | Loss : 0.4868 | Acc : 0.7519
     Batch 175 | Loss : 0.4272 | Acc : 0.7944
     Batch 200 | Loss : 0.4785 | Acc : 0.7665
     Batch 225 | Loss : 0.4343 | Acc : 0.7954
     Batch 250 | Loss : 0.4333 | Acc : 0.7939
     Batch 275 | Loss : 0.4983 | Acc : 0.7517
     Batch 300 | Loss : 0.4525 | Acc : 0.7716
Epoch 00019 | Train Loss : 0.4520 | Eval Loss : 0.4437 | Train acc : 0.7785 | Eval Acc : 0.7778 | Eval Log. Respected : 0.5908
     Batch 000 | Loss : 0.4408 | Acc : 0.7850
     Batch 025 | Loss : 0.4762 | Acc : 0.7620
     Batch 050 | Loss : 0.4575 | Acc : 0.7636
     Batch 075 | Loss : 0.4260 | Acc : 0.8055
     Batch 100 | Loss : 0.4691 | Acc : 0.7678
     Batch 125 | Loss : 0.4670 | Acc : 0.7664
     Batch 150 | Loss : 0.4623 | Acc : 0.7659
     Batch 175 | Loss : 0.4266 | Acc : 0.8028
     Batch 200 | Loss : 0.3968 | Acc : 0.8185
     Batch 225 | Loss : 0.3973 | Acc : 0.8112
     Batch 250 | Loss : 0.4691 | Acc : 0.7695
     Batch 275 | Loss : 0.4779 | Acc : 0.7585
     Batch 300 | Loss : 0.4225 | Acc : 0.8046
Epoch 00020 | Train Loss : 0.4430 | Eval Loss : 0.4580 | Train acc : 0.7835 | Eval Acc : 0.7711 | Eval Log. Respected : 0.5680
     Batch 000 | Loss : 0.4408 | Acc : 0.7752
     Batch 025 | Loss : 0.4078 | Acc : 0.8150
     Batch 050 | Loss : 0.4815 | Acc : 0.7551
     Batch 075 | Loss : 0.3897 | Acc : 0.8178
     Batch 100 | Loss : 0.4239 | Acc : 0.7873
     Batch 125 | Loss : 0.4457 | Acc : 0.7799
     Batch 150 | Loss : 0.3818 | Acc : 0.8286
     Batch 175 | Loss : 0.4373 | Acc : 0.7936
     Batch 200 | Loss : 0.4219 | Acc : 0.8034
     Batch 225 | Loss : 0.4385 | Acc : 0.7901
     Batch 250 | Loss : 0.4723 | Acc : 0.7549
     Batch 275 | Loss : 0.4946 | Acc : 0.7530
     Batch 300 | Loss : 0.5011 | Acc : 0.7499
Epoch 00021 | Train Loss : 0.4472 | Eval Loss : 0.4352 | Train acc : 0.7816 | Eval Acc : 0.7847 | Eval Log. Respected : 0.4558
     Batch 000 | Loss : 0.4099 | Acc : 0.8001
     Batch 025 | Loss : 0.4351 | Acc : 0.7765
     Batch 050 | Loss : 0.4236 | Acc : 0.7916
     Batch 075 | Loss : 0.4229 | Acc : 0.7890
     Batch 100 | Loss : 0.4592 | Acc : 0.7688
     Batch 125 | Loss : 0.4225 | Acc : 0.7959
     Batch 150 | Loss : 0.4694 | Acc : 0.7667
     Batch 175 | Loss : 0.5480 | Acc : 0.7149
     Batch 200 | Loss : 0.4687 | Acc : 0.7685
     Batch 225 | Loss : 0.4269 | Acc : 0.8039
     Batch 250 | Loss : 0.4237 | Acc : 0.7960
     Batch 275 | Loss : 0.4578 | Acc : 0.7702
     Batch 300 | Loss : 0.4184 | Acc : 0.8053
Epoch 00022 | Train Loss : 0.4588 | Eval Loss : 0.4393 | Train acc : 0.7736 | Eval Acc : 0.7842 | Eval Log. Respected : 0.4800
     Batch 000 | Loss : 0.4776 | Acc : 0.7597
     Batch 025 | Loss : 0.4817 | Acc : 0.7665
     Batch 050 | Loss : 0.4858 | Acc : 0.7548
     Batch 075 | Loss : 0.3897 | Acc : 0.8235
     Batch 100 | Loss : 0.5319 | Acc : 0.7299
     Batch 125 | Loss : 0.3951 | Acc : 0.8307
     Batch 150 | Loss : 0.4809 | Acc : 0.7577
     Batch 175 | Loss : 0.4097 | Acc : 0.8098
     Batch 200 | Loss : 0.4729 | Acc : 0.7649
     Batch 225 | Loss : 0.3859 | Acc : 0.8228
     Batch 250 | Loss : 0.4589 | Acc : 0.7716
     Batch 275 | Loss : 0.4016 | Acc : 0.8238
     Batch 300 | Loss : 0.4050 | Acc : 0.8060
Epoch 00023 | Train Loss : 0.4511 | Eval Loss : 0.4820 | Train acc : 0.7786 | Eval Acc : 0.7583 | Eval Log. Respected : 0.7058
     Batch 000 | Loss : 0.4218 | Acc : 0.8103
     Batch 025 | Loss : 0.4492 | Acc : 0.7920
     Batch 050 | Loss : 0.4688 | Acc : 0.7750
     Batch 075 | Loss : 0.4779 | Acc : 0.7581
     Batch 100 | Loss : 0.5186 | Acc : 0.7260
     Batch 125 | Loss : 0.5097 | Acc : 0.7453
     Batch 150 | Loss : 0.4493 | Acc : 0.7784
     Batch 175 | Loss : 0.4219 | Acc : 0.7975
     Batch 200 | Loss : 0.4045 | Acc : 0.8038
     Batch 225 | Loss : 0.4234 | Acc : 0.7975
     Batch 250 | Loss : 0.4492 | Acc : 0.7766
     Batch 275 | Loss : 0.4041 | Acc : 0.8076
     Batch 300 | Loss : 0.4295 | Acc : 0.7959
Epoch 00024 | Train Loss : 0.4511 | Eval Loss : 0.4264 | Train acc : 0.7790 | Eval Acc : 0.7919 | Eval Log. Respected : 0.6618
     Batch 000 | Loss : 0.4590 | Acc : 0.7703
     Batch 025 | Loss : 0.4794 | Acc : 0.7560
     Batch 050 | Loss : 0.5333 | Acc : 0.7437
     Batch 075 | Loss : 0.4296 | Acc : 0.7869
     Batch 100 | Loss : 0.4128 | Acc : 0.8008
     Batch 125 | Loss : 0.4079 | Acc : 0.8073
     Batch 150 | Loss : 0.4368 | Acc : 0.7795
     Batch 175 | Loss : 0.4388 | Acc : 0.7899
     Batch 200 | Loss : 0.5001 | Acc : 0.7406
     Batch 225 | Loss : 0.4158 | Acc : 0.8109
     Batch 250 | Loss : 0.5228 | Acc : 0.7337
     Batch 275 | Loss : 0.3732 | Acc : 0.8342
     Batch 300 | Loss : 0.5034 | Acc : 0.7502
Epoch 00025 | Train Loss : 0.4449 | Eval Loss : 0.4437 | Train acc : 0.7826 | Eval Acc : 0.7781 | Eval Log. Respected : 0.6566
     Batch 000 | Loss : 0.3902 | Acc : 0.8135
     Batch 025 | Loss : 0.4230 | Acc : 0.7904
     Batch 050 | Loss : 0.5362 | Acc : 0.7291
     Batch 075 | Loss : 0.4559 | Acc : 0.7681
     Batch 100 | Loss : 0.4282 | Acc : 0.7924
     Batch 125 | Loss : 0.4551 | Acc : 0.7683
     Batch 150 | Loss : 0.3863 | Acc : 0.8162
     Batch 175 | Loss : 0.4743 | Acc : 0.7524
     Batch 200 | Loss : 0.4827 | Acc : 0.7388
     Batch 225 | Loss : 0.4400 | Acc : 0.7745
     Batch 250 | Loss : 0.4053 | Acc : 0.8017
     Batch 275 | Loss : 0.4309 | Acc : 0.8028
     Batch 300 | Loss : 0.3975 | Acc : 0.8178
Epoch 00026 | Train Loss : 0.4468 | Eval Loss : 0.4333 | Train acc : 0.7813 | Eval Acc : 0.7874 | Eval Log. Respected : 0.6875
     Batch 000 | Loss : 0.4680 | Acc : 0.7618
     Batch 025 | Loss : 0.4942 | Acc : 0.7492
     Batch 050 | Loss : 0.5945 | Acc : 0.6851
     Batch 075 | Loss : 0.4770 | Acc : 0.7628
     Batch 100 | Loss : 0.4782 | Acc : 0.7596
     Batch 125 | Loss : 0.5121 | Acc : 0.7376
     Batch 150 | Loss : 0.3915 | Acc : 0.8192
     Batch 175 | Loss : 0.4565 | Acc : 0.7816
     Batch 200 | Loss : 0.3801 | Acc : 0.8204
     Batch 225 | Loss : 0.4057 | Acc : 0.8031
     Batch 250 | Loss : 0.4908 | Acc : 0.7432
     Batch 275 | Loss : 0.4756 | Acc : 0.7658
     Batch 300 | Loss : 0.4293 | Acc : 0.7965
Epoch 00027 | Train Loss : 0.4556 | Eval Loss : 0.4427 | Train acc : 0.7761 | Eval Acc : 0.7784 | Eval Log. Respected : 0.5834
     Batch 000 | Loss : 0.4372 | Acc : 0.7848
     Batch 025 | Loss : 0.4803 | Acc : 0.7554
     Batch 050 | Loss : 0.3621 | Acc : 0.8371
     Batch 075 | Loss : 0.5031 | Acc : 0.7364
     Batch 100 | Loss : 0.4504 | Acc : 0.7798
     Batch 125 | Loss : 0.4051 | Acc : 0.8101
     Batch 150 | Loss : 0.4281 | Acc : 0.7865
     Batch 175 | Loss : 0.3992 | Acc : 0.8207
     Batch 200 | Loss : 0.4186 | Acc : 0.7913
     Batch 225 | Loss : 0.5313 | Acc : 0.7205
     Batch 250 | Loss : 0.4575 | Acc : 0.7758
     Batch 275 | Loss : 0.4910 | Acc : 0.7468
     Batch 300 | Loss : 0.4724 | Acc : 0.7493
Epoch 00028 | Train Loss : 0.4472 | Eval Loss : 0.4557 | Train acc : 0.7812 | Eval Acc : 0.7742 | Eval Log. Respected : 0.6707
     Batch 000 | Loss : 0.4526 | Acc : 0.7916
     Batch 025 | Loss : 0.4741 | Acc : 0.7610
     Batch 050 | Loss : 0.4346 | Acc : 0.7829
     Batch 075 | Loss : 0.4236 | Acc : 0.7945
     Batch 100 | Loss : 0.3845 | Acc : 0.8196
     Batch 125 | Loss : 0.4384 | Acc : 0.7845
     Batch 150 | Loss : 0.4061 | Acc : 0.8098
     Batch 175 | Loss : 0.4769 | Acc : 0.7528
     Batch 200 | Loss : 0.4858 | Acc : 0.7498
     Batch 225 | Loss : 0.4212 | Acc : 0.7941
     Batch 250 | Loss : 0.4005 | Acc : 0.8150
     Batch 275 | Loss : 0.5244 | Acc : 0.7333
     Batch 300 | Loss : 0.4364 | Acc : 0.7914
Epoch 00029 | Train Loss : 0.4488 | Eval Loss : 0.4309 | Train acc : 0.7800 | Eval Acc : 0.7897 | Eval Log. Respected : 0.6043
     Batch 000 | Loss : 0.5343 | Acc : 0.7212
     Batch 025 | Loss : 0.4039 | Acc : 0.8120
     Batch 050 | Loss : 0.4458 | Acc : 0.7797
     Batch 075 | Loss : 0.3885 | Acc : 0.8248
     Batch 100 | Loss : 0.4823 | Acc : 0.7613
     Batch 125 | Loss : 0.4268 | Acc : 0.8009
     Batch 150 | Loss : 0.4150 | Acc : 0.8011
     Batch 175 | Loss : 0.4828 | Acc : 0.7501
     Batch 200 | Loss : 0.4284 | Acc : 0.8074
     Batch 225 | Loss : 0.5015 | Acc : 0.7473
     Batch 250 | Loss : 0.5476 | Acc : 0.7212
     Batch 275 | Loss : 0.3935 | Acc : 0.8192
     Batch 300 | Loss : 0.3963 | Acc : 0.8181
Epoch 00030 | Train Loss : 0.4430 | Eval Loss : 0.4224 | Train acc : 0.7838 | Eval Acc : 0.7936 | Eval Log. Respected : 0.6570
     Batch 000 | Loss : 0.4544 | Acc : 0.7731
     Batch 025 | Loss : 0.3836 | Acc : 0.8203
     Batch 050 | Loss : 0.4017 | Acc : 0.8114
     Batch 075 | Loss : 0.4482 | Acc : 0.7869
     Batch 100 | Loss : 0.4935 | Acc : 0.7532
     Batch 125 | Loss : 0.4397 | Acc : 0.7812
     Batch 150 | Loss : 0.4948 | Acc : 0.7582
     Batch 175 | Loss : 0.5028 | Acc : 0.7286
     Batch 200 | Loss : 0.4084 | Acc : 0.8012
     Batch 225 | Loss : 0.3887 | Acc : 0.8167
     Batch 250 | Loss : 0.4214 | Acc : 0.8106
     Batch 275 | Loss : 0.4382 | Acc : 0.7871
     Batch 300 | Loss : 0.5016 | Acc : 0.7547
Epoch 00031 | Train Loss : 0.4439 | Eval Loss : 0.4434 | Train acc : 0.7832 | Eval Acc : 0.7829 | Eval Log. Respected : 0.4786
     Batch 000 | Loss : 0.5908 | Acc : 0.7023
     Batch 025 | Loss : 0.4154 | Acc : 0.8128
     Batch 050 | Loss : 0.4440 | Acc : 0.7870
     Batch 075 | Loss : 0.6618 | Acc : 0.6521
     Batch 100 | Loss : 0.4906 | Acc : 0.7512
     Batch 125 | Loss : 0.4598 | Acc : 0.7683
     Batch 150 | Loss : 0.4547 | Acc : 0.7925
     Batch 175 | Loss : 0.4167 | Acc : 0.8076
     Batch 200 | Loss : 0.4407 | Acc : 0.7982
     Batch 225 | Loss : 0.4619 | Acc : 0.7704
     Batch 250 | Loss : 0.4229 | Acc : 0.7969
     Batch 275 | Loss : 0.4123 | Acc : 0.8033
     Batch 300 | Loss : 0.3854 | Acc : 0.8253
Epoch 00032 | Train Loss : 0.4637 | Eval Loss : 0.4273 | Train acc : 0.7713 | Eval Acc : 0.7911 | Eval Log. Respected : 0.4441
     Batch 000 | Loss : 0.4003 | Acc : 0.8094
     Batch 025 | Loss : 0.4092 | Acc : 0.7947
     Batch 050 | Loss : 0.4000 | Acc : 0.8205
     Batch 075 | Loss : 0.3745 | Acc : 0.8327
     Batch 100 | Loss : 0.5455 | Acc : 0.7297
     Batch 125 | Loss : 0.4187 | Acc : 0.8028
     Batch 150 | Loss : 0.4062 | Acc : 0.8022
     Batch 175 | Loss : 0.3765 | Acc : 0.8268
     Batch 200 | Loss : 0.3761 | Acc : 0.8309
     Batch 225 | Loss : 0.4697 | Acc : 0.7628
     Batch 250 | Loss : 0.4777 | Acc : 0.7677
     Batch 275 | Loss : 0.4172 | Acc : 0.8068
     Batch 300 | Loss : 0.3813 | Acc : 0.8281
Epoch 00033 | Train Loss : 0.4440 | Eval Loss : 0.4377 | Train acc : 0.7838 | Eval Acc : 0.7853 | Eval Log. Respected : 0.6826
     Batch 000 | Loss : 0.4057 | Acc : 0.8201
     Batch 025 | Loss : 0.3863 | Acc : 0.8217
     Batch 050 | Loss : 0.4545 | Acc : 0.7785
     Batch 075 | Loss : 0.4214 | Acc : 0.8076
     Batch 100 | Loss : 0.4517 | Acc : 0.7720
     Batch 125 | Loss : 0.5004 | Acc : 0.7475
     Batch 150 | Loss : 0.4060 | Acc : 0.8037
     Batch 175 | Loss : 0.4323 | Acc : 0.8021
     Batch 200 | Loss : 0.4616 | Acc : 0.7758
     Batch 225 | Loss : 0.4737 | Acc : 0.7659
     Batch 250 | Loss : 0.4544 | Acc : 0.7789
     Batch 275 | Loss : 0.4007 | Acc : 0.8116
     Batch 300 | Loss : 0.3734 | Acc : 0.8372
Epoch 00034 | Train Loss : 0.4415 | Eval Loss : 0.4246 | Train acc : 0.7847 | Eval Acc : 0.7946 | Eval Log. Respected : 0.6287
     Batch 000 | Loss : 0.4020 | Acc : 0.8096
     Batch 025 | Loss : 0.4021 | Acc : 0.8106
     Batch 050 | Loss : 0.4362 | Acc : 0.7795
     Batch 075 | Loss : 0.4347 | Acc : 0.7925
     Batch 100 | Loss : 0.3661 | Acc : 0.8399
     Batch 125 | Loss : 0.4629 | Acc : 0.7677
     Batch 150 | Loss : 0.5489 | Acc : 0.7103
     Batch 175 | Loss : 0.4511 | Acc : 0.7742
     Batch 200 | Loss : 0.4695 | Acc : 0.7660
     Batch 225 | Loss : 0.5047 | Acc : 0.7458
     Batch 250 | Loss : 0.3843 | Acc : 0.8165
     Batch 275 | Loss : 0.4262 | Acc : 0.7910
     Batch 300 | Loss : 0.4566 | Acc : 0.7689
Epoch 00035 | Train Loss : 0.4415 | Eval Loss : 0.4724 | Train acc : 0.7847 | Eval Acc : 0.7685 | Eval Log. Respected : 0.5687
     Batch 000 | Loss : 0.4419 | Acc : 0.7868
     Batch 025 | Loss : 0.4380 | Acc : 0.7855
     Batch 050 | Loss : 0.4567 | Acc : 0.7770
     Batch 075 | Loss : 0.4773 | Acc : 0.7589
     Batch 100 | Loss : 0.4749 | Acc : 0.7697
     Batch 125 | Loss : 0.4436 | Acc : 0.7765
     Batch 150 | Loss : 0.3914 | Acc : 0.8290
     Batch 175 | Loss : 0.4336 | Acc : 0.7927
     Batch 200 | Loss : 0.3843 | Acc : 0.8158
     Batch 225 | Loss : 0.4203 | Acc : 0.7860
     Batch 250 | Loss : 0.4067 | Acc : 0.8047
     Batch 275 | Loss : 0.4158 | Acc : 0.8030
     Batch 300 | Loss : 0.4568 | Acc : 0.7887
Epoch 00036 | Train Loss : 0.4521 | Eval Loss : 0.4595 | Train acc : 0.7791 | Eval Acc : 0.7741 | Eval Log. Respected : 0.6188
     Batch 000 | Loss : 0.4659 | Acc : 0.7656
     Batch 025 | Loss : 0.4029 | Acc : 0.8231
     Batch 050 | Loss : 0.4822 | Acc : 0.7636
     Batch 075 | Loss : 0.3722 | Acc : 0.8329
     Batch 100 | Loss : 0.4311 | Acc : 0.7807
     Batch 125 | Loss : 0.3974 | Acc : 0.8221
     Batch 150 | Loss : 0.3775 | Acc : 0.8211
     Batch 175 | Loss : 0.3803 | Acc : 0.8137
     Batch 200 | Loss : 0.5464 | Acc : 0.7150
     Batch 225 | Loss : 0.4606 | Acc : 0.7673
     Batch 250 | Loss : 0.4016 | Acc : 0.8074
     Batch 275 | Loss : 0.4711 | Acc : 0.7619
     Batch 300 | Loss : 0.4366 | Acc : 0.7897
Epoch 00037 | Train Loss : 0.4447 | Eval Loss : 0.4234 | Train acc : 0.7828 | Eval Acc : 0.7950 | Eval Log. Respected : 0.6354
     Batch 000 | Loss : 0.3721 | Acc : 0.8387
     Batch 025 | Loss : 0.3918 | Acc : 0.8225
     Batch 050 | Loss : 0.3760 | Acc : 0.8321
     Batch 075 | Loss : 0.3700 | Acc : 0.8298
     Batch 100 | Loss : 0.3960 | Acc : 0.8152
     Batch 125 | Loss : 0.4492 | Acc : 0.7685
     Batch 150 | Loss : 0.4478 | Acc : 0.7812
     Batch 175 | Loss : 0.5023 | Acc : 0.7338
     Batch 200 | Loss : 0.4052 | Acc : 0.8106
     Batch 225 | Loss : 0.3946 | Acc : 0.8184
     Batch 250 | Loss : 0.4539 | Acc : 0.7732
     Batch 275 | Loss : 0.4271 | Acc : 0.7847
     Batch 300 | Loss : 0.4605 | Acc : 0.7680
Epoch 00038 | Train Loss : 0.4371 | Eval Loss : 0.4482 | Train acc : 0.7875 | Eval Acc : 0.7765 | Eval Log. Respected : 0.5209
     Batch 000 | Loss : 0.4705 | Acc : 0.7670
     Batch 025 | Loss : 0.4369 | Acc : 0.7894
     Batch 050 | Loss : 0.4996 | Acc : 0.7580
     Batch 075 | Loss : 0.4039 | Acc : 0.8139
     Batch 100 | Loss : 0.4726 | Acc : 0.7630
     Batch 125 | Loss : 0.4755 | Acc : 0.7588
     Batch 150 | Loss : 0.4268 | Acc : 0.7971
     Batch 175 | Loss : 0.4613 | Acc : 0.7694
     Batch 200 | Loss : 0.3947 | Acc : 0.8210
     Batch 225 | Loss : 0.3878 | Acc : 0.8151
     Batch 250 | Loss : 0.4705 | Acc : 0.7729
     Batch 275 | Loss : 0.5304 | Acc : 0.7278
     Batch 300 | Loss : 0.4294 | Acc : 0.7879
Epoch 00039 | Train Loss : 0.4476 | Eval Loss : 0.4253 | Train acc : 0.7819 | Eval Acc : 0.7919 | Eval Log. Respected : 0.5749
     Batch 000 | Loss : 0.3928 | Acc : 0.8153
     Batch 025 | Loss : 0.4115 | Acc : 0.8032
     Batch 050 | Loss : 0.4134 | Acc : 0.8098
     Batch 075 | Loss : 0.4220 | Acc : 0.7892
     Batch 100 | Loss : 0.3854 | Acc : 0.8208
     Batch 125 | Loss : 0.4154 | Acc : 0.8011
     Batch 150 | Loss : 0.4144 | Acc : 0.8002
     Batch 175 | Loss : 0.4175 | Acc : 0.8003
     Batch 200 | Loss : 0.4229 | Acc : 0.7988
     Batch 225 | Loss : 0.4647 | Acc : 0.7591
     Batch 250 | Loss : 0.4561 | Acc : 0.7717
     Batch 275 | Loss : 0.4532 | Acc : 0.7724
     Batch 300 | Loss : 0.4607 | Acc : 0.7670
Epoch 00040 | Train Loss : 0.4354 | Eval Loss : 0.4263 | Train acc : 0.7885 | Eval Acc : 0.7926 | Eval Log. Respected : 0.6224
Early Stopping
Testing...
Test Loss 0.6198 | Test Acc 0.7865 | Test Log. Res. 0.5443
