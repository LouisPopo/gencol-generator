Done loading data from cached files.
Training ...
     Batch 000 | Loss : 0.6941 | Acc : 0.4895
     Batch 025 | Loss : 0.6832 | Acc : 0.5722
     Batch 050 | Loss : 0.6693 | Acc : 0.5912
     Batch 075 | Loss : 0.6763 | Acc : 0.5768
     Batch 100 | Loss : 0.6377 | Acc : 0.5966
     Batch 125 | Loss : 0.6972 | Acc : 0.5554
     Batch 150 | Loss : 0.6961 | Acc : 0.5660
     Batch 175 | Loss : 0.6401 | Acc : 0.6000
     Batch 200 | Loss : 0.6436 | Acc : 0.5938
     Batch 225 | Loss : 0.7117 | Acc : 0.5029
     Batch 250 | Loss : 0.6374 | Acc : 0.6093
     Batch 275 | Loss : 0.6974 | Acc : 0.5290
     Batch 300 | Loss : 0.6647 | Acc : 0.5712
Epoch 00000 | Train Loss : 0.6610 | Eval Loss : 0.6375 | Train acc : 0.5782 | Eval Acc : 0.5928 | Eval Log. Respected : 0.0001
     Batch 000 | Loss : 0.6248 | Acc : 0.6195
     Batch 025 | Loss : 0.6371 | Acc : 0.6000
     Batch 050 | Loss : 0.6030 | Acc : 0.6322
     Batch 075 | Loss : 0.6297 | Acc : 0.6135
     Batch 100 | Loss : 0.6129 | Acc : 0.6405
     Batch 125 | Loss : 0.6274 | Acc : 0.6003
     Batch 150 | Loss : 0.6063 | Acc : 0.6456
     Batch 175 | Loss : 0.6362 | Acc : 0.6125
     Batch 200 | Loss : 0.5777 | Acc : 0.6588
     Batch 225 | Loss : 0.5788 | Acc : 0.6634
     Batch 250 | Loss : 0.5801 | Acc : 0.6681
     Batch 275 | Loss : 0.5481 | Acc : 0.6793
     Batch 300 | Loss : 0.5453 | Acc : 0.6844
Epoch 00001 | Train Loss : 0.6051 | Eval Loss : 0.5517 | Train acc : 0.6352 | Eval Acc : 0.6683 | Eval Log. Respected : 0.9232
     Batch 000 | Loss : 0.5582 | Acc : 0.6845
     Batch 025 | Loss : 0.5280 | Acc : 0.6972
     Batch 050 | Loss : 0.5282 | Acc : 0.7065
     Batch 075 | Loss : 0.5467 | Acc : 0.6777
     Batch 100 | Loss : 0.5530 | Acc : 0.6600
     Batch 125 | Loss : 0.5473 | Acc : 0.6735
     Batch 150 | Loss : 0.5321 | Acc : 0.6789
     Batch 175 | Loss : 0.5440 | Acc : 0.6814
     Batch 200 | Loss : 0.5461 | Acc : 0.6779
     Batch 225 | Loss : 0.5230 | Acc : 0.7064
     Batch 250 | Loss : 0.5344 | Acc : 0.7007
     Batch 275 | Loss : 0.5351 | Acc : 0.6846
     Batch 300 | Loss : 0.5012 | Acc : 0.7205
Epoch 00002 | Train Loss : 0.5415 | Eval Loss : 0.5360 | Train acc : 0.6871 | Eval Acc : 0.6856 | Eval Log. Respected : 0.9438
     Batch 000 | Loss : 0.5537 | Acc : 0.6732
     Batch 025 | Loss : 0.5613 | Acc : 0.7089
     Batch 050 | Loss : 0.5446 | Acc : 0.6944
     Batch 075 | Loss : 0.5187 | Acc : 0.7139
     Batch 100 | Loss : 0.5181 | Acc : 0.7077
     Batch 125 | Loss : 0.5150 | Acc : 0.7028
     Batch 150 | Loss : 0.5096 | Acc : 0.7218
     Batch 175 | Loss : 0.5091 | Acc : 0.7270
     Batch 200 | Loss : 0.5084 | Acc : 0.7073
     Batch 225 | Loss : 0.5570 | Acc : 0.6890
     Batch 250 | Loss : 0.5505 | Acc : 0.6935
     Batch 275 | Loss : 0.4905 | Acc : 0.7346
     Batch 300 | Loss : 0.4764 | Acc : 0.7605
Epoch 00003 | Train Loss : 0.5170 | Eval Loss : 0.5389 | Train acc : 0.7184 | Eval Acc : 0.6891 | Eval Log. Respected : 0.9560
     Batch 000 | Loss : 0.5473 | Acc : 0.6954
     Batch 025 | Loss : 0.4678 | Acc : 0.7509
     Batch 050 | Loss : 0.4697 | Acc : 0.7616
     Batch 075 | Loss : 0.4701 | Acc : 0.7602
     Batch 100 | Loss : 0.4741 | Acc : 0.7567
     Batch 125 | Loss : 0.5287 | Acc : 0.7144
     Batch 150 | Loss : 0.5082 | Acc : 0.7233
     Batch 175 | Loss : 0.5541 | Acc : 0.7279
     Batch 200 | Loss : 0.5155 | Acc : 0.7209
     Batch 225 | Loss : 0.4631 | Acc : 0.7734
     Batch 250 | Loss : 0.4427 | Acc : 0.7770
     Batch 275 | Loss : 0.4839 | Acc : 0.7487
     Batch 300 | Loss : 0.4510 | Acc : 0.7669
Epoch 00004 | Train Loss : 0.4787 | Eval Loss : 0.4403 | Train acc : 0.7527 | Eval Acc : 0.7787 | Eval Log. Respected : 0.9375
     Batch 000 | Loss : 0.4006 | Acc : 0.8156
     Batch 025 | Loss : 0.4515 | Acc : 0.7682
     Batch 050 | Loss : 0.4412 | Acc : 0.7921
     Batch 075 | Loss : 0.4647 | Acc : 0.7534
     Batch 100 | Loss : 0.3985 | Acc : 0.8180
     Batch 125 | Loss : 0.4263 | Acc : 0.7928
     Batch 150 | Loss : 0.4765 | Acc : 0.7616
     Batch 175 | Loss : 0.3938 | Acc : 0.8068
     Batch 200 | Loss : 0.4465 | Acc : 0.7667
     Batch 225 | Loss : 0.4127 | Acc : 0.8043
     Batch 250 | Loss : 0.4884 | Acc : 0.7524
     Batch 275 | Loss : 0.4463 | Acc : 0.7703
     Batch 300 | Loss : 0.4558 | Acc : 0.7832
Epoch 00005 | Train Loss : 0.4493 | Eval Loss : 0.4393 | Train acc : 0.7747 | Eval Acc : 0.7761 | Eval Log. Respected : 0.9442
     Batch 000 | Loss : 0.3914 | Acc : 0.8113
     Batch 025 | Loss : 0.4504 | Acc : 0.7851
     Batch 050 | Loss : 0.3932 | Acc : 0.8104
     Batch 075 | Loss : 0.4297 | Acc : 0.7833
     Batch 100 | Loss : 0.3775 | Acc : 0.8193
     Batch 125 | Loss : 0.3944 | Acc : 0.8148
     Batch 150 | Loss : 0.4010 | Acc : 0.7993
     Batch 175 | Loss : 0.4840 | Acc : 0.7483
     Batch 200 | Loss : 0.3876 | Acc : 0.8193
     Batch 225 | Loss : 0.4379 | Acc : 0.7816
     Batch 250 | Loss : 0.4228 | Acc : 0.8007
     Batch 275 | Loss : 0.3946 | Acc : 0.8128
     Batch 300 | Loss : 0.4025 | Acc : 0.8039
Epoch 00006 | Train Loss : 0.4222 | Eval Loss : 0.4036 | Train acc : 0.7933 | Eval Acc : 0.8024 | Eval Log. Respected : 0.9296
     Batch 000 | Loss : 0.4594 | Acc : 0.7658
     Batch 025 | Loss : 0.4201 | Acc : 0.7912
     Batch 050 | Loss : 0.4185 | Acc : 0.7969
     Batch 075 | Loss : 0.3928 | Acc : 0.8145
     Batch 100 | Loss : 0.3614 | Acc : 0.8382
     Batch 125 | Loss : 0.3908 | Acc : 0.8141
     Batch 150 | Loss : 0.3434 | Acc : 0.8473
     Batch 175 | Loss : 0.4066 | Acc : 0.8043
     Batch 200 | Loss : 0.3726 | Acc : 0.8277
     Batch 225 | Loss : 0.4404 | Acc : 0.7782
     Batch 250 | Loss : 0.3877 | Acc : 0.8112
     Batch 275 | Loss : 0.4045 | Acc : 0.8035
     Batch 300 | Loss : 0.3483 | Acc : 0.8412
Epoch 00007 | Train Loss : 0.4120 | Eval Loss : 0.4079 | Train acc : 0.8008 | Eval Acc : 0.8005 | Eval Log. Respected : 0.9275
     Batch 000 | Loss : 0.3810 | Acc : 0.8212
     Batch 025 | Loss : 0.3818 | Acc : 0.8119
     Batch 050 | Loss : 0.4398 | Acc : 0.7793
     Batch 075 | Loss : 0.4558 | Acc : 0.7898
     Batch 100 | Loss : 0.3754 | Acc : 0.8179
     Batch 125 | Loss : 0.3726 | Acc : 0.8348
     Batch 150 | Loss : 0.3729 | Acc : 0.8358
     Batch 175 | Loss : 0.3801 | Acc : 0.8130
     Batch 200 | Loss : 0.4788 | Acc : 0.7823
     Batch 225 | Loss : 0.4136 | Acc : 0.8041
     Batch 250 | Loss : 0.4407 | Acc : 0.7717
     Batch 275 | Loss : 0.3331 | Acc : 0.8448
     Batch 300 | Loss : 0.3347 | Acc : 0.8457
Epoch 00008 | Train Loss : 0.4002 | Eval Loss : 0.3680 | Train acc : 0.8086 | Eval Acc : 0.8273 | Eval Log. Respected : 0.9348
     Batch 000 | Loss : 0.3472 | Acc : 0.8391
     Batch 025 | Loss : 0.3558 | Acc : 0.8330
     Batch 050 | Loss : 0.3513 | Acc : 0.8321
     Batch 075 | Loss : 0.3337 | Acc : 0.8479
     Batch 100 | Loss : 0.4025 | Acc : 0.8096
     Batch 125 | Loss : 0.4418 | Acc : 0.7805
     Batch 150 | Loss : 0.3244 | Acc : 0.8527
     Batch 175 | Loss : 0.3729 | Acc : 0.8242
     Batch 200 | Loss : 0.3652 | Acc : 0.8268
     Batch 225 | Loss : 0.3550 | Acc : 0.8313
     Batch 250 | Loss : 0.3163 | Acc : 0.8605
     Batch 275 | Loss : 0.4297 | Acc : 0.7947
     Batch 300 | Loss : 0.3824 | Acc : 0.8147
Epoch 00009 | Train Loss : 0.3691 | Eval Loss : 0.3615 | Train acc : 0.8268 | Eval Acc : 0.8268 | Eval Log. Respected : 0.9282
     Batch 000 | Loss : 0.3581 | Acc : 0.8294
     Batch 025 | Loss : 0.3336 | Acc : 0.8434
     Batch 050 | Loss : 0.4076 | Acc : 0.8091
     Batch 075 | Loss : 0.3158 | Acc : 0.8551
     Batch 100 | Loss : 0.3887 | Acc : 0.8146
     Batch 125 | Loss : 0.4050 | Acc : 0.8168
     Batch 150 | Loss : 0.3900 | Acc : 0.8152
     Batch 175 | Loss : 0.3414 | Acc : 0.8409
     Batch 200 | Loss : 0.3458 | Acc : 0.8412
     Batch 225 | Loss : 0.5489 | Acc : 0.7614
     Batch 250 | Loss : 0.3366 | Acc : 0.8507
     Batch 275 | Loss : 0.3553 | Acc : 0.8294
     Batch 300 | Loss : 0.2828 | Acc : 0.8753
Epoch 00010 | Train Loss : 0.3655 | Eval Loss : 0.3576 | Train acc : 0.8289 | Eval Acc : 0.8288 | Eval Log. Respected : 0.9260
     Batch 000 | Loss : 0.3670 | Acc : 0.8264
     Batch 025 | Loss : 0.3760 | Acc : 0.8209
     Batch 050 | Loss : 0.3335 | Acc : 0.8392
     Batch 075 | Loss : 0.3329 | Acc : 0.8398
     Batch 100 | Loss : 0.2949 | Acc : 0.8695
     Batch 125 | Loss : 0.3461 | Acc : 0.8385
     Batch 150 | Loss : 0.3209 | Acc : 0.8535
     Batch 175 | Loss : 0.4646 | Acc : 0.7688
     Batch 200 | Loss : 0.3654 | Acc : 0.8232
     Batch 225 | Loss : 0.3412 | Acc : 0.8361
     Batch 250 | Loss : 0.3997 | Acc : 0.8094
     Batch 275 | Loss : 0.4044 | Acc : 0.8051
     Batch 300 | Loss : 0.3651 | Acc : 0.8260
Epoch 00011 | Train Loss : 0.3629 | Eval Loss : 0.3530 | Train acc : 0.8300 | Eval Acc : 0.8312 | Eval Log. Respected : 0.9314
     Batch 000 | Loss : 0.3129 | Acc : 0.8544
     Batch 025 | Loss : 0.3479 | Acc : 0.8329
     Batch 050 | Loss : 0.3349 | Acc : 0.8408
     Batch 075 | Loss : 0.3992 | Acc : 0.8085
     Batch 100 | Loss : 0.3794 | Acc : 0.8211
     Batch 125 | Loss : 0.3910 | Acc : 0.8106
     Batch 150 | Loss : 0.2762 | Acc : 0.8823
     Batch 175 | Loss : 0.4635 | Acc : 0.7925
     Batch 200 | Loss : 0.3315 | Acc : 0.8484
     Batch 225 | Loss : 0.3328 | Acc : 0.8418
     Batch 250 | Loss : 0.3056 | Acc : 0.8660
     Batch 275 | Loss : 0.3897 | Acc : 0.8090
     Batch 300 | Loss : 0.3986 | Acc : 0.8047
Epoch 00012 | Train Loss : 0.3616 | Eval Loss : 0.3528 | Train acc : 0.8307 | Eval Acc : 0.8311 | Eval Log. Respected : 0.9261
     Batch 000 | Loss : 0.3165 | Acc : 0.8614
     Batch 025 | Loss : 0.3761 | Acc : 0.8221
     Batch 050 | Loss : 0.3111 | Acc : 0.8617
     Batch 075 | Loss : 0.3768 | Acc : 0.8237
     Batch 100 | Loss : 0.4236 | Acc : 0.7920
     Batch 125 | Loss : 0.3296 | Acc : 0.8484
     Batch 150 | Loss : 0.5624 | Acc : 0.7559
     Batch 175 | Loss : 0.3956 | Acc : 0.8139
     Batch 200 | Loss : 0.3498 | Acc : 0.8344
     Batch 225 | Loss : 0.2802 | Acc : 0.8835
     Batch 250 | Loss : 0.3422 | Acc : 0.8411
     Batch 275 | Loss : 0.4490 | Acc : 0.7820
     Batch 300 | Loss : 0.4676 | Acc : 0.7807
Epoch 00013 | Train Loss : 0.3593 | Eval Loss : 0.3557 | Train acc : 0.8318 | Eval Acc : 0.8303 | Eval Log. Respected : 0.9199
     Batch 000 | Loss : 0.3325 | Acc : 0.8503
     Batch 025 | Loss : 0.3752 | Acc : 0.8219
     Batch 050 | Loss : 0.3428 | Acc : 0.8362
     Batch 075 | Loss : 0.3154 | Acc : 0.8604
     Batch 100 | Loss : 0.3557 | Acc : 0.8325
     Batch 125 | Loss : 0.3482 | Acc : 0.8382
     Batch 150 | Loss : 0.3451 | Acc : 0.8419
     Batch 175 | Loss : 0.3919 | Acc : 0.8185
     Batch 200 | Loss : 0.3246 | Acc : 0.8521
     Batch 225 | Loss : 0.3867 | Acc : 0.8240
     Batch 250 | Loss : 0.4068 | Acc : 0.7999
     Batch 275 | Loss : 0.3973 | Acc : 0.8081
     Batch 300 | Loss : 0.3922 | Acc : 0.8148
Epoch 00014 | Train Loss : 0.3596 | Eval Loss : 0.3534 | Train acc : 0.8319 | Eval Acc : 0.8308 | Eval Log. Respected : 0.9239
     Batch 000 | Loss : 0.3400 | Acc : 0.8371
     Batch 025 | Loss : 0.3136 | Acc : 0.8605
     Batch 050 | Loss : 0.4204 | Acc : 0.7937
     Batch 075 | Loss : 0.4058 | Acc : 0.8158
     Batch 100 | Loss : 0.3141 | Acc : 0.8614
     Batch 125 | Loss : 0.3616 | Acc : 0.8228
     Batch 150 | Loss : 0.3236 | Acc : 0.8531
     Batch 175 | Loss : 0.3920 | Acc : 0.8145
     Batch 200 | Loss : 0.3335 | Acc : 0.8496
     Batch 225 | Loss : 0.3107 | Acc : 0.8562
     Batch 250 | Loss : 0.3680 | Acc : 0.8236
     Batch 275 | Loss : 0.3672 | Acc : 0.8289
     Batch 300 | Loss : 0.3238 | Acc : 0.8583
Epoch 00015 | Train Loss : 0.3588 | Eval Loss : 0.3524 | Train acc : 0.8324 | Eval Acc : 0.8326 | Eval Log. Respected : 0.9308
     Batch 000 | Loss : 0.3822 | Acc : 0.8146
     Batch 025 | Loss : 0.3401 | Acc : 0.8504
     Batch 050 | Loss : 0.3740 | Acc : 0.8164
     Batch 075 | Loss : 0.2948 | Acc : 0.8674
     Batch 100 | Loss : 0.4547 | Acc : 0.7780
     Batch 125 | Loss : 0.3468 | Acc : 0.8347
     Batch 150 | Loss : 0.4093 | Acc : 0.8015
     Batch 175 | Loss : 0.2840 | Acc : 0.8734
     Batch 200 | Loss : 0.3420 | Acc : 0.8406
     Batch 225 | Loss : 0.4356 | Acc : 0.7937
     Batch 250 | Loss : 0.3371 | Acc : 0.8479
     Batch 275 | Loss : 0.3374 | Acc : 0.8447
     Batch 300 | Loss : 0.3440 | Acc : 0.8383
Epoch 00016 | Train Loss : 0.3581 | Eval Loss : 0.3522 | Train acc : 0.8325 | Eval Acc : 0.8317 | Eval Log. Respected : 0.9205
     Batch 000 | Loss : 0.3702 | Acc : 0.8245
     Batch 025 | Loss : 0.3563 | Acc : 0.8360
     Batch 050 | Loss : 0.4484 | Acc : 0.7834
     Batch 075 | Loss : 0.2863 | Acc : 0.8714
     Batch 100 | Loss : 0.3055 | Acc : 0.8693
     Batch 125 | Loss : 0.3562 | Acc : 0.8317
     Batch 150 | Loss : 0.3279 | Acc : 0.8498
     Batch 175 | Loss : 0.3350 | Acc : 0.8409
     Batch 200 | Loss : 0.3370 | Acc : 0.8419
     Batch 225 | Loss : 0.3194 | Acc : 0.8508
     Batch 250 | Loss : 0.3446 | Acc : 0.8485
     Batch 275 | Loss : 0.4016 | Acc : 0.8037
     Batch 300 | Loss : 0.3243 | Acc : 0.8530
Epoch 00017 | Train Loss : 0.3567 | Eval Loss : 0.3495 | Train acc : 0.8333 | Eval Acc : 0.8333 | Eval Log. Respected : 0.9353
     Batch 000 | Loss : 0.3200 | Acc : 0.8482
     Batch 025 | Loss : 0.3155 | Acc : 0.8537
     Batch 050 | Loss : 0.4748 | Acc : 0.7835
     Batch 075 | Loss : 0.3706 | Acc : 0.8260
     Batch 100 | Loss : 0.3069 | Acc : 0.8639
     Batch 125 | Loss : 0.3744 | Acc : 0.8271
     Batch 150 | Loss : 0.3060 | Acc : 0.8633
     Batch 175 | Loss : 0.3809 | Acc : 0.8180
     Batch 200 | Loss : 0.3350 | Acc : 0.8442
     Batch 225 | Loss : 0.3192 | Acc : 0.8520
     Batch 250 | Loss : 0.3186 | Acc : 0.8554
     Batch 275 | Loss : 0.3484 | Acc : 0.8332
     Batch 300 | Loss : 0.3356 | Acc : 0.8453
Epoch 00018 | Train Loss : 0.3586 | Eval Loss : 0.3577 | Train acc : 0.8320 | Eval Acc : 0.8297 | Eval Log. Respected : 0.9413
     Batch 000 | Loss : 0.4222 | Acc : 0.7907
     Batch 025 | Loss : 0.4380 | Acc : 0.7863
     Batch 050 | Loss : 0.3769 | Acc : 0.8203
     Batch 075 | Loss : 0.3258 | Acc : 0.8450
     Batch 100 | Loss : 0.4091 | Acc : 0.7979
     Batch 125 | Loss : 0.3905 | Acc : 0.8154
     Batch 150 | Loss : 0.3225 | Acc : 0.8563
     Batch 175 | Loss : 0.3271 | Acc : 0.8499
     Batch 200 | Loss : 0.4289 | Acc : 0.7902
     Batch 225 | Loss : 0.3084 | Acc : 0.8535
     Batch 250 | Loss : 0.3346 | Acc : 0.8470
     Batch 275 | Loss : 0.3335 | Acc : 0.8444
     Batch 300 | Loss : 0.3514 | Acc : 0.8344
Epoch 00019 | Train Loss : 0.3546 | Eval Loss : 0.3510 | Train acc : 0.8340 | Eval Acc : 0.8332 | Eval Log. Respected : 0.9284
     Batch 000 | Loss : 0.3742 | Acc : 0.8251
     Batch 025 | Loss : 0.3269 | Acc : 0.8499
     Batch 050 | Loss : 0.3134 | Acc : 0.8628
     Batch 075 | Loss : 0.3904 | Acc : 0.8149
     Batch 100 | Loss : 0.3442 | Acc : 0.8331
     Batch 125 | Loss : 0.3725 | Acc : 0.8255
     Batch 150 | Loss : 0.4305 | Acc : 0.7909
     Batch 175 | Loss : 0.3279 | Acc : 0.8491
     Batch 200 | Loss : 0.2924 | Acc : 0.8708
     Batch 225 | Loss : 0.3475 | Acc : 0.8320
     Batch 250 | Loss : 0.3247 | Acc : 0.8538
     Batch 275 | Loss : 0.3281 | Acc : 0.8446
     Batch 300 | Loss : 0.4147 | Acc : 0.7987
Epoch 00020 | Train Loss : 0.3541 | Eval Loss : 0.3465 | Train acc : 0.8344 | Eval Acc : 0.8347 | Eval Log. Respected : 0.9269
     Batch 000 | Loss : 0.3251 | Acc : 0.8504
     Batch 025 | Loss : 0.3892 | Acc : 0.8124
     Batch 050 | Loss : 0.3389 | Acc : 0.8413
     Batch 075 | Loss : 0.3312 | Acc : 0.8475
     Batch 100 | Loss : 0.3708 | Acc : 0.8225
     Batch 125 | Loss : 0.3341 | Acc : 0.8436
     Batch 150 | Loss : 0.3294 | Acc : 0.8402
     Batch 175 | Loss : 0.3430 | Acc : 0.8408
     Batch 200 | Loss : 0.3285 | Acc : 0.8463
     Batch 225 | Loss : 0.3857 | Acc : 0.8175
     Batch 250 | Loss : 0.3929 | Acc : 0.8115
     Batch 275 | Loss : 0.3168 | Acc : 0.8535
     Batch 300 | Loss : 0.3726 | Acc : 0.8186
Epoch 00021 | Train Loss : 0.3540 | Eval Loss : 0.3479 | Train acc : 0.8346 | Eval Acc : 0.8330 | Eval Log. Respected : 0.9345
     Batch 000 | Loss : 0.3993 | Acc : 0.8041
     Batch 025 | Loss : 0.3027 | Acc : 0.8698
     Batch 050 | Loss : 0.3141 | Acc : 0.8539
     Batch 075 | Loss : 0.3975 | Acc : 0.8234
     Batch 100 | Loss : 0.3291 | Acc : 0.8507
     Batch 125 | Loss : 0.3081 | Acc : 0.8590
     Batch 150 | Loss : 0.4568 | Acc : 0.7841
     Batch 175 | Loss : 0.3121 | Acc : 0.8608
     Batch 200 | Loss : 0.2971 | Acc : 0.8748
     Batch 225 | Loss : 0.4910 | Acc : 0.7789
     Batch 250 | Loss : 0.2904 | Acc : 0.8734
     Batch 275 | Loss : 0.3873 | Acc : 0.8114
     Batch 300 | Loss : 0.3145 | Acc : 0.8554
Epoch 00022 | Train Loss : 0.3537 | Eval Loss : 0.3494 | Train acc : 0.8347 | Eval Acc : 0.8329 | Eval Log. Respected : 0.9449
     Batch 000 | Loss : 0.4345 | Acc : 0.7905
     Batch 025 | Loss : 0.3194 | Acc : 0.8491
     Batch 050 | Loss : 0.3894 | Acc : 0.8177
     Batch 075 | Loss : 0.4783 | Acc : 0.7748
     Batch 100 | Loss : 0.3212 | Acc : 0.8503
     Batch 125 | Loss : 0.3132 | Acc : 0.8558
     Batch 150 | Loss : 0.3825 | Acc : 0.8192
     Batch 175 | Loss : 0.3767 | Acc : 0.8230
     Batch 200 | Loss : 0.3789 | Acc : 0.8200
     Batch 225 | Loss : 0.3090 | Acc : 0.8563
     Batch 250 | Loss : 0.3202 | Acc : 0.8519
     Batch 275 | Loss : 0.4219 | Acc : 0.7946
     Batch 300 | Loss : 0.3801 | Acc : 0.8193
Epoch 00023 | Train Loss : 0.3540 | Eval Loss : 0.3463 | Train acc : 0.8348 | Eval Acc : 0.8354 | Eval Log. Respected : 0.9334
     Batch 000 | Loss : 0.3623 | Acc : 0.8256
     Batch 025 | Loss : 0.3392 | Acc : 0.8402
     Batch 050 | Loss : 0.3705 | Acc : 0.8285
     Batch 075 | Loss : 0.4145 | Acc : 0.8105
     Batch 100 | Loss : 0.3142 | Acc : 0.8532
     Batch 125 | Loss : 0.4010 | Acc : 0.7974
     Batch 150 | Loss : 0.3393 | Acc : 0.8364
     Batch 175 | Loss : 0.3004 | Acc : 0.8661
     Batch 200 | Loss : 0.3332 | Acc : 0.8507
     Batch 225 | Loss : 0.3125 | Acc : 0.8590
     Batch 250 | Loss : 0.3730 | Acc : 0.8298
     Batch 275 | Loss : 0.2895 | Acc : 0.8719
     Batch 300 | Loss : 0.3122 | Acc : 0.8595
Epoch 00024 | Train Loss : 0.3528 | Eval Loss : 0.3520 | Train acc : 0.8354 | Eval Acc : 0.8337 | Eval Log. Respected : 0.9420
     Batch 000 | Loss : 0.3263 | Acc : 0.8544
     Batch 025 | Loss : 0.3720 | Acc : 0.8215
     Batch 050 | Loss : 0.3187 | Acc : 0.8577
     Batch 075 | Loss : 0.3530 | Acc : 0.8278
     Batch 100 | Loss : 0.3678 | Acc : 0.8241
     Batch 125 | Loss : 0.4067 | Acc : 0.8011
     Batch 150 | Loss : 0.3979 | Acc : 0.8073
     Batch 175 | Loss : 0.3802 | Acc : 0.8116
     Batch 200 | Loss : 0.3791 | Acc : 0.8087
     Batch 225 | Loss : 0.3746 | Acc : 0.8221
     Batch 250 | Loss : 0.3175 | Acc : 0.8552
     Batch 275 | Loss : 0.3088 | Acc : 0.8594
     Batch 300 | Loss : 0.3427 | Acc : 0.8458
Epoch 00025 | Train Loss : 0.3517 | Eval Loss : 0.3479 | Train acc : 0.8358 | Eval Acc : 0.8331 | Eval Log. Respected : 0.9287
     Batch 000 | Loss : 0.3540 | Acc : 0.8304
     Batch 025 | Loss : 0.3138 | Acc : 0.8549
     Batch 050 | Loss : 0.3316 | Acc : 0.8426
     Batch 075 | Loss : 0.3426 | Acc : 0.8341
     Batch 100 | Loss : 0.3779 | Acc : 0.8155
     Batch 125 | Loss : 0.3097 | Acc : 0.8667
     Batch 150 | Loss : 0.4126 | Acc : 0.8007
     Batch 175 | Loss : 0.3390 | Acc : 0.8393
     Batch 200 | Loss : 0.3479 | Acc : 0.8354
     Batch 225 | Loss : 0.3348 | Acc : 0.8468
     Batch 250 | Loss : 0.3871 | Acc : 0.8098
     Batch 275 | Loss : 0.3127 | Acc : 0.8572
     Batch 300 | Loss : 0.3965 | Acc : 0.8140
Epoch 00026 | Train Loss : 0.3514 | Eval Loss : 0.3434 | Train acc : 0.8356 | Eval Acc : 0.8363 | Eval Log. Respected : 0.9387
     Batch 000 | Loss : 0.2849 | Acc : 0.8725
     Batch 025 | Loss : 0.4406 | Acc : 0.7860
     Batch 050 | Loss : 0.3849 | Acc : 0.8200
     Batch 075 | Loss : 0.3541 | Acc : 0.8319
     Batch 100 | Loss : 0.3973 | Acc : 0.8109
     Batch 125 | Loss : 0.3722 | Acc : 0.8119
     Batch 150 | Loss : 0.4026 | Acc : 0.8158
     Batch 175 | Loss : 0.3388 | Acc : 0.8426
     Batch 200 | Loss : 0.4401 | Acc : 0.7878
     Batch 225 | Loss : 0.2784 | Acc : 0.8745
     Batch 250 | Loss : 0.3234 | Acc : 0.8488
     Batch 275 | Loss : 0.3320 | Acc : 0.8411
     Batch 300 | Loss : 0.2913 | Acc : 0.8730
Epoch 00027 | Train Loss : 0.3500 | Eval Loss : 0.3462 | Train acc : 0.8365 | Eval Acc : 0.8345 | Eval Log. Respected : 0.9311
     Batch 000 | Loss : 0.3094 | Acc : 0.8594
     Batch 025 | Loss : 0.3951 | Acc : 0.8222
     Batch 050 | Loss : 0.3459 | Acc : 0.8405
     Batch 075 | Loss : 0.3224 | Acc : 0.8535
     Batch 100 | Loss : 0.3367 | Acc : 0.8429
     Batch 125 | Loss : 0.3166 | Acc : 0.8555
     Batch 150 | Loss : 0.2992 | Acc : 0.8685
     Batch 175 | Loss : 0.3215 | Acc : 0.8527
     Batch 200 | Loss : 0.3020 | Acc : 0.8652
     Batch 225 | Loss : 0.3209 | Acc : 0.8512
     Batch 250 | Loss : 0.3377 | Acc : 0.8385
     Batch 275 | Loss : 0.3557 | Acc : 0.8323
     Batch 300 | Loss : 0.4817 | Acc : 0.7794
Epoch 00028 | Train Loss : 0.3503 | Eval Loss : 0.3479 | Train acc : 0.8367 | Eval Acc : 0.8360 | Eval Log. Respected : 0.9229
     Batch 000 | Loss : 0.3121 | Acc : 0.8657
     Batch 025 | Loss : 0.2834 | Acc : 0.8719
     Batch 050 | Loss : 0.4548 | Acc : 0.7888
     Batch 075 | Loss : 0.2865 | Acc : 0.8721
     Batch 100 | Loss : 0.3718 | Acc : 0.8205
     Batch 125 | Loss : 0.2940 | Acc : 0.8710
     Batch 150 | Loss : 0.3350 | Acc : 0.8419
     Batch 175 | Loss : 0.3365 | Acc : 0.8414
     Batch 200 | Loss : 0.3348 | Acc : 0.8414
     Batch 225 | Loss : 0.3845 | Acc : 0.8184
     Batch 250 | Loss : 0.3348 | Acc : 0.8461
     Batch 275 | Loss : 0.3408 | Acc : 0.8373
     Batch 300 | Loss : 0.4293 | Acc : 0.7911
Epoch 00029 | Train Loss : 0.3496 | Eval Loss : 0.3832 | Train acc : 0.8368 | Eval Acc : 0.8144 | Eval Log. Respected : 0.9171
     Batch 000 | Loss : 0.4231 | Acc : 0.7905
     Batch 025 | Loss : 0.3470 | Acc : 0.8326
     Batch 050 | Loss : 0.3643 | Acc : 0.8241
     Batch 075 | Loss : 0.4983 | Acc : 0.7661
     Batch 100 | Loss : 0.3129 | Acc : 0.8557
     Batch 125 | Loss : 0.3289 | Acc : 0.8496
     Batch 150 | Loss : 0.4596 | Acc : 0.7836
     Batch 175 | Loss : 0.3826 | Acc : 0.8195
     Batch 200 | Loss : 0.3924 | Acc : 0.8172
     Batch 225 | Loss : 0.3747 | Acc : 0.8190
     Batch 250 | Loss : 0.3612 | Acc : 0.8287
     Batch 275 | Loss : 0.3561 | Acc : 0.8380
     Batch 300 | Loss : 0.3436 | Acc : 0.8365
Epoch 00030 | Train Loss : 0.3500 | Eval Loss : 0.3449 | Train acc : 0.8366 | Eval Acc : 0.8369 | Eval Log. Respected : 0.9396
     Batch 000 | Loss : 0.4392 | Acc : 0.7994
     Batch 025 | Loss : 0.2894 | Acc : 0.8758
     Batch 050 | Loss : 0.3771 | Acc : 0.8177
     Batch 075 | Loss : 0.3510 | Acc : 0.8368
     Batch 100 | Loss : 0.3126 | Acc : 0.8561
     Batch 125 | Loss : 0.3033 | Acc : 0.8632
     Batch 150 | Loss : 0.3097 | Acc : 0.8572
     Batch 175 | Loss : 0.2928 | Acc : 0.8717
     Batch 200 | Loss : 0.3187 | Acc : 0.8549
     Batch 225 | Loss : 0.3246 | Acc : 0.8464
     Batch 250 | Loss : 0.3567 | Acc : 0.8363
     Batch 275 | Loss : 0.3125 | Acc : 0.8564
     Batch 300 | Loss : 0.4134 | Acc : 0.8102
Epoch 00031 | Train Loss : 0.3482 | Eval Loss : 0.3461 | Train acc : 0.8376 | Eval Acc : 0.8369 | Eval Log. Respected : 0.9370
     Batch 000 | Loss : 0.3505 | Acc : 0.8408
     Batch 025 | Loss : 0.3165 | Acc : 0.8520
     Batch 050 | Loss : 0.3239 | Acc : 0.8485
     Batch 075 | Loss : 0.3331 | Acc : 0.8479
     Batch 100 | Loss : 0.3269 | Acc : 0.8500
     Batch 125 | Loss : 0.3545 | Acc : 0.8327
     Batch 150 | Loss : 0.3562 | Acc : 0.8319
     Batch 175 | Loss : 0.2958 | Acc : 0.8694
     Batch 200 | Loss : 0.3191 | Acc : 0.8502
     Batch 225 | Loss : 0.3105 | Acc : 0.8565
     Batch 250 | Loss : 0.3034 | Acc : 0.8603
     Batch 275 | Loss : 0.4569 | Acc : 0.7699
     Batch 300 | Loss : 0.3233 | Acc : 0.8569
Epoch 00032 | Train Loss : 0.3475 | Eval Loss : 0.3472 | Train acc : 0.8379 | Eval Acc : 0.8347 | Eval Log. Respected : 0.9348
     Batch 000 | Loss : 0.2901 | Acc : 0.8698
     Batch 025 | Loss : 0.3638 | Acc : 0.8320
     Batch 050 | Loss : 0.3816 | Acc : 0.8228
     Batch 075 | Loss : 0.2833 | Acc : 0.8750
     Batch 100 | Loss : 0.2953 | Acc : 0.8636
     Batch 125 | Loss : 0.3407 | Acc : 0.8415
     Batch 150 | Loss : 0.3672 | Acc : 0.8229
     Batch 175 | Loss : 0.3043 | Acc : 0.8621
     Batch 200 | Loss : 0.2887 | Acc : 0.8731
     Batch 225 | Loss : 0.3722 | Acc : 0.8205
     Batch 250 | Loss : 0.3190 | Acc : 0.8503
     Batch 275 | Loss : 0.3857 | Acc : 0.8212
     Batch 300 | Loss : 0.3211 | Acc : 0.8554
Epoch 00033 | Train Loss : 0.3475 | Eval Loss : 0.3419 | Train acc : 0.8378 | Eval Acc : 0.8376 | Eval Log. Respected : 0.9302
     Batch 000 | Loss : 0.3273 | Acc : 0.8449
     Batch 025 | Loss : 0.2908 | Acc : 0.8705
     Batch 050 | Loss : 0.3072 | Acc : 0.8689
     Batch 075 | Loss : 0.3678 | Acc : 0.8194
     Batch 100 | Loss : 0.3325 | Acc : 0.8477
     Batch 125 | Loss : 0.3848 | Acc : 0.8175
     Batch 150 | Loss : 0.3998 | Acc : 0.8014
     Batch 175 | Loss : 0.3688 | Acc : 0.8213
     Batch 200 | Loss : 0.4505 | Acc : 0.7856
     Batch 225 | Loss : 0.3435 | Acc : 0.8420
     Batch 250 | Loss : 0.3203 | Acc : 0.8483
     Batch 275 | Loss : 0.3434 | Acc : 0.8356
     Batch 300 | Loss : 0.3796 | Acc : 0.8234
Epoch 00034 | Train Loss : 0.3469 | Eval Loss : 0.3452 | Train acc : 0.8382 | Eval Acc : 0.8353 | Eval Log. Respected : 0.9414
     Batch 000 | Loss : 0.3478 | Acc : 0.8383
     Batch 025 | Loss : 0.3435 | Acc : 0.8419
     Batch 050 | Loss : 0.3100 | Acc : 0.8564
     Batch 075 | Loss : 0.3231 | Acc : 0.8526
     Batch 100 | Loss : 0.3675 | Acc : 0.8192
     Batch 125 | Loss : 0.3186 | Acc : 0.8561
     Batch 150 | Loss : 0.3152 | Acc : 0.8524
     Batch 175 | Loss : 0.3127 | Acc : 0.8596
     Batch 200 | Loss : 0.3103 | Acc : 0.8566
     Batch 225 | Loss : 0.3321 | Acc : 0.8442
     Batch 250 | Loss : 0.3229 | Acc : 0.8553
     Batch 275 | Loss : 0.3423 | Acc : 0.8445
     Batch 300 | Loss : 0.2931 | Acc : 0.8702
Epoch 00035 | Train Loss : 0.3466 | Eval Loss : 0.3457 | Train acc : 0.8383 | Eval Acc : 0.8370 | Eval Log. Respected : 0.9331
     Batch 000 | Loss : 0.3874 | Acc : 0.8106
     Batch 025 | Loss : 0.3828 | Acc : 0.8209
     Batch 050 | Loss : 0.3743 | Acc : 0.8268
     Batch 075 | Loss : 0.3089 | Acc : 0.8581
     Batch 100 | Loss : 0.3253 | Acc : 0.8471
     Batch 125 | Loss : 0.3112 | Acc : 0.8611
     Batch 150 | Loss : 0.3688 | Acc : 0.8167
     Batch 175 | Loss : 0.3176 | Acc : 0.8552
     Batch 200 | Loss : 0.4058 | Acc : 0.8138
     Batch 225 | Loss : 0.2875 | Acc : 0.8746
     Batch 250 | Loss : 0.3225 | Acc : 0.8514
     Batch 275 | Loss : 0.3554 | Acc : 0.8345
     Batch 300 | Loss : 0.3439 | Acc : 0.8368
Epoch 00036 | Train Loss : 0.3461 | Eval Loss : 0.3395 | Train acc : 0.8385 | Eval Acc : 0.8376 | Eval Log. Respected : 0.9339
     Batch 000 | Loss : 0.4194 | Acc : 0.7931
     Batch 025 | Loss : 0.3227 | Acc : 0.8527
     Batch 050 | Loss : 0.4024 | Acc : 0.8167
     Batch 075 | Loss : 0.3600 | Acc : 0.8266
     Batch 100 | Loss : 0.3780 | Acc : 0.8230
     Batch 125 | Loss : 0.3344 | Acc : 0.8418
     Batch 150 | Loss : 0.3770 | Acc : 0.8146
     Batch 175 | Loss : 0.3579 | Acc : 0.8375
     Batch 200 | Loss : 0.2784 | Acc : 0.8772
     Batch 225 | Loss : 0.3209 | Acc : 0.8504
     Batch 250 | Loss : 0.3810 | Acc : 0.8121
     Batch 275 | Loss : 0.3427 | Acc : 0.8426
     Batch 300 | Loss : 0.3087 | Acc : 0.8620
Epoch 00037 | Train Loss : 0.3466 | Eval Loss : 0.3416 | Train acc : 0.8384 | Eval Acc : 0.8368 | Eval Log. Respected : 0.9380
     Batch 000 | Loss : 0.3344 | Acc : 0.8429
     Batch 025 | Loss : 0.3495 | Acc : 0.8395
     Batch 050 | Loss : 0.3845 | Acc : 0.8253
     Batch 075 | Loss : 0.3170 | Acc : 0.8519
     Batch 100 | Loss : 0.3547 | Acc : 0.8331
     Batch 125 | Loss : 0.3338 | Acc : 0.8410
     Batch 150 | Loss : 0.3291 | Acc : 0.8521
     Batch 175 | Loss : 0.3065 | Acc : 0.8616
     Batch 200 | Loss : 0.3451 | Acc : 0.8337
     Batch 225 | Loss : 0.3764 | Acc : 0.8159
     Batch 250 | Loss : 0.2846 | Acc : 0.8780
     Batch 275 | Loss : 0.3848 | Acc : 0.8194
     Batch 300 | Loss : 0.3043 | Acc : 0.8558
Epoch 00038 | Train Loss : 0.3447 | Eval Loss : 0.3418 | Train acc : 0.8391 | Eval Acc : 0.8375 | Eval Log. Respected : 0.9319
     Batch 000 | Loss : 0.2822 | Acc : 0.8757
     Batch 025 | Loss : 0.3040 | Acc : 0.8603
     Batch 050 | Loss : 0.3897 | Acc : 0.8113
     Batch 075 | Loss : 0.3818 | Acc : 0.8150
     Batch 100 | Loss : 0.3404 | Acc : 0.8361
     Batch 125 | Loss : 0.3761 | Acc : 0.8192
     Batch 150 | Loss : 0.3906 | Acc : 0.8104
     Batch 175 | Loss : 0.4268 | Acc : 0.7909
     Batch 200 | Loss : 0.3109 | Acc : 0.8572
     Batch 225 | Loss : 0.3160 | Acc : 0.8563
     Batch 250 | Loss : 0.4373 | Acc : 0.7944
     Batch 275 | Loss : 0.4643 | Acc : 0.7679
     Batch 300 | Loss : 0.3266 | Acc : 0.8523
Epoch 00039 | Train Loss : 0.3465 | Eval Loss : 0.3439 | Train acc : 0.8384 | Eval Acc : 0.8355 | Eval Log. Respected : 0.9344
     Batch 000 | Loss : 0.3284 | Acc : 0.8488
     Batch 025 | Loss : 0.3001 | Acc : 0.8650
     Batch 050 | Loss : 0.4742 | Acc : 0.7745
     Batch 075 | Loss : 0.3082 | Acc : 0.8618
     Batch 100 | Loss : 0.3539 | Acc : 0.8374
     Batch 125 | Loss : 0.3076 | Acc : 0.8555
     Batch 150 | Loss : 0.4249 | Acc : 0.7991
     Batch 175 | Loss : 0.3034 | Acc : 0.8698
     Batch 200 | Loss : 0.4067 | Acc : 0.7988
     Batch 225 | Loss : 0.3281 | Acc : 0.8481
     Batch 250 | Loss : 0.2946 | Acc : 0.8719
     Batch 275 | Loss : 0.3076 | Acc : 0.8598
     Batch 300 | Loss : 0.3424 | Acc : 0.8387
Epoch 00040 | Train Loss : 0.3442 | Eval Loss : 0.3403 | Train acc : 0.8394 | Eval Acc : 0.8382 | Eval Log. Respected : 0.9337
     Batch 000 | Loss : 0.4028 | Acc : 0.8063
     Batch 025 | Loss : 0.2797 | Acc : 0.8775
     Batch 050 | Loss : 0.2959 | Acc : 0.8660
     Batch 075 | Loss : 0.3722 | Acc : 0.8297
     Batch 100 | Loss : 0.3414 | Acc : 0.8446
     Batch 125 | Loss : 0.3910 | Acc : 0.8121
     Batch 150 | Loss : 0.3073 | Acc : 0.8529
     Batch 175 | Loss : 0.3263 | Acc : 0.8487
     Batch 200 | Loss : 0.2795 | Acc : 0.8768
     Batch 225 | Loss : 0.3844 | Acc : 0.8143
     Batch 250 | Loss : 0.4514 | Acc : 0.7775
     Batch 275 | Loss : 0.3236 | Acc : 0.8439
     Batch 300 | Loss : 0.3267 | Acc : 0.8429
Epoch 00041 | Train Loss : 0.3442 | Eval Loss : 0.3488 | Train acc : 0.8394 | Eval Acc : 0.8371 | Eval Log. Respected : 0.9483
     Batch 000 | Loss : 0.3489 | Acc : 0.8359
     Batch 025 | Loss : 0.3944 | Acc : 0.8060
     Batch 050 | Loss : 0.3773 | Acc : 0.8265
     Batch 075 | Loss : 0.3946 | Acc : 0.8109
     Batch 100 | Loss : 0.3199 | Acc : 0.8474
     Batch 125 | Loss : 0.3773 | Acc : 0.8177
     Batch 150 | Loss : 0.3521 | Acc : 0.8316
     Batch 175 | Loss : 0.3071 | Acc : 0.8595
     Batch 200 | Loss : 0.3088 | Acc : 0.8525
     Batch 225 | Loss : 0.2777 | Acc : 0.8741
     Batch 250 | Loss : 0.2913 | Acc : 0.8745
     Batch 275 | Loss : 0.3004 | Acc : 0.8588
     Batch 300 | Loss : 0.3141 | Acc : 0.8568
Epoch 00042 | Train Loss : 0.3437 | Eval Loss : 0.3399 | Train acc : 0.8396 | Eval Acc : 0.8376 | Eval Log. Respected : 0.9255
     Batch 000 | Loss : 0.3232 | Acc : 0.8517
     Batch 025 | Loss : 0.3632 | Acc : 0.8285
     Batch 050 | Loss : 0.3330 | Acc : 0.8425
     Batch 075 | Loss : 0.4192 | Acc : 0.7997
     Batch 100 | Loss : 0.3376 | Acc : 0.8391
     Batch 125 | Loss : 0.3526 | Acc : 0.8373
     Batch 150 | Loss : 0.3508 | Acc : 0.8382
     Batch 175 | Loss : 0.3095 | Acc : 0.8529
     Batch 200 | Loss : 0.3079 | Acc : 0.8529
     Batch 225 | Loss : 0.3518 | Acc : 0.8298
     Batch 250 | Loss : 0.4270 | Acc : 0.7916
     Batch 275 | Loss : 0.3237 | Acc : 0.8457
     Batch 300 | Loss : 0.2967 | Acc : 0.8770
Epoch 00043 | Train Loss : 0.3431 | Eval Loss : 0.3401 | Train acc : 0.8400 | Eval Acc : 0.8370 | Eval Log. Respected : 0.9340
     Batch 000 | Loss : 0.3084 | Acc : 0.8671
     Batch 025 | Loss : 0.3356 | Acc : 0.8391
     Batch 050 | Loss : 0.3205 | Acc : 0.8533
     Batch 075 | Loss : 0.3742 | Acc : 0.8180
     Batch 100 | Loss : 0.3692 | Acc : 0.8233
     Batch 125 | Loss : 0.3095 | Acc : 0.8570
     Batch 150 | Loss : 0.3006 | Acc : 0.8595
     Batch 175 | Loss : 0.3360 | Acc : 0.8399
     Batch 200 | Loss : 0.3079 | Acc : 0.8611
     Batch 225 | Loss : 0.4138 | Acc : 0.7971
     Batch 250 | Loss : 0.3103 | Acc : 0.8660
     Batch 275 | Loss : 0.3904 | Acc : 0.8148
     Batch 300 | Loss : 0.3046 | Acc : 0.8596
Epoch 00044 | Train Loss : 0.3427 | Eval Loss : 0.3431 | Train acc : 0.8401 | Eval Acc : 0.8361 | Eval Log. Respected : 0.9294
     Batch 000 | Loss : 0.4577 | Acc : 0.7877
     Batch 025 | Loss : 0.3778 | Acc : 0.8258
     Batch 050 | Loss : 0.3711 | Acc : 0.8276
     Batch 075 | Loss : 0.3522 | Acc : 0.8330
     Batch 100 | Loss : 0.3565 | Acc : 0.8282
     Batch 125 | Loss : 0.3518 | Acc : 0.8362
     Batch 150 | Loss : 0.3332 | Acc : 0.8491
     Batch 175 | Loss : 0.3081 | Acc : 0.8555
     Batch 200 | Loss : 0.3310 | Acc : 0.8557
     Batch 225 | Loss : 0.3584 | Acc : 0.8316
     Batch 250 | Loss : 0.2955 | Acc : 0.8674
     Batch 275 | Loss : 0.3049 | Acc : 0.8564
     Batch 300 | Loss : 0.2918 | Acc : 0.8715
Epoch 00045 | Train Loss : 0.3436 | Eval Loss : 0.3406 | Train acc : 0.8398 | Eval Acc : 0.8379 | Eval Log. Respected : 0.9248
     Batch 000 | Loss : 0.3109 | Acc : 0.8630
     Batch 025 | Loss : 0.3234 | Acc : 0.8526
     Batch 050 | Loss : 0.3042 | Acc : 0.8574
     Batch 075 | Loss : 0.3909 | Acc : 0.8091
     Batch 100 | Loss : 0.3722 | Acc : 0.8211
     Batch 125 | Loss : 0.3460 | Acc : 0.8406
     Batch 150 | Loss : 0.3172 | Acc : 0.8532
     Batch 175 | Loss : 0.2873 | Acc : 0.8739
     Batch 200 | Loss : 0.3321 | Acc : 0.8442
     Batch 225 | Loss : 0.2641 | Acc : 0.8896
     Batch 250 | Loss : 0.3517 | Acc : 0.8311
     Batch 275 | Loss : 0.3576 | Acc : 0.8344
     Batch 300 | Loss : 0.3299 | Acc : 0.8515
Epoch 00046 | Train Loss : 0.3421 | Eval Loss : 0.3400 | Train acc : 0.8406 | Eval Acc : 0.8379 | Eval Log. Respected : 0.9297
Early Stopping
Testing...
Test Loss 0.5914 | Test Acc 0.8332 | Test Log. Res. 0.9313
