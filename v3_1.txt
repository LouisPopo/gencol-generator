Done loading data from cached files.
Training ...
     Batch 000 | Loss : 0.6974 | Acc : 0.4853
     Batch 025 | Loss : 0.6689 | Acc : 0.5761
     Batch 050 | Loss : 0.6542 | Acc : 0.5836
     Batch 075 | Loss : 0.6890 | Acc : 0.5302
     Batch 100 | Loss : 0.6858 | Acc : 0.5479
     Batch 125 | Loss : 0.6876 | Acc : 0.5391
     Batch 150 | Loss : 0.6829 | Acc : 0.5912
     Batch 175 | Loss : 0.6840 | Acc : 0.5658
     Batch 200 | Loss : 0.6721 | Acc : 0.6023
     Batch 225 | Loss : 0.6006 | Acc : 0.6567
     Batch 250 | Loss : 0.6043 | Acc : 0.6524
     Batch 275 | Loss : 0.5537 | Acc : 0.7206
     Batch 300 | Loss : 0.5511 | Acc : 0.7220
Epoch 00000 | Train Loss : 0.6459 | Eval Loss : 0.5178 | Train acc : 0.6087 | Eval Acc : 0.7404 | Eval Log. Respected : 0.9656
     Batch 000 | Loss : 0.4897 | Acc : 0.7651
     Batch 025 | Loss : 0.5095 | Acc : 0.7467
     Batch 050 | Loss : 0.4922 | Acc : 0.7734
     Batch 075 | Loss : 0.4985 | Acc : 0.7540
     Batch 100 | Loss : 0.5446 | Acc : 0.7161
     Batch 125 | Loss : 0.4892 | Acc : 0.7585
     Batch 150 | Loss : 0.5926 | Acc : 0.6915
     Batch 175 | Loss : 0.5680 | Acc : 0.6927
     Batch 200 | Loss : 0.5712 | Acc : 0.6928
     Batch 225 | Loss : 0.5838 | Acc : 0.7105
     Batch 250 | Loss : 0.6539 | Acc : 0.6969
     Batch 275 | Loss : 0.4935 | Acc : 0.7494
     Batch 300 | Loss : 0.4886 | Acc : 0.7640
Epoch 00001 | Train Loss : 0.5075 | Eval Loss : 0.4930 | Train acc : 0.7485 | Eval Acc : 0.7613 | Eval Log. Respected : 0.9344
     Batch 000 | Loss : 0.5134 | Acc : 0.7443
     Batch 025 | Loss : 0.4917 | Acc : 0.7603
     Batch 050 | Loss : 0.4300 | Acc : 0.8177
     Batch 075 | Loss : 0.4479 | Acc : 0.7887
     Batch 100 | Loss : 0.4274 | Acc : 0.8116
     Batch 125 | Loss : 0.5262 | Acc : 0.7259
     Batch 150 | Loss : 0.4490 | Acc : 0.7862
     Batch 175 | Loss : 0.5338 | Acc : 0.7412
     Batch 200 | Loss : 0.4244 | Acc : 0.8107
     Batch 225 | Loss : 0.4538 | Acc : 0.7811
     Batch 250 | Loss : 0.4165 | Acc : 0.8158
     Batch 275 | Loss : 0.4633 | Acc : 0.7775
     Batch 300 | Loss : 0.4896 | Acc : 0.7556
Epoch 00002 | Train Loss : 0.4698 | Eval Loss : 0.4346 | Train acc : 0.7777 | Eval Acc : 0.7984 | Eval Log. Respected : 0.9374
     Batch 000 | Loss : 0.3906 | Acc : 0.8242
     Batch 025 | Loss : 0.3893 | Acc : 0.8232
     Batch 050 | Loss : 0.4160 | Acc : 0.8195
     Batch 075 | Loss : 0.4237 | Acc : 0.8055
     Batch 100 | Loss : 0.3834 | Acc : 0.8283
     Batch 125 | Loss : 0.4057 | Acc : 0.8122
     Batch 150 | Loss : 0.4245 | Acc : 0.8108
     Batch 175 | Loss : 0.4648 | Acc : 0.7699
     Batch 200 | Loss : 0.4626 | Acc : 0.7760
     Batch 225 | Loss : 0.4752 | Acc : 0.7721
     Batch 250 | Loss : 0.4810 | Acc : 0.7620
     Batch 275 | Loss : 0.4482 | Acc : 0.7841
     Batch 300 | Loss : 0.4316 | Acc : 0.7997
Epoch 00003 | Train Loss : 0.4489 | Eval Loss : 0.4245 | Train acc : 0.7886 | Eval Acc : 0.7983 | Eval Log. Respected : 0.9196
     Batch 000 | Loss : 0.4372 | Acc : 0.7916
     Batch 025 | Loss : 0.4660 | Acc : 0.7804
     Batch 050 | Loss : 0.5452 | Acc : 0.7413
     Batch 075 | Loss : 0.4843 | Acc : 0.7597
     Batch 100 | Loss : 0.4394 | Acc : 0.7960
     Batch 125 | Loss : 0.4298 | Acc : 0.7978
     Batch 150 | Loss : 0.5483 | Acc : 0.7453
     Batch 175 | Loss : 0.4367 | Acc : 0.7939
     Batch 200 | Loss : 0.3977 | Acc : 0.8100
     Batch 225 | Loss : 0.4092 | Acc : 0.8076
     Batch 250 | Loss : 0.4252 | Acc : 0.7940
     Batch 275 | Loss : 0.5056 | Acc : 0.7460
     Batch 300 | Loss : 0.3913 | Acc : 0.8226
Epoch 00004 | Train Loss : 0.4388 | Eval Loss : 0.4281 | Train acc : 0.7932 | Eval Acc : 0.8025 | Eval Log. Respected : 0.9737
     Batch 000 | Loss : 0.4086 | Acc : 0.8146
     Batch 025 | Loss : 0.3824 | Acc : 0.8228
     Batch 050 | Loss : 0.3988 | Acc : 0.8203
     Batch 075 | Loss : 0.4101 | Acc : 0.8099
     Batch 100 | Loss : 0.3813 | Acc : 0.8290
     Batch 125 | Loss : 0.4301 | Acc : 0.7921
     Batch 150 | Loss : 0.4652 | Acc : 0.7713
     Batch 175 | Loss : 0.3694 | Acc : 0.8340
     Batch 200 | Loss : 0.5388 | Acc : 0.7537
     Batch 225 | Loss : 0.4151 | Acc : 0.8115
     Batch 250 | Loss : 0.4017 | Acc : 0.8133
     Batch 275 | Loss : 0.3996 | Acc : 0.8124
     Batch 300 | Loss : 0.4251 | Acc : 0.7951
Epoch 00005 | Train Loss : 0.4365 | Eval Loss : 0.4216 | Train acc : 0.7946 | Eval Acc : 0.7989 | Eval Log. Respected : 0.9181
     Batch 000 | Loss : 0.4097 | Acc : 0.8070
     Batch 025 | Loss : 0.3759 | Acc : 0.8253
     Batch 050 | Loss : 0.5356 | Acc : 0.7760
     Batch 075 | Loss : 0.3940 | Acc : 0.8220
     Batch 100 | Loss : 0.4703 | Acc : 0.7823
     Batch 125 | Loss : 0.4531 | Acc : 0.7742
     Batch 150 | Loss : 0.4402 | Acc : 0.7863
     Batch 175 | Loss : 0.4243 | Acc : 0.7928
     Batch 200 | Loss : 0.4241 | Acc : 0.8018
     Batch 225 | Loss : 0.3852 | Acc : 0.8375
     Batch 250 | Loss : 0.4264 | Acc : 0.7906
     Batch 275 | Loss : 0.3898 | Acc : 0.8148
     Batch 300 | Loss : 0.3740 | Acc : 0.8343
Epoch 00006 | Train Loss : 0.4322 | Eval Loss : 0.4116 | Train acc : 0.7972 | Eval Acc : 0.8042 | Eval Log. Respected : 0.9519
     Batch 000 | Loss : 0.4329 | Acc : 0.7936
     Batch 025 | Loss : 0.3930 | Acc : 0.8121
     Batch 050 | Loss : 0.4157 | Acc : 0.8132
     Batch 075 | Loss : 0.3666 | Acc : 0.8346
     Batch 100 | Loss : 0.4240 | Acc : 0.8110
     Batch 125 | Loss : 0.3820 | Acc : 0.8238
     Batch 150 | Loss : 0.4421 | Acc : 0.7851
     Batch 175 | Loss : 0.3626 | Acc : 0.8416
     Batch 200 | Loss : 0.3937 | Acc : 0.8183
     Batch 225 | Loss : 0.4088 | Acc : 0.8054
     Batch 250 | Loss : 0.4751 | Acc : 0.7614
     Batch 275 | Loss : 0.4532 | Acc : 0.7816
     Batch 300 | Loss : 0.5036 | Acc : 0.7544
Epoch 00007 | Train Loss : 0.4306 | Eval Loss : 0.4190 | Train acc : 0.7975 | Eval Acc : 0.7981 | Eval Log. Respected : 0.9566
     Batch 000 | Loss : 0.4251 | Acc : 0.7941
     Batch 025 | Loss : 0.4760 | Acc : 0.7674
     Batch 050 | Loss : 0.4263 | Acc : 0.7932
     Batch 075 | Loss : 0.5144 | Acc : 0.7562
     Batch 100 | Loss : 0.4089 | Acc : 0.8057
     Batch 125 | Loss : 0.4154 | Acc : 0.8161
     Batch 150 | Loss : 0.4319 | Acc : 0.7894
     Batch 175 | Loss : 0.4360 | Acc : 0.7936
     Batch 200 | Loss : 0.4005 | Acc : 0.8116
     Batch 225 | Loss : 0.3978 | Acc : 0.8195
     Batch 250 | Loss : 0.4919 | Acc : 0.7508
     Batch 275 | Loss : 0.4285 | Acc : 0.7908
     Batch 300 | Loss : 0.5440 | Acc : 0.7403
Epoch 00008 | Train Loss : 0.4286 | Eval Loss : 0.3990 | Train acc : 0.7979 | Eval Acc : 0.8115 | Eval Log. Respected : 0.9523
     Batch 000 | Loss : 0.4243 | Acc : 0.7952
     Batch 025 | Loss : 0.3543 | Acc : 0.8420
     Batch 050 | Loss : 0.4230 | Acc : 0.7964
     Batch 075 | Loss : 0.4052 | Acc : 0.8093
     Batch 100 | Loss : 0.4490 | Acc : 0.7751
     Batch 125 | Loss : 0.3288 | Acc : 0.8611
     Batch 150 | Loss : 0.3698 | Acc : 0.8294
     Batch 175 | Loss : 0.3991 | Acc : 0.8164
     Batch 200 | Loss : 0.3723 | Acc : 0.8285
     Batch 225 | Loss : 0.4576 | Acc : 0.7847
     Batch 250 | Loss : 0.3653 | Acc : 0.8351
     Batch 275 | Loss : 0.4167 | Acc : 0.7958
     Batch 300 | Loss : 0.4112 | Acc : 0.8019
Epoch 00009 | Train Loss : 0.4179 | Eval Loss : 0.4284 | Train acc : 0.8035 | Eval Acc : 0.7964 | Eval Log. Respected : 0.8847
     Batch 000 | Loss : 0.4859 | Acc : 0.7519
     Batch 025 | Loss : 0.4309 | Acc : 0.7866
     Batch 050 | Loss : 0.4190 | Acc : 0.8009
     Batch 075 | Loss : 0.4306 | Acc : 0.7958
     Batch 100 | Loss : 0.4533 | Acc : 0.7830
     Batch 125 | Loss : 0.3389 | Acc : 0.8473
     Batch 150 | Loss : 0.4012 | Acc : 0.8125
     Batch 175 | Loss : 0.4652 | Acc : 0.7895
     Batch 200 | Loss : 0.3445 | Acc : 0.8519
     Batch 225 | Loss : 0.3819 | Acc : 0.8256
     Batch 250 | Loss : 0.3495 | Acc : 0.8396
     Batch 275 | Loss : 0.4445 | Acc : 0.7808
     Batch 300 | Loss : 0.3655 | Acc : 0.8321
Epoch 00010 | Train Loss : 0.4179 | Eval Loss : 0.4145 | Train acc : 0.8038 | Eval Acc : 0.8017 | Eval Log. Respected : 0.9228
     Batch 000 | Loss : 0.4363 | Acc : 0.7785
     Batch 025 | Loss : 0.4281 | Acc : 0.7949
     Batch 050 | Loss : 0.4503 | Acc : 0.7758
     Batch 075 | Loss : 0.3608 | Acc : 0.8414
     Batch 100 | Loss : 0.4114 | Acc : 0.8089
     Batch 125 | Loss : 0.5468 | Acc : 0.7454
     Batch 150 | Loss : 0.3603 | Acc : 0.8424
     Batch 175 | Loss : 0.3304 | Acc : 0.8629
     Batch 200 | Loss : 0.3869 | Acc : 0.8163
     Batch 225 | Loss : 0.4334 | Acc : 0.8018
     Batch 250 | Loss : 0.3717 | Acc : 0.8270
     Batch 275 | Loss : 0.4225 | Acc : 0.7883
     Batch 300 | Loss : 0.3510 | Acc : 0.8384
Epoch 00011 | Train Loss : 0.4152 | Eval Loss : 0.3962 | Train acc : 0.8051 | Eval Acc : 0.8147 | Eval Log. Respected : 0.9522
     Batch 000 | Loss : 0.3450 | Acc : 0.8443
     Batch 025 | Loss : 0.3855 | Acc : 0.8161
     Batch 050 | Loss : 0.4672 | Acc : 0.7730
     Batch 075 | Loss : 0.4814 | Acc : 0.7685
     Batch 100 | Loss : 0.4081 | Acc : 0.8073
     Batch 125 | Loss : 0.4838 | Acc : 0.7618
     Batch 150 | Loss : 0.3765 | Acc : 0.8245
     Batch 175 | Loss : 0.3563 | Acc : 0.8382
     Batch 200 | Loss : 0.3805 | Acc : 0.8385
     Batch 225 | Loss : 0.3721 | Acc : 0.8300
     Batch 250 | Loss : 0.4214 | Acc : 0.7936
     Batch 275 | Loss : 0.3503 | Acc : 0.8436
     Batch 300 | Loss : 0.3881 | Acc : 0.8249
Epoch 00012 | Train Loss : 0.4189 | Eval Loss : 0.4016 | Train acc : 0.8023 | Eval Acc : 0.8075 | Eval Log. Respected : 0.9051
     Batch 000 | Loss : 0.4305 | Acc : 0.7896
     Batch 025 | Loss : 0.4255 | Acc : 0.7890
     Batch 050 | Loss : 0.4624 | Acc : 0.7773
     Batch 075 | Loss : 0.4115 | Acc : 0.8015
     Batch 100 | Loss : 0.3612 | Acc : 0.8325
     Batch 125 | Loss : 0.3450 | Acc : 0.8516
     Batch 150 | Loss : 0.3218 | Acc : 0.8661
     Batch 175 | Loss : 0.4225 | Acc : 0.8032
     Batch 200 | Loss : 0.5864 | Acc : 0.7164
     Batch 225 | Loss : 0.4098 | Acc : 0.8060
     Batch 250 | Loss : 0.4854 | Acc : 0.7695
     Batch 275 | Loss : 0.3697 | Acc : 0.8279
     Batch 300 | Loss : 0.3468 | Acc : 0.8498
Epoch 00013 | Train Loss : 0.4112 | Eval Loss : 0.3857 | Train acc : 0.8068 | Eval Acc : 0.8173 | Eval Log. Respected : 0.9286
     Batch 000 | Loss : 0.3635 | Acc : 0.8417
     Batch 025 | Loss : 0.3271 | Acc : 0.8562
     Batch 050 | Loss : 0.3997 | Acc : 0.8090
     Batch 075 | Loss : 0.4838 | Acc : 0.7731
     Batch 100 | Loss : 0.4680 | Acc : 0.7789
     Batch 125 | Loss : 0.4049 | Acc : 0.8094
     Batch 150 | Loss : 0.4094 | Acc : 0.7994
     Batch 175 | Loss : 0.3990 | Acc : 0.8082
     Batch 200 | Loss : 0.4943 | Acc : 0.7575
     Batch 225 | Loss : 0.3467 | Acc : 0.8402
     Batch 250 | Loss : 0.4110 | Acc : 0.8059
     Batch 275 | Loss : 0.3938 | Acc : 0.8196
     Batch 300 | Loss : 0.4457 | Acc : 0.7779
Epoch 00014 | Train Loss : 0.4045 | Eval Loss : 0.3951 | Train acc : 0.8100 | Eval Acc : 0.8134 | Eval Log. Respected : 0.9006
     Batch 000 | Loss : 0.3733 | Acc : 0.8323
     Batch 025 | Loss : 0.3623 | Acc : 0.8318
     Batch 050 | Loss : 0.3571 | Acc : 0.8440
     Batch 075 | Loss : 0.3450 | Acc : 0.8521
     Batch 100 | Loss : 0.3382 | Acc : 0.8534
     Batch 125 | Loss : 0.4853 | Acc : 0.7815
     Batch 150 | Loss : 0.5048 | Acc : 0.7561
     Batch 175 | Loss : 0.4044 | Acc : 0.8097
     Batch 200 | Loss : 0.4222 | Acc : 0.7935
     Batch 225 | Loss : 0.4110 | Acc : 0.7985
     Batch 250 | Loss : 0.3407 | Acc : 0.8479
     Batch 275 | Loss : 0.4312 | Acc : 0.7912
     Batch 300 | Loss : 0.3410 | Acc : 0.8434
Epoch 00015 | Train Loss : 0.4046 | Eval Loss : 0.3988 | Train acc : 0.8106 | Eval Acc : 0.8110 | Eval Log. Respected : 0.8981
     Batch 000 | Loss : 0.3732 | Acc : 0.8299
     Batch 025 | Loss : 0.3933 | Acc : 0.8148
     Batch 050 | Loss : 0.3742 | Acc : 0.8368
     Batch 075 | Loss : 0.4802 | Acc : 0.7546
     Batch 100 | Loss : 0.4999 | Acc : 0.7667
     Batch 125 | Loss : 0.3686 | Acc : 0.8317
     Batch 150 | Loss : 0.5086 | Acc : 0.7482
     Batch 175 | Loss : 0.4094 | Acc : 0.8077
     Batch 200 | Loss : 0.4300 | Acc : 0.7916
     Batch 225 | Loss : 0.3747 | Acc : 0.8285
     Batch 250 | Loss : 0.3471 | Acc : 0.8477
     Batch 275 | Loss : 0.3962 | Acc : 0.8108
     Batch 300 | Loss : 0.4357 | Acc : 0.7795
Epoch 00016 | Train Loss : 0.4054 | Eval Loss : 0.3973 | Train acc : 0.8092 | Eval Acc : 0.8082 | Eval Log. Respected : 0.8974
     Batch 000 | Loss : 0.4693 | Acc : 0.7684
     Batch 025 | Loss : 0.3865 | Acc : 0.8212
     Batch 050 | Loss : 0.4677 | Acc : 0.7726
     Batch 075 | Loss : 0.4156 | Acc : 0.7979
     Batch 100 | Loss : 0.3417 | Acc : 0.8581
     Batch 125 | Loss : 0.4281 | Acc : 0.7936
     Batch 150 | Loss : 0.4354 | Acc : 0.7884
     Batch 175 | Loss : 0.3331 | Acc : 0.8544
     Batch 200 | Loss : 0.4379 | Acc : 0.7885
     Batch 225 | Loss : 0.3649 | Acc : 0.8357
     Batch 250 | Loss : 0.4168 | Acc : 0.7980
     Batch 275 | Loss : 0.3418 | Acc : 0.8479
     Batch 300 | Loss : 0.3431 | Acc : 0.8540
Epoch 00017 | Train Loss : 0.4079 | Eval Loss : 0.4125 | Train acc : 0.8074 | Eval Acc : 0.8044 | Eval Log. Respected : 0.9543
     Batch 000 | Loss : 0.4073 | Acc : 0.8110
     Batch 025 | Loss : 0.3729 | Acc : 0.8229
     Batch 050 | Loss : 0.5348 | Acc : 0.7412
     Batch 075 | Loss : 0.4791 | Acc : 0.7691
     Batch 100 | Loss : 0.3752 | Acc : 0.8268
     Batch 125 | Loss : 0.4150 | Acc : 0.8043
     Batch 150 | Loss : 0.4378 | Acc : 0.7792
     Batch 175 | Loss : 0.4407 | Acc : 0.7912
     Batch 200 | Loss : 0.3565 | Acc : 0.8434
     Batch 225 | Loss : 0.4417 | Acc : 0.7771
     Batch 250 | Loss : 0.4448 | Acc : 0.7833
     Batch 275 | Loss : 0.4566 | Acc : 0.7862
     Batch 300 | Loss : 0.4603 | Acc : 0.7815
Epoch 00018 | Train Loss : 0.4016 | Eval Loss : 0.3923 | Train acc : 0.8105 | Eval Acc : 0.8130 | Eval Log. Respected : 0.9275
     Batch 000 | Loss : 0.4319 | Acc : 0.7879
     Batch 025 | Loss : 0.4466 | Acc : 0.7840
     Batch 050 | Loss : 0.4033 | Acc : 0.8065
     Batch 075 | Loss : 0.3696 | Acc : 0.8282
     Batch 100 | Loss : 0.3420 | Acc : 0.8460
     Batch 125 | Loss : 0.3607 | Acc : 0.8340
     Batch 150 | Loss : 0.3544 | Acc : 0.8439
     Batch 175 | Loss : 0.3585 | Acc : 0.8392
     Batch 200 | Loss : 0.3627 | Acc : 0.8436
     Batch 225 | Loss : 0.3463 | Acc : 0.8477
     Batch 250 | Loss : 0.3408 | Acc : 0.8431
     Batch 275 | Loss : 0.3911 | Acc : 0.8125
     Batch 300 | Loss : 0.4397 | Acc : 0.8002
Epoch 00019 | Train Loss : 0.3987 | Eval Loss : 0.3871 | Train acc : 0.8117 | Eval Acc : 0.8181 | Eval Log. Respected : 0.8986
     Batch 000 | Loss : 0.4390 | Acc : 0.7836
     Batch 025 | Loss : 0.3657 | Acc : 0.8305
     Batch 050 | Loss : 0.3632 | Acc : 0.8368
     Batch 075 | Loss : 0.4122 | Acc : 0.7971
     Batch 100 | Loss : 0.3617 | Acc : 0.8479
     Batch 125 | Loss : 0.3763 | Acc : 0.8263
     Batch 150 | Loss : 0.3111 | Acc : 0.8689
     Batch 175 | Loss : 0.3706 | Acc : 0.8254
     Batch 200 | Loss : 0.4505 | Acc : 0.7771
     Batch 225 | Loss : 0.4242 | Acc : 0.7892
     Batch 250 | Loss : 0.3191 | Acc : 0.8640
     Batch 275 | Loss : 0.4169 | Acc : 0.7926
     Batch 300 | Loss : 0.3552 | Acc : 0.8329
Epoch 00020 | Train Loss : 0.3991 | Eval Loss : 0.3835 | Train acc : 0.8118 | Eval Acc : 0.8152 | Eval Log. Respected : 0.9128
     Batch 000 | Loss : 0.3365 | Acc : 0.8493
     Batch 025 | Loss : 0.3720 | Acc : 0.8292
     Batch 050 | Loss : 0.4128 | Acc : 0.7994
     Batch 075 | Loss : 0.4080 | Acc : 0.8048
     Batch 100 | Loss : 0.3769 | Acc : 0.8201
     Batch 125 | Loss : 0.4405 | Acc : 0.7886
     Batch 150 | Loss : 0.3286 | Acc : 0.8573
     Batch 175 | Loss : 0.4516 | Acc : 0.7736
     Batch 200 | Loss : 0.3283 | Acc : 0.8525
     Batch 225 | Loss : 0.4881 | Acc : 0.7524
     Batch 250 | Loss : 0.4132 | Acc : 0.7982
     Batch 275 | Loss : 0.3421 | Acc : 0.8504
     Batch 300 | Loss : 0.4802 | Acc : 0.7533
Epoch 00021 | Train Loss : 0.3946 | Eval Loss : 0.3796 | Train acc : 0.8135 | Eval Acc : 0.8201 | Eval Log. Respected : 0.9528
     Batch 000 | Loss : 0.3643 | Acc : 0.8303
     Batch 025 | Loss : 0.4240 | Acc : 0.7916
     Batch 050 | Loss : 0.4300 | Acc : 0.7934
     Batch 075 | Loss : 0.4632 | Acc : 0.7737
     Batch 100 | Loss : 0.3559 | Acc : 0.8345
     Batch 125 | Loss : 0.4071 | Acc : 0.7972
     Batch 150 | Loss : 0.4494 | Acc : 0.7759
     Batch 175 | Loss : 0.3277 | Acc : 0.8548
     Batch 200 | Loss : 0.3386 | Acc : 0.8504
     Batch 225 | Loss : 0.3873 | Acc : 0.8129
     Batch 250 | Loss : 0.3139 | Acc : 0.8630
     Batch 275 | Loss : 0.3277 | Acc : 0.8557
     Batch 300 | Loss : 0.4304 | Acc : 0.7981
Epoch 00022 | Train Loss : 0.3943 | Eval Loss : 0.3916 | Train acc : 0.8142 | Eval Acc : 0.8127 | Eval Log. Respected : 0.8722
     Batch 000 | Loss : 0.4131 | Acc : 0.8022
     Batch 025 | Loss : 0.3815 | Acc : 0.8221
     Batch 050 | Loss : 0.3201 | Acc : 0.8637
     Batch 075 | Loss : 0.3859 | Acc : 0.8173
     Batch 100 | Loss : 0.3343 | Acc : 0.8641
     Batch 125 | Loss : 0.3524 | Acc : 0.8369
     Batch 150 | Loss : 0.3094 | Acc : 0.8605
     Batch 175 | Loss : 0.3781 | Acc : 0.8172
     Batch 200 | Loss : 0.3705 | Acc : 0.8241
     Batch 225 | Loss : 0.4969 | Acc : 0.7485
     Batch 250 | Loss : 0.3318 | Acc : 0.8520
     Batch 275 | Loss : 0.3882 | Acc : 0.8159
     Batch 300 | Loss : 0.3532 | Acc : 0.8390
Epoch 00023 | Train Loss : 0.3940 | Eval Loss : 0.3814 | Train acc : 0.8139 | Eval Acc : 0.8172 | Eval Log. Respected : 0.9058
     Batch 000 | Loss : 0.4079 | Acc : 0.7981
     Batch 025 | Loss : 0.4371 | Acc : 0.7876
     Batch 050 | Loss : 0.3200 | Acc : 0.8590
     Batch 075 | Loss : 0.3406 | Acc : 0.8524
     Batch 100 | Loss : 0.3671 | Acc : 0.8248
     Batch 125 | Loss : 0.4539 | Acc : 0.7732
     Batch 150 | Loss : 0.4352 | Acc : 0.7848
     Batch 175 | Loss : 0.4420 | Acc : 0.7837
     Batch 200 | Loss : 0.4569 | Acc : 0.7809
     Batch 225 | Loss : 0.3241 | Acc : 0.8529
     Batch 250 | Loss : 0.4173 | Acc : 0.7973
     Batch 275 | Loss : 0.3639 | Acc : 0.8384
     Batch 300 | Loss : 0.3198 | Acc : 0.8553
Epoch 00024 | Train Loss : 0.3942 | Eval Loss : 0.3805 | Train acc : 0.8146 | Eval Acc : 0.8162 | Eval Log. Respected : 0.9105
     Batch 000 | Loss : 0.4393 | Acc : 0.7813
     Batch 025 | Loss : 0.3663 | Acc : 0.8236
     Batch 050 | Loss : 0.4352 | Acc : 0.7781
     Batch 075 | Loss : 0.4115 | Acc : 0.8005
     Batch 100 | Loss : 0.3375 | Acc : 0.8377
     Batch 125 | Loss : 0.3295 | Acc : 0.8536
     Batch 150 | Loss : 0.3812 | Acc : 0.8154
     Batch 175 | Loss : 0.4238 | Acc : 0.7961
     Batch 200 | Loss : 0.3153 | Acc : 0.8565
     Batch 225 | Loss : 0.5033 | Acc : 0.7449
     Batch 250 | Loss : 0.3738 | Acc : 0.8229
     Batch 275 | Loss : 0.3785 | Acc : 0.8200
     Batch 300 | Loss : 0.3320 | Acc : 0.8516
Epoch 00025 | Train Loss : 0.3910 | Eval Loss : 0.3862 | Train acc : 0.8155 | Eval Acc : 0.8171 | Eval Log. Respected : 0.9065
     Batch 000 | Loss : 0.4548 | Acc : 0.7659
     Batch 025 | Loss : 0.3323 | Acc : 0.8584
     Batch 050 | Loss : 0.4744 | Acc : 0.7819
     Batch 075 | Loss : 0.3742 | Acc : 0.8295
     Batch 100 | Loss : 0.4694 | Acc : 0.7660
     Batch 125 | Loss : 0.4542 | Acc : 0.7800
     Batch 150 | Loss : 0.4084 | Acc : 0.7994
     Batch 175 | Loss : 0.5068 | Acc : 0.7398
     Batch 200 | Loss : 0.3525 | Acc : 0.8423
     Batch 225 | Loss : 0.3336 | Acc : 0.8533
     Batch 250 | Loss : 0.5383 | Acc : 0.7477
     Batch 275 | Loss : 0.3602 | Acc : 0.8305
     Batch 300 | Loss : 0.4148 | Acc : 0.7983
Epoch 00026 | Train Loss : 0.3904 | Eval Loss : 0.4032 | Train acc : 0.8157 | Eval Acc : 0.8035 | Eval Log. Respected : 0.9183
     Batch 000 | Loss : 0.3599 | Acc : 0.8351
     Batch 025 | Loss : 0.4218 | Acc : 0.7998
     Batch 050 | Loss : 0.3245 | Acc : 0.8507
     Batch 075 | Loss : 0.3326 | Acc : 0.8541
     Batch 100 | Loss : 0.4882 | Acc : 0.7576
     Batch 125 | Loss : 0.4278 | Acc : 0.7813
     Batch 150 | Loss : 0.3971 | Acc : 0.8032
     Batch 175 | Loss : 0.4383 | Acc : 0.7821
     Batch 200 | Loss : 0.4454 | Acc : 0.7800
     Batch 225 | Loss : 0.3518 | Acc : 0.8461
     Batch 250 | Loss : 0.4517 | Acc : 0.7851
     Batch 275 | Loss : 0.3766 | Acc : 0.8211
     Batch 300 | Loss : 0.4189 | Acc : 0.8054
Epoch 00027 | Train Loss : 0.3907 | Eval Loss : 0.3837 | Train acc : 0.8156 | Eval Acc : 0.8182 | Eval Log. Respected : 0.9108
     Batch 000 | Loss : 0.4074 | Acc : 0.8016
     Batch 025 | Loss : 0.3931 | Acc : 0.8124
     Batch 050 | Loss : 0.5098 | Acc : 0.7447
     Batch 075 | Loss : 0.4171 | Acc : 0.7921
     Batch 100 | Loss : 0.4256 | Acc : 0.7920
     Batch 125 | Loss : 0.3490 | Acc : 0.8436
     Batch 150 | Loss : 0.4113 | Acc : 0.8112
     Batch 175 | Loss : 0.4382 | Acc : 0.7850
     Batch 200 | Loss : 0.3127 | Acc : 0.8706
     Batch 225 | Loss : 0.4411 | Acc : 0.7926
     Batch 250 | Loss : 0.3432 | Acc : 0.8409
     Batch 275 | Loss : 0.3476 | Acc : 0.8360
     Batch 300 | Loss : 0.3890 | Acc : 0.8337
Epoch 00028 | Train Loss : 0.3931 | Eval Loss : 0.3863 | Train acc : 0.8149 | Eval Acc : 0.8143 | Eval Log. Respected : 0.9134
     Batch 000 | Loss : 0.4608 | Acc : 0.7719
     Batch 025 | Loss : 0.3668 | Acc : 0.8285
     Batch 050 | Loss : 0.5248 | Acc : 0.7498
     Batch 075 | Loss : 0.3773 | Acc : 0.8131
     Batch 100 | Loss : 0.4494 | Acc : 0.7719
     Batch 125 | Loss : 0.3994 | Acc : 0.7997
     Batch 150 | Loss : 0.3518 | Acc : 0.8425
     Batch 175 | Loss : 0.4034 | Acc : 0.8087
     Batch 200 | Loss : 0.4048 | Acc : 0.8122
     Batch 225 | Loss : 0.3444 | Acc : 0.8416
     Batch 250 | Loss : 0.3481 | Acc : 0.8394
     Batch 275 | Loss : 0.3302 | Acc : 0.8564
     Batch 300 | Loss : 0.3929 | Acc : 0.8113
Epoch 00029 | Train Loss : 0.3883 | Eval Loss : 0.3706 | Train acc : 0.8169 | Eval Acc : 0.8220 | Eval Log. Respected : 0.9138
     Batch 000 | Loss : 0.4131 | Acc : 0.7933
     Batch 025 | Loss : 0.4244 | Acc : 0.7912
     Batch 050 | Loss : 0.4021 | Acc : 0.8009
     Batch 075 | Loss : 0.3601 | Acc : 0.8387
     Batch 100 | Loss : 0.3338 | Acc : 0.8519
     Batch 125 | Loss : 0.5669 | Acc : 0.7423
     Batch 150 | Loss : 0.3982 | Acc : 0.8065
     Batch 175 | Loss : 0.4269 | Acc : 0.7928
     Batch 200 | Loss : 0.3326 | Acc : 0.8501
     Batch 225 | Loss : 0.3281 | Acc : 0.8526
     Batch 250 | Loss : 0.4597 | Acc : 0.7728
     Batch 275 | Loss : 0.3413 | Acc : 0.8441
     Batch 300 | Loss : 0.3827 | Acc : 0.8230
Epoch 00030 | Train Loss : 0.3867 | Eval Loss : 0.3910 | Train acc : 0.8173 | Eval Acc : 0.8168 | Eval Log. Respected : 0.9621
     Batch 000 | Loss : 0.5429 | Acc : 0.7486
     Batch 025 | Loss : 0.3735 | Acc : 0.8209
     Batch 050 | Loss : 0.4882 | Acc : 0.7594
     Batch 075 | Loss : 0.3896 | Acc : 0.8129
     Batch 100 | Loss : 0.3972 | Acc : 0.8079
     Batch 125 | Loss : 0.3549 | Acc : 0.8340
     Batch 150 | Loss : 0.3790 | Acc : 0.8330
     Batch 175 | Loss : 0.4769 | Acc : 0.7565
     Batch 200 | Loss : 0.3757 | Acc : 0.8197
     Batch 225 | Loss : 0.4074 | Acc : 0.8021
     Batch 250 | Loss : 0.4366 | Acc : 0.7949
     Batch 275 | Loss : 0.3308 | Acc : 0.8498
     Batch 300 | Loss : 0.4302 | Acc : 0.7917
Epoch 00031 | Train Loss : 0.3888 | Eval Loss : 0.3772 | Train acc : 0.8171 | Eval Acc : 0.8200 | Eval Log. Respected : 0.9423
     Batch 000 | Loss : 0.4457 | Acc : 0.7930
     Batch 025 | Loss : 0.4743 | Acc : 0.7709
     Batch 050 | Loss : 0.3559 | Acc : 0.8462
     Batch 075 | Loss : 0.3518 | Acc : 0.8384
     Batch 100 | Loss : 0.3926 | Acc : 0.8068
     Batch 125 | Loss : 0.4933 | Acc : 0.7532
     Batch 150 | Loss : 0.4721 | Acc : 0.7586
     Batch 175 | Loss : 0.3896 | Acc : 0.8305
     Batch 200 | Loss : 0.4151 | Acc : 0.7954
     Batch 225 | Loss : 0.3580 | Acc : 0.8340
     Batch 250 | Loss : 0.3665 | Acc : 0.8366
     Batch 275 | Loss : 0.3870 | Acc : 0.8130
     Batch 300 | Loss : 0.3151 | Acc : 0.8633
Epoch 00032 | Train Loss : 0.3893 | Eval Loss : 0.3736 | Train acc : 0.8165 | Eval Acc : 0.8209 | Eval Log. Respected : 0.9228
     Batch 000 | Loss : 0.4014 | Acc : 0.8107
     Batch 025 | Loss : 0.3551 | Acc : 0.8310
     Batch 050 | Loss : 0.3056 | Acc : 0.8686
     Batch 075 | Loss : 0.4244 | Acc : 0.7915
     Batch 100 | Loss : 0.3245 | Acc : 0.8532
     Batch 125 | Loss : 0.4034 | Acc : 0.8056
     Batch 150 | Loss : 0.3643 | Acc : 0.8285
     Batch 175 | Loss : 0.4376 | Acc : 0.7926
     Batch 200 | Loss : 0.3656 | Acc : 0.8365
     Batch 225 | Loss : 0.4742 | Acc : 0.7581
     Batch 250 | Loss : 0.4009 | Acc : 0.8076
     Batch 275 | Loss : 0.3255 | Acc : 0.8577
     Batch 300 | Loss : 0.3421 | Acc : 0.8511
Epoch 00033 | Train Loss : 0.3859 | Eval Loss : 0.3805 | Train acc : 0.8180 | Eval Acc : 0.8193 | Eval Log. Respected : 0.9472
     Batch 000 | Loss : 0.4255 | Acc : 0.7997
     Batch 025 | Loss : 0.4111 | Acc : 0.7975
     Batch 050 | Loss : 0.3972 | Acc : 0.8112
     Batch 075 | Loss : 0.4221 | Acc : 0.8003
     Batch 100 | Loss : 0.4495 | Acc : 0.7734
     Batch 125 | Loss : 0.3632 | Acc : 0.8277
     Batch 150 | Loss : 0.3871 | Acc : 0.8089
     Batch 175 | Loss : 0.4141 | Acc : 0.7958
     Batch 200 | Loss : 0.4238 | Acc : 0.7845
     Batch 225 | Loss : 0.4228 | Acc : 0.7940
     Batch 250 | Loss : 0.3221 | Acc : 0.8546
     Batch 275 | Loss : 0.3087 | Acc : 0.8682
     Batch 300 | Loss : 0.3399 | Acc : 0.8495
Epoch 00034 | Train Loss : 0.3847 | Eval Loss : 0.3816 | Train acc : 0.8190 | Eval Acc : 0.8171 | Eval Log. Respected : 0.9386
     Batch 000 | Loss : 0.4965 | Acc : 0.7627
     Batch 025 | Loss : 0.3675 | Acc : 0.8196
     Batch 050 | Loss : 0.4007 | Acc : 0.8166
     Batch 075 | Loss : 0.4558 | Acc : 0.7779
     Batch 100 | Loss : 0.3798 | Acc : 0.8187
     Batch 125 | Loss : 0.3552 | Acc : 0.8284
     Batch 150 | Loss : 0.4747 | Acc : 0.7670
     Batch 175 | Loss : 0.3976 | Acc : 0.8095
     Batch 200 | Loss : 0.3427 | Acc : 0.8415
     Batch 225 | Loss : 0.4274 | Acc : 0.7916
     Batch 250 | Loss : 0.5340 | Acc : 0.7431
     Batch 275 | Loss : 0.3970 | Acc : 0.8042
     Batch 300 | Loss : 0.3726 | Acc : 0.8191
Epoch 00035 | Train Loss : 0.3875 | Eval Loss : 0.3849 | Train acc : 0.8173 | Eval Acc : 0.8168 | Eval Log. Respected : 0.9090
     Batch 000 | Loss : 0.3697 | Acc : 0.8261
     Batch 025 | Loss : 0.4236 | Acc : 0.7931
     Batch 050 | Loss : 0.4194 | Acc : 0.7928
     Batch 075 | Loss : 0.4023 | Acc : 0.8018
     Batch 100 | Loss : 0.4126 | Acc : 0.8064
     Batch 125 | Loss : 0.3704 | Acc : 0.8276
     Batch 150 | Loss : 0.4102 | Acc : 0.7943
     Batch 175 | Loss : 0.3370 | Acc : 0.8517
     Batch 200 | Loss : 0.3335 | Acc : 0.8449
     Batch 225 | Loss : 0.3296 | Acc : 0.8573
     Batch 250 | Loss : 0.3680 | Acc : 0.8183
     Batch 275 | Loss : 0.4868 | Acc : 0.7539
     Batch 300 | Loss : 0.4183 | Acc : 0.7867
Epoch 00036 | Train Loss : 0.3845 | Eval Loss : 0.3744 | Train acc : 0.8181 | Eval Acc : 0.8190 | Eval Log. Respected : 0.9409
     Batch 000 | Loss : 0.3490 | Acc : 0.8344
     Batch 025 | Loss : 0.3596 | Acc : 0.8367
     Batch 050 | Loss : 0.3791 | Acc : 0.8144
     Batch 075 | Loss : 0.4356 | Acc : 0.7859
     Batch 100 | Loss : 0.4056 | Acc : 0.8106
     Batch 125 | Loss : 0.4985 | Acc : 0.7613
     Batch 150 | Loss : 0.3336 | Acc : 0.8503
     Batch 175 | Loss : 0.3945 | Acc : 0.8077
     Batch 200 | Loss : 0.4413 | Acc : 0.7796
     Batch 225 | Loss : 0.4588 | Acc : 0.7757
     Batch 250 | Loss : 0.3305 | Acc : 0.8529
     Batch 275 | Loss : 0.3669 | Acc : 0.8265
     Batch 300 | Loss : 0.4188 | Acc : 0.7884
Epoch 00037 | Train Loss : 0.3841 | Eval Loss : 0.3776 | Train acc : 0.8189 | Eval Acc : 0.8201 | Eval Log. Respected : 0.9281
     Batch 000 | Loss : 0.4322 | Acc : 0.7966
     Batch 025 | Loss : 0.4357 | Acc : 0.7805
     Batch 050 | Loss : 0.3709 | Acc : 0.8246
     Batch 075 | Loss : 0.4293 | Acc : 0.7892
     Batch 100 | Loss : 0.3632 | Acc : 0.8219
     Batch 125 | Loss : 0.3456 | Acc : 0.8407
     Batch 150 | Loss : 0.3588 | Acc : 0.8381
     Batch 175 | Loss : 0.3421 | Acc : 0.8425
     Batch 200 | Loss : 0.3417 | Acc : 0.8439
     Batch 225 | Loss : 0.3412 | Acc : 0.8522
     Batch 250 | Loss : 0.3657 | Acc : 0.8437
     Batch 275 | Loss : 0.3691 | Acc : 0.8317
     Batch 300 | Loss : 0.3518 | Acc : 0.8351
Epoch 00038 | Train Loss : 0.3837 | Eval Loss : 0.3682 | Train acc : 0.8191 | Eval Acc : 0.8232 | Eval Log. Respected : 0.9298
     Batch 000 | Loss : 0.4847 | Acc : 0.7484
     Batch 025 | Loss : 0.3624 | Acc : 0.8212
     Batch 050 | Loss : 0.3478 | Acc : 0.8384
     Batch 075 | Loss : 0.3672 | Acc : 0.8354
     Batch 100 | Loss : 0.3188 | Acc : 0.8527
     Batch 125 | Loss : 0.3285 | Acc : 0.8504
     Batch 150 | Loss : 0.4249 | Acc : 0.7923
     Batch 175 | Loss : 0.3150 | Acc : 0.8577
     Batch 200 | Loss : 0.4302 | Acc : 0.7922
     Batch 225 | Loss : 0.4018 | Acc : 0.8101
     Batch 250 | Loss : 0.3769 | Acc : 0.8245
     Batch 275 | Loss : 0.3359 | Acc : 0.8555
     Batch 300 | Loss : 0.4129 | Acc : 0.7963
Epoch 00039 | Train Loss : 0.3846 | Eval Loss : 0.3824 | Train acc : 0.8185 | Eval Acc : 0.8153 | Eval Log. Respected : 0.9116
     Batch 000 | Loss : 0.3785 | Acc : 0.8252
     Batch 025 | Loss : 0.4241 | Acc : 0.7995
     Batch 050 | Loss : 0.3620 | Acc : 0.8413
     Batch 075 | Loss : 0.4022 | Acc : 0.8011
     Batch 100 | Loss : 0.4712 | Acc : 0.7838
     Batch 125 | Loss : 0.3333 | Acc : 0.8515
     Batch 150 | Loss : 0.3442 | Acc : 0.8425
     Batch 175 | Loss : 0.3170 | Acc : 0.8593
     Batch 200 | Loss : 0.3638 | Acc : 0.8408
     Batch 225 | Loss : 0.3690 | Acc : 0.8283
     Batch 250 | Loss : 0.4178 | Acc : 0.7957
     Batch 275 | Loss : 0.3818 | Acc : 0.8180
     Batch 300 | Loss : 0.4518 | Acc : 0.7872
Epoch 00040 | Train Loss : 0.3827 | Eval Loss : 0.3895 | Train acc : 0.8197 | Eval Acc : 0.8172 | Eval Log. Respected : 0.9421
     Batch 000 | Loss : 0.3082 | Acc : 0.8587
     Batch 025 | Loss : 0.3792 | Acc : 0.8128
     Batch 050 | Loss : 0.3473 | Acc : 0.8432
     Batch 075 | Loss : 0.3751 | Acc : 0.8191
     Batch 100 | Loss : 0.4182 | Acc : 0.7981
     Batch 125 | Loss : 0.3413 | Acc : 0.8413
     Batch 150 | Loss : 0.3969 | Acc : 0.8112
     Batch 175 | Loss : 0.4323 | Acc : 0.7859
     Batch 200 | Loss : 0.3224 | Acc : 0.8513
     Batch 225 | Loss : 0.3605 | Acc : 0.8327
     Batch 250 | Loss : 0.4381 | Acc : 0.7880
     Batch 275 | Loss : 0.4330 | Acc : 0.7851
     Batch 300 | Loss : 0.4106 | Acc : 0.8013
Epoch 00041 | Train Loss : 0.3827 | Eval Loss : 0.3677 | Train acc : 0.8193 | Eval Acc : 0.8240 | Eval Log. Respected : 0.8971
     Batch 000 | Loss : 0.3244 | Acc : 0.8539
     Batch 025 | Loss : 0.3182 | Acc : 0.8543
     Batch 050 | Loss : 0.3141 | Acc : 0.8664
     Batch 075 | Loss : 0.3802 | Acc : 0.8167
     Batch 100 | Loss : 0.3885 | Acc : 0.8060
     Batch 125 | Loss : 0.3684 | Acc : 0.8268
     Batch 150 | Loss : 0.3146 | Acc : 0.8543
     Batch 175 | Loss : 0.4138 | Acc : 0.7950
     Batch 200 | Loss : 0.3168 | Acc : 0.8603
     Batch 225 | Loss : 0.3214 | Acc : 0.8560
     Batch 250 | Loss : 0.4540 | Acc : 0.7686
     Batch 275 | Loss : 0.4203 | Acc : 0.7892
     Batch 300 | Loss : 0.4245 | Acc : 0.7957
Epoch 00042 | Train Loss : 0.3828 | Eval Loss : 0.3714 | Train acc : 0.8196 | Eval Acc : 0.8236 | Eval Log. Respected : 0.9318
     Batch 000 | Loss : 0.3246 | Acc : 0.8592
     Batch 025 | Loss : 0.3326 | Acc : 0.8479
     Batch 050 | Loss : 0.3935 | Acc : 0.8166
     Batch 075 | Loss : 0.4064 | Acc : 0.8082
     Batch 100 | Loss : 0.4452 | Acc : 0.7891
     Batch 125 | Loss : 0.3228 | Acc : 0.8656
     Batch 150 | Loss : 0.5457 | Acc : 0.7436
     Batch 175 | Loss : 0.3743 | Acc : 0.8260
     Batch 200 | Loss : 0.3302 | Acc : 0.8605
     Batch 225 | Loss : 0.4393 | Acc : 0.7927
     Batch 250 | Loss : 0.4718 | Acc : 0.7854
     Batch 275 | Loss : 0.4189 | Acc : 0.7971
     Batch 300 | Loss : 0.3182 | Acc : 0.8564
Epoch 00043 | Train Loss : 0.3862 | Eval Loss : 0.3749 | Train acc : 0.8179 | Eval Acc : 0.8216 | Eval Log. Respected : 0.9079
     Batch 000 | Loss : 0.4360 | Acc : 0.7902
     Batch 025 | Loss : 0.4580 | Acc : 0.7751
     Batch 050 | Loss : 0.4827 | Acc : 0.7751
     Batch 075 | Loss : 0.2972 | Acc : 0.8785
     Batch 100 | Loss : 0.5460 | Acc : 0.7274
     Batch 125 | Loss : 0.5109 | Acc : 0.7787
     Batch 150 | Loss : 0.3648 | Acc : 0.8272
     Batch 175 | Loss : 0.3822 | Acc : 0.8158
     Batch 200 | Loss : 0.3483 | Acc : 0.8426
     Batch 225 | Loss : 0.3284 | Acc : 0.8537
     Batch 250 | Loss : 0.3581 | Acc : 0.8219
     Batch 275 | Loss : 0.4466 | Acc : 0.7879
     Batch 300 | Loss : 0.4132 | Acc : 0.7964
Epoch 00044 | Train Loss : 0.3798 | Eval Loss : 0.3635 | Train acc : 0.8209 | Eval Acc : 0.8256 | Eval Log. Respected : 0.9136
     Batch 000 | Loss : 0.3042 | Acc : 0.8688
     Batch 025 | Loss : 0.3812 | Acc : 0.8109
     Batch 050 | Loss : 0.3484 | Acc : 0.8386
     Batch 075 | Loss : 0.3301 | Acc : 0.8519
     Batch 100 | Loss : 0.3325 | Acc : 0.8526
     Batch 125 | Loss : 0.3965 | Acc : 0.8125
     Batch 150 | Loss : 0.3463 | Acc : 0.8356
     Batch 175 | Loss : 0.3480 | Acc : 0.8361
     Batch 200 | Loss : 0.4252 | Acc : 0.7821
     Batch 225 | Loss : 0.3239 | Acc : 0.8596
     Batch 250 | Loss : 0.3445 | Acc : 0.8510
     Batch 275 | Loss : 0.3742 | Acc : 0.8158
     Batch 300 | Loss : 0.4186 | Acc : 0.7994
Epoch 00045 | Train Loss : 0.3800 | Eval Loss : 0.3845 | Train acc : 0.8205 | Eval Acc : 0.8203 | Eval Log. Respected : 0.9111
     Batch 000 | Loss : 0.3675 | Acc : 0.8417
     Batch 025 | Loss : 0.3815 | Acc : 0.8141
     Batch 050 | Loss : 0.3275 | Acc : 0.8475
     Batch 075 | Loss : 0.3795 | Acc : 0.8092
     Batch 100 | Loss : 0.3714 | Acc : 0.8244
     Batch 125 | Loss : 0.3562 | Acc : 0.8277
     Batch 150 | Loss : 0.3973 | Acc : 0.8067
     Batch 175 | Loss : 0.3400 | Acc : 0.8412
     Batch 200 | Loss : 0.3959 | Acc : 0.8051
     Batch 225 | Loss : 0.3827 | Acc : 0.8128
     Batch 250 | Loss : 0.3563 | Acc : 0.8307
     Batch 275 | Loss : 0.3738 | Acc : 0.8307
     Batch 300 | Loss : 0.3807 | Acc : 0.8146
Epoch 00046 | Train Loss : 0.3815 | Eval Loss : 0.3676 | Train acc : 0.8201 | Eval Acc : 0.8245 | Eval Log. Respected : 0.9229
     Batch 000 | Loss : 0.3718 | Acc : 0.8243
     Batch 025 | Loss : 0.3997 | Acc : 0.8061
     Batch 050 | Loss : 0.5832 | Acc : 0.7225
     Batch 075 | Loss : 0.3559 | Acc : 0.8373
     Batch 100 | Loss : 0.3775 | Acc : 0.8184
     Batch 125 | Loss : 0.3344 | Acc : 0.8577
     Batch 150 | Loss : 0.3838 | Acc : 0.8161
     Batch 175 | Loss : 0.4455 | Acc : 0.7800
     Batch 200 | Loss : 0.3245 | Acc : 0.8532
     Batch 225 | Loss : 0.3742 | Acc : 0.8271
     Batch 250 | Loss : 0.3717 | Acc : 0.8255
     Batch 275 | Loss : 0.3882 | Acc : 0.8084
     Batch 300 | Loss : 0.3852 | Acc : 0.8141
Epoch 00047 | Train Loss : 0.3831 | Eval Loss : 0.3674 | Train acc : 0.8190 | Eval Acc : 0.8225 | Eval Log. Respected : 0.9267
     Batch 000 | Loss : 0.3672 | Acc : 0.8235
     Batch 025 | Loss : 0.3663 | Acc : 0.8227
     Batch 050 | Loss : 0.3896 | Acc : 0.8105
     Batch 075 | Loss : 0.3153 | Acc : 0.8572
     Batch 100 | Loss : 0.4364 | Acc : 0.7842
     Batch 125 | Loss : 0.3609 | Acc : 0.8324
     Batch 150 | Loss : 0.4262 | Acc : 0.7971
     Batch 175 | Loss : 0.4737 | Acc : 0.7597
     Batch 200 | Loss : 0.3241 | Acc : 0.8507
     Batch 225 | Loss : 0.3705 | Acc : 0.8262
     Batch 250 | Loss : 0.3425 | Acc : 0.8504
     Batch 275 | Loss : 0.3522 | Acc : 0.8365
     Batch 300 | Loss : 0.3407 | Acc : 0.8556
Epoch 00048 | Train Loss : 0.3795 | Eval Loss : 0.3637 | Train acc : 0.8206 | Eval Acc : 0.8255 | Eval Log. Respected : 0.9002
     Batch 000 | Loss : 0.4431 | Acc : 0.7828
     Batch 025 | Loss : 0.3637 | Acc : 0.8314
     Batch 050 | Loss : 0.3374 | Acc : 0.8420
     Batch 075 | Loss : 0.3548 | Acc : 0.8298
     Batch 100 | Loss : 0.3801 | Acc : 0.8211
     Batch 125 | Loss : 0.3215 | Acc : 0.8543
     Batch 150 | Loss : 0.3442 | Acc : 0.8427
     Batch 175 | Loss : 0.3400 | Acc : 0.8536
     Batch 200 | Loss : 0.4173 | Acc : 0.7952
     Batch 225 | Loss : 0.3334 | Acc : 0.8433
     Batch 250 | Loss : 0.3978 | Acc : 0.7993
     Batch 275 | Loss : 0.4219 | Acc : 0.7894
     Batch 300 | Loss : 0.3621 | Acc : 0.8270
Epoch 00049 | Train Loss : 0.3790 | Eval Loss : 0.3743 | Train acc : 0.8209 | Eval Acc : 0.8218 | Eval Log. Respected : 0.9528
     Batch 000 | Loss : 0.3233 | Acc : 0.8586
     Batch 025 | Loss : 0.3007 | Acc : 0.8631
     Batch 050 | Loss : 0.3888 | Acc : 0.8179
     Batch 075 | Loss : 0.3446 | Acc : 0.8522
     Batch 100 | Loss : 0.3822 | Acc : 0.8216
     Batch 125 | Loss : 0.4489 | Acc : 0.7679
     Batch 150 | Loss : 0.4038 | Acc : 0.8078
     Batch 175 | Loss : 0.3666 | Acc : 0.8257
     Batch 200 | Loss : 0.3452 | Acc : 0.8377
     Batch 225 | Loss : 0.3818 | Acc : 0.8150
     Batch 250 | Loss : 0.3621 | Acc : 0.8343
     Batch 275 | Loss : 0.2985 | Acc : 0.8691
     Batch 300 | Loss : 0.3558 | Acc : 0.8309
Epoch 00050 | Train Loss : 0.3804 | Eval Loss : 0.3660 | Train acc : 0.8206 | Eval Acc : 0.8239 | Eval Log. Respected : 0.9261
     Batch 000 | Loss : 0.4034 | Acc : 0.8061
     Batch 025 | Loss : 0.3509 | Acc : 0.8387
     Batch 050 | Loss : 0.3490 | Acc : 0.8340
     Batch 075 | Loss : 0.3280 | Acc : 0.8454
     Batch 100 | Loss : 0.3665 | Acc : 0.8328
     Batch 125 | Loss : 0.3933 | Acc : 0.8061
     Batch 150 | Loss : 0.3265 | Acc : 0.8500
     Batch 175 | Loss : 0.4222 | Acc : 0.8002
     Batch 200 | Loss : 0.4418 | Acc : 0.7834
     Batch 225 | Loss : 0.4313 | Acc : 0.7845
     Batch 250 | Loss : 0.3935 | Acc : 0.8067
     Batch 275 | Loss : 0.3378 | Acc : 0.8419
     Batch 300 | Loss : 0.4439 | Acc : 0.7857
Epoch 00051 | Train Loss : 0.3788 | Eval Loss : 0.3631 | Train acc : 0.8210 | Eval Acc : 0.8252 | Eval Log. Respected : 0.9109
     Batch 000 | Loss : 0.3426 | Acc : 0.8321
     Batch 025 | Loss : 0.3510 | Acc : 0.8391
     Batch 050 | Loss : 0.3729 | Acc : 0.8214
     Batch 075 | Loss : 0.4629 | Acc : 0.7738
     Batch 100 | Loss : 0.4265 | Acc : 0.7914
     Batch 125 | Loss : 0.3088 | Acc : 0.8610
     Batch 150 | Loss : 0.3849 | Acc : 0.8118
     Batch 175 | Loss : 0.3110 | Acc : 0.8681
     Batch 200 | Loss : 0.3399 | Acc : 0.8440
     Batch 225 | Loss : 0.3327 | Acc : 0.8426
     Batch 250 | Loss : 0.3390 | Acc : 0.8358
     Batch 275 | Loss : 0.4396 | Acc : 0.7791
     Batch 300 | Loss : 0.3153 | Acc : 0.8556
Epoch 00052 | Train Loss : 0.3780 | Eval Loss : 0.3615 | Train acc : 0.8217 | Eval Acc : 0.8263 | Eval Log. Respected : 0.9158
     Batch 000 | Loss : 0.4037 | Acc : 0.7944
     Batch 025 | Loss : 0.4347 | Acc : 0.7869
     Batch 050 | Loss : 0.3991 | Acc : 0.8120
     Batch 075 | Loss : 0.3398 | Acc : 0.8409
     Batch 100 | Loss : 0.3814 | Acc : 0.8307
     Batch 125 | Loss : 0.3287 | Acc : 0.8508
     Batch 150 | Loss : 0.3141 | Acc : 0.8635
     Batch 175 | Loss : 0.5348 | Acc : 0.7405
     Batch 200 | Loss : 0.3733 | Acc : 0.8235
     Batch 225 | Loss : 0.3882 | Acc : 0.8085
     Batch 250 | Loss : 0.3899 | Acc : 0.8042
     Batch 275 | Loss : 0.4082 | Acc : 0.8000
     Batch 300 | Loss : 0.3261 | Acc : 0.8523
Epoch 00053 | Train Loss : 0.3797 | Eval Loss : 0.3632 | Train acc : 0.8208 | Eval Acc : 0.8246 | Eval Log. Respected : 0.9332
     Batch 000 | Loss : 0.3142 | Acc : 0.8538
     Batch 025 | Loss : 0.3736 | Acc : 0.8267
     Batch 050 | Loss : 0.4257 | Acc : 0.7994
     Batch 075 | Loss : 0.4765 | Acc : 0.7611
     Batch 100 | Loss : 0.3218 | Acc : 0.8544
     Batch 125 | Loss : 0.4218 | Acc : 0.7949
     Batch 150 | Loss : 0.3673 | Acc : 0.8248
     Batch 175 | Loss : 0.3948 | Acc : 0.8055
     Batch 200 | Loss : 0.3529 | Acc : 0.8367
     Batch 225 | Loss : 0.4484 | Acc : 0.7749
     Batch 250 | Loss : 0.3357 | Acc : 0.8440
     Batch 275 | Loss : 0.3337 | Acc : 0.8520
     Batch 300 | Loss : 0.3000 | Acc : 0.8678
Epoch 00054 | Train Loss : 0.3773 | Eval Loss : 0.3613 | Train acc : 0.8218 | Eval Acc : 0.8261 | Eval Log. Respected : 0.9188
     Batch 000 | Loss : 0.3211 | Acc : 0.8584
     Batch 025 | Loss : 0.3360 | Acc : 0.8414
     Batch 050 | Loss : 0.3323 | Acc : 0.8519
     Batch 075 | Loss : 0.3944 | Acc : 0.8106
     Batch 100 | Loss : 0.3169 | Acc : 0.8660
     Batch 125 | Loss : 0.3827 | Acc : 0.8190
     Batch 150 | Loss : 0.3679 | Acc : 0.8267
     Batch 175 | Loss : 0.3291 | Acc : 0.8558
     Batch 200 | Loss : 0.4502 | Acc : 0.7799
     Batch 225 | Loss : 0.3772 | Acc : 0.8132
     Batch 250 | Loss : 0.4313 | Acc : 0.7817
     Batch 275 | Loss : 0.3542 | Acc : 0.8384
     Batch 300 | Loss : 0.3757 | Acc : 0.8205
Epoch 00055 | Train Loss : 0.3765 | Eval Loss : 0.3731 | Train acc : 0.8224 | Eval Acc : 0.8217 | Eval Log. Respected : 0.9007
     Batch 000 | Loss : 0.3486 | Acc : 0.8394
     Batch 025 | Loss : 0.4064 | Acc : 0.7990
     Batch 050 | Loss : 0.3863 | Acc : 0.8106
     Batch 075 | Loss : 0.3734 | Acc : 0.8155
     Batch 100 | Loss : 0.3860 | Acc : 0.8172
     Batch 125 | Loss : 0.3583 | Acc : 0.8313
     Batch 150 | Loss : 0.3639 | Acc : 0.8291
     Batch 175 | Loss : 0.4126 | Acc : 0.8032
     Batch 200 | Loss : 0.3201 | Acc : 0.8638
     Batch 225 | Loss : 0.3990 | Acc : 0.8131
     Batch 250 | Loss : 0.3170 | Acc : 0.8571
     Batch 275 | Loss : 0.3285 | Acc : 0.8535
     Batch 300 | Loss : 0.3905 | Acc : 0.8108
Epoch 00056 | Train Loss : 0.3758 | Eval Loss : 0.3774 | Train acc : 0.8227 | Eval Acc : 0.8230 | Eval Log. Respected : 0.9221
     Batch 000 | Loss : 0.3631 | Acc : 0.8322
     Batch 025 | Loss : 0.3202 | Acc : 0.8572
     Batch 050 | Loss : 0.3453 | Acc : 0.8309
     Batch 075 | Loss : 0.3297 | Acc : 0.8478
     Batch 100 | Loss : 0.3731 | Acc : 0.8201
     Batch 125 | Loss : 0.3560 | Acc : 0.8345
     Batch 150 | Loss : 0.4296 | Acc : 0.7856
     Batch 175 | Loss : 0.3928 | Acc : 0.8121
     Batch 200 | Loss : 0.3824 | Acc : 0.8115
     Batch 225 | Loss : 0.4195 | Acc : 0.8000
     Batch 250 | Loss : 0.3561 | Acc : 0.8349
     Batch 275 | Loss : 0.4095 | Acc : 0.7982
     Batch 300 | Loss : 0.3980 | Acc : 0.8058
Epoch 00057 | Train Loss : 0.3760 | Eval Loss : 0.3632 | Train acc : 0.8228 | Eval Acc : 0.8254 | Eval Log. Respected : 0.9120
     Batch 000 | Loss : 0.3045 | Acc : 0.8725
     Batch 025 | Loss : 0.4515 | Acc : 0.7765
     Batch 050 | Loss : 0.3653 | Acc : 0.8263
     Batch 075 | Loss : 0.3928 | Acc : 0.8089
     Batch 100 | Loss : 0.3201 | Acc : 0.8533
     Batch 125 | Loss : 0.3475 | Acc : 0.8381
     Batch 150 | Loss : 0.4812 | Acc : 0.7600
     Batch 175 | Loss : 0.5206 | Acc : 0.7515
     Batch 200 | Loss : 0.3365 | Acc : 0.8513
     Batch 225 | Loss : 0.4385 | Acc : 0.7842
     Batch 250 | Loss : 0.3242 | Acc : 0.8469
     Batch 275 | Loss : 0.3798 | Acc : 0.8199
     Batch 300 | Loss : 0.3278 | Acc : 0.8406
Epoch 00058 | Train Loss : 0.3763 | Eval Loss : 0.3586 | Train acc : 0.8225 | Eval Acc : 0.8282 | Eval Log. Respected : 0.9314
     Batch 000 | Loss : 0.3033 | Acc : 0.8640
     Batch 025 | Loss : 0.3118 | Acc : 0.8609
     Batch 050 | Loss : 0.3784 | Acc : 0.8231
     Batch 075 | Loss : 0.3708 | Acc : 0.8367
     Batch 100 | Loss : 0.4297 | Acc : 0.7922
     Batch 125 | Loss : 0.3300 | Acc : 0.8482
     Batch 150 | Loss : 0.4081 | Acc : 0.8014
     Batch 175 | Loss : 0.3674 | Acc : 0.8194
     Batch 200 | Loss : 0.4473 | Acc : 0.7761
     Batch 225 | Loss : 0.3284 | Acc : 0.8490
     Batch 250 | Loss : 0.3099 | Acc : 0.8599
     Batch 275 | Loss : 0.4062 | Acc : 0.8032
     Batch 300 | Loss : 0.3402 | Acc : 0.8377
Epoch 00059 | Train Loss : 0.3779 | Eval Loss : 0.3675 | Train acc : 0.8215 | Eval Acc : 0.8244 | Eval Log. Respected : 0.9122
     Batch 000 | Loss : 0.5478 | Acc : 0.7496
     Batch 025 | Loss : 0.3545 | Acc : 0.8382
     Batch 050 | Loss : 0.3918 | Acc : 0.8109
     Batch 075 | Loss : 0.3568 | Acc : 0.8258
     Batch 100 | Loss : 0.3571 | Acc : 0.8257
     Batch 125 | Loss : 0.3398 | Acc : 0.8394
     Batch 150 | Loss : 0.3460 | Acc : 0.8458
     Batch 175 | Loss : 0.3883 | Acc : 0.8159
     Batch 200 | Loss : 0.3571 | Acc : 0.8289
     Batch 225 | Loss : 0.3009 | Acc : 0.8654
     Batch 250 | Loss : 0.3106 | Acc : 0.8608
     Batch 275 | Loss : 0.4491 | Acc : 0.7824
     Batch 300 | Loss : 0.3180 | Acc : 0.8561
Epoch 00060 | Train Loss : 0.3739 | Eval Loss : 0.3593 | Train acc : 0.8239 | Eval Acc : 0.8276 | Eval Log. Respected : 0.9184
     Batch 000 | Loss : 0.3202 | Acc : 0.8571
     Batch 025 | Loss : 0.3176 | Acc : 0.8618
     Batch 050 | Loss : 0.3589 | Acc : 0.8343
     Batch 075 | Loss : 0.3374 | Acc : 0.8454
     Batch 100 | Loss : 0.3314 | Acc : 0.8506
     Batch 125 | Loss : 0.3470 | Acc : 0.8536
     Batch 150 | Loss : 0.4397 | Acc : 0.7777
     Batch 175 | Loss : 0.3783 | Acc : 0.8222
     Batch 200 | Loss : 0.4268 | Acc : 0.7847
     Batch 225 | Loss : 0.4512 | Acc : 0.7808
     Batch 250 | Loss : 0.4689 | Acc : 0.7725
     Batch 275 | Loss : 0.3666 | Acc : 0.8292
     Batch 300 | Loss : 0.3175 | Acc : 0.8532
Epoch 00061 | Train Loss : 0.3734 | Eval Loss : 0.3618 | Train acc : 0.8240 | Eval Acc : 0.8280 | Eval Log. Respected : 0.9150
     Batch 000 | Loss : 0.3935 | Acc : 0.8058
     Batch 025 | Loss : 0.3691 | Acc : 0.8215
     Batch 050 | Loss : 0.4072 | Acc : 0.8006
     Batch 075 | Loss : 0.3868 | Acc : 0.8125
     Batch 100 | Loss : 0.4684 | Acc : 0.7684
     Batch 125 | Loss : 0.4654 | Acc : 0.7706
     Batch 150 | Loss : 0.3942 | Acc : 0.8097
     Batch 175 | Loss : 0.3311 | Acc : 0.8547
     Batch 200 | Loss : 0.3299 | Acc : 0.8433
     Batch 225 | Loss : 0.3736 | Acc : 0.8217
     Batch 250 | Loss : 0.3129 | Acc : 0.8612
     Batch 275 | Loss : 0.3983 | Acc : 0.8049
     Batch 300 | Loss : 0.3713 | Acc : 0.8168
Epoch 00062 | Train Loss : 0.3719 | Eval Loss : 0.3591 | Train acc : 0.8245 | Eval Acc : 0.8280 | Eval Log. Respected : 0.9216
     Batch 000 | Loss : 0.3738 | Acc : 0.8212
     Batch 025 | Loss : 0.3276 | Acc : 0.8518
     Batch 050 | Loss : 0.3664 | Acc : 0.8243
     Batch 075 | Loss : 0.3666 | Acc : 0.8208
     Batch 100 | Loss : 0.3726 | Acc : 0.8208
     Batch 125 | Loss : 0.4457 | Acc : 0.7810
     Batch 150 | Loss : 0.3278 | Acc : 0.8493
     Batch 175 | Loss : 0.3636 | Acc : 0.8298
     Batch 200 | Loss : 0.4282 | Acc : 0.7973
     Batch 225 | Loss : 0.3066 | Acc : 0.8683
     Batch 250 | Loss : 0.4373 | Acc : 0.7825
     Batch 275 | Loss : 0.4193 | Acc : 0.7905
     Batch 300 | Loss : 0.3590 | Acc : 0.8273
Epoch 00063 | Train Loss : 0.3725 | Eval Loss : 0.3592 | Train acc : 0.8245 | Eval Acc : 0.8287 | Eval Log. Respected : 0.9060
     Batch 000 | Loss : 0.2945 | Acc : 0.8710
     Batch 025 | Loss : 0.3865 | Acc : 0.8165
     Batch 050 | Loss : 0.3732 | Acc : 0.8217
     Batch 075 | Loss : 0.3765 | Acc : 0.8191
     Batch 100 | Loss : 0.3424 | Acc : 0.8398
     Batch 125 | Loss : 0.3519 | Acc : 0.8369
     Batch 150 | Loss : 0.3208 | Acc : 0.8566
     Batch 175 | Loss : 0.3243 | Acc : 0.8544
     Batch 200 | Loss : 0.3370 | Acc : 0.8525
     Batch 225 | Loss : 0.4086 | Acc : 0.8101
     Batch 250 | Loss : 0.3140 | Acc : 0.8590
     Batch 275 | Loss : 0.2869 | Acc : 0.8762
     Batch 300 | Loss : 0.3322 | Acc : 0.8475
Epoch 00064 | Train Loss : 0.3739 | Eval Loss : 0.3643 | Train acc : 0.8243 | Eval Acc : 0.8267 | Eval Log. Respected : 0.9160
     Batch 000 | Loss : 0.4084 | Acc : 0.7996
     Batch 025 | Loss : 0.3678 | Acc : 0.8337
     Batch 050 | Loss : 0.3881 | Acc : 0.8095
     Batch 075 | Loss : 0.3593 | Acc : 0.8323
     Batch 100 | Loss : 0.3533 | Acc : 0.8324
     Batch 125 | Loss : 0.3217 | Acc : 0.8543
     Batch 150 | Loss : 0.3271 | Acc : 0.8530
     Batch 175 | Loss : 0.3624 | Acc : 0.8335
     Batch 200 | Loss : 0.4921 | Acc : 0.7663
     Batch 225 | Loss : 0.4336 | Acc : 0.7784
     Batch 250 | Loss : 0.4406 | Acc : 0.7874
     Batch 275 | Loss : 0.4896 | Acc : 0.7771
     Batch 300 | Loss : 0.4052 | Acc : 0.8001
Epoch 00065 | Train Loss : 0.3713 | Eval Loss : 0.3642 | Train acc : 0.8254 | Eval Acc : 0.8265 | Eval Log. Respected : 0.9141
     Batch 000 | Loss : 0.4646 | Acc : 0.7760
     Batch 025 | Loss : 0.3624 | Acc : 0.8248
     Batch 050 | Loss : 0.4056 | Acc : 0.8052
     Batch 075 | Loss : 0.3353 | Acc : 0.8492
     Batch 100 | Loss : 0.3211 | Acc : 0.8535
     Batch 125 | Loss : 0.3975 | Acc : 0.8019
     Batch 150 | Loss : 0.3639 | Acc : 0.8269
     Batch 175 | Loss : 0.3394 | Acc : 0.8461
     Batch 200 | Loss : 0.3190 | Acc : 0.8615
     Batch 225 | Loss : 0.3378 | Acc : 0.8564
     Batch 250 | Loss : 0.3986 | Acc : 0.8067
     Batch 275 | Loss : 0.3594 | Acc : 0.8336
     Batch 300 | Loss : 0.3032 | Acc : 0.8642
Epoch 00066 | Train Loss : 0.3708 | Eval Loss : 0.3566 | Train acc : 0.8257 | Eval Acc : 0.8301 | Eval Log. Respected : 0.9282
     Batch 000 | Loss : 0.3739 | Acc : 0.8142
     Batch 025 | Loss : 0.3544 | Acc : 0.8339
     Batch 050 | Loss : 0.3700 | Acc : 0.8314
     Batch 075 | Loss : 0.3501 | Acc : 0.8315
     Batch 100 | Loss : 0.3994 | Acc : 0.7940
     Batch 125 | Loss : 0.2932 | Acc : 0.8742
     Batch 150 | Loss : 0.3052 | Acc : 0.8643
     Batch 175 | Loss : 0.3938 | Acc : 0.8084
     Batch 200 | Loss : 0.3756 | Acc : 0.8206
     Batch 225 | Loss : 0.3410 | Acc : 0.8456
     Batch 250 | Loss : 0.3855 | Acc : 0.8135
     Batch 275 | Loss : 0.3293 | Acc : 0.8575
     Batch 300 | Loss : 0.3956 | Acc : 0.8072
Epoch 00067 | Train Loss : 0.3705 | Eval Loss : 0.3681 | Train acc : 0.8257 | Eval Acc : 0.8240 | Eval Log. Respected : 0.9492
     Batch 000 | Loss : 0.3103 | Acc : 0.8618
     Batch 025 | Loss : 0.4376 | Acc : 0.7878
     Batch 050 | Loss : 0.3954 | Acc : 0.8161
     Batch 075 | Loss : 0.3972 | Acc : 0.8117
     Batch 100 | Loss : 0.3089 | Acc : 0.8579
     Batch 125 | Loss : 0.3435 | Acc : 0.8407
     Batch 150 | Loss : 0.3865 | Acc : 0.8105
     Batch 175 | Loss : 0.3920 | Acc : 0.8111
     Batch 200 | Loss : 0.4178 | Acc : 0.7966
     Batch 225 | Loss : 0.4185 | Acc : 0.7973
     Batch 250 | Loss : 0.3308 | Acc : 0.8458
     Batch 275 | Loss : 0.4162 | Acc : 0.8002
     Batch 300 | Loss : 0.3235 | Acc : 0.8504
Epoch 00068 | Train Loss : 0.3699 | Eval Loss : 0.3638 | Train acc : 0.8258 | Eval Acc : 0.8254 | Eval Log. Respected : 0.9188
     Batch 000 | Loss : 0.3444 | Acc : 0.8431
     Batch 025 | Loss : 0.3507 | Acc : 0.8371
     Batch 050 | Loss : 0.3489 | Acc : 0.8458
     Batch 075 | Loss : 0.3817 | Acc : 0.8181
     Batch 100 | Loss : 0.4127 | Acc : 0.8015
     Batch 125 | Loss : 0.3170 | Acc : 0.8574
     Batch 150 | Loss : 0.4118 | Acc : 0.8023
     Batch 175 | Loss : 0.3054 | Acc : 0.8622
     Batch 200 | Loss : 0.3496 | Acc : 0.8388
     Batch 225 | Loss : 0.3531 | Acc : 0.8340
     Batch 250 | Loss : 0.2983 | Acc : 0.8660
     Batch 275 | Loss : 0.4176 | Acc : 0.7961
     Batch 300 | Loss : 0.4160 | Acc : 0.7943
Epoch 00069 | Train Loss : 0.3714 | Eval Loss : 0.3609 | Train acc : 0.8256 | Eval Acc : 0.8283 | Eval Log. Respected : 0.9220
     Batch 000 | Loss : 0.3075 | Acc : 0.8639
     Batch 025 | Loss : 0.3242 | Acc : 0.8445
     Batch 050 | Loss : 0.3091 | Acc : 0.8666
     Batch 075 | Loss : 0.3941 | Acc : 0.8103
     Batch 100 | Loss : 0.3599 | Acc : 0.8305
     Batch 125 | Loss : 0.3736 | Acc : 0.8217
     Batch 150 | Loss : 0.4398 | Acc : 0.7855
     Batch 175 | Loss : 0.3627 | Acc : 0.8308
     Batch 200 | Loss : 0.3728 | Acc : 0.8256
     Batch 225 | Loss : 0.3129 | Acc : 0.8568
     Batch 250 | Loss : 0.3354 | Acc : 0.8409
     Batch 275 | Loss : 0.3770 | Acc : 0.8209
     Batch 300 | Loss : 0.4141 | Acc : 0.7980
Epoch 00070 | Train Loss : 0.3704 | Eval Loss : 0.3580 | Train acc : 0.8259 | Eval Acc : 0.8300 | Eval Log. Respected : 0.9177
     Batch 000 | Loss : 0.3323 | Acc : 0.8482
     Batch 025 | Loss : 0.3394 | Acc : 0.8387
     Batch 050 | Loss : 0.3489 | Acc : 0.8385
     Batch 075 | Loss : 0.2976 | Acc : 0.8691
     Batch 100 | Loss : 0.3562 | Acc : 0.8318
     Batch 125 | Loss : 0.4912 | Acc : 0.7485
     Batch 150 | Loss : 0.3271 | Acc : 0.8481
     Batch 175 | Loss : 0.3072 | Acc : 0.8612
     Batch 200 | Loss : 0.3282 | Acc : 0.8453
     Batch 225 | Loss : 0.3150 | Acc : 0.8557
     Batch 250 | Loss : 0.3950 | Acc : 0.8106
     Batch 275 | Loss : 0.3415 | Acc : 0.8423
     Batch 300 | Loss : 0.3069 | Acc : 0.8690
Epoch 00071 | Train Loss : 0.3718 | Eval Loss : 0.3567 | Train acc : 0.8251 | Eval Acc : 0.8314 | Eval Log. Respected : 0.9286
     Batch 000 | Loss : 0.2982 | Acc : 0.8709
     Batch 025 | Loss : 0.3359 | Acc : 0.8461
     Batch 050 | Loss : 0.3654 | Acc : 0.8271
     Batch 075 | Loss : 0.4516 | Acc : 0.7756
     Batch 100 | Loss : 0.3352 | Acc : 0.8490
     Batch 125 | Loss : 0.3746 | Acc : 0.8253
     Batch 150 | Loss : 0.3876 | Acc : 0.8113
     Batch 175 | Loss : 0.3215 | Acc : 0.8613
     Batch 200 | Loss : 0.4611 | Acc : 0.7696
     Batch 225 | Loss : 0.3666 | Acc : 0.8264
     Batch 250 | Loss : 0.3070 | Acc : 0.8610
     Batch 275 | Loss : 0.4253 | Acc : 0.7969
     Batch 300 | Loss : 0.3139 | Acc : 0.8589
Epoch 00072 | Train Loss : 0.3714 | Eval Loss : 0.3555 | Train acc : 0.8256 | Eval Acc : 0.8309 | Eval Log. Respected : 0.9157
     Batch 000 | Loss : 0.3416 | Acc : 0.8372
     Batch 025 | Loss : 0.4039 | Acc : 0.7973
     Batch 050 | Loss : 0.4189 | Acc : 0.7992
     Batch 075 | Loss : 0.5434 | Acc : 0.7561
     Batch 100 | Loss : 0.3139 | Acc : 0.8556
     Batch 125 | Loss : 0.3103 | Acc : 0.8684
     Batch 150 | Loss : 0.3617 | Acc : 0.8293
     Batch 175 | Loss : 0.5496 | Acc : 0.7494
     Batch 200 | Loss : 0.3499 | Acc : 0.8343
     Batch 225 | Loss : 0.4015 | Acc : 0.8084
     Batch 250 | Loss : 0.3424 | Acc : 0.8474
     Batch 275 | Loss : 0.3279 | Acc : 0.8484
     Batch 300 | Loss : 0.3200 | Acc : 0.8519
Epoch 00073 | Train Loss : 0.3696 | Eval Loss : 0.3581 | Train acc : 0.8264 | Eval Acc : 0.8286 | Eval Log. Respected : 0.9510
     Batch 000 | Loss : 0.4148 | Acc : 0.7947
     Batch 025 | Loss : 0.3755 | Acc : 0.8329
     Batch 050 | Loss : 0.3661 | Acc : 0.8267
     Batch 075 | Loss : 0.3500 | Acc : 0.8328
     Batch 100 | Loss : 0.3420 | Acc : 0.8390
     Batch 125 | Loss : 0.4353 | Acc : 0.7851
     Batch 150 | Loss : 0.4364 | Acc : 0.7856
     Batch 175 | Loss : 0.4162 | Acc : 0.7971
     Batch 200 | Loss : 0.3553 | Acc : 0.8341
     Batch 225 | Loss : 0.4085 | Acc : 0.7993
     Batch 250 | Loss : 0.4986 | Acc : 0.7627
     Batch 275 | Loss : 0.4088 | Acc : 0.8113
     Batch 300 | Loss : 0.3460 | Acc : 0.8327
Epoch 00074 | Train Loss : 0.3699 | Eval Loss : 0.3545 | Train acc : 0.8264 | Eval Acc : 0.8307 | Eval Log. Respected : 0.9244
     Batch 000 | Loss : 0.2886 | Acc : 0.8770
     Batch 025 | Loss : 0.3199 | Acc : 0.8554
     Batch 050 | Loss : 0.4545 | Acc : 0.7763
     Batch 075 | Loss : 0.3222 | Acc : 0.8609
     Batch 100 | Loss : 0.3505 | Acc : 0.8333
     Batch 125 | Loss : 0.4142 | Acc : 0.8092
     Batch 150 | Loss : 0.3258 | Acc : 0.8540
     Batch 175 | Loss : 0.3944 | Acc : 0.8041
     Batch 200 | Loss : 0.3453 | Acc : 0.8449
     Batch 225 | Loss : 0.2968 | Acc : 0.8715
     Batch 250 | Loss : 0.2926 | Acc : 0.8764
     Batch 275 | Loss : 0.3092 | Acc : 0.8646
     Batch 300 | Loss : 0.3800 | Acc : 0.8161
Epoch 00075 | Train Loss : 0.3688 | Eval Loss : 0.3578 | Train acc : 0.8269 | Eval Acc : 0.8303 | Eval Log. Respected : 0.9240
     Batch 000 | Loss : 0.3607 | Acc : 0.8378
     Batch 025 | Loss : 0.3258 | Acc : 0.8589
     Batch 050 | Loss : 0.3536 | Acc : 0.8382
     Batch 075 | Loss : 0.4030 | Acc : 0.8046
     Batch 100 | Loss : 0.3034 | Acc : 0.8670
     Batch 125 | Loss : 0.3762 | Acc : 0.8236
     Batch 150 | Loss : 0.3346 | Acc : 0.8403
     Batch 175 | Loss : 0.4030 | Acc : 0.8092
     Batch 200 | Loss : 0.2876 | Acc : 0.8754
     Batch 225 | Loss : 0.3366 | Acc : 0.8545
     Batch 250 | Loss : 0.3204 | Acc : 0.8530
     Batch 275 | Loss : 0.4407 | Acc : 0.7875
     Batch 300 | Loss : 0.4891 | Acc : 0.7580
Epoch 00076 | Train Loss : 0.3799 | Eval Loss : 0.4560 | Train acc : 0.8206 | Eval Acc : 0.7766 | Eval Log. Respected : 1.0000
     Batch 000 | Loss : 0.4352 | Acc : 0.7909
     Batch 025 | Loss : 0.4427 | Acc : 0.7903
     Batch 050 | Loss : 0.3630 | Acc : 0.8325
     Batch 075 | Loss : 0.5002 | Acc : 0.7522
     Batch 100 | Loss : 0.3889 | Acc : 0.8182
     Batch 125 | Loss : 0.4638 | Acc : 0.7613
     Batch 150 | Loss : 0.4662 | Acc : 0.7720
     Batch 175 | Loss : 0.3623 | Acc : 0.8335
     Batch 200 | Loss : 0.3273 | Acc : 0.8464
     Batch 225 | Loss : 0.3527 | Acc : 0.8350
     Batch 250 | Loss : 0.4211 | Acc : 0.7969
     Batch 275 | Loss : 0.4032 | Acc : 0.8092
     Batch 300 | Loss : 0.4672 | Acc : 0.7665
Epoch 00077 | Train Loss : 0.4008 | Eval Loss : 0.3838 | Train acc : 0.8084 | Eval Acc : 0.8159 | Eval Log. Respected : 0.9503
     Batch 000 | Loss : 0.3548 | Acc : 0.8331
     Batch 025 | Loss : 0.4073 | Acc : 0.8048
     Batch 050 | Loss : 0.3171 | Acc : 0.8663
     Batch 075 | Loss : 0.4220 | Acc : 0.7938
     Batch 100 | Loss : 0.3331 | Acc : 0.8464
     Batch 125 | Loss : 0.3838 | Acc : 0.8131
     Batch 150 | Loss : 0.3635 | Acc : 0.8312
     Batch 175 | Loss : 0.3384 | Acc : 0.8333
     Batch 200 | Loss : 0.4880 | Acc : 0.7638
     Batch 225 | Loss : 0.3656 | Acc : 0.8237
     Batch 250 | Loss : 0.3958 | Acc : 0.8083
     Batch 275 | Loss : 0.3988 | Acc : 0.8135
     Batch 300 | Loss : 0.3874 | Acc : 0.8153
Epoch 00078 | Train Loss : 0.3796 | Eval Loss : 0.3683 | Train acc : 0.8206 | Eval Acc : 0.8249 | Eval Log. Respected : 0.9349
     Batch 000 | Loss : 0.4767 | Acc : 0.7667
     Batch 025 | Loss : 0.4398 | Acc : 0.7884
     Batch 050 | Loss : 0.4020 | Acc : 0.8081
     Batch 075 | Loss : 0.3423 | Acc : 0.8436
     Batch 100 | Loss : 0.3715 | Acc : 0.8256
     Batch 125 | Loss : 0.3733 | Acc : 0.8224
     Batch 150 | Loss : 0.3248 | Acc : 0.8606
     Batch 175 | Loss : 0.3983 | Acc : 0.8140
     Batch 200 | Loss : 0.3958 | Acc : 0.8109
     Batch 225 | Loss : 0.3232 | Acc : 0.8574
     Batch 250 | Loss : 0.3259 | Acc : 0.8521
     Batch 275 | Loss : 0.4555 | Acc : 0.7788
     Batch 300 | Loss : 0.3480 | Acc : 0.8388
Epoch 00079 | Train Loss : 0.3762 | Eval Loss : 0.3616 | Train acc : 0.8233 | Eval Acc : 0.8283 | Eval Log. Respected : 0.9053
     Batch 000 | Loss : 0.3215 | Acc : 0.8512
     Batch 025 | Loss : 0.3907 | Acc : 0.8192
     Batch 050 | Loss : 0.4604 | Acc : 0.7850
     Batch 075 | Loss : 0.4057 | Acc : 0.7977
     Batch 100 | Loss : 0.5110 | Acc : 0.7630
     Batch 125 | Loss : 0.3966 | Acc : 0.8146
     Batch 150 | Loss : 0.3339 | Acc : 0.8427
     Batch 175 | Loss : 0.3903 | Acc : 0.8022
     Batch 200 | Loss : 0.3989 | Acc : 0.8168
     Batch 225 | Loss : 0.3261 | Acc : 0.8540
     Batch 250 | Loss : 0.3766 | Acc : 0.8210
     Batch 275 | Loss : 0.3332 | Acc : 0.8446
     Batch 300 | Loss : 0.3560 | Acc : 0.8301
Epoch 00080 | Train Loss : 0.3728 | Eval Loss : 0.3601 | Train acc : 0.8247 | Eval Acc : 0.8299 | Eval Log. Respected : 0.9185
     Batch 000 | Loss : 0.3352 | Acc : 0.8459
     Batch 025 | Loss : 0.2976 | Acc : 0.8733
     Batch 050 | Loss : 0.3611 | Acc : 0.8323
     Batch 075 | Loss : 0.4042 | Acc : 0.8049
     Batch 100 | Loss : 0.3198 | Acc : 0.8512
     Batch 125 | Loss : 0.4049 | Acc : 0.8035
     Batch 150 | Loss : 0.3335 | Acc : 0.8519
     Batch 175 | Loss : 0.4208 | Acc : 0.7938
     Batch 200 | Loss : 0.3416 | Acc : 0.8410
     Batch 225 | Loss : 0.4033 | Acc : 0.8055
     Batch 250 | Loss : 0.2923 | Acc : 0.8777
     Batch 275 | Loss : 0.5023 | Acc : 0.7629
     Batch 300 | Loss : 0.4140 | Acc : 0.7976
Epoch 00081 | Train Loss : 0.3712 | Eval Loss : 0.3602 | Train acc : 0.8257 | Eval Acc : 0.8288 | Eval Log. Respected : 0.9012
     Batch 000 | Loss : 0.3865 | Acc : 0.8104
     Batch 025 | Loss : 0.3194 | Acc : 0.8515
     Batch 050 | Loss : 0.3052 | Acc : 0.8622
     Batch 075 | Loss : 0.3931 | Acc : 0.8076
     Batch 100 | Loss : 0.3003 | Acc : 0.8735
     Batch 125 | Loss : 0.4147 | Acc : 0.8020
     Batch 150 | Loss : 0.3209 | Acc : 0.8517
     Batch 175 | Loss : 0.3704 | Acc : 0.8252
     Batch 200 | Loss : 0.3993 | Acc : 0.8140
     Batch 225 | Loss : 0.4006 | Acc : 0.8035
     Batch 250 | Loss : 0.4045 | Acc : 0.8050
     Batch 275 | Loss : 0.3574 | Acc : 0.8283
     Batch 300 | Loss : 0.3804 | Acc : 0.8267
Epoch 00082 | Train Loss : 0.3705 | Eval Loss : 0.3569 | Train acc : 0.8260 | Eval Acc : 0.8306 | Eval Log. Respected : 0.9235
     Batch 000 | Loss : 0.3277 | Acc : 0.8453
     Batch 025 | Loss : 0.4030 | Acc : 0.8046
     Batch 050 | Loss : 0.3021 | Acc : 0.8640
     Batch 075 | Loss : 0.4174 | Acc : 0.7976
     Batch 100 | Loss : 0.3600 | Acc : 0.8234
     Batch 125 | Loss : 0.4191 | Acc : 0.7891
     Batch 150 | Loss : 0.3915 | Acc : 0.8135
     Batch 175 | Loss : 0.3986 | Acc : 0.8113
     Batch 200 | Loss : 0.3237 | Acc : 0.8580
     Batch 225 | Loss : 0.3767 | Acc : 0.8215
     Batch 250 | Loss : 0.3104 | Acc : 0.8596
     Batch 275 | Loss : 0.3830 | Acc : 0.8089
     Batch 300 | Loss : 0.3342 | Acc : 0.8477
Epoch 00083 | Train Loss : 0.3701 | Eval Loss : 0.3593 | Train acc : 0.8258 | Eval Acc : 0.8291 | Eval Log. Respected : 0.9148
     Batch 000 | Loss : 0.4204 | Acc : 0.8041
     Batch 025 | Loss : 0.3945 | Acc : 0.8129
     Batch 050 | Loss : 0.3377 | Acc : 0.8408
     Batch 075 | Loss : 0.3514 | Acc : 0.8392
     Batch 100 | Loss : 0.3701 | Acc : 0.8307
     Batch 125 | Loss : 0.3294 | Acc : 0.8453
     Batch 150 | Loss : 0.3493 | Acc : 0.8376
     Batch 175 | Loss : 0.4094 | Acc : 0.8033
     Batch 200 | Loss : 0.3791 | Acc : 0.8225
     Batch 225 | Loss : 0.3721 | Acc : 0.8170
     Batch 250 | Loss : 0.4097 | Acc : 0.7941
     Batch 275 | Loss : 0.3719 | Acc : 0.8235
     Batch 300 | Loss : 0.3451 | Acc : 0.8361
Epoch 00084 | Train Loss : 0.3705 | Eval Loss : 0.3628 | Train acc : 0.8259 | Eval Acc : 0.8273 | Eval Log. Respected : 0.9174
Early Stopping
Testing...
Test Loss 0.6043 | Test Acc 0.8164 | Test Log. Res. 0.9183
