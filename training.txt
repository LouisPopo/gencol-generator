Done loading data from cached files.
Training ...
     Batch 000 | Loss : 8.1975 | Acc : 0.4459
     Batch 025 | Loss : 0.6416 | Acc : 0.6253
     Batch 050 | Loss : 0.5904 | Acc : 0.6402
     Batch 075 | Loss : 0.5922 | Acc : 0.6390
     Batch 100 | Loss : 0.5759 | Acc : 0.6518
     Batch 125 | Loss : 0.6338 | Acc : 0.6028
     Batch 150 | Loss : 0.6345 | Acc : 0.6033
     Batch 175 | Loss : 0.6089 | Acc : 0.6530
     Batch 200 | Loss : 0.5899 | Acc : 0.6575
     Batch 225 | Loss : 0.6205 | Acc : 0.6302
     Batch 250 | Loss : 0.6295 | Acc : 0.6266
     Batch 275 | Loss : 0.6547 | Acc : 0.5892
     Batch 300 | Loss : 0.6415 | Acc : 0.6140
Epoch 00000 | Train Loss : 0.7309 | Eval Loss : 0.6171 | Train acc : 0.6140 | Eval Acc : 0.6349
     Batch 000 | Loss : 0.6369 | Acc : 0.6184
     Batch 025 | Loss : 0.5755 | Acc : 0.6739
     Batch 050 | Loss : 0.6481 | Acc : 0.6053
     Batch 075 | Loss : 0.6169 | Acc : 0.6281
     Batch 100 | Loss : 0.6347 | Acc : 0.5947
     Batch 125 | Loss : 0.6480 | Acc : 0.5747
     Batch 150 | Loss : 0.5914 | Acc : 0.6508
     Batch 175 | Loss : 0.6282 | Acc : 0.6149
     Batch 200 | Loss : 0.6148 | Acc : 0.6329
     Batch 225 | Loss : 0.6482 | Acc : 0.5799
     Batch 250 | Loss : 0.6351 | Acc : 0.6129
     Batch 275 | Loss : 0.6140 | Acc : 0.6265
     Batch 300 | Loss : 0.5975 | Acc : 0.6404
Epoch 00001 | Train Loss : 0.6153 | Eval Loss : 0.6066 | Train acc : 0.6291 | Eval Acc : 0.6374
     Batch 000 | Loss : 0.6232 | Acc : 0.6279
     Batch 025 | Loss : 0.6080 | Acc : 0.6383
     Batch 050 | Loss : 0.5911 | Acc : 0.6329
     Batch 075 | Loss : 0.6429 | Acc : 0.5842
     Batch 100 | Loss : 0.6162 | Acc : 0.6118
     Batch 125 | Loss : 0.5425 | Acc : 0.6889
     Batch 150 | Loss : 0.5938 | Acc : 0.6470
     Batch 175 | Loss : 0.6305 | Acc : 0.6246
     Batch 200 | Loss : 0.6448 | Acc : 0.5995
     Batch 225 | Loss : 0.6194 | Acc : 0.6272
     Batch 250 | Loss : 0.6160 | Acc : 0.6230
     Batch 275 | Loss : 0.6443 | Acc : 0.5833
     Batch 300 | Loss : 0.6439 | Acc : 0.5968
Epoch 00002 | Train Loss : 0.6074 | Eval Loss : 0.6038 | Train acc : 0.6307 | Eval Acc : 0.6288
     Batch 000 | Loss : 0.6412 | Acc : 0.5883
     Batch 025 | Loss : 0.6219 | Acc : 0.6237
     Batch 050 | Loss : 0.6372 | Acc : 0.6030
     Batch 075 | Loss : 0.6228 | Acc : 0.6087
     Batch 100 | Loss : 0.5649 | Acc : 0.6650
     Batch 125 | Loss : 0.6010 | Acc : 0.6312
     Batch 150 | Loss : 0.6285 | Acc : 0.6116
     Batch 175 | Loss : 0.6086 | Acc : 0.6387
     Batch 200 | Loss : 0.6290 | Acc : 0.6183
     Batch 225 | Loss : 0.5627 | Acc : 0.6771
     Batch 250 | Loss : 0.6308 | Acc : 0.6152
     Batch 275 | Loss : 0.5907 | Acc : 0.6548
     Batch 300 | Loss : 0.6181 | Acc : 0.6223
Epoch 00003 | Train Loss : 0.6048 | Eval Loss : 0.6034 | Train acc : 0.6338 | Eval Acc : 0.6382
     Batch 000 | Loss : 0.6306 | Acc : 0.6162
     Batch 025 | Loss : 0.5489 | Acc : 0.6892
     Batch 050 | Loss : 0.5971 | Acc : 0.6393
     Batch 075 | Loss : 0.5758 | Acc : 0.6626
     Batch 100 | Loss : 0.6317 | Acc : 0.6145
     Batch 125 | Loss : 0.6317 | Acc : 0.6070
     Batch 150 | Loss : 0.5570 | Acc : 0.6739
     Batch 175 | Loss : 0.6246 | Acc : 0.6107
     Batch 200 | Loss : 0.6167 | Acc : 0.6327
     Batch 225 | Loss : 0.5851 | Acc : 0.6607
     Batch 250 | Loss : 0.6172 | Acc : 0.6249
     Batch 275 | Loss : 0.5888 | Acc : 0.6595
     Batch 300 | Loss : 0.5679 | Acc : 0.6721
Epoch 00004 | Train Loss : 0.6037 | Eval Loss : 0.5994 | Train acc : 0.6354 | Eval Acc : 0.6384
     Batch 000 | Loss : 0.5966 | Acc : 0.6414
     Batch 025 | Loss : 0.5915 | Acc : 0.6507
     Batch 050 | Loss : 0.6250 | Acc : 0.6096
     Batch 075 | Loss : 0.6002 | Acc : 0.6458
     Batch 100 | Loss : 0.6026 | Acc : 0.6393
     Batch 125 | Loss : 0.5920 | Acc : 0.6428
     Batch 150 | Loss : 0.6396 | Acc : 0.6118
     Batch 175 | Loss : 0.6089 | Acc : 0.6325
     Batch 200 | Loss : 0.5540 | Acc : 0.6778
     Batch 225 | Loss : 0.6347 | Acc : 0.6152
     Batch 250 | Loss : 0.6229 | Acc : 0.6206
     Batch 275 | Loss : 0.5796 | Acc : 0.6647
     Batch 300 | Loss : 0.5649 | Acc : 0.6747
Epoch 00005 | Train Loss : 0.6025 | Eval Loss : 0.6005 | Train acc : 0.6354 | Eval Acc : 0.6355
     Batch 000 | Loss : 0.6296 | Acc : 0.6123
     Batch 025 | Loss : 0.6437 | Acc : 0.5997
     Batch 050 | Loss : 0.6300 | Acc : 0.6084
     Batch 075 | Loss : 0.6171 | Acc : 0.6174
     Batch 100 | Loss : 0.6208 | Acc : 0.6102
     Batch 125 | Loss : 0.6240 | Acc : 0.6141
     Batch 150 | Loss : 0.6184 | Acc : 0.6219
     Batch 175 | Loss : 0.6133 | Acc : 0.6294
     Batch 200 | Loss : 0.6041 | Acc : 0.6241
     Batch 225 | Loss : 0.6022 | Acc : 0.6321
     Batch 250 | Loss : 0.6360 | Acc : 0.6053
     Batch 275 | Loss : 0.5787 | Acc : 0.6672
     Batch 300 | Loss : 0.5592 | Acc : 0.6719
Epoch 00006 | Train Loss : 0.6014 | Eval Loss : 0.5992 | Train acc : 0.6357 | Eval Acc : 0.6362
     Batch 000 | Loss : 0.6161 | Acc : 0.6158
     Batch 025 | Loss : 0.6407 | Acc : 0.6005
     Batch 050 | Loss : 0.6211 | Acc : 0.6239
     Batch 075 | Loss : 0.5996 | Acc : 0.6301
     Batch 100 | Loss : 0.5601 | Acc : 0.6703
     Batch 125 | Loss : 0.6369 | Acc : 0.6015
     Batch 150 | Loss : 0.6066 | Acc : 0.6303
     Batch 175 | Loss : 0.5439 | Acc : 0.6929
     Batch 200 | Loss : 0.6230 | Acc : 0.6246
     Batch 225 | Loss : 0.6343 | Acc : 0.5911
     Batch 250 | Loss : 0.5663 | Acc : 0.6644
     Batch 275 | Loss : 0.6290 | Acc : 0.6189
     Batch 300 | Loss : 0.6351 | Acc : 0.6080
Epoch 00007 | Train Loss : 0.6011 | Eval Loss : 0.5991 | Train acc : 0.6361 | Eval Acc : 0.6373
     Batch 000 | Loss : 0.5635 | Acc : 0.6729
     Batch 025 | Loss : 0.5532 | Acc : 0.6732
     Batch 050 | Loss : 0.6126 | Acc : 0.6347
     Batch 075 | Loss : 0.5939 | Acc : 0.6349
     Batch 100 | Loss : 0.6001 | Acc : 0.6389
     Batch 125 | Loss : 0.6430 | Acc : 0.5968
     Batch 150 | Loss : 0.5878 | Acc : 0.6450
     Batch 175 | Loss : 0.5990 | Acc : 0.6308
     Batch 200 | Loss : 0.6164 | Acc : 0.6094
     Batch 225 | Loss : 0.5460 | Acc : 0.6846
     Batch 250 | Loss : 0.6420 | Acc : 0.5922
     Batch 275 | Loss : 0.5588 | Acc : 0.6814
     Batch 300 | Loss : 0.6232 | Acc : 0.6123
Epoch 00008 | Train Loss : 0.6004 | Eval Loss : 0.5991 | Train acc : 0.6359 | Eval Acc : 0.6354
     Batch 000 | Loss : 0.6053 | Acc : 0.6258
     Batch 025 | Loss : 0.6075 | Acc : 0.6302
     Batch 050 | Loss : 0.6342 | Acc : 0.6028
     Batch 075 | Loss : 0.6028 | Acc : 0.6202
     Batch 100 | Loss : 0.6297 | Acc : 0.6126
     Batch 125 | Loss : 0.5813 | Acc : 0.6560
     Batch 150 | Loss : 0.6450 | Acc : 0.5847
     Batch 175 | Loss : 0.5433 | Acc : 0.6912
     Batch 200 | Loss : 0.6177 | Acc : 0.6262
     Batch 225 | Loss : 0.6291 | Acc : 0.6166
     Batch 250 | Loss : 0.6234 | Acc : 0.6233
     Batch 275 | Loss : 0.6403 | Acc : 0.5845
     Batch 300 | Loss : 0.5882 | Acc : 0.6403
Epoch 00009 | Train Loss : 0.5998 | Eval Loss : 0.5977 | Train acc : 0.6363 | Eval Acc : 0.6388
     Batch 000 | Loss : 0.5825 | Acc : 0.6504
     Batch 025 | Loss : 0.6395 | Acc : 0.6025
     Batch 050 | Loss : 0.6738 | Acc : 0.5619
     Batch 075 | Loss : 0.5874 | Acc : 0.6410
     Batch 100 | Loss : 0.6167 | Acc : 0.6101
     Batch 125 | Loss : 0.5506 | Acc : 0.6750
     Batch 150 | Loss : 0.6362 | Acc : 0.6083
     Batch 175 | Loss : 0.5468 | Acc : 0.6718
     Batch 200 | Loss : 0.5539 | Acc : 0.6743
     Batch 225 | Loss : 0.5492 | Acc : 0.6727
     Batch 250 | Loss : 0.5931 | Acc : 0.6471
     Batch 275 | Loss : 0.6406 | Acc : 0.5880
     Batch 300 | Loss : 0.6158 | Acc : 0.6296
Epoch 00010 | Train Loss : 0.5999 | Eval Loss : 0.5982 | Train acc : 0.6354 | Eval Acc : 0.6356
     Batch 000 | Loss : 0.6203 | Acc : 0.6221
     Batch 025 | Loss : 0.5996 | Acc : 0.6384
     Batch 050 | Loss : 1.1062 | Acc : 0.6090
     Batch 075 | Loss : 0.6537 | Acc : 0.5935
     Batch 100 | Loss : 0.6471 | Acc : 0.5905
     Batch 125 | Loss : 0.6185 | Acc : 0.6118
     Batch 150 | Loss : 0.6383 | Acc : 0.5905
     Batch 175 | Loss : 0.5887 | Acc : 0.6403
     Batch 200 | Loss : 0.6075 | Acc : 0.6090
     Batch 225 | Loss : 0.6178 | Acc : 0.6238
     Batch 250 | Loss : 0.6166 | Acc : 0.6423
     Batch 275 | Loss : 0.5799 | Acc : 0.6614
     Batch 300 | Loss : 0.6617 | Acc : 0.5623
Epoch 00011 | Train Loss : 0.6411 | Eval Loss : 0.6204 | Train acc : 0.6138 | Eval Acc : 0.6251
     Batch 000 | Loss : 0.5676 | Acc : 0.6742
     Batch 025 | Loss : 0.6415 | Acc : 0.5944
     Batch 050 | Loss : 0.6296 | Acc : 0.6085
     Batch 075 | Loss : 0.5666 | Acc : 0.6721
     Batch 100 | Loss : 0.5798 | Acc : 0.6509
     Batch 125 | Loss : 0.5899 | Acc : 0.6388
     Batch 150 | Loss : 0.6256 | Acc : 0.5991
     Batch 175 | Loss : 0.6364 | Acc : 0.5935
     Batch 200 | Loss : 0.6219 | Acc : 0.6045
     Batch 225 | Loss : 0.6368 | Acc : 0.5874
     Batch 250 | Loss : 0.6054 | Acc : 0.6218
     Batch 275 | Loss : 0.5526 | Acc : 0.6654
     Batch 300 | Loss : 0.5823 | Acc : 0.6414
Epoch 00012 | Train Loss : 0.6058 | Eval Loss : 0.5995 | Train acc : 0.6225 | Eval Acc : 0.6255
     Batch 000 | Loss : 0.6252 | Acc : 0.6032
     Batch 025 | Loss : 0.6116 | Acc : 0.6004
     Batch 050 | Loss : 0.5528 | Acc : 0.6700
     Batch 075 | Loss : 0.6036 | Acc : 0.6354
     Batch 100 | Loss : 0.5442 | Acc : 0.6749
     Batch 125 | Loss : 0.5947 | Acc : 0.6349
     Batch 150 | Loss : 0.5523 | Acc : 0.6715
     Batch 175 | Loss : 0.5455 | Acc : 0.6804
     Batch 200 | Loss : 0.5998 | Acc : 0.6094
     Batch 225 | Loss : 0.6425 | Acc : 0.5853
     Batch 250 | Loss : 0.5632 | Acc : 0.6500
     Batch 275 | Loss : 0.6344 | Acc : 0.5789
     Batch 300 | Loss : 0.5559 | Acc : 0.6613
Epoch 00013 | Train Loss : 0.6016 | Eval Loss : 0.5993 | Train acc : 0.6221 | Eval Acc : 0.6255
     Batch 000 | Loss : 0.6344 | Acc : 0.5918
     Batch 025 | Loss : 0.6299 | Acc : 0.5952
     Batch 050 | Loss : 0.6317 | Acc : 0.5925
     Batch 075 | Loss : 0.5465 | Acc : 0.6747
     Batch 100 | Loss : 0.6339 | Acc : 0.5893
     Batch 125 | Loss : 0.6026 | Acc : 0.6220
     Batch 150 | Loss : 0.5928 | Acc : 0.6291
     Batch 175 | Loss : 0.5706 | Acc : 0.6509
     Batch 200 | Loss : 0.5952 | Acc : 0.6349
     Batch 225 | Loss : 0.6364 | Acc : 0.5899
     Batch 250 | Loss : 0.5610 | Acc : 0.6652
     Batch 275 | Loss : 0.6120 | Acc : 0.6124
     Batch 300 | Loss : 0.6238 | Acc : 0.5883
Epoch 00014 | Train Loss : 0.6007 | Eval Loss : 0.5990 | Train acc : 0.6225 | Eval Acc : 0.6255
     Batch 000 | Loss : 0.5452 | Acc : 0.6804
     Batch 025 | Loss : 0.6410 | Acc : 0.5846
     Batch 050 | Loss : 0.5467 | Acc : 0.6747
     Batch 075 | Loss : 0.6439 | Acc : 0.5669
     Batch 100 | Loss : 0.5835 | Acc : 0.6408
     Batch 125 | Loss : 0.5980 | Acc : 0.6257
     Batch 150 | Loss : 0.6014 | Acc : 0.6239
     Batch 175 | Loss : 0.6364 | Acc : 0.5761
     Batch 200 | Loss : 0.6272 | Acc : 0.5966
     Batch 225 | Loss : 0.6314 | Acc : 0.5938
     Batch 250 | Loss : 0.6210 | Acc : 0.5895
     Batch 275 | Loss : 0.6044 | Acc : 0.6225
     Batch 300 | Loss : 0.5606 | Acc : 0.6616
Epoch 00015 | Train Loss : 0.6007 | Eval Loss : 0.5995 | Train acc : 0.6217 | Eval Acc : 0.6255
     Batch 000 | Loss : 0.6373 | Acc : 0.5877
     Batch 025 | Loss : 0.5980 | Acc : 0.6257
     Batch 050 | Loss : 0.6229 | Acc : 0.6022
     Batch 075 | Loss : 0.5599 | Acc : 0.6525
     Batch 100 | Loss : 0.6006 | Acc : 0.6259
     Batch 125 | Loss : 0.5626 | Acc : 0.6535
     Batch 150 | Loss : 0.5515 | Acc : 0.6684
     Batch 175 | Loss : 0.6585 | Acc : 0.5625
     Batch 200 | Loss : 0.6177 | Acc : 0.6085
     Batch 225 | Loss : 0.6158 | Acc : 0.5989
     Batch 250 | Loss : 0.6160 | Acc : 0.6066
     Batch 275 | Loss : 0.5860 | Acc : 0.6419
     Batch 300 | Loss : 0.5929 | Acc : 0.6284
Epoch 00016 | Train Loss : 0.6007 | Eval Loss : 0.5991 | Train acc : 0.6219 | Eval Acc : 0.6255
     Batch 000 | Loss : 0.5929 | Acc : 0.6284
     Batch 025 | Loss : 0.5927 | Acc : 0.6363
     Batch 050 | Loss : 0.6034 | Acc : 0.6103
     Batch 075 | Loss : 0.5947 | Acc : 0.6296
     Batch 100 | Loss : 0.6335 | Acc : 0.5893
     Batch 125 | Loss : 0.6021 | Acc : 0.6222
     Batch 150 | Loss : 0.6228 | Acc : 0.5992
     Batch 175 | Loss : 0.5879 | Acc : 0.6408
     Batch 200 | Loss : 0.6024 | Acc : 0.6220
     Batch 225 | Loss : 0.5931 | Acc : 0.6404
     Batch 250 | Loss : 0.6348 | Acc : 0.5896
     Batch 275 | Loss : 0.5943 | Acc : 0.6448
     Batch 300 | Loss : 0.5665 | Acc : 0.6675
Epoch 00017 | Train Loss : 0.6021 | Eval Loss : 0.6060 | Train acc : 0.6223 | Eval Acc : 0.6255
     Batch 000 | Loss : 0.6352 | Acc : 0.5940
     Batch 025 | Loss : 0.5979 | Acc : 0.6238
     Batch 050 | Loss : 0.6273 | Acc : 0.5976
     Batch 075 | Loss : 0.6371 | Acc : 0.5879
     Batch 100 | Loss : 0.5960 | Acc : 0.6404
     Batch 125 | Loss : 0.6338 | Acc : 0.5914
     Batch 150 | Loss : 0.6417 | Acc : 0.5846
     Batch 175 | Loss : 0.6400 | Acc : 0.5874
     Batch 200 | Loss : 0.6359 | Acc : 0.5910
     Batch 225 | Loss : 0.6162 | Acc : 0.6075
     Batch 250 | Loss : 0.5643 | Acc : 0.6596
     Batch 275 | Loss : 0.6188 | Acc : 0.6063
     Batch 300 | Loss : 0.6200 | Acc : 0.6077
Epoch 00018 | Train Loss : 0.6018 | Eval Loss : 0.5995 | Train acc : 0.6223 | Eval Acc : 0.6255
     Batch 000 | Loss : 0.5524 | Acc : 0.6684
     Batch 025 | Loss : 0.6357 | Acc : 0.5760
     Batch 050 | Loss : 0.5454 | Acc : 0.6753
     Batch 075 | Loss : 0.5683 | Acc : 0.6555
     Batch 100 | Loss : 0.6128 | Acc : 0.5999
     Batch 125 | Loss : 0.5867 | Acc : 0.6287
     Batch 150 | Loss : 0.6152 | Acc : 0.6149
     Batch 175 | Loss : 0.6352 | Acc : 0.5956
     Batch 200 | Loss : 0.5926 | Acc : 0.6337
     Batch 225 | Loss : 0.5974 | Acc : 0.6296
     Batch 250 | Loss : 0.6191 | Acc : 0.6101
     Batch 275 | Loss : 0.5626 | Acc : 0.6535
     Batch 300 | Loss : 0.5626 | Acc : 0.6615
Epoch 00019 | Train Loss : 0.6010 | Eval Loss : 0.5990 | Train acc : 0.6216 | Eval Acc : 0.6255
     Batch 000 | Loss : 0.6356 | Acc : 0.5879
     Batch 025 | Loss : 0.5819 | Acc : 0.6435
     Batch 050 | Loss : 0.6012 | Acc : 0.6220
     Batch 075 | Loss : 0.6400 | Acc : 0.5874
     Batch 100 | Loss : 0.5976 | Acc : 0.6295
     Batch 125 | Loss : 0.5783 | Acc : 0.6455
     Batch 150 | Loss : 0.5409 | Acc : 0.6835
     Batch 175 | Loss : 0.5930 | Acc : 0.6404
     Batch 200 | Loss : 0.6061 | Acc : 0.6263
     Batch 225 | Loss : 0.5946 | Acc : 0.6183
     Batch 250 | Loss : 0.6300 | Acc : 0.5962
     Batch 275 | Loss : 0.6269 | Acc : 0.5850
     Batch 300 | Loss : 0.5884 | Acc : 0.6350
Epoch 00020 | Train Loss : 0.6006 | Eval Loss : 0.6003 | Train acc : 0.6220 | Eval Acc : 0.6255
     Batch 000 | Loss : 0.5638 | Acc : 0.6580
     Batch 025 | Loss : 0.5562 | Acc : 0.6675
     Batch 050 | Loss : 0.6181 | Acc : 0.5967
     Batch 075 | Loss : 0.6415 | Acc : 0.5817
     Batch 100 | Loss : 0.6354 | Acc : 0.5954
     Batch 125 | Loss : 0.6172 | Acc : 0.6071
     Batch 150 | Loss : 0.6231 | Acc : 0.5992
     Batch 175 | Loss : 0.6316 | Acc : 0.5780
     Batch 200 | Loss : 0.5658 | Acc : 0.6565
     Batch 225 | Loss : 0.5996 | Acc : 0.6239
     Batch 250 | Loss : 0.6299 | Acc : 0.5962
     Batch 275 | Loss : 0.5940 | Acc : 0.6292
     Batch 300 | Loss : 0.5608 | Acc : 0.6549
Epoch 00021 | Train Loss : 0.6008 | Eval Loss : 0.5991 | Train acc : 0.6222 | Eval Acc : 0.6255
     Batch 000 | Loss : 0.6153 | Acc : 0.6090
     Batch 025 | Loss : 0.5427 | Acc : 0.6853
     Batch 050 | Loss : 0.6073 | Acc : 0.6174
     Batch 075 | Loss : 0.6251 | Acc : 0.6085
     Batch 100 | Loss : 0.6566 | Acc : 0.5758
     Batch 125 | Loss : 0.5797 | Acc : 0.6468
     Batch 150 | Loss : 0.6432 | Acc : 0.5682
     Batch 175 | Loss : 0.5611 | Acc : 0.6625
     Batch 200 | Loss : 0.5517 | Acc : 0.6735
     Batch 225 | Loss : 0.6205 | Acc : 0.6018
     Batch 250 | Loss : 0.5636 | Acc : 0.6573
     Batch 275 | Loss : 0.6406 | Acc : 0.5864
     Batch 300 | Loss : 0.6061 | Acc : 0.6150
Epoch 00022 | Train Loss : 0.6116 | Eval Loss : 0.6012 | Train acc : 0.6184 | Eval Acc : 0.6243
     Batch 000 | Loss : 0.6179 | Acc : 0.6104
     Batch 025 | Loss : 0.6041 | Acc : 0.6117
     Batch 050 | Loss : 0.6423 | Acc : 0.5836
     Batch 075 | Loss : 0.5945 | Acc : 0.6211
     Batch 100 | Loss : 0.6019 | Acc : 0.6266
     Batch 125 | Loss : 0.6203 | Acc : 0.6087
     Batch 150 | Loss : 0.5979 | Acc : 0.6301
     Batch 175 | Loss : 0.6099 | Acc : 0.6175
     Batch 200 | Loss : 0.6488 | Acc : 0.5725
     Batch 225 | Loss : 0.6247 | Acc : 0.6052
     Batch 250 | Loss : 0.5994 | Acc : 0.6219
     Batch 275 | Loss : 0.6373 | Acc : 0.5901
     Batch 300 | Loss : 0.5581 | Acc : 0.6623
Epoch 00023 | Train Loss : 0.6025 | Eval Loss : 0.6007 | Train acc : 0.6202 | Eval Acc : 0.6237
     Batch 000 | Loss : 0.6348 | Acc : 0.5898
     Batch 025 | Loss : 0.5888 | Acc : 0.6387
     Batch 050 | Loss : 0.6210 | Acc : 0.6022
     Batch 075 | Loss : 0.6425 | Acc : 0.5688
     Batch 100 | Loss : 0.6138 | Acc : 0.5967
     Batch 125 | Loss : 0.6167 | Acc : 0.6050
     Batch 150 | Loss : 0.5424 | Acc : 0.6827
     Batch 175 | Loss : 0.5467 | Acc : 0.6762
     Batch 200 | Loss : 0.6247 | Acc : 0.5899
     Batch 225 | Loss : 0.6042 | Acc : 0.6226
     Batch 250 | Loss : 0.5587 | Acc : 0.6623
     Batch 275 | Loss : 0.6072 | Acc : 0.6145
     Batch 300 | Loss : 0.5961 | Acc : 0.6172
Epoch 00024 | Train Loss : 0.6026 | Eval Loss : 0.6006 | Train acc : 0.6196 | Eval Acc : 0.6237
     Batch 000 | Loss : 0.5755 | Acc : 0.6446
     Batch 025 | Loss : 0.6015 | Acc : 0.6261
     Batch 050 | Loss : 0.6315 | Acc : 0.5943
     Batch 075 | Loss : 0.5436 | Acc : 0.6825
     Batch 100 | Loss : 0.5958 | Acc : 0.6274
     Batch 125 | Loss : 0.6393 | Acc : 0.5836
     Batch 150 | Loss : 0.6269 | Acc : 0.6042
     Batch 175 | Loss : 0.5849 | Acc : 0.6492
     Batch 200 | Loss : 0.6036 | Acc : 0.6238
     Batch 225 | Loss : 0.6132 | Acc : 0.6179
     Batch 250 | Loss : 0.5413 | Acc : 0.6790
     Batch 275 | Loss : 0.5958 | Acc : 0.6344
     Batch 300 | Loss : 0.6307 | Acc : 0.5920
Epoch 00025 | Train Loss : 0.6023 | Eval Loss : 0.6008 | Train acc : 0.6204 | Eval Acc : 0.6113
     Batch 000 | Loss : 0.6261 | Acc : 0.5878
     Batch 025 | Loss : 0.6356 | Acc : 0.5903
     Batch 050 | Loss : 0.5947 | Acc : 0.6267
     Batch 075 | Loss : 0.6137 | Acc : 0.6158
     Batch 100 | Loss : 0.6247 | Acc : 0.5998
     Batch 125 | Loss : 0.5797 | Acc : 0.6501
     Batch 150 | Loss : 0.6216 | Acc : 0.6002
     Batch 175 | Loss : 0.6416 | Acc : 0.5840
     Batch 200 | Loss : 0.5607 | Acc : 0.6614
     Batch 225 | Loss : 0.5803 | Acc : 0.6434
     Batch 250 | Loss : 0.5976 | Acc : 0.6178
     Batch 275 | Loss : 0.6422 | Acc : 0.5736
     Batch 300 | Loss : 0.6165 | Acc : 0.6134
Epoch 00026 | Train Loss : 0.6023 | Eval Loss : 0.6006 | Train acc : 0.6203 | Eval Acc : 0.6243
     Batch 000 | Loss : 0.6362 | Acc : 0.5881
     Batch 025 | Loss : 0.6274 | Acc : 0.5942
     Batch 050 | Loss : 0.5756 | Acc : 0.6446
     Batch 075 | Loss : 0.6165 | Acc : 0.6065
     Batch 100 | Loss : 0.6337 | Acc : 0.5906
     Batch 125 | Loss : 0.5877 | Acc : 0.6401
     Batch 150 | Loss : 0.6377 | Acc : 0.5869
     Batch 175 | Loss : 0.6043 | Acc : 0.6339
     Batch 200 | Loss : 0.6355 | Acc : 0.5904
     Batch 225 | Loss : 0.5712 | Acc : 0.6479
     Batch 250 | Loss : 0.5610 | Acc : 0.6657
     Batch 275 | Loss : 0.5998 | Acc : 0.6247
     Batch 300 | Loss : 0.5498 | Acc : 0.6716
Epoch 00027 | Train Loss : 0.6023 | Eval Loss : 0.6003 | Train acc : 0.6202 | Eval Acc : 0.6253
     Batch 000 | Loss : 0.6122 | Acc : 0.6131
     Batch 025 | Loss : 0.6450 | Acc : 0.5961
     Batch 050 | Loss : 0.6250 | Acc : 0.6048
     Batch 075 | Loss : 0.6432 | Acc : 0.5800
     Batch 100 | Loss : 0.6312 | Acc : 0.5939
     Batch 125 | Loss : 0.6375 | Acc : 0.5904
     Batch 150 | Loss : 0.6258 | Acc : 0.6031
     Batch 175 | Loss : 0.6340 | Acc : 0.5901
     Batch 200 | Loss : 0.5466 | Acc : 0.6807
     Batch 225 | Loss : 0.5610 | Acc : 0.6614
     Batch 250 | Loss : 0.5803 | Acc : 0.6434
     Batch 275 | Loss : 0.6030 | Acc : 0.6221
     Batch 300 | Loss : 0.5655 | Acc : 0.6553
Epoch 00028 | Train Loss : 0.6119 | Eval Loss : 0.6008 | Train acc : 0.6176 | Eval Acc : 0.6237
     Batch 000 | Loss : 0.5803 | Acc : 0.6434
     Batch 025 | Loss : 0.6317 | Acc : 0.5943
     Batch 050 | Loss : 0.6363 | Acc : 0.5903
     Batch 075 | Loss : 0.5628 | Acc : 0.6569
     Batch 100 | Loss : 0.5681 | Acc : 0.6538
     Batch 125 | Loss : 0.6105 | Acc : 0.6139
     Batch 150 | Loss : 0.5501 | Acc : 0.6691
     Batch 175 | Loss : 0.5837 | Acc : 0.6426
     Batch 200 | Loss : 0.6041 | Acc : 0.6232
     Batch 225 | Loss : 0.6364 | Acc : 0.5745
     Batch 250 | Loss : 0.5992 | Acc : 0.6219
     Batch 275 | Loss : 0.5968 | Acc : 0.6135
     Batch 300 | Loss : 0.5644 | Acc : 0.6616
Epoch 00029 | Train Loss : 0.6024 | Eval Loss : 0.6023 | Train acc : 0.6201 | Eval Acc : 0.6102
     Batch 000 | Loss : 0.6008 | Acc : 0.6133
     Batch 025 | Loss : 0.5901 | Acc : 0.6329
     Batch 050 | Loss : 0.6380 | Acc : 0.5861
     Batch 075 | Loss : 0.5657 | Acc : 0.6507
     Batch 100 | Loss : 0.6436 | Acc : 0.5837
     Batch 125 | Loss : 0.6114 | Acc : 0.6139
     Batch 150 | Loss : 0.6344 | Acc : 0.5930
     Batch 175 | Loss : 0.6430 | Acc : 0.5729
     Batch 200 | Loss : 0.6137 | Acc : 0.6108
     Batch 225 | Loss : 0.6186 | Acc : 0.6098
     Batch 250 | Loss : 0.6237 | Acc : 0.5978
     Batch 275 | Loss : 0.5904 | Acc : 0.6326
     Batch 300 | Loss : 0.6128 | Acc : 0.6117
Epoch 00030 | Train Loss : 0.6028 | Eval Loss : 0.6010 | Train acc : 0.6192 | Eval Acc : 0.6237
     Batch 000 | Loss : 0.6040 | Acc : 0.6238
     Batch 025 | Loss : 0.6367 | Acc : 0.5896
     Batch 050 | Loss : 0.6434 | Acc : 0.5800
     Batch 075 | Loss : 0.5553 | Acc : 0.6689
     Batch 100 | Loss : 0.5597 | Acc : 0.6549
     Batch 125 | Loss : 0.6390 | Acc : 0.5851
     Batch 150 | Loss : 0.6164 | Acc : 0.6134
     Batch 175 | Loss : 0.5913 | Acc : 0.6286
     Batch 200 | Loss : 0.5874 | Acc : 0.6399
     Batch 225 | Loss : 0.6165 | Acc : 0.6137
     Batch 250 | Loss : 0.5638 | Acc : 0.6513
     Batch 275 | Loss : 0.6372 | Acc : 0.5684
     Batch 300 | Loss : 0.6224 | Acc : 0.6002
Epoch 00031 | Train Loss : 0.6027 | Eval Loss : 0.6009 | Train acc : 0.6196 | Eval Acc : 0.6113
     Batch 000 | Loss : 0.6132 | Acc : 0.5993
     Batch 025 | Loss : 0.6278 | Acc : 0.5942
     Batch 050 | Loss : 0.6029 | Acc : 0.6221
     Batch 075 | Loss : 0.5633 | Acc : 0.6597
     Batch 100 | Loss : 0.5653 | Acc : 0.6556
     Batch 125 | Loss : 0.6027 | Acc : 0.6217
     Batch 150 | Loss : 0.6366 | Acc : 0.5896
     Batch 175 | Loss : 0.6177 | Acc : 0.6056
     Batch 200 | Loss : 0.5592 | Acc : 0.6662
     Batch 225 | Loss : 0.6137 | Acc : 0.6096
     Batch 250 | Loss : 0.5781 | Acc : 0.6501
     Batch 275 | Loss : 0.5870 | Acc : 0.6387
     Batch 300 | Loss : 0.5498 | Acc : 0.6700
Epoch 00032 | Train Loss : 0.6026 | Eval Loss : 0.6008 | Train acc : 0.6198 | Eval Acc : 0.6237
     Batch 000 | Loss : 0.5504 | Acc : 0.6694
     Batch 025 | Loss : 0.5432 | Acc : 0.6785
     Batch 050 | Loss : 0.5926 | Acc : 0.6319
     Batch 075 | Loss : 0.6352 | Acc : 0.5823
     Batch 100 | Loss : 0.5940 | Acc : 0.6361
     Batch 125 | Loss : 0.5653 | Acc : 0.6597
     Batch 150 | Loss : 0.5634 | Acc : 0.6563
     Batch 175 | Loss : 0.5616 | Acc : 0.6593
     Batch 200 | Loss : 0.6273 | Acc : 0.5869
     Batch 225 | Loss : 0.5494 | Acc : 0.6720
     Batch 250 | Loss : 0.5638 | Acc : 0.6524
     Batch 275 | Loss : 0.6048 | Acc : 0.6231
     Batch 300 | Loss : 0.5588 | Acc : 0.6609
Epoch 00033 | Train Loss : 0.6027 | Eval Loss : 0.6008 | Train acc : 0.6199 | Eval Acc : 0.6237
     Batch 000 | Loss : 0.6067 | Acc : 0.6182
     Batch 025 | Loss : 0.5607 | Acc : 0.6637
     Batch 050 | Loss : 0.5398 | Acc : 0.6710
     Batch 075 | Loss : 0.5637 | Acc : 0.6570
     Batch 100 | Loss : 0.5949 | Acc : 0.6267
     Batch 125 | Loss : 0.6270 | Acc : 0.5948
     Batch 150 | Loss : 0.6039 | Acc : 0.6179
     Batch 175 | Loss : 0.6059 | Acc : 0.6202
     Batch 200 | Loss : 0.6170 | Acc : 0.6080
     Batch 225 | Loss : 0.5757 | Acc : 0.6433
     Batch 250 | Loss : 0.6249 | Acc : 0.5877
     Batch 275 | Loss : 0.6500 | Acc : 0.5728
     Batch 300 | Loss : 0.5950 | Acc : 0.6386
Epoch 00034 | Train Loss : 0.6025 | Eval Loss : 0.6007 | Train acc : 0.6199 | Eval Acc : 0.6237
     Batch 000 | Loss : 0.6191 | Acc : 0.6043
     Batch 025 | Loss : 0.5933 | Acc : 0.6308
     Batch 050 | Loss : 0.5544 | Acc : 0.6628
     Batch 075 | Loss : 0.6197 | Acc : 0.5943
     Batch 100 | Loss : 0.5690 | Acc : 0.6488
     Batch 125 | Loss : 0.6059 | Acc : 0.6208
     Batch 150 | Loss : 0.5568 | Acc : 0.6634
     Batch 175 | Loss : 0.5657 | Acc : 0.6563
     Batch 200 | Loss : 0.5583 | Acc : 0.6609
     Batch 225 | Loss : 0.6144 | Acc : 0.6000
     Batch 250 | Loss : 0.6407 | Acc : 0.5702
     Batch 275 | Loss : 0.5637 | Acc : 0.6563
     Batch 300 | Loss : 0.5995 | Acc : 0.6278
Epoch 00035 | Train Loss : 0.6026 | Eval Loss : 0.6006 | Train acc : 0.6198 | Eval Acc : 0.6237
     Batch 000 | Loss : 0.6350 | Acc : 0.5943
     Batch 025 | Loss : 0.5554 | Acc : 0.6534
     Batch 050 | Loss : 0.5605 | Acc : 0.6625
     Batch 075 | Loss : 0.6200 | Acc : 0.5906
     Batch 100 | Loss : 0.6306 | Acc : 0.5956
     Batch 125 | Loss : 0.5413 | Acc : 0.6815
     Batch 150 | Loss : 0.6282 | Acc : 0.5911
     Batch 175 | Loss : 0.6148 | Acc : 0.6137
     Batch 200 | Loss : 0.5823 | Acc : 0.6426
     Batch 225 | Loss : 0.6274 | Acc : 0.5955
     Batch 250 | Loss : 0.5634 | Acc : 0.6563
     Batch 275 | Loss : 0.5582 | Acc : 0.6567
     Batch 300 | Loss : 0.5990 | Acc : 0.6219
Epoch 00036 | Train Loss : 0.6024 | Eval Loss : 0.6009 | Train acc : 0.6200 | Eval Acc : 0.6113
     Batch 000 | Loss : 0.6371 | Acc : 0.5738
     Batch 025 | Loss : 0.5485 | Acc : 0.6721
     Batch 050 | Loss : 0.5895 | Acc : 0.6387
     Batch 075 | Loss : 0.6348 | Acc : 0.5943
     Batch 100 | Loss : 0.5391 | Acc : 0.6833
     Batch 125 | Loss : 0.6148 | Acc : 0.6092
     Batch 150 | Loss : 0.6073 | Acc : 0.6246
     Batch 175 | Loss : 0.5589 | Acc : 0.6609
     Batch 200 | Loss : 0.6041 | Acc : 0.6080
     Batch 225 | Loss : 0.5540 | Acc : 0.6697
     Batch 250 | Loss : 0.5704 | Acc : 0.6520
     Batch 275 | Loss : 0.6184 | Acc : 0.6075
     Batch 300 | Loss : 0.5975 | Acc : 0.6319
Epoch 00037 | Train Loss : 0.6024 | Eval Loss : 0.6007 | Train acc : 0.6203 | Eval Acc : 0.6237
     Batch 000 | Loss : 0.5608 | Acc : 0.6629
     Batch 025 | Loss : 0.6219 | Acc : 0.6002
     Batch 050 | Loss : 0.5867 | Acc : 0.6413
     Batch 075 | Loss : 0.5708 | Acc : 0.6412
     Batch 100 | Loss : 0.5998 | Acc : 0.6120
     Batch 125 | Loss : 0.5880 | Acc : 0.6492
     Batch 150 | Loss : 0.6101 | Acc : 0.6171
     Batch 175 | Loss : 0.5991 | Acc : 0.6279
     Batch 200 | Loss : 0.5884 | Acc : 0.6265
     Batch 225 | Loss : 0.6069 | Acc : 0.6102
     Batch 250 | Loss : 0.6426 | Acc : 0.5706
     Batch 275 | Loss : 0.6273 | Acc : 0.5957
     Batch 300 | Loss : 0.6265 | Acc : 0.5830
Epoch 00038 | Train Loss : 0.6048 | Eval Loss : 0.6011 | Train acc : 0.6194 | Eval Acc : 0.6116
     Batch 000 | Loss : 0.6008 | Acc : 0.6166
     Batch 025 | Loss : 0.6308 | Acc : 0.6050
     Batch 050 | Loss : 0.5914 | Acc : 0.6456
     Batch 075 | Loss : 0.6278 | Acc : 0.5917
     Batch 100 | Loss : 0.6420 | Acc : 0.5683
     Batch 125 | Loss : 0.6276 | Acc : 0.5957
     Batch 150 | Loss : 0.6110 | Acc : 0.6141
     Batch 175 | Loss : 0.6045 | Acc : 0.6185
     Batch 200 | Loss : 0.6068 | Acc : 0.6203
     Batch 225 | Loss : 0.5984 | Acc : 0.6332
     Batch 250 | Loss : 0.5501 | Acc : 0.6684
     Batch 275 | Loss : 0.6600 | Acc : 0.5610
     Batch 300 | Loss : 0.5437 | Acc : 0.6817
Epoch 00039 | Train Loss : 0.6674 | Eval Loss : 0.6011 | Train acc : 0.6145 | Eval Acc : 0.6237
     Batch 000 | Loss : 0.5661 | Acc : 0.6591
     Batch 025 | Loss : 0.6037 | Acc : 0.6232
     Batch 050 | Loss : 0.6326 | Acc : 0.5913
     Batch 075 | Loss : 0.5527 | Acc : 0.6664
     Batch 100 | Loss : 0.6051 | Acc : 0.6221
     Batch 125 | Loss : 0.6038 | Acc : 0.6234
     Batch 150 | Loss : 0.6344 | Acc : 0.5889
     Batch 175 | Loss : 0.6418 | Acc : 0.5820
     Batch 200 | Loss : 0.5436 | Acc : 0.6716
     Batch 225 | Loss : 0.6488 | Acc : 0.5691
     Batch 250 | Loss : 0.5526 | Acc : 0.6640
     Batch 275 | Loss : 0.5604 | Acc : 0.6567
     Batch 300 | Loss : 0.5589 | Acc : 0.6674
Epoch 00040 | Train Loss : 0.6026 | Eval Loss : 0.6003 | Train acc : 0.6196 | Eval Acc : 0.6258
     Batch 000 | Loss : 0.6276 | Acc : 0.5975
     Batch 025 | Loss : 0.5845 | Acc : 0.6276
     Batch 050 | Loss : 0.6025 | Acc : 0.6227
     Batch 075 | Loss : 0.6205 | Acc : 0.6087
     Batch 100 | Loss : 0.5617 | Acc : 0.6601
     Batch 125 | Loss : 0.6389 | Acc : 0.5863
     Batch 150 | Loss : 0.5803 | Acc : 0.6465
     Batch 175 | Loss : 0.6352 | Acc : 0.5926
     Batch 200 | Loss : 0.5848 | Acc : 0.6509
     Batch 225 | Loss : 0.5392 | Acc : 0.6841
     Batch 250 | Loss : 0.6405 | Acc : 0.5862
     Batch 275 | Loss : 0.5950 | Acc : 0.6245
     Batch 300 | Loss : 0.5583 | Acc : 0.6576
Epoch 00041 | Train Loss : 0.6023 | Eval Loss : 0.6007 | Train acc : 0.6207 | Eval Acc : 0.6134
     Batch 000 | Loss : 0.6364 | Acc : 0.5772
     Batch 025 | Loss : 0.6192 | Acc : 0.6116
     Batch 050 | Loss : 0.6285 | Acc : 0.5874
     Batch 075 | Loss : 0.6455 | Acc : 0.5789
     Batch 100 | Loss : 0.6171 | Acc : 0.6089
     Batch 125 | Loss : 0.5890 | Acc : 0.6270
     Batch 150 | Loss : 0.5986 | Acc : 0.6286
     Batch 175 | Loss : 0.5765 | Acc : 0.6439
     Batch 200 | Loss : 0.6452 | Acc : 0.5768
     Batch 225 | Loss : 0.5493 | Acc : 0.6707
     Batch 250 | Loss : 0.6390 | Acc : 0.5896
     Batch 275 | Loss : 0.6170 | Acc : 0.6000
     Batch 300 | Loss : 0.6011 | Acc : 0.6322
Epoch 00042 | Train Loss : 0.6023 | Eval Loss : 0.6000 | Train acc : 0.6207 | Eval Acc : 0.6259
     Batch 000 | Loss : 0.5535 | Acc : 0.6646
     Batch 025 | Loss : 0.6417 | Acc : 0.5844
     Batch 050 | Loss : 0.6040 | Acc : 0.6218
     Batch 075 | Loss : 0.5656 | Acc : 0.6484
     Batch 100 | Loss : 0.6588 | Acc : 0.5647
     Batch 125 | Loss : 0.6254 | Acc : 0.5995
     Batch 150 | Loss : 0.6172 | Acc : 0.6083
     Batch 175 | Loss : 0.5620 | Acc : 0.6489
     Batch 200 | Loss : 0.6169 | Acc : 0.6130
     Batch 225 | Loss : 0.5883 | Acc : 0.6398
     Batch 250 | Loss : 0.5853 | Acc : 0.6509
     Batch 275 | Loss : 0.5395 | Acc : 0.6723
     Batch 300 | Loss : 0.6264 | Acc : 0.5965
Epoch 00043 | Train Loss : 0.6019 | Eval Loss : 0.6000 | Train acc : 0.6217 | Eval Acc : 0.6259
     Batch 000 | Loss : 0.5467 | Acc : 0.6743
     Batch 025 | Loss : 0.5502 | Acc : 0.6816
     Batch 050 | Loss : 0.6317 | Acc : 0.5944
     Batch 075 | Loss : 0.5598 | Acc : 0.6567
     Batch 100 | Loss : 0.6070 | Acc : 0.6091
     Batch 125 | Loss : 0.6035 | Acc : 0.6221
     Batch 150 | Loss : 0.6037 | Acc : 0.6243
     Batch 175 | Loss : 0.6286 | Acc : 0.6001
     Batch 200 | Loss : 0.6344 | Acc : 0.5796
     Batch 225 | Loss : 0.6053 | Acc : 0.6222
     Batch 250 | Loss : 0.6153 | Acc : 0.6171
     Batch 275 | Loss : 0.6309 | Acc : 0.5968
     Batch 300 | Loss : 0.6014 | Acc : 0.6293
Epoch 00044 | Train Loss : 0.6019 | Eval Loss : 0.6007 | Train acc : 0.6223 | Eval Acc : 0.6268
     Batch 000 | Loss : 0.5694 | Acc : 0.6553
     Batch 025 | Loss : 0.5924 | Acc : 0.6349
     Batch 050 | Loss : 0.6300 | Acc : 0.5980
     Batch 075 | Loss : 0.6411 | Acc : 0.5861
     Batch 100 | Loss : 0.6184 | Acc : 0.5989
     Batch 125 | Loss : 0.6376 | Acc : 0.5883
     Batch 150 | Loss : 0.6427 | Acc : 0.5830
     Batch 175 | Loss : 0.6225 | Acc : 0.6042
     Batch 200 | Loss : 0.5402 | Acc : 0.6824
     Batch 225 | Loss : 0.5615 | Acc : 0.6612
     Batch 250 | Loss : 0.6458 | Acc : 0.5773
     Batch 275 | Loss : 0.5887 | Acc : 0.6374
     Batch 300 | Loss : 0.6181 | Acc : 0.6074
Epoch 00045 | Train Loss : 0.6017 | Eval Loss : 0.5998 | Train acc : 0.6232 | Eval Acc : 0.6267
     Batch 000 | Loss : 0.5463 | Acc : 0.6743
     Batch 025 | Loss : 0.6428 | Acc : 0.5863
     Batch 050 | Loss : 0.6056 | Acc : 0.6267
     Batch 075 | Loss : 0.6093 | Acc : 0.6189
     Batch 100 | Loss : 0.6183 | Acc : 0.6074
     Batch 125 | Loss : 0.6289 | Acc : 0.5980
     Batch 150 | Loss : 0.6343 | Acc : 0.5897
     Batch 175 | Loss : 0.6124 | Acc : 0.6126
     Batch 200 | Loss : 0.6000 | Acc : 0.6279
     Batch 225 | Loss : 0.5873 | Acc : 0.6401
     Batch 250 | Loss : 0.6289 | Acc : 0.5874
     Batch 275 | Loss : 0.6138 | Acc : 0.6165
     Batch 300 | Loss : 0.6021 | Acc : 0.6236
Epoch 00046 | Train Loss : 0.6016 | Eval Loss : 0.6012 | Train acc : 0.6238 | Eval Acc : 0.6264
     Batch 000 | Loss : 0.6045 | Acc : 0.6211
     Batch 025 | Loss : 0.6193 | Acc : 0.6125
     Batch 050 | Loss : 0.6169 | Acc : 0.6136
     Batch 075 | Loss : 0.6428 | Acc : 0.5767
     Batch 100 | Loss : 0.6382 | Acc : 0.5866
     Batch 125 | Loss : 0.6162 | Acc : 0.6083
     Batch 150 | Loss : 0.6381 | Acc : 0.5874
     Batch 175 | Loss : 0.5842 | Acc : 0.6420
     Batch 200 | Loss : 0.5651 | Acc : 0.6602
     Batch 225 | Loss : 0.6188 | Acc : 0.6065
     Batch 250 | Loss : 0.5465 | Acc : 0.6816
     Batch 275 | Loss : 0.6174 | Acc : 0.6079
     Batch 300 | Loss : 0.5816 | Acc : 0.6458
Epoch 00047 | Train Loss : 0.6018 | Eval Loss : 0.6006 | Train acc : 0.6230 | Eval Acc : 0.6267
     Batch 000 | Loss : 0.6040 | Acc : 0.6239
     Batch 025 | Loss : 0.6024 | Acc : 0.6204
     Batch 050 | Loss : 0.6295 | Acc : 0.6053
     Batch 075 | Loss : 0.5875 | Acc : 0.6364
     Batch 100 | Loss : 0.6407 | Acc : 0.5866
     Batch 125 | Loss : 0.6001 | Acc : 0.6280
     Batch 150 | Loss : 0.6363 | Acc : 0.5902
     Batch 175 | Loss : 0.6268 | Acc : 0.5984
     Batch 200 | Loss : 0.5934 | Acc : 0.6310
     Batch 225 | Loss : 0.6049 | Acc : 0.6230
     Batch 250 | Loss : 0.5399 | Acc : 0.6856
     Batch 275 | Loss : 0.5935 | Acc : 0.6254
     Batch 300 | Loss : 0.6344 | Acc : 0.5932
Epoch 00048 | Train Loss : 0.6017 | Eval Loss : 0.6000 | Train acc : 0.6231 | Eval Acc : 0.6267
     Batch 000 | Loss : 0.5938 | Acc : 0.6298
     Batch 025 | Loss : 0.6188 | Acc : 0.6084
     Batch 050 | Loss : 0.6477 | Acc : 0.5661
     Batch 075 | Loss : 0.5951 | Acc : 0.6359
     Batch 100 | Loss : 0.6376 | Acc : 0.5886
     Batch 125 | Loss : 0.6422 | Acc : 0.5864
     Batch 150 | Loss : 0.5926 | Acc : 0.6351
     Batch 175 | Loss : 0.5942 | Acc : 0.6411
     Batch 200 | Loss : 0.6092 | Acc : 0.6190
     Batch 225 | Loss : 0.6181 | Acc : 0.6102
     Batch 250 | Loss : 0.6361 | Acc : 0.5894
     Batch 275 | Loss : 0.5723 | Acc : 0.6422
     Batch 300 | Loss : 0.6399 | Acc : 0.5858
Epoch 00049 | Train Loss : 0.6016 | Eval Loss : 0.6005 | Train acc : 0.6233 | Eval Acc : 0.6143
     Batch 000 | Loss : 0.5633 | Acc : 0.6540
     Batch 025 | Loss : 0.5616 | Acc : 0.6612
     Batch 050 | Loss : 0.5877 | Acc : 0.6449
     Batch 075 | Loss : 0.5534 | Acc : 0.6714
     Batch 100 | Loss : 0.5785 | Acc : 0.6519
     Batch 125 | Loss : 0.6430 | Acc : 0.5847
     Batch 150 | Loss : 0.6402 | Acc : 0.5721
     Batch 175 | Loss : 0.5626 | Acc : 0.6573
     Batch 200 | Loss : 0.6341 | Acc : 0.5967
     Batch 225 | Loss : 0.5640 | Acc : 0.6578
     Batch 250 | Loss : 0.6158 | Acc : 0.6099
     Batch 275 | Loss : 0.6427 | Acc : 0.5829
     Batch 300 | Loss : 0.6022 | Acc : 0.6236
Epoch 00050 | Train Loss : 0.6016 | Eval Loss : 0.5998 | Train acc : 0.6235 | Eval Acc : 0.6268
     Batch 000 | Loss : 0.5886 | Acc : 0.6375
     Batch 025 | Loss : 0.6377 | Acc : 0.5898
     Batch 050 | Loss : 0.5486 | Acc : 0.6734
     Batch 075 | Loss : 0.5719 | Acc : 0.6511
     Batch 100 | Loss : 0.6155 | Acc : 0.6086
     Batch 125 | Loss : 0.5635 | Acc : 0.6601
     Batch 150 | Loss : 0.6213 | Acc : 0.6085
     Batch 175 | Loss : 0.6301 | Acc : 0.5972
     Batch 200 | Loss : 0.5902 | Acc : 0.6364
     Batch 225 | Loss : 0.5571 | Acc : 0.6676
     Batch 250 | Loss : 0.6190 | Acc : 0.5966
     Batch 275 | Loss : 0.6224 | Acc : 0.5922
     Batch 300 | Loss : 0.5697 | Acc : 0.6534
Epoch 00051 | Train Loss : 0.6015 | Eval Loss : 0.6000 | Train acc : 0.6237 | Eval Acc : 0.6268
     Batch 000 | Loss : 0.6432 | Acc : 0.5831
     Batch 025 | Loss : 0.6165 | Acc : 0.6136
     Batch 050 | Loss : 0.6223 | Acc : 0.6042
     Batch 075 | Loss : 0.6353 | Acc : 0.5791
     Batch 100 | Loss : 0.5385 | Acc : 0.6856
     Batch 125 | Loss : 0.5715 | Acc : 0.6498
     Batch 150 | Loss : 0.5591 | Acc : 0.6659
     Batch 175 | Loss : 0.6208 | Acc : 0.5922
     Batch 200 | Loss : 0.6164 | Acc : 0.6007
     Batch 225 | Loss : 0.5949 | Acc : 0.6302
     Batch 250 | Loss : 0.6365 | Acc : 0.5898
     Batch 275 | Loss : 0.5384 | Acc : 0.6738
     Batch 300 | Loss : 0.6421 | Acc : 0.5723
Epoch 00052 | Train Loss : 0.6015 | Eval Loss : 0.5998 | Train acc : 0.6234 | Eval Acc : 0.6271
     Batch 000 | Loss : 0.5423 | Acc : 0.6856
     Batch 025 | Loss : 0.5652 | Acc : 0.6545
     Batch 050 | Loss : 0.5970 | Acc : 0.6341
     Batch 075 | Loss : 0.6189 | Acc : 0.6054
     Batch 100 | Loss : 0.6388 | Acc : 0.5886
     Batch 125 | Loss : 0.5842 | Acc : 0.6318
     Batch 150 | Loss : 0.6185 | Acc : 0.6065
     Batch 175 | Loss : 0.6340 | Acc : 0.5937
     Batch 200 | Loss : 0.6152 | Acc : 0.6173
     Batch 225 | Loss : 0.6594 | Acc : 0.5557
     Batch 250 | Loss : 0.6270 | Acc : 0.5967
     Batch 275 | Loss : 0.5392 | Acc : 0.6856
     Batch 300 | Loss : 0.5600 | Acc : 0.6657
Epoch 00053 | Train Loss : 0.6015 | Eval Loss : 0.5999 | Train acc : 0.6232 | Eval Acc : 0.6267
     Batch 000 | Loss : 0.5906 | Acc : 0.6362
     Batch 025 | Loss : 0.5927 | Acc : 0.6334
     Batch 050 | Loss : 0.6323 | Acc : 0.5948
     Batch 075 | Loss : 0.5504 | Acc : 0.6713
     Batch 100 | Loss : 0.6167 | Acc : 0.6007
     Batch 125 | Loss : 0.6203 | Acc : 0.6048
     Batch 150 | Loss : 0.6059 | Acc : 0.6235
     Batch 175 | Loss : 0.6384 | Acc : 0.5760
     Batch 200 | Loss : 0.5885 | Acc : 0.6375
     Batch 225 | Loss : 0.6288 | Acc : 0.6005
     Batch 250 | Loss : 0.5811 | Acc : 0.6458
     Batch 275 | Loss : 0.5794 | Acc : 0.6477
     Batch 300 | Loss : 0.5628 | Acc : 0.6664
Epoch 00054 | Train Loss : 0.6014 | Eval Loss : 0.5998 | Train acc : 0.6237 | Eval Acc : 0.6268
     Batch 000 | Loss : 0.6060 | Acc : 0.6279
     Batch 025 | Loss : 0.5923 | Acc : 0.6380
     Batch 050 | Loss : 0.6419 | Acc : 0.5836
     Batch 075 | Loss : 0.6024 | Acc : 0.6252
     Batch 100 | Loss : 0.6104 | Acc : 0.6247
     Batch 125 | Loss : 0.6409 | Acc : 0.5861
     Batch 150 | Loss : 0.5932 | Acc : 0.6396
     Batch 175 | Loss : 0.6159 | Acc : 0.6174
     Batch 200 | Loss : 0.5985 | Acc : 0.6302
     Batch 225 | Loss : 0.5840 | Acc : 0.6420
     Batch 250 | Loss : 0.6001 | Acc : 0.6284
     Batch 275 | Loss : 0.6391 | Acc : 0.5900
     Batch 300 | Loss : 0.6352 | Acc : 0.5807
Epoch 00055 | Train Loss : 0.6016 | Eval Loss : 0.5998 | Train acc : 0.6230 | Eval Acc : 0.6268
     Batch 000 | Loss : 0.6287 | Acc : 0.5954
     Batch 025 | Loss : 0.5878 | Acc : 0.6422
     Batch 050 | Loss : 0.6434 | Acc : 0.5826
     Batch 075 | Loss : 0.6324 | Acc : 0.5948
     Batch 100 | Loss : 0.5854 | Acc : 0.6518
     Batch 125 | Loss : 0.6031 | Acc : 0.6221
     Batch 150 | Loss : 0.5962 | Acc : 0.6324
     Batch 175 | Loss : 0.5624 | Acc : 0.6603
     Batch 200 | Loss : 0.6405 | Acc : 0.5854
     Batch 225 | Loss : 0.6292 | Acc : 0.5998
     Batch 250 | Loss : 0.5872 | Acc : 0.6429
     Batch 275 | Loss : 0.6056 | Acc : 0.6230
     Batch 300 | Loss : 0.5709 | Acc : 0.6529
Epoch 00056 | Train Loss : 0.6023 | Eval Loss : 0.6023 | Train acc : 0.6214 | Eval Acc : 0.6261
     Batch 000 | Loss : 0.5414 | Acc : 0.6866
     Batch 025 | Loss : 0.6379 | Acc : 0.5893
     Batch 050 | Loss : 0.6369 | Acc : 0.5880
     Batch 075 | Loss : 0.5840 | Acc : 0.6417
     Batch 100 | Loss : 0.6258 | Acc : 0.5894
     Batch 125 | Loss : 0.5654 | Acc : 0.6481
     Batch 150 | Loss : 0.5699 | Acc : 0.6521
     Batch 175 | Loss : 0.6011 | Acc : 0.6250
     Batch 200 | Loss : 0.5988 | Acc : 0.6294
     Batch 225 | Loss : 0.6009 | Acc : 0.6256
     Batch 250 | Loss : 0.6220 | Acc : 0.6050
     Batch 275 | Loss : 0.6241 | Acc : 0.6023
     Batch 300 | Loss : 0.5925 | Acc : 0.6373
Epoch 00057 | Train Loss : 0.6020 | Eval Loss : 0.6001 | Train acc : 0.6218 | Eval Acc : 0.6257
     Batch 000 | Loss : 0.5890 | Acc : 0.6357
     Batch 025 | Loss : 0.6183 | Acc : 0.6088
     Batch 050 | Loss : 0.5933 | Acc : 0.6343
     Batch 075 | Loss : 0.6289 | Acc : 0.5993
     Batch 100 | Loss : 0.6231 | Acc : 0.5893
     Batch 125 | Loss : 0.6306 | Acc : 0.5957
     Batch 150 | Loss : 0.5643 | Acc : 0.6585
     Batch 175 | Loss : 0.6270 | Acc : 0.5980
     Batch 200 | Loss : 0.5685 | Acc : 0.6617
     Batch 225 | Loss : 0.6248 | Acc : 0.6030
     Batch 250 | Loss : 0.6360 | Acc : 0.5902
     Batch 275 | Loss : 0.6205 | Acc : 0.6040
     Batch 300 | Loss : 0.6401 | Acc : 0.5848
Epoch 00058 | Train Loss : 0.6019 | Eval Loss : 0.6002 | Train acc : 0.6221 | Eval Acc : 0.6260
     Batch 000 | Loss : 0.5478 | Acc : 0.6805
     Batch 025 | Loss : 0.5876 | Acc : 0.6361
     Batch 050 | Loss : 0.5707 | Acc : 0.6481
     Batch 075 | Loss : 0.6402 | Acc : 0.5854
     Batch 100 | Loss : 0.6459 | Acc : 0.5771
     Batch 125 | Loss : 0.6242 | Acc : 0.5981
     Batch 150 | Loss : 0.6422 | Acc : 0.5828
     Batch 175 | Loss : 0.6306 | Acc : 0.5850
     Batch 200 | Loss : 0.5466 | Acc : 0.6743
     Batch 225 | Loss : 0.6033 | Acc : 0.6254
     Batch 250 | Loss : 0.6195 | Acc : 0.6033
     Batch 275 | Loss : 0.6292 | Acc : 0.5999
     Batch 300 | Loss : 0.5505 | Acc : 0.6711
Epoch 00059 | Train Loss : 0.6017 | Eval Loss : 0.6003 | Train acc : 0.6225 | Eval Acc : 0.6261
     Batch 000 | Loss : 0.6320 | Acc : 0.5956
     Batch 025 | Loss : 0.5632 | Acc : 0.6536
     Batch 050 | Loss : 0.6348 | Acc : 0.5956
     Batch 075 | Loss : 0.6099 | Acc : 0.6184
     Batch 100 | Loss : 0.6243 | Acc : 0.6011
     Batch 125 | Loss : 0.6289 | Acc : 0.5948
     Batch 150 | Loss : 0.5529 | Acc : 0.6704
     Batch 175 | Loss : 0.5521 | Acc : 0.6680
     Batch 200 | Loss : 0.6216 | Acc : 0.6067
     Batch 225 | Loss : 0.6589 | Acc : 0.5638
     Batch 250 | Loss : 0.5948 | Acc : 0.6401
     Batch 275 | Loss : 0.5939 | Acc : 0.6299
     Batch 300 | Loss : 0.5625 | Acc : 0.6651
Epoch 00060 | Train Loss : 0.6018 | Eval Loss : 0.6001 | Train acc : 0.6225 | Eval Acc : 0.6257
     Batch 000 | Loss : 0.5617 | Acc : 0.6646
     Batch 025 | Loss : 0.6422 | Acc : 0.5857
     Batch 050 | Loss : 0.5622 | Acc : 0.6649
     Batch 075 | Loss : 0.6420 | Acc : 0.5859
     Batch 100 | Loss : 0.6369 | Acc : 0.5892
     Batch 125 | Loss : 0.6180 | Acc : 0.6079
     Batch 150 | Loss : 0.6406 | Acc : 0.5853
     Batch 175 | Loss : 0.6240 | Acc : 0.6013
     Batch 200 | Loss : 0.6226 | Acc : 0.5898
     Batch 225 | Loss : 0.5624 | Acc : 0.6594
     Batch 250 | Loss : 0.5498 | Acc : 0.6720
     Batch 275 | Loss : 0.5990 | Acc : 0.6300
     Batch 300 | Loss : 0.6189 | Acc : 0.6050
Epoch 00061 | Train Loss : 0.6019 | Eval Loss : 0.6007 | Train acc : 0.6224 | Eval Acc : 0.6261
     Batch 000 | Loss : 0.5886 | Acc : 0.6394
     Batch 025 | Loss : 0.6491 | Acc : 0.5620
     Batch 050 | Loss : 0.6036 | Acc : 0.6269
     Batch 075 | Loss : 0.6276 | Acc : 0.6026
     Batch 100 | Loss : 0.5993 | Acc : 0.6258
     Batch 125 | Loss : 0.6181 | Acc : 0.6166
     Batch 150 | Loss : 0.6167 | Acc : 0.6104
     Batch 175 | Loss : 0.6190 | Acc : 0.6121
     Batch 200 | Loss : 0.6322 | Acc : 0.5956
     Batch 225 | Loss : 0.6266 | Acc : 0.6066
     Batch 250 | Loss : 0.6258 | Acc : 0.5981
     Batch 275 | Loss : 0.5496 | Acc : 0.6725
     Batch 300 | Loss : 0.5610 | Acc : 0.6656
Epoch 00062 | Train Loss : 0.6018 | Eval Loss : 0.6003 | Train acc : 0.6224 | Eval Acc : 0.6261
     Batch 000 | Loss : 0.6213 | Acc : 0.6023
     Batch 025 | Loss : 0.6364 | Acc : 0.5912
     Batch 050 | Loss : 0.6038 | Acc : 0.6219
     Batch 075 | Loss : 0.6371 | Acc : 0.5884
     Batch 100 | Loss : 0.6096 | Acc : 0.6195
     Batch 125 | Loss : 0.6009 | Acc : 0.6261
     Batch 150 | Loss : 0.5831 | Acc : 0.6424
     Batch 175 | Loss : 0.5971 | Acc : 0.6270
     Batch 200 | Loss : 0.5536 | Acc : 0.6653
     Batch 225 | Loss : 0.6343 | Acc : 0.5953
     Batch 250 | Loss : 0.5587 | Acc : 0.6600
     Batch 275 | Loss : 0.6022 | Acc : 0.6231
     Batch 300 | Loss : 0.6321 | Acc : 0.5792
Epoch 00063 | Train Loss : 0.6017 | Eval Loss : 0.6000 | Train acc : 0.6229 | Eval Acc : 0.6261
     Batch 000 | Loss : 0.5843 | Acc : 0.6412
     Batch 025 | Loss : 0.6414 | Acc : 0.5857
     Batch 050 | Loss : 0.5879 | Acc : 0.6411
     Batch 075 | Loss : 0.6256 | Acc : 0.5993
     Batch 100 | Loss : 0.6418 | Acc : 0.5856
     Batch 125 | Loss : 0.5873 | Acc : 0.6429
     Batch 150 | Loss : 0.5626 | Acc : 0.6609
     Batch 175 | Loss : 0.6152 | Acc : 0.6102
     Batch 200 | Loss : 0.6034 | Acc : 0.6258
     Batch 225 | Loss : 0.6180 | Acc : 0.6083
     Batch 250 | Loss : 0.6370 | Acc : 0.5791
     Batch 275 | Loss : 0.5816 | Acc : 0.6310
     Batch 300 | Loss : 0.5997 | Acc : 0.6172
Epoch 00064 | Train Loss : 0.6018 | Eval Loss : 0.6011 | Train acc : 0.6228 | Eval Acc : 0.6133
     Batch 000 | Loss : 0.6122 | Acc : 0.6023
     Batch 025 | Loss : 0.6003 | Acc : 0.6193
     Batch 050 | Loss : 0.5907 | Acc : 0.6341
     Batch 075 | Loss : 0.6212 | Acc : 0.6079
     Batch 100 | Loss : 0.5639 | Acc : 0.6596
     Batch 125 | Loss : 0.6386 | Acc : 0.5873
     Batch 150 | Loss : 0.6167 | Acc : 0.5984
     Batch 175 | Loss : 0.6275 | Acc : 0.6052
     Batch 200 | Loss : 0.5681 | Acc : 0.6457
     Batch 225 | Loss : 0.5719 | Acc : 0.6504
     Batch 250 | Loss : 0.6363 | Acc : 0.5738
     Batch 275 | Loss : 0.5898 | Acc : 0.6367
     Batch 300 | Loss : 0.6167 | Acc : 0.6092
Epoch 00065 | Train Loss : 0.6031 | Eval Loss : 0.6017 | Train acc : 0.6210 | Eval Acc : 0.6237
     Batch 000 | Loss : 0.6421 | Acc : 0.5834
     Batch 025 | Loss : 0.5946 | Acc : 0.6361
     Batch 050 | Loss : 0.5733 | Acc : 0.6493
     Batch 075 | Loss : 0.5857 | Acc : 0.6394
     Batch 100 | Loss : 0.6203 | Acc : 0.6016
     Batch 125 | Loss : 0.6420 | Acc : 0.5724
     Batch 150 | Loss : 0.6487 | Acc : 0.5747
     Batch 175 | Loss : 0.5595 | Acc : 0.6670
     Batch 200 | Loss : 0.6413 | Acc : 0.5825
     Batch 225 | Loss : 0.6253 | Acc : 0.5999
     Batch 250 | Loss : 0.5641 | Acc : 0.6563
     Batch 275 | Loss : 0.6089 | Acc : 0.6047
     Batch 300 | Loss : 0.5578 | Acc : 0.6545
Epoch 00066 | Train Loss : 0.6030 | Eval Loss : 0.6023 | Train acc : 0.6199 | Eval Acc : 0.6113
     Batch 000 | Loss : 0.5894 | Acc : 0.6259
     Batch 025 | Loss : 0.6348 | Acc : 0.5944
     Batch 050 | Loss : 0.6069 | Acc : 0.6220
     Batch 075 | Loss : 0.6452 | Acc : 0.5806
     Batch 100 | Loss : 0.6018 | Acc : 0.6250
     Batch 125 | Loss : 0.5437 | Acc : 0.6666
     Batch 150 | Loss : 0.5622 | Acc : 0.6652
     Batch 175 | Loss : 0.5508 | Acc : 0.6578
     Batch 200 | Loss : 0.6383 | Acc : 0.5738
     Batch 225 | Loss : 0.6001 | Acc : 0.6245
     Batch 250 | Loss : 0.6421 | Acc : 0.5806
     Batch 275 | Loss : 0.5842 | Acc : 0.6414
     Batch 300 | Loss : 0.5697 | Acc : 0.6548
Epoch 00067 | Train Loss : 0.6029 | Eval Loss : 0.6015 | Train acc : 0.6202 | Eval Acc : 0.6113
     Batch 000 | Loss : 0.6000 | Acc : 0.6167
     Batch 025 | Loss : 0.6167 | Acc : 0.6071
     Batch 050 | Loss : 0.5896 | Acc : 0.6331
     Batch 075 | Loss : 0.6381 | Acc : 0.5867
     Batch 100 | Loss : 0.5524 | Acc : 0.6666
     Batch 125 | Loss : 0.5604 | Acc : 0.6634
     Batch 150 | Loss : 0.6373 | Acc : 0.5744
     Batch 175 | Loss : 0.5890 | Acc : 0.6391
     Batch 200 | Loss : 0.5886 | Acc : 0.6406
     Batch 225 | Loss : 0.6272 | Acc : 0.5960
     Batch 250 | Loss : 0.6215 | Acc : 0.6063
     Batch 275 | Loss : 0.6322 | Acc : 0.5932
     Batch 300 | Loss : 0.5961 | Acc : 0.6338
Epoch 00068 | Train Loss : 0.6028 | Eval Loss : 0.6014 | Train acc : 0.6208 | Eval Acc : 0.6113
     Batch 000 | Loss : 0.6043 | Acc : 0.6117
     Batch 025 | Loss : 0.5963 | Acc : 0.6274
     Batch 050 | Loss : 0.6384 | Acc : 0.5887
     Batch 075 | Loss : 0.5425 | Acc : 0.6798
     Batch 100 | Loss : 0.5654 | Acc : 0.6452
     Batch 125 | Loss : 0.5513 | Acc : 0.6588
     Batch 150 | Loss : 0.6226 | Acc : 0.6026
     Batch 175 | Loss : 0.6229 | Acc : 0.6040
     Batch 200 | Loss : 0.5592 | Acc : 0.6670
     Batch 225 | Loss : 0.6008 | Acc : 0.6304
     Batch 250 | Loss : 0.6176 | Acc : 0.6077
     Batch 275 | Loss : 0.5789 | Acc : 0.6501
     Batch 300 | Loss : 0.6073 | Acc : 0.6210
Epoch 00069 | Train Loss : 0.6028 | Eval Loss : 0.6012 | Train acc : 0.6205 | Eval Acc : 0.6237
     Batch 000 | Loss : 0.6363 | Acc : 0.5885
     Batch 025 | Loss : 0.6044 | Acc : 0.6232
     Batch 050 | Loss : 0.6017 | Acc : 0.6226
     Batch 075 | Loss : 0.6134 | Acc : 0.6113
     Batch 100 | Loss : 0.6151 | Acc : 0.6098
     Batch 125 | Loss : 0.5823 | Acc : 0.6414
     Batch 150 | Loss : 0.5965 | Acc : 0.6338
     Batch 175 | Loss : 0.5812 | Acc : 0.6327
     Batch 200 | Loss : 0.5957 | Acc : 0.6277
     Batch 225 | Loss : 0.6144 | Acc : 0.6128
     Batch 250 | Loss : 0.6298 | Acc : 0.5980
     Batch 275 | Loss : 0.6374 | Acc : 0.5896
     Batch 300 | Loss : 0.5479 | Acc : 0.6733
Epoch 00070 | Train Loss : 0.6029 | Eval Loss : 0.6015 | Train acc : 0.6203 | Eval Acc : 0.6237
     Batch 000 | Loss : 0.6038 | Acc : 0.6174
     Batch 025 | Loss : 0.6195 | Acc : 0.6048
     Batch 050 | Loss : 0.5941 | Acc : 0.6312
     Batch 075 | Loss : 0.6136 | Acc : 0.6101
     Batch 100 | Loss : 0.5598 | Acc : 0.6661
     Batch 125 | Loss : 0.5687 | Acc : 0.6488
     Batch 150 | Loss : 0.6219 | Acc : 0.6007
     Batch 175 | Loss : 0.6604 | Acc : 0.5621
     Batch 200 | Loss : 0.5644 | Acc : 0.6531
     Batch 225 | Loss : 0.6173 | Acc : 0.6093
     Batch 250 | Loss : 0.5962 | Acc : 0.6335
     Batch 275 | Loss : 0.6015 | Acc : 0.6250
     Batch 300 | Loss : 0.5492 | Acc : 0.6729
Epoch 00071 | Train Loss : 0.6026 | Eval Loss : 0.6012 | Train acc : 0.6208 | Eval Acc : 0.6243
     Batch 000 | Loss : 0.5892 | Acc : 0.6374
     Batch 025 | Loss : 0.6225 | Acc : 0.6052
     Batch 050 | Loss : 0.6372 | Acc : 0.5748
     Batch 075 | Loss : 0.6326 | Acc : 0.5932
     Batch 100 | Loss : 0.5917 | Acc : 0.6333
     Batch 125 | Loss : 0.5931 | Acc : 0.6195
     Batch 150 | Loss : 0.5626 | Acc : 0.6479
     Batch 175 | Loss : 0.6395 | Acc : 0.5840
     Batch 200 | Loss : 0.6201 | Acc : 0.6054
     Batch 225 | Loss : 0.6171 | Acc : 0.6055
     Batch 250 | Loss : 0.5758 | Acc : 0.6436
     Batch 275 | Loss : 0.5622 | Acc : 0.6602
     Batch 300 | Loss : 0.5762 | Acc : 0.6453
Epoch 00072 | Train Loss : 0.6027 | Eval Loss : 0.6012 | Train acc : 0.6208 | Eval Acc : 0.6117
     Batch 000 | Loss : 0.5643 | Acc : 0.6460
     Batch 025 | Loss : 0.6600 | Acc : 0.5627
     Batch 050 | Loss : 0.6238 | Acc : 0.5868
     Batch 075 | Loss : 0.5964 | Acc : 0.6335
     Batch 100 | Loss : 0.5885 | Acc : 0.6391
     Batch 125 | Loss : 0.6038 | Acc : 0.6222
     Batch 150 | Loss : 0.6354 | Acc : 0.5948
     Batch 175 | Loss : 0.5912 | Acc : 0.6372
     Batch 200 | Loss : 0.6072 | Acc : 0.6214
     Batch 225 | Loss : 0.6316 | Acc : 0.5962
     Batch 250 | Loss : 0.6106 | Acc : 0.6152
     Batch 275 | Loss : 0.6011 | Acc : 0.6251
     Batch 300 | Loss : 0.6211 | Acc : 0.6044
Epoch 00073 | Train Loss : 0.6025 | Eval Loss : 0.6008 | Train acc : 0.6213 | Eval Acc : 0.6257
     Batch 000 | Loss : 0.6134 | Acc : 0.6115
     Batch 025 | Loss : 0.6226 | Acc : 0.6020
     Batch 050 | Loss : 0.5590 | Acc : 0.6692
     Batch 075 | Loss : 0.6394 | Acc : 0.5852
     Batch 100 | Loss : 0.6171 | Acc : 0.6081
     Batch 125 | Loss : 0.5631 | Acc : 0.6640
     Batch 150 | Loss : 1.4817 | Acc : 0.5889
     Batch 175 | Loss : 0.6261 | Acc : 0.5990
     Batch 200 | Loss : 0.6574 | Acc : 0.5718
     Batch 225 | Loss : 0.6424 | Acc : 0.5635
     Batch 250 | Loss : 0.6350 | Acc : 0.5755
     Batch 275 | Loss : 0.6300 | Acc : 0.5752
     Batch 300 | Loss : 0.6301 | Acc : 0.5753
Epoch 00074 | Train Loss : 0.6829 | Eval Loss : 0.6243 | Train acc : 0.6015 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6181 | Acc : 0.5772
     Batch 025 | Loss : 0.6473 | Acc : 0.5591
     Batch 050 | Loss : 0.6376 | Acc : 0.5745
     Batch 075 | Loss : 0.6174 | Acc : 0.5870
     Batch 100 | Loss : 0.6502 | Acc : 0.5524
     Batch 125 | Loss : 0.5876 | Acc : 0.6011
     Batch 150 | Loss : 0.6503 | Acc : 0.5532
     Batch 175 | Loss : 0.6500 | Acc : 0.5524
     Batch 200 | Loss : 0.6514 | Acc : 0.5479
     Batch 225 | Loss : 0.6520 | Acc : 0.5539
     Batch 250 | Loss : 0.6112 | Acc : 0.5842
     Batch 275 | Loss : 0.5914 | Acc : 0.5951
     Batch 300 | Loss : 0.5806 | Acc : 0.6159
Epoch 00075 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5928 | Acc : 0.5932
     Batch 025 | Loss : 0.6271 | Acc : 0.5792
     Batch 050 | Loss : 0.6278 | Acc : 0.5775
     Batch 075 | Loss : 0.5937 | Acc : 0.6010
     Batch 100 | Loss : 0.6323 | Acc : 0.5798
     Batch 125 | Loss : 0.6443 | Acc : 0.5582
     Batch 150 | Loss : 0.5972 | Acc : 0.5943
     Batch 175 | Loss : 0.6397 | Acc : 0.5599
     Batch 200 | Loss : 0.6331 | Acc : 0.5714
     Batch 225 | Loss : 0.5914 | Acc : 0.5951
     Batch 250 | Loss : 0.6299 | Acc : 0.5688
     Batch 275 | Loss : 0.6269 | Acc : 0.5685
     Batch 300 | Loss : 0.6457 | Acc : 0.5541
Epoch 00076 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6170 | Acc : 0.5730
     Batch 025 | Loss : 0.6539 | Acc : 0.5459
     Batch 050 | Loss : 0.6561 | Acc : 0.5490
     Batch 075 | Loss : 0.5906 | Acc : 0.5974
     Batch 100 | Loss : 0.6398 | Acc : 0.5658
     Batch 125 | Loss : 0.5993 | Acc : 0.5940
     Batch 150 | Loss : 0.5964 | Acc : 0.5996
     Batch 175 | Loss : 0.6195 | Acc : 0.5814
     Batch 200 | Loss : 0.5987 | Acc : 0.5894
     Batch 225 | Loss : 0.6484 | Acc : 0.5504
     Batch 250 | Loss : 0.6221 | Acc : 0.5813
     Batch 275 | Loss : 0.6559 | Acc : 0.5426
     Batch 300 | Loss : 0.6135 | Acc : 0.5812
Epoch 00077 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5964 | Acc : 0.5945
     Batch 025 | Loss : 0.6415 | Acc : 0.5589
     Batch 050 | Loss : 0.6261 | Acc : 0.5836
     Batch 075 | Loss : 0.6484 | Acc : 0.5504
     Batch 100 | Loss : 0.5797 | Acc : 0.6077
     Batch 125 | Loss : 0.5820 | Acc : 0.6111
     Batch 150 | Loss : 0.6303 | Acc : 0.5698
     Batch 175 | Loss : 0.6476 | Acc : 0.5515
     Batch 200 | Loss : 0.6301 | Acc : 0.5753
     Batch 225 | Loss : 0.6107 | Acc : 0.5942
     Batch 250 | Loss : 0.5845 | Acc : 0.6120
     Batch 275 | Loss : 0.5940 | Acc : 0.5961
     Batch 300 | Loss : 0.6258 | Acc : 0.5856
Epoch 00078 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6530 | Acc : 0.5529
     Batch 025 | Loss : 0.6427 | Acc : 0.5622
     Batch 050 | Loss : 0.6347 | Acc : 0.5755
     Batch 075 | Loss : 0.6336 | Acc : 0.5630
     Batch 100 | Loss : 0.5902 | Acc : 0.5978
     Batch 125 | Loss : 0.5797 | Acc : 0.6077
     Batch 150 | Loss : 0.6307 | Acc : 0.5656
     Batch 175 | Loss : 0.6412 | Acc : 0.5632
     Batch 200 | Loss : 0.6228 | Acc : 0.5845
     Batch 225 | Loss : 0.6493 | Acc : 0.5524
     Batch 250 | Loss : 0.6301 | Acc : 0.5752
     Batch 275 | Loss : 0.6557 | Acc : 0.5503
     Batch 300 | Loss : 0.6132 | Acc : 0.5837
Epoch 00079 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6244 | Acc : 0.5755
     Batch 025 | Loss : 0.6132 | Acc : 0.5837
     Batch 050 | Loss : 0.6299 | Acc : 0.5725
     Batch 075 | Loss : 0.5774 | Acc : 0.6179
     Batch 100 | Loss : 0.6169 | Acc : 0.5730
     Batch 125 | Loss : 0.6536 | Acc : 0.5507
     Batch 150 | Loss : 0.6192 | Acc : 0.5795
     Batch 175 | Loss : 0.6549 | Acc : 0.5421
     Batch 200 | Loss : 0.6579 | Acc : 0.5478
     Batch 225 | Loss : 0.5865 | Acc : 0.6041
     Batch 250 | Loss : 0.6555 | Acc : 0.5434
     Batch 275 | Loss : 0.6478 | Acc : 0.5566
     Batch 300 | Loss : 0.6121 | Acc : 0.5819
Epoch 00080 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6326 | Acc : 0.5684
     Batch 025 | Loss : 0.5793 | Acc : 0.6008
     Batch 050 | Loss : 0.5954 | Acc : 0.6074
     Batch 075 | Loss : 0.5861 | Acc : 0.6218
     Batch 100 | Loss : 0.5874 | Acc : 0.6034
     Batch 125 | Loss : 0.6393 | Acc : 0.5619
     Batch 150 | Loss : 0.6308 | Acc : 0.5811
     Batch 175 | Loss : 0.6520 | Acc : 0.5539
     Batch 200 | Loss : 0.5940 | Acc : 0.5961
     Batch 225 | Loss : 0.6479 | Acc : 0.5608
     Batch 250 | Loss : 0.6348 | Acc : 0.5670
     Batch 275 | Loss : 0.6007 | Acc : 0.5960
     Batch 300 | Loss : 0.5941 | Acc : 0.5986
Epoch 00081 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6184 | Acc : 0.5826
     Batch 025 | Loss : 0.6255 | Acc : 0.5856
     Batch 050 | Loss : 0.6433 | Acc : 0.5568
     Batch 075 | Loss : 0.5986 | Acc : 0.6021
     Batch 100 | Loss : 0.6299 | Acc : 0.5688
     Batch 125 | Loss : 0.6415 | Acc : 0.5589
     Batch 150 | Loss : 0.6261 | Acc : 0.5737
     Batch 175 | Loss : 0.6278 | Acc : 0.5775
     Batch 200 | Loss : 0.5902 | Acc : 0.5978
     Batch 225 | Loss : 0.6460 | Acc : 0.5541
     Batch 250 | Loss : 0.6106 | Acc : 0.5895
     Batch 275 | Loss : 0.6529 | Acc : 0.5451
     Batch 300 | Loss : 0.5923 | Acc : 0.6005
Epoch 00082 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6300 | Acc : 0.5707
     Batch 025 | Loss : 0.6235 | Acc : 0.5886
     Batch 050 | Loss : 0.5993 | Acc : 0.5940
     Batch 075 | Loss : 0.6689 | Acc : 0.5296
     Batch 100 | Loss : 0.6257 | Acc : 0.5818
     Batch 125 | Loss : 0.6418 | Acc : 0.5582
     Batch 150 | Loss : 0.6579 | Acc : 0.5462
     Batch 175 | Loss : 0.6175 | Acc : 0.5816
     Batch 200 | Loss : 0.6348 | Acc : 0.5612
     Batch 225 | Loss : 0.5816 | Acc : 0.5998
     Batch 250 | Loss : 0.6319 | Acc : 0.5696
     Batch 275 | Loss : 0.6269 | Acc : 0.5827
     Batch 300 | Loss : 0.5972 | Acc : 0.5943
Epoch 00083 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6405 | Acc : 0.5613
     Batch 025 | Loss : 0.6423 | Acc : 0.5616
     Batch 050 | Loss : 0.6324 | Acc : 0.5630
     Batch 075 | Loss : 0.6399 | Acc : 0.5577
     Batch 100 | Loss : 0.5785 | Acc : 0.6138
     Batch 125 | Loss : 0.6444 | Acc : 0.5582
     Batch 150 | Loss : 0.6167 | Acc : 0.5806
     Batch 175 | Loss : 0.6527 | Acc : 0.5545
     Batch 200 | Loss : 0.6528 | Acc : 0.5451
     Batch 225 | Loss : 0.6346 | Acc : 0.5755
     Batch 250 | Loss : 0.6372 | Acc : 0.5604
     Batch 275 | Loss : 0.6301 | Acc : 0.5752
     Batch 300 | Loss : 0.6563 | Acc : 0.5453
Epoch 00084 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6307 | Acc : 0.5723
     Batch 025 | Loss : 0.5917 | Acc : 0.6024
     Batch 050 | Loss : 0.6520 | Acc : 0.5539
     Batch 075 | Loss : 0.6269 | Acc : 0.5685
     Batch 100 | Loss : 0.5905 | Acc : 0.6021
     Batch 125 | Loss : 0.5846 | Acc : 0.6028
     Batch 150 | Loss : 0.6249 | Acc : 0.5765
     Batch 175 | Loss : 0.6127 | Acc : 0.5776
     Batch 200 | Loss : 0.6403 | Acc : 0.5662
     Batch 225 | Loss : 0.5914 | Acc : 0.5951
     Batch 250 | Loss : 0.5988 | Acc : 0.5894
     Batch 275 | Loss : 0.6319 | Acc : 0.5696
     Batch 300 | Loss : 0.6289 | Acc : 0.5767
Epoch 00085 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6422 | Acc : 0.5590
     Batch 025 | Loss : 0.6306 | Acc : 0.5723
     Batch 050 | Loss : 0.6323 | Acc : 0.5721
     Batch 075 | Loss : 0.6546 | Acc : 0.5571
     Batch 100 | Loss : 0.6363 | Acc : 0.5723
     Batch 125 | Loss : 0.6412 | Acc : 0.5632
     Batch 150 | Loss : 0.5737 | Acc : 0.6252
     Batch 175 | Loss : 0.6506 | Acc : 0.5535
     Batch 200 | Loss : 0.6529 | Acc : 0.5649
     Batch 225 | Loss : 0.6299 | Acc : 0.5725
     Batch 250 | Loss : 0.6124 | Acc : 0.5829
     Batch 275 | Loss : 0.5906 | Acc : 0.6021
     Batch 300 | Loss : 0.6456 | Acc : 0.5541
Epoch 00086 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6147 | Acc : 0.5832
     Batch 025 | Loss : 0.6527 | Acc : 0.5545
     Batch 050 | Loss : 0.6260 | Acc : 0.5677
     Batch 075 | Loss : 0.6265 | Acc : 0.5757
     Batch 100 | Loss : 0.6192 | Acc : 0.5795
     Batch 125 | Loss : 0.6402 | Acc : 0.5688
     Batch 150 | Loss : 0.5902 | Acc : 0.5978
     Batch 175 | Loss : 0.6336 | Acc : 0.5652
     Batch 200 | Loss : 0.5972 | Acc : 0.5943
     Batch 225 | Loss : 0.6121 | Acc : 0.5819
     Batch 250 | Loss : 0.6170 | Acc : 0.5730
     Batch 275 | Loss : 0.6508 | Acc : 0.5535
     Batch 300 | Loss : 0.5931 | Acc : 0.5999
Epoch 00087 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6170 | Acc : 0.5730
     Batch 025 | Loss : 0.6565 | Acc : 0.5441
     Batch 050 | Loss : 0.6503 | Acc : 0.5532
     Batch 075 | Loss : 0.5918 | Acc : 0.5989
     Batch 100 | Loss : 0.6254 | Acc : 0.5778
     Batch 125 | Loss : 0.6397 | Acc : 0.5599
     Batch 150 | Loss : 0.6299 | Acc : 0.5725
     Batch 175 | Loss : 0.6499 | Acc : 0.5594
     Batch 200 | Loss : 0.5928 | Acc : 0.5976
     Batch 225 | Loss : 0.6256 | Acc : 0.5818
     Batch 250 | Loss : 0.6454 | Acc : 0.5618
     Batch 275 | Loss : 0.6287 | Acc : 0.5826
     Batch 300 | Loss : 0.6315 | Acc : 0.5650
Epoch 00088 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6381 | Acc : 0.5660
     Batch 025 | Loss : 0.6501 | Acc : 0.5469
     Batch 050 | Loss : 0.5859 | Acc : 0.6208
     Batch 075 | Loss : 0.6514 | Acc : 0.5529
     Batch 100 | Loss : 0.6132 | Acc : 0.5837
     Batch 125 | Loss : 0.6297 | Acc : 0.5672
     Batch 150 | Loss : 0.6560 | Acc : 0.5432
     Batch 175 | Loss : 0.6499 | Acc : 0.5594
     Batch 200 | Loss : 0.5947 | Acc : 0.5939
     Batch 225 | Loss : 0.5828 | Acc : 0.6024
     Batch 250 | Loss : 0.6490 | Acc : 0.5504
     Batch 275 | Loss : 0.6303 | Acc : 0.5753
     Batch 300 | Loss : 0.6373 | Acc : 0.5604
Epoch 00089 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6323 | Acc : 0.5641
     Batch 025 | Loss : 0.6381 | Acc : 0.5660
     Batch 050 | Loss : 0.5907 | Acc : 0.6043
     Batch 075 | Loss : 0.6536 | Acc : 0.5767
     Batch 100 | Loss : 0.5928 | Acc : 0.5976
     Batch 125 | Loss : 0.6167 | Acc : 0.5806
     Batch 150 | Loss : 0.6270 | Acc : 0.5685
     Batch 175 | Loss : 0.6180 | Acc : 0.5772
     Batch 200 | Loss : 0.6401 | Acc : 0.5688
     Batch 225 | Loss : 0.5930 | Acc : 0.6004
     Batch 250 | Loss : 0.6421 | Acc : 0.5546
     Batch 275 | Loss : 0.6423 | Acc : 0.5616
     Batch 300 | Loss : 0.5846 | Acc : 0.6057
Epoch 00090 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6360 | Acc : 0.5758
     Batch 025 | Loss : 0.6302 | Acc : 0.5753
     Batch 050 | Loss : 0.6564 | Acc : 0.5475
     Batch 075 | Loss : 0.6087 | Acc : 0.5920
     Batch 100 | Loss : 0.6270 | Acc : 0.5685
     Batch 125 | Loss : 0.6159 | Acc : 0.5818
     Batch 150 | Loss : 0.5792 | Acc : 0.6008
     Batch 175 | Loss : 0.6323 | Acc : 0.5641
     Batch 200 | Loss : 0.6462 | Acc : 0.5510
     Batch 225 | Loss : 0.6560 | Acc : 0.5487
     Batch 250 | Loss : 0.6180 | Acc : 0.5772
     Batch 275 | Loss : 0.6363 | Acc : 0.5723
     Batch 300 | Loss : 0.5905 | Acc : 0.6029
Epoch 00091 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6362 | Acc : 0.5723
     Batch 025 | Loss : 0.6454 | Acc : 0.5618
     Batch 050 | Loss : 0.6198 | Acc : 0.5780
     Batch 075 | Loss : 0.5792 | Acc : 0.6008
     Batch 100 | Loss : 0.5905 | Acc : 0.6021
     Batch 125 | Loss : 0.6561 | Acc : 0.5487
     Batch 150 | Loss : 0.6087 | Acc : 0.5920
     Batch 175 | Loss : 0.5867 | Acc : 0.6049
     Batch 200 | Loss : 0.6317 | Acc : 0.5780
     Batch 225 | Loss : 0.6495 | Acc : 0.5498
     Batch 250 | Loss : 0.6219 | Acc : 0.5730
     Batch 275 | Loss : 0.5737 | Acc : 0.6252
     Batch 300 | Loss : 0.5826 | Acc : 0.6098
Epoch 00092 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6506 | Acc : 0.5570
     Batch 025 | Loss : 0.5820 | Acc : 0.6111
     Batch 050 | Loss : 0.5837 | Acc : 0.6137
     Batch 075 | Loss : 0.6319 | Acc : 0.5696
     Batch 100 | Loss : 0.6460 | Acc : 0.5570
     Batch 125 | Loss : 0.5940 | Acc : 0.5926
     Batch 150 | Loss : 0.6423 | Acc : 0.5546
     Batch 175 | Loss : 0.5828 | Acc : 0.6024
     Batch 200 | Loss : 0.6398 | Acc : 0.5658
     Batch 225 | Loss : 0.6561 | Acc : 0.5490
     Batch 250 | Loss : 0.6564 | Acc : 0.5475
     Batch 275 | Loss : 0.6503 | Acc : 0.5498
     Batch 300 | Loss : 0.6345 | Acc : 0.5649
Epoch 00093 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6502 | Acc : 0.5585
     Batch 025 | Loss : 0.6455 | Acc : 0.5618
     Batch 050 | Loss : 0.6473 | Acc : 0.5626
     Batch 075 | Loss : 0.6111 | Acc : 0.5954
     Batch 100 | Loss : 0.6325 | Acc : 0.5659
     Batch 125 | Loss : 0.6159 | Acc : 0.5818
     Batch 150 | Loss : 0.6300 | Acc : 0.5752
     Batch 175 | Loss : 0.6080 | Acc : 0.5903
     Batch 200 | Loss : 0.5954 | Acc : 0.6074
     Batch 225 | Loss : 0.6316 | Acc : 0.5650
     Batch 250 | Loss : 0.6532 | Acc : 0.5515
     Batch 275 | Loss : 0.6531 | Acc : 0.5649
     Batch 300 | Loss : 0.5801 | Acc : 0.6118
Epoch 00094 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6531 | Acc : 0.5515
     Batch 025 | Loss : 0.5964 | Acc : 0.5996
     Batch 050 | Loss : 0.6530 | Acc : 0.5562
     Batch 075 | Loss : 0.6365 | Acc : 0.5654
     Batch 100 | Loss : 0.6443 | Acc : 0.5582
     Batch 125 | Loss : 0.6121 | Acc : 0.5819
     Batch 150 | Loss : 0.6163 | Acc : 0.5763
     Batch 175 | Loss : 0.6504 | Acc : 0.5524
     Batch 200 | Loss : 0.5854 | Acc : 0.6000
     Batch 225 | Loss : 0.6145 | Acc : 0.5790
     Batch 250 | Loss : 0.6142 | Acc : 0.5789
     Batch 275 | Loss : 0.6419 | Acc : 0.5565
     Batch 300 | Loss : 0.5876 | Acc : 0.6011
Epoch 00095 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6148 | Acc : 0.5770
     Batch 025 | Loss : 0.6398 | Acc : 0.5577
     Batch 050 | Loss : 0.6331 | Acc : 0.5714
     Batch 075 | Loss : 0.6419 | Acc : 0.5655
     Batch 100 | Loss : 0.6415 | Acc : 0.5583
     Batch 125 | Loss : 0.6180 | Acc : 0.5772
     Batch 150 | Loss : 0.6304 | Acc : 0.5698
     Batch 175 | Loss : 0.6502 | Acc : 0.5469
     Batch 200 | Loss : 0.6254 | Acc : 0.5778
     Batch 225 | Loss : 0.5793 | Acc : 0.6008
     Batch 250 | Loss : 0.6505 | Acc : 0.5535
     Batch 275 | Loss : 0.6587 | Acc : 0.5456
     Batch 300 | Loss : 0.6154 | Acc : 0.5874
Epoch 00096 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6419 | Acc : 0.5582
     Batch 025 | Loss : 0.6460 | Acc : 0.5570
     Batch 050 | Loss : 0.6173 | Acc : 0.5778
     Batch 075 | Loss : 0.6317 | Acc : 0.5780
     Batch 100 | Loss : 0.6195 | Acc : 0.5814
     Batch 125 | Loss : 0.6515 | Acc : 0.5529
     Batch 150 | Loss : 0.6373 | Acc : 0.5566
     Batch 175 | Loss : 0.6377 | Acc : 0.5599
     Batch 200 | Loss : 0.6306 | Acc : 0.5811
     Batch 225 | Loss : 0.6499 | Acc : 0.5594
     Batch 250 | Loss : 0.6506 | Acc : 0.5570
     Batch 275 | Loss : 0.6167 | Acc : 0.5806
     Batch 300 | Loss : 0.6416 | Acc : 0.5589
Epoch 00097 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6564 | Acc : 0.5453
     Batch 025 | Loss : 0.6461 | Acc : 0.5510
     Batch 050 | Loss : 0.6501 | Acc : 0.5516
     Batch 075 | Loss : 0.6347 | Acc : 0.5755
     Batch 100 | Loss : 0.6345 | Acc : 0.5649
     Batch 125 | Loss : 0.6168 | Acc : 0.5730
     Batch 150 | Loss : 0.6079 | Acc : 0.5903
     Batch 175 | Loss : 0.6261 | Acc : 0.5737
     Batch 200 | Loss : 0.6165 | Acc : 0.5763
     Batch 225 | Loss : 0.6473 | Acc : 0.5591
     Batch 250 | Loss : 0.6476 | Acc : 0.5515
     Batch 275 | Loss : 0.6308 | Acc : 0.5811
     Batch 300 | Loss : 0.6531 | Acc : 0.5451
Epoch 00098 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6575 | Acc : 0.5477
     Batch 025 | Loss : 0.6364 | Acc : 0.5710
     Batch 050 | Loss : 0.6306 | Acc : 0.5656
     Batch 075 | Loss : 0.6566 | Acc : 0.5441
     Batch 100 | Loss : 0.6135 | Acc : 0.5812
     Batch 125 | Loss : 0.6238 | Acc : 0.5787
     Batch 150 | Loss : 0.5859 | Acc : 0.6218
     Batch 175 | Loss : 0.6286 | Acc : 0.5691
     Batch 200 | Loss : 0.6289 | Acc : 0.5767
     Batch 225 | Loss : 0.6112 | Acc : 0.5842
     Batch 250 | Loss : 0.6473 | Acc : 0.5626
     Batch 275 | Loss : 0.6296 | Acc : 0.5809
     Batch 300 | Loss : 0.6332 | Acc : 0.5724
Epoch 00099 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5738 | Acc : 0.6252
     Batch 025 | Loss : 0.6402 | Acc : 0.5595
     Batch 050 | Loss : 0.6458 | Acc : 0.5541
     Batch 075 | Loss : 0.6154 | Acc : 0.5874
     Batch 100 | Loss : 0.6402 | Acc : 0.5688
     Batch 125 | Loss : 0.5907 | Acc : 0.6043
     Batch 150 | Loss : 0.6332 | Acc : 0.5724
     Batch 175 | Loss : 0.5838 | Acc : 0.6137
     Batch 200 | Loss : 0.6360 | Acc : 0.5758
     Batch 225 | Loss : 0.6348 | Acc : 0.5571
     Batch 250 | Loss : 0.6545 | Acc : 0.5571
     Batch 275 | Loss : 0.6495 | Acc : 0.5498
     Batch 300 | Loss : 0.5931 | Acc : 0.5999
Epoch 00100 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6427 | Acc : 0.5622
     Batch 025 | Loss : 0.6575 | Acc : 0.5477
     Batch 050 | Loss : 0.6409 | Acc : 0.5645
     Batch 075 | Loss : 0.5797 | Acc : 0.6077
     Batch 100 | Loss : 0.5961 | Acc : 0.5987
     Batch 125 | Loss : 0.5874 | Acc : 0.6034
     Batch 150 | Loss : 0.6544 | Acc : 0.5512
     Batch 175 | Loss : 0.6402 | Acc : 0.5595
     Batch 200 | Loss : 0.6529 | Acc : 0.5649
     Batch 225 | Loss : 0.6159 | Acc : 0.5818
     Batch 250 | Loss : 0.6270 | Acc : 0.5685
     Batch 275 | Loss : 0.6561 | Acc : 0.5403
     Batch 300 | Loss : 0.6113 | Acc : 0.5894
Epoch 00101 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5833 | Acc : 0.6109
     Batch 025 | Loss : 0.6347 | Acc : 0.5586
     Batch 050 | Loss : 0.5823 | Acc : 0.6023
     Batch 075 | Loss : 0.6393 | Acc : 0.5619
     Batch 100 | Loss : 0.6116 | Acc : 0.5897
     Batch 125 | Loss : 0.6234 | Acc : 0.5886
     Batch 150 | Loss : 0.5905 | Acc : 0.6021
     Batch 175 | Loss : 0.6105 | Acc : 0.5895
     Batch 200 | Loss : 0.6564 | Acc : 0.5475
     Batch 225 | Loss : 0.6121 | Acc : 0.5819
     Batch 250 | Loss : 0.6394 | Acc : 0.5550
     Batch 275 | Loss : 0.6316 | Acc : 0.5650
     Batch 300 | Loss : 0.6434 | Acc : 0.5568
Epoch 00102 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6354 | Acc : 0.5680
     Batch 025 | Loss : 0.5900 | Acc : 0.6035
     Batch 050 | Loss : 0.6473 | Acc : 0.5591
     Batch 075 | Loss : 0.5817 | Acc : 0.5998
     Batch 100 | Loss : 0.6219 | Acc : 0.5730
     Batch 125 | Loss : 0.6534 | Acc : 0.5502
     Batch 150 | Loss : 0.6151 | Acc : 0.5851
     Batch 175 | Loss : 0.6506 | Acc : 0.5570
     Batch 200 | Loss : 0.6273 | Acc : 0.5773
     Batch 225 | Loss : 0.6183 | Acc : 0.5869
     Batch 250 | Loss : 0.5940 | Acc : 0.5926
     Batch 275 | Loss : 0.6510 | Acc : 0.5535
     Batch 300 | Loss : 0.5809 | Acc : 0.6159
Epoch 00103 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6393 | Acc : 0.5619
     Batch 025 | Loss : 0.6405 | Acc : 0.5613
     Batch 050 | Loss : 0.5886 | Acc : 0.6167
     Batch 075 | Loss : 0.6479 | Acc : 0.5608
     Batch 100 | Loss : 0.6303 | Acc : 0.5698
     Batch 125 | Loss : 0.6491 | Acc : 0.5627
     Batch 150 | Loss : 0.6286 | Acc : 0.5691
     Batch 175 | Loss : 0.5908 | Acc : 0.6043
     Batch 200 | Loss : 0.6148 | Acc : 0.5770
     Batch 225 | Loss : 0.6081 | Acc : 0.5903
     Batch 250 | Loss : 0.6331 | Acc : 0.5724
     Batch 275 | Loss : 0.6145 | Acc : 0.5790
     Batch 300 | Loss : 0.6299 | Acc : 0.5725
Epoch 00104 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6674 | Acc : 0.5363
     Batch 025 | Loss : 0.6399 | Acc : 0.5541
     Batch 050 | Loss : 0.6517 | Acc : 0.5529
     Batch 075 | Loss : 0.6401 | Acc : 0.5688
     Batch 100 | Loss : 0.6403 | Acc : 0.5658
     Batch 125 | Loss : 0.5959 | Acc : 0.5953
     Batch 150 | Loss : 0.6133 | Acc : 0.5837
     Batch 175 | Loss : 0.6105 | Acc : 0.5895
     Batch 200 | Loss : 0.6484 | Acc : 0.5504
     Batch 225 | Loss : 0.6459 | Acc : 0.5541
     Batch 250 | Loss : 0.5918 | Acc : 0.5989
     Batch 275 | Loss : 0.6086 | Acc : 0.5920
     Batch 300 | Loss : 0.6433 | Acc : 0.5568
Epoch 00105 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6364 | Acc : 0.5687
     Batch 025 | Loss : 0.6231 | Acc : 0.5826
     Batch 050 | Loss : 0.6366 | Acc : 0.5655
     Batch 075 | Loss : 0.6500 | Acc : 0.5469
     Batch 100 | Loss : 0.6406 | Acc : 0.5584
     Batch 125 | Loss : 0.6305 | Acc : 0.5742
     Batch 150 | Loss : 0.6530 | Acc : 0.5529
     Batch 175 | Loss : 0.5877 | Acc : 0.5970
     Batch 200 | Loss : 0.6112 | Acc : 0.5954
     Batch 225 | Loss : 0.6402 | Acc : 0.5595
     Batch 250 | Loss : 0.6467 | Acc : 0.5587
     Batch 275 | Loss : 0.6508 | Acc : 0.5580
     Batch 300 | Loss : 0.6298 | Acc : 0.5672
Epoch 00106 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6526 | Acc : 0.5545
     Batch 025 | Loss : 0.6561 | Acc : 0.5487
     Batch 050 | Loss : 0.6256 | Acc : 0.5818
     Batch 075 | Loss : 0.6500 | Acc : 0.5524
     Batch 100 | Loss : 0.6169 | Acc : 0.5730
     Batch 125 | Loss : 0.6473 | Acc : 0.5591
     Batch 150 | Loss : 0.6563 | Acc : 0.5453
     Batch 175 | Loss : 0.6392 | Acc : 0.5550
     Batch 200 | Loss : 0.5987 | Acc : 0.5894
     Batch 225 | Loss : 0.6364 | Acc : 0.5654
     Batch 250 | Loss : 0.6537 | Acc : 0.5571
     Batch 275 | Loss : 0.6173 | Acc : 0.5870
     Batch 300 | Loss : 0.6088 | Acc : 0.5920
Epoch 00107 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6456 | Acc : 0.5541
     Batch 025 | Loss : 0.6508 | Acc : 0.5580
     Batch 050 | Loss : 0.6526 | Acc : 0.5541
     Batch 075 | Loss : 0.6143 | Acc : 0.5789
     Batch 100 | Loss : 0.6088 | Acc : 0.5920
     Batch 125 | Loss : 0.6167 | Acc : 0.5806
     Batch 150 | Loss : 0.6371 | Acc : 0.5566
     Batch 175 | Loss : 0.5928 | Acc : 0.5940
     Batch 200 | Loss : 0.6132 | Acc : 0.5837
     Batch 225 | Loss : 0.6135 | Acc : 0.5812
     Batch 250 | Loss : 0.6484 | Acc : 0.5504
     Batch 275 | Loss : 0.6404 | Acc : 0.5662
     Batch 300 | Loss : 0.6198 | Acc : 0.5777
Epoch 00108 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5887 | Acc : 0.6167
     Batch 025 | Loss : 0.6397 | Acc : 0.5577
     Batch 050 | Loss : 0.6331 | Acc : 0.5714
     Batch 075 | Loss : 0.6260 | Acc : 0.5677
     Batch 100 | Loss : 0.6305 | Acc : 0.5742
     Batch 125 | Loss : 0.6294 | Acc : 0.5809
     Batch 150 | Loss : 0.5997 | Acc : 0.5885
     Batch 175 | Loss : 0.5928 | Acc : 0.5976
     Batch 200 | Loss : 0.5854 | Acc : 0.6044
     Batch 225 | Loss : 0.6006 | Acc : 0.5960
     Batch 250 | Loss : 0.6184 | Acc : 0.5869
     Batch 275 | Loss : 0.5931 | Acc : 0.6004
     Batch 300 | Loss : 0.6515 | Acc : 0.5479
Epoch 00109 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5827 | Acc : 0.6098
     Batch 025 | Loss : 0.5834 | Acc : 0.6109
     Batch 050 | Loss : 0.6249 | Acc : 0.5765
     Batch 075 | Loss : 0.6109 | Acc : 0.5954
     Batch 100 | Loss : 0.6346 | Acc : 0.5649
     Batch 125 | Loss : 0.5972 | Acc : 0.5943
     Batch 150 | Loss : 0.6306 | Acc : 0.5723
     Batch 175 | Loss : 0.6147 | Acc : 0.5770
     Batch 200 | Loss : 0.6560 | Acc : 0.5487
     Batch 225 | Loss : 0.6238 | Acc : 0.5787
     Batch 250 | Loss : 0.6395 | Acc : 0.5619
     Batch 275 | Loss : 0.6491 | Acc : 0.5555
     Batch 300 | Loss : 0.6173 | Acc : 0.5778
Epoch 00110 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5964 | Acc : 0.5945
     Batch 025 | Loss : 0.6458 | Acc : 0.5510
     Batch 050 | Loss : 0.6561 | Acc : 0.5426
     Batch 075 | Loss : 0.6506 | Acc : 0.5570
     Batch 100 | Loss : 0.6006 | Acc : 0.5960
     Batch 125 | Loss : 0.6461 | Acc : 0.5514
     Batch 150 | Loss : 0.6416 | Acc : 0.5583
     Batch 175 | Loss : 0.6579 | Acc : 0.5462
     Batch 200 | Loss : 0.6588 | Acc : 0.5456
     Batch 225 | Loss : 0.6486 | Acc : 0.5504
     Batch 250 | Loss : 0.6322 | Acc : 0.5641
     Batch 275 | Loss : 0.6274 | Acc : 0.5725
     Batch 300 | Loss : 0.5822 | Acc : 0.6111
Epoch 00111 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6167 | Acc : 0.5806
     Batch 025 | Loss : 0.6484 | Acc : 0.5504
     Batch 050 | Loss : 0.5997 | Acc : 0.5997
     Batch 075 | Loss : 0.6347 | Acc : 0.5755
     Batch 100 | Loss : 0.6533 | Acc : 0.5767
     Batch 125 | Loss : 0.6124 | Acc : 0.5829
     Batch 150 | Loss : 0.5855 | Acc : 0.6000
     Batch 175 | Loss : 0.5931 | Acc : 0.5999
     Batch 200 | Loss : 0.6688 | Acc : 0.5296
     Batch 225 | Loss : 0.6256 | Acc : 0.5818
     Batch 250 | Loss : 0.5824 | Acc : 0.6023
     Batch 275 | Loss : 0.6404 | Acc : 0.5584
     Batch 300 | Loss : 0.6303 | Acc : 0.5698
Epoch 00112 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6401 | Acc : 0.5595
     Batch 025 | Loss : 0.6147 | Acc : 0.5832
     Batch 050 | Loss : 0.6301 | Acc : 0.5752
     Batch 075 | Loss : 0.5918 | Acc : 0.5989
     Batch 100 | Loss : 0.6132 | Acc : 0.5837
     Batch 125 | Loss : 0.6509 | Acc : 0.5535
     Batch 150 | Loss : 0.6289 | Acc : 0.5767
     Batch 175 | Loss : 0.6279 | Acc : 0.5775
     Batch 200 | Loss : 0.6258 | Acc : 0.5678
     Batch 225 | Loss : 0.6313 | Acc : 0.5736
     Batch 250 | Loss : 0.5936 | Acc : 0.6010
     Batch 275 | Loss : 0.5833 | Acc : 0.6109
     Batch 300 | Loss : 0.5931 | Acc : 0.6071
Epoch 00113 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6345 | Acc : 0.5649
     Batch 025 | Loss : 0.6260 | Acc : 0.5677
     Batch 050 | Loss : 0.6467 | Acc : 0.5587
     Batch 075 | Loss : 0.6561 | Acc : 0.5487
     Batch 100 | Loss : 0.5996 | Acc : 0.5885
     Batch 125 | Loss : 0.5926 | Acc : 0.5932
     Batch 150 | Loss : 0.6686 | Acc : 0.5296
     Batch 175 | Loss : 0.6536 | Acc : 0.5571
     Batch 200 | Loss : 0.6262 | Acc : 0.5749
     Batch 225 | Loss : 0.6399 | Acc : 0.5582
     Batch 250 | Loss : 0.6297 | Acc : 0.5672
     Batch 275 | Loss : 0.6300 | Acc : 0.5688
     Batch 300 | Loss : 0.6546 | Acc : 0.5571
Epoch 00114 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5941 | Acc : 0.5986
     Batch 025 | Loss : 0.6147 | Acc : 0.5770
     Batch 050 | Loss : 0.6526 | Acc : 0.5476
     Batch 075 | Loss : 0.6538 | Acc : 0.5767
     Batch 100 | Loss : 0.6560 | Acc : 0.5490
     Batch 125 | Loss : 0.5867 | Acc : 0.6049
     Batch 150 | Loss : 0.6309 | Acc : 0.5811
     Batch 175 | Loss : 0.5854 | Acc : 0.6000
     Batch 200 | Loss : 0.5802 | Acc : 0.6118
     Batch 225 | Loss : 0.5937 | Acc : 0.6010
     Batch 250 | Loss : 0.6142 | Acc : 0.5789
     Batch 275 | Loss : 0.6476 | Acc : 0.5594
     Batch 300 | Loss : 0.6111 | Acc : 0.5954
Epoch 00115 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6397 | Acc : 0.5577
     Batch 025 | Loss : 0.6499 | Acc : 0.5594
     Batch 050 | Loss : 0.6151 | Acc : 0.5851
     Batch 075 | Loss : 0.6325 | Acc : 0.5630
     Batch 100 | Loss : 0.5984 | Acc : 0.6013
     Batch 125 | Loss : 0.6176 | Acc : 0.5816
     Batch 150 | Loss : 0.5959 | Acc : 0.5953
     Batch 175 | Loss : 0.6404 | Acc : 0.5662
     Batch 200 | Loss : 0.6527 | Acc : 0.5649
     Batch 225 | Loss : 0.6396 | Acc : 0.5599
     Batch 250 | Loss : 0.6559 | Acc : 0.5426
     Batch 275 | Loss : 0.5846 | Acc : 0.6120
     Batch 300 | Loss : 0.6280 | Acc : 0.5692
Epoch 00116 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6177 | Acc : 0.5864
     Batch 025 | Loss : 0.6173 | Acc : 0.5778
     Batch 050 | Loss : 0.6401 | Acc : 0.5688
     Batch 075 | Loss : 0.6380 | Acc : 0.5660
     Batch 100 | Loss : 0.6488 | Acc : 0.5570
     Batch 125 | Loss : 0.5954 | Acc : 0.6074
     Batch 150 | Loss : 0.6567 | Acc : 0.5441
     Batch 175 | Loss : 0.6531 | Acc : 0.5535
     Batch 200 | Loss : 0.6402 | Acc : 0.5595
     Batch 225 | Loss : 0.5986 | Acc : 0.5923
     Batch 250 | Loss : 0.6244 | Acc : 0.5755
     Batch 275 | Loss : 0.6346 | Acc : 0.5649
     Batch 300 | Loss : 0.6492 | Acc : 0.5555
Epoch 00117 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6366 | Acc : 0.5655
     Batch 025 | Loss : 0.5993 | Acc : 0.5940
     Batch 050 | Loss : 0.6323 | Acc : 0.5641
     Batch 075 | Loss : 0.6323 | Acc : 0.5650
     Batch 100 | Loss : 0.6558 | Acc : 0.5426
     Batch 125 | Loss : 0.5902 | Acc : 0.5978
     Batch 150 | Loss : 0.5793 | Acc : 0.6008
     Batch 175 | Loss : 0.5858 | Acc : 0.6218
     Batch 200 | Loss : 0.6409 | Acc : 0.5645
     Batch 225 | Loss : 0.6240 | Acc : 0.5786
     Batch 250 | Loss : 0.6503 | Acc : 0.5524
     Batch 275 | Loss : 0.6408 | Acc : 0.5585
     Batch 300 | Loss : 0.6514 | Acc : 0.5479
Epoch 00118 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6506 | Acc : 0.5570
     Batch 025 | Loss : 0.5978 | Acc : 0.6061
     Batch 050 | Loss : 0.6217 | Acc : 0.5818
     Batch 075 | Loss : 0.5846 | Acc : 0.6120
     Batch 100 | Loss : 0.6473 | Acc : 0.5591
     Batch 125 | Loss : 0.6493 | Acc : 0.5524
     Batch 150 | Loss : 0.6115 | Acc : 0.5897
     Batch 175 | Loss : 0.6372 | Acc : 0.5566
     Batch 200 | Loss : 0.5972 | Acc : 0.5943
     Batch 225 | Loss : 0.6346 | Acc : 0.5755
     Batch 250 | Loss : 0.6306 | Acc : 0.5723
     Batch 275 | Loss : 0.6173 | Acc : 0.5778
     Batch 300 | Loss : 0.6562 | Acc : 0.5487
Epoch 00119 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5845 | Acc : 0.6057
     Batch 025 | Loss : 0.6306 | Acc : 0.5811
     Batch 050 | Loss : 0.5959 | Acc : 0.5953
     Batch 075 | Loss : 0.6169 | Acc : 0.5730
     Batch 100 | Loss : 0.6423 | Acc : 0.5616
     Batch 125 | Loss : 0.6580 | Acc : 0.5478
     Batch 150 | Loss : 0.6581 | Acc : 0.5462
     Batch 175 | Loss : 0.6231 | Acc : 0.5826
     Batch 200 | Loss : 0.6167 | Acc : 0.5806
     Batch 225 | Loss : 0.5941 | Acc : 0.5986
     Batch 250 | Loss : 0.6150 | Acc : 0.5851
     Batch 275 | Loss : 0.6261 | Acc : 0.5737
     Batch 300 | Loss : 0.6278 | Acc : 0.5775
Epoch 00120 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5846 | Acc : 0.6057
     Batch 025 | Loss : 0.5802 | Acc : 0.6118
     Batch 050 | Loss : 0.6301 | Acc : 0.5753
     Batch 075 | Loss : 0.6459 | Acc : 0.5539
     Batch 100 | Loss : 0.6473 | Acc : 0.5591
     Batch 125 | Loss : 0.6575 | Acc : 0.5477
     Batch 150 | Loss : 0.6183 | Acc : 0.5826
     Batch 175 | Loss : 0.5964 | Acc : 0.5945
     Batch 200 | Loss : 0.6419 | Acc : 0.5565
     Batch 225 | Loss : 0.6509 | Acc : 0.5535
     Batch 250 | Loss : 0.5954 | Acc : 0.6074
     Batch 275 | Loss : 0.6346 | Acc : 0.5649
     Batch 300 | Loss : 0.6555 | Acc : 0.5434
Epoch 00121 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6366 | Acc : 0.5655
     Batch 025 | Loss : 0.5796 | Acc : 0.6186
     Batch 050 | Loss : 0.5987 | Acc : 0.6021
     Batch 075 | Loss : 0.6504 | Acc : 0.5532
     Batch 100 | Loss : 0.6362 | Acc : 0.5631
     Batch 125 | Loss : 0.6378 | Acc : 0.5745
     Batch 150 | Loss : 0.6300 | Acc : 0.5707
     Batch 175 | Loss : 0.6266 | Acc : 0.5718
     Batch 200 | Loss : 0.6506 | Acc : 0.5570
     Batch 225 | Loss : 0.5844 | Acc : 0.6120
     Batch 250 | Loss : 0.6326 | Acc : 0.5659
     Batch 275 | Loss : 0.5952 | Acc : 0.6074
     Batch 300 | Loss : 0.6303 | Acc : 0.5753
Epoch 00122 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6183 | Acc : 0.5869
     Batch 025 | Loss : 0.5846 | Acc : 0.6028
     Batch 050 | Loss : 0.6227 | Acc : 0.5845
     Batch 075 | Loss : 0.6113 | Acc : 0.5894
     Batch 100 | Loss : 0.6088 | Acc : 0.5920
     Batch 125 | Loss : 0.6219 | Acc : 0.5730
     Batch 150 | Loss : 0.6113 | Acc : 0.5954
     Batch 175 | Loss : 0.6256 | Acc : 0.5856
     Batch 200 | Loss : 0.6509 | Acc : 0.5535
     Batch 225 | Loss : 0.5964 | Acc : 0.5945
     Batch 250 | Loss : 0.6546 | Acc : 0.5571
     Batch 275 | Loss : 0.6515 | Acc : 0.5529
     Batch 300 | Loss : 0.6135 | Acc : 0.5812
Epoch 00123 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5978 | Acc : 0.6061
     Batch 025 | Loss : 0.5876 | Acc : 0.6064
     Batch 050 | Loss : 0.5985 | Acc : 0.6021
     Batch 075 | Loss : 0.6346 | Acc : 0.5649
     Batch 100 | Loss : 0.5854 | Acc : 0.6044
     Batch 125 | Loss : 0.6260 | Acc : 0.5836
     Batch 150 | Loss : 0.6262 | Acc : 0.5749
     Batch 175 | Loss : 0.6348 | Acc : 0.5670
     Batch 200 | Loss : 0.5834 | Acc : 0.6109
     Batch 225 | Loss : 0.6306 | Acc : 0.5656
     Batch 250 | Loss : 0.5967 | Acc : 0.5955
     Batch 275 | Loss : 0.6353 | Acc : 0.5680
     Batch 300 | Loss : 0.6574 | Acc : 0.5477
Epoch 00124 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6394 | Acc : 0.5550
     Batch 025 | Loss : 0.6531 | Acc : 0.5535
     Batch 050 | Loss : 0.6299 | Acc : 0.5725
     Batch 075 | Loss : 0.6239 | Acc : 0.5786
     Batch 100 | Loss : 0.6461 | Acc : 0.5570
     Batch 125 | Loss : 0.6422 | Acc : 0.5590
     Batch 150 | Loss : 0.6314 | Acc : 0.5736
     Batch 175 | Loss : 0.6288 | Acc : 0.5826
     Batch 200 | Loss : 0.6373 | Acc : 0.5604
     Batch 225 | Loss : 0.5803 | Acc : 0.6118
     Batch 250 | Loss : 0.6183 | Acc : 0.5826
     Batch 275 | Loss : 0.5807 | Acc : 0.6159
     Batch 300 | Loss : 0.6256 | Acc : 0.5856
Epoch 00125 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5997 | Acc : 0.5885
     Batch 025 | Loss : 0.5972 | Acc : 0.5943
     Batch 050 | Loss : 0.6574 | Acc : 0.5477
     Batch 075 | Loss : 0.6298 | Acc : 0.5688
     Batch 100 | Loss : 0.6550 | Acc : 0.5421
     Batch 125 | Loss : 0.6112 | Acc : 0.5842
     Batch 150 | Loss : 0.6269 | Acc : 0.5685
     Batch 175 | Loss : 0.5964 | Acc : 0.5945
     Batch 200 | Loss : 0.6256 | Acc : 0.5818
     Batch 225 | Loss : 0.6380 | Acc : 0.5660
     Batch 250 | Loss : 0.5904 | Acc : 0.6029
     Batch 275 | Loss : 0.5947 | Acc : 0.5939
     Batch 300 | Loss : 0.6557 | Acc : 0.5503
Epoch 00126 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6396 | Acc : 0.5599
     Batch 025 | Loss : 0.6269 | Acc : 0.5827
     Batch 050 | Loss : 0.6121 | Acc : 0.5819
     Batch 075 | Loss : 0.6286 | Acc : 0.5691
     Batch 100 | Loss : 0.5960 | Acc : 0.5953
     Batch 125 | Loss : 0.6300 | Acc : 0.5707
     Batch 150 | Loss : 0.6180 | Acc : 0.5772
     Batch 175 | Loss : 0.6393 | Acc : 0.5619
     Batch 200 | Loss : 0.5997 | Acc : 0.5997
     Batch 225 | Loss : 0.5938 | Acc : 0.6010
     Batch 250 | Loss : 0.5838 | Acc : 0.6137
     Batch 275 | Loss : 0.5928 | Acc : 0.5976
     Batch 300 | Loss : 0.6281 | Acc : 0.5692
Epoch 00127 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6266 | Acc : 0.5718
     Batch 025 | Loss : 0.6542 | Acc : 0.5508
     Batch 050 | Loss : 0.6539 | Acc : 0.5487
     Batch 075 | Loss : 0.6558 | Acc : 0.5403
     Batch 100 | Loss : 0.6278 | Acc : 0.5775
     Batch 125 | Loss : 0.5854 | Acc : 0.6000
     Batch 150 | Loss : 0.6587 | Acc : 0.5456
     Batch 175 | Loss : 0.6561 | Acc : 0.5490
     Batch 200 | Loss : 0.6254 | Acc : 0.5856
     Batch 225 | Loss : 0.6500 | Acc : 0.5634
     Batch 250 | Loss : 0.6180 | Acc : 0.5772
     Batch 275 | Loss : 0.6297 | Acc : 0.5672
     Batch 300 | Loss : 0.6125 | Acc : 0.5829
Epoch 00128 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6393 | Acc : 0.5630
     Batch 025 | Loss : 0.5797 | Acc : 0.6186
     Batch 050 | Loss : 0.6473 | Acc : 0.5591
     Batch 075 | Loss : 0.6406 | Acc : 0.5613
     Batch 100 | Loss : 0.6410 | Acc : 0.5645
     Batch 125 | Loss : 0.6270 | Acc : 0.5827
     Batch 150 | Loss : 0.6108 | Acc : 0.5904
     Batch 175 | Loss : 0.5792 | Acc : 0.6008
     Batch 200 | Loss : 0.6455 | Acc : 0.5618
     Batch 225 | Loss : 0.6325 | Acc : 0.5630
     Batch 250 | Loss : 0.6262 | Acc : 0.5677
     Batch 275 | Loss : 0.6334 | Acc : 0.5725
     Batch 300 | Loss : 0.6297 | Acc : 0.5672
Epoch 00129 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5956 | Acc : 0.6074
     Batch 025 | Loss : 0.6216 | Acc : 0.5818
     Batch 050 | Loss : 0.6309 | Acc : 0.5811
     Batch 075 | Loss : 0.5964 | Acc : 0.5996
     Batch 100 | Loss : 0.6565 | Acc : 0.5453
     Batch 125 | Loss : 0.5959 | Acc : 0.5953
     Batch 150 | Loss : 0.5983 | Acc : 0.5919
     Batch 175 | Loss : 0.5855 | Acc : 0.6000
     Batch 200 | Loss : 0.6364 | Acc : 0.5723
     Batch 225 | Loss : 0.6254 | Acc : 0.5856
     Batch 250 | Loss : 0.6262 | Acc : 0.5749
     Batch 275 | Loss : 0.6419 | Acc : 0.5655
     Batch 300 | Loss : 0.6367 | Acc : 0.5647
Epoch 00130 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6261 | Acc : 0.5737
     Batch 025 | Loss : 0.5940 | Acc : 0.6011
     Batch 050 | Loss : 0.6485 | Acc : 0.5504
     Batch 075 | Loss : 0.6112 | Acc : 0.5954
     Batch 100 | Loss : 0.6266 | Acc : 0.5718
     Batch 125 | Loss : 0.6337 | Acc : 0.5630
     Batch 150 | Loss : 0.5827 | Acc : 0.6098
     Batch 175 | Loss : 0.6418 | Acc : 0.5565
     Batch 200 | Loss : 0.5940 | Acc : 0.5961
     Batch 225 | Loss : 0.6172 | Acc : 0.5870
     Batch 250 | Loss : 0.6105 | Acc : 0.5942
     Batch 275 | Loss : 0.6249 | Acc : 0.5765
     Batch 300 | Loss : 0.6301 | Acc : 0.5752
Epoch 00131 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6403 | Acc : 0.5595
     Batch 025 | Loss : 0.5926 | Acc : 0.5932
     Batch 050 | Loss : 0.6338 | Acc : 0.5630
     Batch 075 | Loss : 0.6400 | Acc : 0.5582
     Batch 100 | Loss : 0.6499 | Acc : 0.5516
     Batch 125 | Loss : 0.6350 | Acc : 0.5571
     Batch 150 | Loss : 0.5977 | Acc : 0.6061
     Batch 175 | Loss : 0.6408 | Acc : 0.5585
     Batch 200 | Loss : 0.5889 | Acc : 0.6167
     Batch 225 | Loss : 0.5940 | Acc : 0.5961
     Batch 250 | Loss : 0.6273 | Acc : 0.5773
     Batch 275 | Loss : 0.6377 | Acc : 0.5745
     Batch 300 | Loss : 0.6127 | Acc : 0.5776
Epoch 00132 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6286 | Acc : 0.5691
     Batch 025 | Loss : 0.6216 | Acc : 0.5818
     Batch 050 | Loss : 0.6365 | Acc : 0.5710
     Batch 075 | Loss : 0.6410 | Acc : 0.5645
     Batch 100 | Loss : 0.6345 | Acc : 0.5649
     Batch 125 | Loss : 0.6221 | Acc : 0.5813
     Batch 150 | Loss : 0.6147 | Acc : 0.5770
     Batch 175 | Loss : 0.6393 | Acc : 0.5619
     Batch 200 | Loss : 0.6542 | Acc : 0.5508
     Batch 225 | Loss : 0.6675 | Acc : 0.5363
     Batch 250 | Loss : 0.6527 | Acc : 0.5649
     Batch 275 | Loss : 0.6568 | Acc : 0.5441
     Batch 300 | Loss : 0.6299 | Acc : 0.5725
Epoch 00133 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6132 | Acc : 0.5837
     Batch 025 | Loss : 0.5928 | Acc : 0.5976
     Batch 050 | Loss : 0.5987 | Acc : 0.5894
     Batch 075 | Loss : 0.6422 | Acc : 0.5590
     Batch 100 | Loss : 0.5899 | Acc : 0.6035
     Batch 125 | Loss : 0.5846 | Acc : 0.6028
     Batch 150 | Loss : 0.6676 | Acc : 0.5363
     Batch 175 | Loss : 0.5964 | Acc : 0.5996
     Batch 200 | Loss : 0.6319 | Acc : 0.5696
     Batch 225 | Loss : 0.6559 | Acc : 0.5432
     Batch 250 | Loss : 0.6502 | Acc : 0.5469
     Batch 275 | Loss : 0.6545 | Acc : 0.5571
     Batch 300 | Loss : 0.5902 | Acc : 0.5978
Epoch 00134 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6415 | Acc : 0.5583
     Batch 025 | Loss : 0.6324 | Acc : 0.5630
     Batch 050 | Loss : 0.6349 | Acc : 0.5670
     Batch 075 | Loss : 0.5853 | Acc : 0.5964
     Batch 100 | Loss : 0.6545 | Acc : 0.5571
     Batch 125 | Loss : 0.5993 | Acc : 0.5940
     Batch 150 | Loss : 0.6677 | Acc : 0.5363
     Batch 175 | Loss : 0.6412 | Acc : 0.5632
     Batch 200 | Loss : 0.5906 | Acc : 0.5974
     Batch 225 | Loss : 0.6301 | Acc : 0.5752
     Batch 250 | Loss : 0.5845 | Acc : 0.6057
     Batch 275 | Loss : 0.5972 | Acc : 0.5943
     Batch 300 | Loss : 0.6135 | Acc : 0.5871
Epoch 00135 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5961 | Acc : 0.5987
     Batch 025 | Loss : 0.6404 | Acc : 0.5643
     Batch 050 | Loss : 0.5959 | Acc : 0.5953
     Batch 075 | Loss : 0.6502 | Acc : 0.5585
     Batch 100 | Loss : 0.6508 | Acc : 0.5580
     Batch 125 | Loss : 0.5854 | Acc : 0.6044
     Batch 150 | Loss : 0.6564 | Acc : 0.5453
     Batch 175 | Loss : 0.6142 | Acc : 0.5969
     Batch 200 | Loss : 0.6484 | Acc : 0.5504
     Batch 225 | Loss : 0.5986 | Acc : 0.6013
     Batch 250 | Loss : 0.6513 | Acc : 0.5548
     Batch 275 | Loss : 0.6588 | Acc : 0.5456
     Batch 300 | Loss : 0.6192 | Acc : 0.5795
Epoch 00136 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6323 | Acc : 0.5641
     Batch 025 | Loss : 0.6503 | Acc : 0.5524
     Batch 050 | Loss : 0.6507 | Acc : 0.5563
     Batch 075 | Loss : 0.6537 | Acc : 0.5571
     Batch 100 | Loss : 0.6176 | Acc : 0.5864
     Batch 125 | Loss : 0.6271 | Acc : 0.5792
     Batch 150 | Loss : 0.6427 | Acc : 0.5622
     Batch 175 | Loss : 0.6219 | Acc : 0.5730
     Batch 200 | Loss : 0.6266 | Acc : 0.5757
     Batch 225 | Loss : 0.5906 | Acc : 0.6043
     Batch 250 | Loss : 0.5959 | Acc : 0.5953
     Batch 275 | Loss : 0.6173 | Acc : 0.5778
     Batch 300 | Loss : 0.6247 | Acc : 0.5722
Epoch 00137 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6499 | Acc : 0.5524
     Batch 025 | Loss : 0.6281 | Acc : 0.5692
     Batch 050 | Loss : 0.6420 | Acc : 0.5635
     Batch 075 | Loss : 0.6306 | Acc : 0.5656
     Batch 100 | Loss : 0.6163 | Acc : 0.5763
     Batch 125 | Loss : 0.6501 | Acc : 0.5516
     Batch 150 | Loss : 0.6255 | Acc : 0.5856
     Batch 175 | Loss : 0.5986 | Acc : 0.5923
     Batch 200 | Loss : 0.5784 | Acc : 0.6170
     Batch 225 | Loss : 0.6502 | Acc : 0.5585
     Batch 250 | Loss : 0.6106 | Acc : 0.5895
     Batch 275 | Loss : 0.6264 | Acc : 0.5729
     Batch 300 | Loss : 0.6254 | Acc : 0.5778
Epoch 00138 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6394 | Acc : 0.5550
     Batch 025 | Loss : 0.6335 | Acc : 0.5630
     Batch 050 | Loss : 0.6473 | Acc : 0.5626
     Batch 075 | Loss : 0.6564 | Acc : 0.5453
     Batch 100 | Loss : 0.6007 | Acc : 0.5960
     Batch 125 | Loss : 0.6393 | Acc : 0.5619
     Batch 150 | Loss : 0.6422 | Acc : 0.5590
     Batch 175 | Loss : 0.6499 | Acc : 0.5594
     Batch 200 | Loss : 0.5928 | Acc : 0.5940
     Batch 225 | Loss : 0.5845 | Acc : 0.6057
     Batch 250 | Loss : 0.5941 | Acc : 0.5986
     Batch 275 | Loss : 0.6529 | Acc : 0.5562
     Batch 300 | Loss : 0.6113 | Acc : 0.5894
Epoch 00139 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5930 | Acc : 0.6071
     Batch 025 | Loss : 0.5797 | Acc : 0.6077
     Batch 050 | Loss : 0.5846 | Acc : 0.6028
     Batch 075 | Loss : 0.6150 | Acc : 0.5851
     Batch 100 | Loss : 0.6443 | Acc : 0.5582
     Batch 125 | Loss : 0.6575 | Acc : 0.5438
     Batch 150 | Loss : 0.6497 | Acc : 0.5498
     Batch 175 | Loss : 0.6336 | Acc : 0.5652
     Batch 200 | Loss : 0.6362 | Acc : 0.5723
     Batch 225 | Loss : 0.5890 | Acc : 0.6167
     Batch 250 | Loss : 0.5972 | Acc : 0.5943
     Batch 275 | Loss : 0.6411 | Acc : 0.5585
     Batch 300 | Loss : 0.6475 | Acc : 0.5515
Epoch 00140 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5876 | Acc : 0.6064
     Batch 025 | Loss : 0.6515 | Acc : 0.5479
     Batch 050 | Loss : 0.6176 | Acc : 0.5864
     Batch 075 | Loss : 0.6174 | Acc : 0.5778
     Batch 100 | Loss : 0.6266 | Acc : 0.5718
     Batch 125 | Loss : 0.6398 | Acc : 0.5582
     Batch 150 | Loss : 0.6501 | Acc : 0.5634
     Batch 175 | Loss : 0.6515 | Acc : 0.5610
     Batch 200 | Loss : 0.5776 | Acc : 0.6179
     Batch 225 | Loss : 0.6373 | Acc : 0.5604
     Batch 250 | Loss : 0.6106 | Acc : 0.5895
     Batch 275 | Loss : 0.5932 | Acc : 0.6071
     Batch 300 | Loss : 0.6216 | Acc : 0.5818
Epoch 00141 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6502 | Acc : 0.5585
     Batch 025 | Loss : 0.6248 | Acc : 0.5765
     Batch 050 | Loss : 0.6220 | Acc : 0.5730
     Batch 075 | Loss : 0.6523 | Acc : 0.5476
     Batch 100 | Loss : 0.5845 | Acc : 0.6057
     Batch 125 | Loss : 0.6323 | Acc : 0.5650
     Batch 150 | Loss : 0.6274 | Acc : 0.5725
     Batch 175 | Loss : 0.6461 | Acc : 0.5514
     Batch 200 | Loss : 0.5839 | Acc : 0.6137
     Batch 225 | Loss : 0.6286 | Acc : 0.5691
     Batch 250 | Loss : 0.6561 | Acc : 0.5487
     Batch 275 | Loss : 0.6544 | Acc : 0.5512
     Batch 300 | Loss : 0.6324 | Acc : 0.5721
Epoch 00142 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6326 | Acc : 0.5684
     Batch 025 | Loss : 0.5846 | Acc : 0.6120
     Batch 050 | Loss : 0.6513 | Acc : 0.5548
     Batch 075 | Loss : 0.5828 | Acc : 0.6098
     Batch 100 | Loss : 0.6415 | Acc : 0.5589
     Batch 125 | Loss : 0.5972 | Acc : 0.5930
     Batch 150 | Loss : 0.5816 | Acc : 0.6039
     Batch 175 | Loss : 0.6475 | Acc : 0.5515
     Batch 200 | Loss : 0.6247 | Acc : 0.5722
     Batch 225 | Loss : 0.6565 | Acc : 0.5441
     Batch 250 | Loss : 0.6142 | Acc : 0.5789
     Batch 275 | Loss : 0.6366 | Acc : 0.5655
     Batch 300 | Loss : 0.6459 | Acc : 0.5541
Epoch 00143 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6079 | Acc : 0.5903
     Batch 025 | Loss : 0.6532 | Acc : 0.5767
     Batch 050 | Loss : 0.5937 | Acc : 0.6010
     Batch 075 | Loss : 0.6392 | Acc : 0.5737
     Batch 100 | Loss : 0.5931 | Acc : 0.6004
     Batch 125 | Loss : 0.5876 | Acc : 0.6011
     Batch 150 | Loss : 0.6467 | Acc : 0.5587
     Batch 175 | Loss : 0.6278 | Acc : 0.5775
     Batch 200 | Loss : 0.6336 | Acc : 0.5630
     Batch 225 | Loss : 0.6326 | Acc : 0.5684
     Batch 250 | Loss : 0.6460 | Acc : 0.5570
     Batch 275 | Loss : 0.6586 | Acc : 0.5456
     Batch 300 | Loss : 0.6002 | Acc : 0.5947
Epoch 00144 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6485 | Acc : 0.5504
     Batch 025 | Loss : 0.6489 | Acc : 0.5570
     Batch 050 | Loss : 0.5740 | Acc : 0.6252
     Batch 075 | Loss : 0.6542 | Acc : 0.5508
     Batch 100 | Loss : 0.6345 | Acc : 0.5649
     Batch 125 | Loss : 0.6254 | Acc : 0.5778
     Batch 150 | Loss : 0.6168 | Acc : 0.5730
     Batch 175 | Loss : 0.6554 | Acc : 0.5434
     Batch 200 | Loss : 0.6458 | Acc : 0.5541
     Batch 225 | Loss : 0.6192 | Acc : 0.5795
     Batch 250 | Loss : 0.6559 | Acc : 0.5403
     Batch 275 | Loss : 0.6299 | Acc : 0.5725
     Batch 300 | Loss : 0.6238 | Acc : 0.5787
Epoch 00145 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6562 | Acc : 0.5426
     Batch 025 | Loss : 0.6244 | Acc : 0.5755
     Batch 050 | Loss : 0.6173 | Acc : 0.5778
     Batch 075 | Loss : 0.5963 | Acc : 0.5996
     Batch 100 | Loss : 0.6377 | Acc : 0.5745
     Batch 125 | Loss : 0.6177 | Acc : 0.5864
     Batch 150 | Loss : 0.6565 | Acc : 0.5453
     Batch 175 | Loss : 0.6346 | Acc : 0.5649
     Batch 200 | Loss : 0.6529 | Acc : 0.5562
     Batch 225 | Loss : 0.5928 | Acc : 0.5940
     Batch 250 | Loss : 0.5922 | Acc : 0.6005
     Batch 275 | Loss : 0.5845 | Acc : 0.6057
     Batch 300 | Loss : 0.6513 | Acc : 0.5548
Epoch 00146 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6393 | Acc : 0.5737
     Batch 025 | Loss : 0.6326 | Acc : 0.5684
     Batch 050 | Loss : 0.6323 | Acc : 0.5798
     Batch 075 | Loss : 0.6306 | Acc : 0.5656
     Batch 100 | Loss : 0.5967 | Acc : 0.5955
     Batch 125 | Loss : 0.6239 | Acc : 0.5786
     Batch 150 | Loss : 0.6302 | Acc : 0.5752
     Batch 175 | Loss : 0.6222 | Acc : 0.5813
     Batch 200 | Loss : 0.6530 | Acc : 0.5562
     Batch 225 | Loss : 0.6167 | Acc : 0.5806
     Batch 250 | Loss : 0.6112 | Acc : 0.5954
     Batch 275 | Loss : 0.6360 | Acc : 0.5758
     Batch 300 | Loss : 0.5797 | Acc : 0.6077
Epoch 00147 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6265 | Acc : 0.5718
     Batch 025 | Loss : 0.6499 | Acc : 0.5594
     Batch 050 | Loss : 0.5811 | Acc : 0.6159
     Batch 075 | Loss : 0.6219 | Acc : 0.5730
     Batch 100 | Loss : 0.6506 | Acc : 0.5570
     Batch 125 | Loss : 0.6159 | Acc : 0.5818
     Batch 150 | Loss : 0.5983 | Acc : 0.5919
     Batch 175 | Loss : 0.5975 | Acc : 0.6061
     Batch 200 | Loss : 0.6335 | Acc : 0.5652
     Batch 225 | Loss : 0.6531 | Acc : 0.5535
     Batch 250 | Loss : 0.6688 | Acc : 0.5296
     Batch 275 | Loss : 0.5953 | Acc : 0.6074
     Batch 300 | Loss : 0.6363 | Acc : 0.5710
Epoch 00148 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6467 | Acc : 0.5587
     Batch 025 | Loss : 0.5972 | Acc : 0.5930
     Batch 050 | Loss : 0.5891 | Acc : 0.6167
     Batch 075 | Loss : 0.6006 | Acc : 0.5960
     Batch 100 | Loss : 0.6434 | Acc : 0.5568
     Batch 125 | Loss : 0.6525 | Acc : 0.5476
     Batch 150 | Loss : 0.6227 | Acc : 0.5845
     Batch 175 | Loss : 0.6515 | Acc : 0.5529
     Batch 200 | Loss : 0.6002 | Acc : 0.5947
     Batch 225 | Loss : 0.6560 | Acc : 0.5426
     Batch 250 | Loss : 0.6198 | Acc : 0.5780
     Batch 275 | Loss : 0.6163 | Acc : 0.5763
     Batch 300 | Loss : 0.5866 | Acc : 0.6041
Epoch 00149 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6405 | Acc : 0.5502
     Batch 025 | Loss : 0.6256 | Acc : 0.5818
     Batch 050 | Loss : 0.6488 | Acc : 0.5570
     Batch 075 | Loss : 0.6262 | Acc : 0.5749
     Batch 100 | Loss : 0.6326 | Acc : 0.5630
     Batch 125 | Loss : 0.6399 | Acc : 0.5541
     Batch 150 | Loss : 0.6114 | Acc : 0.5897
     Batch 175 | Loss : 0.5964 | Acc : 0.5945
     Batch 200 | Loss : 0.6335 | Acc : 0.5630
     Batch 225 | Loss : 0.6420 | Acc : 0.5655
     Batch 250 | Loss : 0.6404 | Acc : 0.5662
     Batch 275 | Loss : 0.6546 | Acc : 0.5571
     Batch 300 | Loss : 0.6199 | Acc : 0.5777
Epoch 00150 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6476 | Acc : 0.5594
     Batch 025 | Loss : 0.6501 | Acc : 0.5469
     Batch 050 | Loss : 0.6407 | Acc : 0.5502
     Batch 075 | Loss : 0.6360 | Acc : 0.5758
     Batch 100 | Loss : 0.6265 | Acc : 0.5757
     Batch 125 | Loss : 0.6514 | Acc : 0.5529
     Batch 150 | Loss : 0.6412 | Acc : 0.5632
     Batch 175 | Loss : 0.5961 | Acc : 0.5987
     Batch 200 | Loss : 0.6323 | Acc : 0.5641
     Batch 225 | Loss : 0.6110 | Acc : 0.5954
     Batch 250 | Loss : 0.6560 | Acc : 0.5487
     Batch 275 | Loss : 0.5873 | Acc : 0.6034
     Batch 300 | Loss : 0.6124 | Acc : 0.5829
Epoch 00151 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6335 | Acc : 0.5652
     Batch 025 | Loss : 0.6507 | Acc : 0.5563
     Batch 050 | Loss : 0.6397 | Acc : 0.5577
     Batch 075 | Loss : 0.6536 | Acc : 0.5502
     Batch 100 | Loss : 0.6287 | Acc : 0.5826
     Batch 125 | Loss : 0.6275 | Acc : 0.5773
     Batch 150 | Loss : 0.6315 | Acc : 0.5650
     Batch 175 | Loss : 0.6184 | Acc : 0.5869
     Batch 200 | Loss : 0.6323 | Acc : 0.5630
     Batch 225 | Loss : 0.6504 | Acc : 0.5748
     Batch 250 | Loss : 0.6175 | Acc : 0.5864
     Batch 275 | Loss : 0.6314 | Acc : 0.5736
     Batch 300 | Loss : 0.6150 | Acc : 0.5851
Epoch 00152 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6239 | Acc : 0.5786
     Batch 025 | Loss : 0.5927 | Acc : 0.5932
     Batch 050 | Loss : 0.5947 | Acc : 0.5939
     Batch 075 | Loss : 0.6530 | Acc : 0.5529
     Batch 100 | Loss : 0.6502 | Acc : 0.5469
     Batch 125 | Loss : 0.6525 | Acc : 0.5476
     Batch 150 | Loss : 0.6319 | Acc : 0.5696
     Batch 175 | Loss : 0.6348 | Acc : 0.5670
     Batch 200 | Loss : 0.6323 | Acc : 0.5650
     Batch 225 | Loss : 0.6114 | Acc : 0.5897
     Batch 250 | Loss : 0.5846 | Acc : 0.6028
     Batch 275 | Loss : 0.6530 | Acc : 0.5562
     Batch 300 | Loss : 0.6575 | Acc : 0.5438
Epoch 00153 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6300 | Acc : 0.5707
     Batch 025 | Loss : 0.5906 | Acc : 0.5974
     Batch 050 | Loss : 0.6418 | Acc : 0.5565
     Batch 075 | Loss : 0.6147 | Acc : 0.5832
     Batch 100 | Loss : 0.6217 | Acc : 0.5818
     Batch 125 | Loss : 0.6473 | Acc : 0.5591
     Batch 150 | Loss : 0.5902 | Acc : 0.5978
     Batch 175 | Loss : 0.6303 | Acc : 0.5698
     Batch 200 | Loss : 0.6272 | Acc : 0.5827
     Batch 225 | Loss : 0.6230 | Acc : 0.5742
     Batch 250 | Loss : 0.6145 | Acc : 0.5790
     Batch 275 | Loss : 0.6257 | Acc : 0.5818
     Batch 300 | Loss : 0.5820 | Acc : 0.6111
Epoch 00154 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6561 | Acc : 0.5487
     Batch 025 | Loss : 0.6393 | Acc : 0.5550
     Batch 050 | Loss : 0.6526 | Acc : 0.5541
     Batch 075 | Loss : 0.5964 | Acc : 0.5996
     Batch 100 | Loss : 0.6404 | Acc : 0.5643
     Batch 125 | Loss : 0.5906 | Acc : 0.5974
     Batch 150 | Loss : 0.5928 | Acc : 0.5940
     Batch 175 | Loss : 0.6505 | Acc : 0.5535
     Batch 200 | Loss : 0.6495 | Acc : 0.5524
     Batch 225 | Loss : 0.6558 | Acc : 0.5503
     Batch 250 | Loss : 0.6500 | Acc : 0.5524
     Batch 275 | Loss : 0.5784 | Acc : 0.6138
     Batch 300 | Loss : 0.6335 | Acc : 0.5630
Epoch 00155 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5877 | Acc : 0.6064
     Batch 025 | Loss : 0.6297 | Acc : 0.5672
     Batch 050 | Loss : 0.6407 | Acc : 0.5584
     Batch 075 | Loss : 0.5816 | Acc : 0.6039
     Batch 100 | Loss : 0.6509 | Acc : 0.5580
     Batch 125 | Loss : 0.6501 | Acc : 0.5524
     Batch 150 | Loss : 0.6349 | Acc : 0.5571
     Batch 175 | Loss : 0.6417 | Acc : 0.5582
     Batch 200 | Loss : 0.6463 | Acc : 0.5514
     Batch 225 | Loss : 0.6233 | Acc : 0.5886
     Batch 250 | Loss : 0.6255 | Acc : 0.5778
     Batch 275 | Loss : 0.6500 | Acc : 0.5516
     Batch 300 | Loss : 0.6183 | Acc : 0.5826
Epoch 00156 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6508 | Acc : 0.5580
     Batch 025 | Loss : 0.6392 | Acc : 0.5630
     Batch 050 | Loss : 0.5823 | Acc : 0.6023
     Batch 075 | Loss : 0.6173 | Acc : 0.5778
     Batch 100 | Loss : 0.5833 | Acc : 0.6109
     Batch 125 | Loss : 0.6231 | Acc : 0.5826
     Batch 150 | Loss : 0.6575 | Acc : 0.5438
     Batch 175 | Loss : 0.6128 | Acc : 0.5776
     Batch 200 | Loss : 0.6184 | Acc : 0.5869
     Batch 225 | Loss : 0.5902 | Acc : 0.5978
     Batch 250 | Loss : 0.6229 | Acc : 0.5742
     Batch 275 | Loss : 0.6494 | Acc : 0.5524
     Batch 300 | Loss : 0.6108 | Acc : 0.5895
Epoch 00157 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6185 | Acc : 0.5826
     Batch 025 | Loss : 0.6528 | Acc : 0.5649
     Batch 050 | Loss : 0.6365 | Acc : 0.5710
     Batch 075 | Loss : 0.6142 | Acc : 0.5789
     Batch 100 | Loss : 0.6561 | Acc : 0.5487
     Batch 125 | Loss : 0.6475 | Acc : 0.5515
     Batch 150 | Loss : 0.6559 | Acc : 0.5426
     Batch 175 | Loss : 0.6115 | Acc : 0.5897
     Batch 200 | Loss : 0.6135 | Acc : 0.5871
     Batch 225 | Loss : 0.5984 | Acc : 0.6021
     Batch 250 | Loss : 0.5828 | Acc : 0.6024
     Batch 275 | Loss : 0.5918 | Acc : 0.5989
     Batch 300 | Loss : 0.6416 | Acc : 0.5583
Epoch 00158 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5928 | Acc : 0.5976
     Batch 025 | Loss : 0.6323 | Acc : 0.5721
     Batch 050 | Loss : 0.6397 | Acc : 0.5599
     Batch 075 | Loss : 0.6367 | Acc : 0.5647
     Batch 100 | Loss : 0.6173 | Acc : 0.5870
     Batch 125 | Loss : 0.6364 | Acc : 0.5687
     Batch 150 | Loss : 0.6167 | Acc : 0.5806
     Batch 175 | Loss : 0.6299 | Acc : 0.5725
     Batch 200 | Loss : 0.6415 | Acc : 0.5583
     Batch 225 | Loss : 0.6495 | Acc : 0.5498
     Batch 250 | Loss : 0.6298 | Acc : 0.5688
     Batch 275 | Loss : 0.5816 | Acc : 0.6039
     Batch 300 | Loss : 0.6006 | Acc : 0.5960
Epoch 00159 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6532 | Acc : 0.5451
     Batch 025 | Loss : 0.6575 | Acc : 0.5477
     Batch 050 | Loss : 0.5816 | Acc : 0.5998
     Batch 075 | Loss : 0.5802 | Acc : 0.6118
     Batch 100 | Loss : 0.6460 | Acc : 0.5570
     Batch 125 | Loss : 0.5876 | Acc : 0.5970
     Batch 150 | Loss : 0.6287 | Acc : 0.5826
     Batch 175 | Loss : 0.6271 | Acc : 0.5827
     Batch 200 | Loss : 0.5797 | Acc : 0.6077
     Batch 225 | Loss : 0.6420 | Acc : 0.5635
     Batch 250 | Loss : 0.5878 | Acc : 0.6014
     Batch 275 | Loss : 0.6336 | Acc : 0.5652
     Batch 300 | Loss : 0.6560 | Acc : 0.5403
Epoch 00160 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6266 | Acc : 0.5757
     Batch 025 | Loss : 0.6532 | Acc : 0.5515
     Batch 050 | Loss : 0.5972 | Acc : 0.5930
     Batch 075 | Loss : 0.6348 | Acc : 0.5571
     Batch 100 | Loss : 0.6537 | Acc : 0.5571
     Batch 125 | Loss : 0.6234 | Acc : 0.5886
     Batch 150 | Loss : 0.6303 | Acc : 0.5698
     Batch 175 | Loss : 0.6392 | Acc : 0.5737
     Batch 200 | Loss : 0.5977 | Acc : 0.6061
     Batch 225 | Loss : 0.6318 | Acc : 0.5696
     Batch 250 | Loss : 0.5899 | Acc : 0.6035
     Batch 275 | Loss : 0.6258 | Acc : 0.5678
     Batch 300 | Loss : 0.6410 | Acc : 0.5585
Epoch 00161 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6527 | Acc : 0.5541
     Batch 025 | Loss : 0.6404 | Acc : 0.5662
     Batch 050 | Loss : 0.6278 | Acc : 0.5775
     Batch 075 | Loss : 0.6506 | Acc : 0.5563
     Batch 100 | Loss : 0.6459 | Acc : 0.5510
     Batch 125 | Loss : 0.6397 | Acc : 0.5577
     Batch 150 | Loss : 0.6113 | Acc : 0.5954
     Batch 175 | Loss : 0.6150 | Acc : 0.5851
     Batch 200 | Loss : 0.5808 | Acc : 0.6159
     Batch 225 | Loss : 0.6372 | Acc : 0.5566
     Batch 250 | Loss : 0.6327 | Acc : 0.5659
     Batch 275 | Loss : 0.6403 | Acc : 0.5574
     Batch 300 | Loss : 0.6559 | Acc : 0.5432
Epoch 00162 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5922 | Acc : 0.6005
     Batch 025 | Loss : 0.6513 | Acc : 0.5548
     Batch 050 | Loss : 0.6261 | Acc : 0.5677
     Batch 075 | Loss : 0.6331 | Acc : 0.5724
     Batch 100 | Loss : 0.6418 | Acc : 0.5565
     Batch 125 | Loss : 0.6324 | Acc : 0.5630
     Batch 150 | Loss : 0.6427 | Acc : 0.5622
     Batch 175 | Loss : 0.6112 | Acc : 0.5842
     Batch 200 | Loss : 0.6509 | Acc : 0.5580
     Batch 225 | Loss : 0.6363 | Acc : 0.5723
     Batch 250 | Loss : 0.5795 | Acc : 0.6186
     Batch 275 | Loss : 0.6424 | Acc : 0.5616
     Batch 300 | Loss : 0.6145 | Acc : 0.5790
Epoch 00163 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6273 | Acc : 0.5773
     Batch 025 | Loss : 0.6566 | Acc : 0.5441
     Batch 050 | Loss : 0.6507 | Acc : 0.5563
     Batch 075 | Loss : 0.5931 | Acc : 0.5999
     Batch 100 | Loss : 0.6491 | Acc : 0.5555
     Batch 125 | Loss : 0.6198 | Acc : 0.5780
     Batch 150 | Loss : 0.6194 | Acc : 0.5814
     Batch 175 | Loss : 0.6402 | Acc : 0.5658
     Batch 200 | Loss : 0.5819 | Acc : 0.6111
     Batch 225 | Loss : 0.5837 | Acc : 0.6137
     Batch 250 | Loss : 0.6543 | Acc : 0.5512
     Batch 275 | Loss : 0.6186 | Acc : 0.5841
     Batch 300 | Loss : 0.6167 | Acc : 0.5806
Epoch 00164 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5906 | Acc : 0.6029
     Batch 025 | Loss : 0.6397 | Acc : 0.5599
     Batch 050 | Loss : 0.6265 | Acc : 0.5757
     Batch 075 | Loss : 0.5940 | Acc : 0.5961
     Batch 100 | Loss : 0.5975 | Acc : 0.6061
     Batch 125 | Loss : 0.6305 | Acc : 0.5742
     Batch 150 | Loss : 0.6295 | Acc : 0.5809
     Batch 175 | Loss : 0.6476 | Acc : 0.5594
     Batch 200 | Loss : 0.6228 | Acc : 0.5845
     Batch 225 | Loss : 0.5846 | Acc : 0.6028
     Batch 250 | Loss : 0.6569 | Acc : 0.5441
     Batch 275 | Loss : 0.6405 | Acc : 0.5584
     Batch 300 | Loss : 0.6345 | Acc : 0.5649
Epoch 00165 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6422 | Acc : 0.5590
     Batch 025 | Loss : 0.6540 | Acc : 0.5487
     Batch 050 | Loss : 0.5987 | Acc : 0.5894
     Batch 075 | Loss : 0.5877 | Acc : 0.6064
     Batch 100 | Loss : 0.6336 | Acc : 0.5652
     Batch 125 | Loss : 0.6529 | Acc : 0.5562
     Batch 150 | Loss : 0.6405 | Acc : 0.5584
     Batch 175 | Loss : 0.6506 | Acc : 0.5535
     Batch 200 | Loss : 0.6419 | Acc : 0.5655
     Batch 225 | Loss : 0.6324 | Acc : 0.5798
     Batch 250 | Loss : 0.5816 | Acc : 0.5998
     Batch 275 | Loss : 0.5965 | Acc : 0.5996
     Batch 300 | Loss : 0.6474 | Acc : 0.5626
Epoch 00166 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6502 | Acc : 0.5524
     Batch 025 | Loss : 0.6247 | Acc : 0.5722
     Batch 050 | Loss : 0.6417 | Acc : 0.5582
     Batch 075 | Loss : 0.6527 | Acc : 0.5545
     Batch 100 | Loss : 0.6537 | Acc : 0.5571
     Batch 125 | Loss : 0.6006 | Acc : 0.5960
     Batch 150 | Loss : 0.6280 | Acc : 0.5692
     Batch 175 | Loss : 0.6460 | Acc : 0.5570
     Batch 200 | Loss : 0.6476 | Acc : 0.5515
     Batch 225 | Loss : 0.5857 | Acc : 0.6208
     Batch 250 | Loss : 0.6411 | Acc : 0.5585
     Batch 275 | Loss : 0.6290 | Acc : 0.5767
     Batch 300 | Loss : 0.6539 | Acc : 0.5487
Epoch 00167 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6365 | Acc : 0.5710
     Batch 025 | Loss : 0.6348 | Acc : 0.5586
     Batch 050 | Loss : 0.5801 | Acc : 0.6118
     Batch 075 | Loss : 0.6422 | Acc : 0.5590
     Batch 100 | Loss : 0.6408 | Acc : 0.5585
     Batch 125 | Loss : 0.6305 | Acc : 0.5742
     Batch 150 | Loss : 0.6303 | Acc : 0.5698
     Batch 175 | Loss : 0.6557 | Acc : 0.5434
     Batch 200 | Loss : 0.5854 | Acc : 0.6044
     Batch 225 | Loss : 0.6258 | Acc : 0.5818
     Batch 250 | Loss : 0.6503 | Acc : 0.5585
     Batch 275 | Loss : 0.6109 | Acc : 0.5904
     Batch 300 | Loss : 0.6167 | Acc : 0.5806
Epoch 00168 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6233 | Acc : 0.5886
     Batch 025 | Loss : 0.6198 | Acc : 0.5777
     Batch 050 | Loss : 0.6527 | Acc : 0.5545
     Batch 075 | Loss : 0.6306 | Acc : 0.5723
     Batch 100 | Loss : 0.6298 | Acc : 0.5688
     Batch 125 | Loss : 0.6289 | Acc : 0.5826
     Batch 150 | Loss : 0.5794 | Acc : 0.6095
     Batch 175 | Loss : 0.5797 | Acc : 0.6077
     Batch 200 | Loss : 0.6529 | Acc : 0.5649
     Batch 225 | Loss : 0.6674 | Acc : 0.5363
     Batch 250 | Loss : 0.5988 | Acc : 0.5894
     Batch 275 | Loss : 0.5783 | Acc : 0.6170
     Batch 300 | Loss : 0.5888 | Acc : 0.6167
Epoch 00169 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6274 | Acc : 0.5725
     Batch 025 | Loss : 0.6326 | Acc : 0.5659
     Batch 050 | Loss : 0.6391 | Acc : 0.5737
     Batch 075 | Loss : 0.5856 | Acc : 0.5964
     Batch 100 | Loss : 0.6475 | Acc : 0.5515
     Batch 125 | Loss : 0.6688 | Acc : 0.5296
     Batch 150 | Loss : 0.6229 | Acc : 0.5742
     Batch 175 | Loss : 0.5967 | Acc : 0.5955
     Batch 200 | Loss : 0.6507 | Acc : 0.5563
     Batch 225 | Loss : 0.5984 | Acc : 0.6021
     Batch 250 | Loss : 0.6513 | Acc : 0.5479
     Batch 275 | Loss : 0.6230 | Acc : 0.5886
     Batch 300 | Loss : 0.5998 | Acc : 0.5997
Epoch 00170 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5828 | Acc : 0.6024
     Batch 025 | Loss : 0.5926 | Acc : 0.5932
     Batch 050 | Loss : 0.6346 | Acc : 0.5649
     Batch 075 | Loss : 0.6529 | Acc : 0.5451
     Batch 100 | Loss : 0.5845 | Acc : 0.6057
     Batch 125 | Loss : 0.5967 | Acc : 0.5955
     Batch 150 | Loss : 0.5886 | Acc : 0.6167
     Batch 175 | Loss : 0.6173 | Acc : 0.5778
     Batch 200 | Loss : 0.5785 | Acc : 0.6138
     Batch 225 | Loss : 0.6261 | Acc : 0.5677
     Batch 250 | Loss : 0.6079 | Acc : 0.5903
     Batch 275 | Loss : 0.6302 | Acc : 0.5753
     Batch 300 | Loss : 0.6392 | Acc : 0.5737
Epoch 00171 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6184 | Acc : 0.5869
     Batch 025 | Loss : 0.6305 | Acc : 0.5656
     Batch 050 | Loss : 0.5794 | Acc : 0.6186
     Batch 075 | Loss : 0.6420 | Acc : 0.5635
     Batch 100 | Loss : 0.6397 | Acc : 0.5599
     Batch 125 | Loss : 0.6479 | Acc : 0.5608
     Batch 150 | Loss : 0.6346 | Acc : 0.5649
     Batch 175 | Loss : 0.5846 | Acc : 0.6057
     Batch 200 | Loss : 0.6557 | Acc : 0.5503
     Batch 225 | Loss : 0.6527 | Acc : 0.5476
     Batch 250 | Loss : 0.6458 | Acc : 0.5541
     Batch 275 | Loss : 0.6540 | Acc : 0.5487
     Batch 300 | Loss : 0.5866 | Acc : 0.6041
Epoch 00172 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6473 | Acc : 0.5626
     Batch 025 | Loss : 0.6403 | Acc : 0.5662
     Batch 050 | Loss : 0.6163 | Acc : 0.5763
     Batch 075 | Loss : 0.5984 | Acc : 0.6021
     Batch 100 | Loss : 0.6145 | Acc : 0.5790
     Batch 125 | Loss : 0.5914 | Acc : 0.5951
     Batch 150 | Loss : 0.6195 | Acc : 0.5814
     Batch 175 | Loss : 0.5876 | Acc : 0.6064
     Batch 200 | Loss : 0.6366 | Acc : 0.5631
     Batch 225 | Loss : 0.5936 | Acc : 0.6010
     Batch 250 | Loss : 0.6303 | Acc : 0.5698
     Batch 275 | Loss : 0.5859 | Acc : 0.6218
     Batch 300 | Loss : 0.6347 | Acc : 0.5612
Epoch 00173 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6409 | Acc : 0.5645
     Batch 025 | Loss : 0.6484 | Acc : 0.5504
     Batch 050 | Loss : 0.5905 | Acc : 0.6021
     Batch 075 | Loss : 0.6364 | Acc : 0.5710
     Batch 100 | Loss : 0.6461 | Acc : 0.5570
     Batch 125 | Loss : 0.6264 | Acc : 0.5729
     Batch 150 | Loss : 0.6194 | Acc : 0.5814
     Batch 175 | Loss : 0.6493 | Acc : 0.5524
     Batch 200 | Loss : 0.6575 | Acc : 0.5477
     Batch 225 | Loss : 0.5940 | Acc : 0.6011
     Batch 250 | Loss : 0.6460 | Acc : 0.5510
     Batch 275 | Loss : 0.6513 | Acc : 0.5548
     Batch 300 | Loss : 0.6325 | Acc : 0.5798
Epoch 00174 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6088 | Acc : 0.5920
     Batch 025 | Loss : 0.6362 | Acc : 0.5631
     Batch 050 | Loss : 0.6192 | Acc : 0.5795
     Batch 075 | Loss : 0.6493 | Acc : 0.5524
     Batch 100 | Loss : 0.6509 | Acc : 0.5535
     Batch 125 | Loss : 0.6371 | Acc : 0.5566
     Batch 150 | Loss : 0.5737 | Acc : 0.6252
     Batch 175 | Loss : 0.5867 | Acc : 0.6049
     Batch 200 | Loss : 0.5834 | Acc : 0.6109
     Batch 225 | Loss : 0.6258 | Acc : 0.5678
     Batch 250 | Loss : 0.5986 | Acc : 0.5923
     Batch 275 | Loss : 0.6114 | Acc : 0.5894
     Batch 300 | Loss : 0.5955 | Acc : 0.6074
Epoch 00175 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5846 | Acc : 0.6028
     Batch 025 | Loss : 0.6187 | Acc : 0.5841
     Batch 050 | Loss : 0.6173 | Acc : 0.5778
     Batch 075 | Loss : 0.6254 | Acc : 0.5856
     Batch 100 | Loss : 0.5993 | Acc : 0.5940
     Batch 125 | Loss : 0.6499 | Acc : 0.5516
     Batch 150 | Loss : 0.5816 | Acc : 0.6039
     Batch 175 | Loss : 0.6506 | Acc : 0.5535
     Batch 200 | Loss : 0.6530 | Acc : 0.5529
     Batch 225 | Loss : 0.6456 | Acc : 0.5541
     Batch 250 | Loss : 0.6239 | Acc : 0.5786
     Batch 275 | Loss : 0.6415 | Acc : 0.5583
     Batch 300 | Loss : 0.6270 | Acc : 0.5685
Epoch 00176 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6393 | Acc : 0.5737
     Batch 025 | Loss : 0.6325 | Acc : 0.5630
     Batch 050 | Loss : 0.6349 | Acc : 0.5571
     Batch 075 | Loss : 0.6294 | Acc : 0.5809
     Batch 100 | Loss : 0.5987 | Acc : 0.6021
     Batch 125 | Loss : 0.6527 | Acc : 0.5541
     Batch 150 | Loss : 0.6373 | Acc : 0.5604
     Batch 175 | Loss : 0.5928 | Acc : 0.5940
     Batch 200 | Loss : 0.6230 | Acc : 0.5826
     Batch 225 | Loss : 0.6560 | Acc : 0.5432
     Batch 250 | Loss : 0.6496 | Acc : 0.5498
     Batch 275 | Loss : 0.5906 | Acc : 0.5974
     Batch 300 | Loss : 0.5802 | Acc : 0.6118
Epoch 00177 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6531 | Acc : 0.5529
     Batch 025 | Loss : 0.6531 | Acc : 0.5535
     Batch 050 | Loss : 0.6247 | Acc : 0.5722
     Batch 075 | Loss : 0.6261 | Acc : 0.5737
     Batch 100 | Loss : 0.5837 | Acc : 0.6137
     Batch 125 | Loss : 0.6459 | Acc : 0.5510
     Batch 150 | Loss : 0.6531 | Acc : 0.5515
     Batch 175 | Loss : 0.6121 | Acc : 0.5819
     Batch 200 | Loss : 0.6500 | Acc : 0.5516
     Batch 225 | Loss : 0.6535 | Acc : 0.5502
     Batch 250 | Loss : 0.5854 | Acc : 0.6000
     Batch 275 | Loss : 0.5827 | Acc : 0.6098
     Batch 300 | Loss : 0.6564 | Acc : 0.5453
Epoch 00178 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6240 | Acc : 0.5786
     Batch 025 | Loss : 0.6365 | Acc : 0.5710
     Batch 050 | Loss : 0.5906 | Acc : 0.5974
     Batch 075 | Loss : 0.6302 | Acc : 0.5752
     Batch 100 | Loss : 0.6403 | Acc : 0.5662
     Batch 125 | Loss : 0.6233 | Acc : 0.5886
     Batch 150 | Loss : 0.6675 | Acc : 0.5363
     Batch 175 | Loss : 0.6335 | Acc : 0.5725
     Batch 200 | Loss : 0.6504 | Acc : 0.5532
     Batch 225 | Loss : 0.6159 | Acc : 0.5818
     Batch 250 | Loss : 0.6136 | Acc : 0.5871
     Batch 275 | Loss : 0.6299 | Acc : 0.5725
     Batch 300 | Loss : 0.5961 | Acc : 0.5987
Epoch 00179 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6362 | Acc : 0.5723
     Batch 025 | Loss : 0.5736 | Acc : 0.6252
     Batch 050 | Loss : 0.6168 | Acc : 0.5730
     Batch 075 | Loss : 0.6379 | Acc : 0.5745
     Batch 100 | Loss : 0.6280 | Acc : 0.5692
     Batch 125 | Loss : 0.6468 | Acc : 0.5587
     Batch 150 | Loss : 0.6257 | Acc : 0.5818
     Batch 175 | Loss : 0.5997 | Acc : 0.5885
     Batch 200 | Loss : 0.6229 | Acc : 0.5742
     Batch 225 | Loss : 0.6239 | Acc : 0.5786
     Batch 250 | Loss : 0.6002 | Acc : 0.5947
     Batch 275 | Loss : 0.5931 | Acc : 0.6004
     Batch 300 | Loss : 0.5962 | Acc : 0.5987
Epoch 00180 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6412 | Acc : 0.5632
     Batch 025 | Loss : 0.5902 | Acc : 0.5978
     Batch 050 | Loss : 0.6509 | Acc : 0.5580
     Batch 075 | Loss : 0.6264 | Acc : 0.5729
     Batch 100 | Loss : 0.6336 | Acc : 0.5652
     Batch 125 | Loss : 0.6547 | Acc : 0.5571
     Batch 150 | Loss : 0.6154 | Acc : 0.5874
     Batch 175 | Loss : 0.5889 | Acc : 0.6167
     Batch 200 | Loss : 0.6331 | Acc : 0.5724
     Batch 225 | Loss : 0.5927 | Acc : 0.5932
     Batch 250 | Loss : 0.5967 | Acc : 0.5955
     Batch 275 | Loss : 0.6308 | Acc : 0.5811
     Batch 300 | Loss : 0.5931 | Acc : 0.6071
Epoch 00181 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6494 | Acc : 0.5524
     Batch 025 | Loss : 0.6500 | Acc : 0.5748
     Batch 050 | Loss : 0.5878 | Acc : 0.6014
     Batch 075 | Loss : 0.5902 | Acc : 0.5978
     Batch 100 | Loss : 0.6163 | Acc : 0.5763
     Batch 125 | Loss : 0.6270 | Acc : 0.5685
     Batch 150 | Loss : 0.6530 | Acc : 0.5562
     Batch 175 | Loss : 0.6420 | Acc : 0.5565
     Batch 200 | Loss : 0.6403 | Acc : 0.5643
     Batch 225 | Loss : 0.5855 | Acc : 0.6208
     Batch 250 | Loss : 0.6433 | Acc : 0.5568
     Batch 275 | Loss : 0.6353 | Acc : 0.5680
     Batch 300 | Loss : 0.6296 | Acc : 0.5809
Epoch 00182 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6467 | Acc : 0.5587
     Batch 025 | Loss : 0.6254 | Acc : 0.5778
     Batch 050 | Loss : 0.6150 | Acc : 0.5851
     Batch 075 | Loss : 0.6538 | Acc : 0.5507
     Batch 100 | Loss : 0.5793 | Acc : 0.6095
     Batch 125 | Loss : 0.6272 | Acc : 0.5792
     Batch 150 | Loss : 0.6326 | Acc : 0.5684
     Batch 175 | Loss : 0.6298 | Acc : 0.5672
     Batch 200 | Loss : 0.6530 | Acc : 0.5767
     Batch 225 | Loss : 0.5960 | Acc : 0.5953
     Batch 250 | Loss : 0.6562 | Acc : 0.5432
     Batch 275 | Loss : 0.6543 | Acc : 0.5512
     Batch 300 | Loss : 0.6534 | Acc : 0.5502
Epoch 00183 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6501 | Acc : 0.5469
     Batch 025 | Loss : 0.6112 | Acc : 0.5842
     Batch 050 | Loss : 0.5876 | Acc : 0.6011
     Batch 075 | Loss : 0.6154 | Acc : 0.5874
     Batch 100 | Loss : 0.6545 | Acc : 0.5571
     Batch 125 | Loss : 0.5977 | Acc : 0.6061
     Batch 150 | Loss : 0.6424 | Acc : 0.5616
     Batch 175 | Loss : 0.6261 | Acc : 0.5737
     Batch 200 | Loss : 0.5795 | Acc : 0.6186
     Batch 225 | Loss : 0.6353 | Acc : 0.5680
     Batch 250 | Loss : 0.6271 | Acc : 0.5827
     Batch 275 | Loss : 0.6563 | Acc : 0.5490
     Batch 300 | Loss : 0.5873 | Acc : 0.6034
Epoch 00184 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6503 | Acc : 0.5469
     Batch 025 | Loss : 0.6393 | Acc : 0.5550
     Batch 050 | Loss : 0.6502 | Acc : 0.5524
     Batch 075 | Loss : 0.6323 | Acc : 0.5641
     Batch 100 | Loss : 0.5931 | Acc : 0.5999
     Batch 125 | Loss : 0.5796 | Acc : 0.6186
     Batch 150 | Loss : 0.6300 | Acc : 0.5752
     Batch 175 | Loss : 0.6150 | Acc : 0.5851
     Batch 200 | Loss : 0.6244 | Acc : 0.5755
     Batch 225 | Loss : 0.6506 | Acc : 0.5563
     Batch 250 | Loss : 0.6332 | Acc : 0.5724
     Batch 275 | Loss : 0.5922 | Acc : 0.6005
     Batch 300 | Loss : 0.6167 | Acc : 0.5806
Epoch 00185 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5846 | Acc : 0.6028
     Batch 025 | Loss : 0.6300 | Acc : 0.5752
     Batch 050 | Loss : 0.6347 | Acc : 0.5649
     Batch 075 | Loss : 0.6393 | Acc : 0.5619
     Batch 100 | Loss : 0.6303 | Acc : 0.5698
     Batch 125 | Loss : 0.6457 | Acc : 0.5539
     Batch 150 | Loss : 0.6221 | Acc : 0.5813
     Batch 175 | Loss : 0.6395 | Acc : 0.5737
     Batch 200 | Loss : 0.6474 | Acc : 0.5626
     Batch 225 | Loss : 0.6404 | Acc : 0.5574
     Batch 250 | Loss : 0.6477 | Acc : 0.5515
     Batch 275 | Loss : 0.5792 | Acc : 0.6095
     Batch 300 | Loss : 0.6463 | Acc : 0.5514
Epoch 00186 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6254 | Acc : 0.5778
     Batch 025 | Loss : 0.6530 | Acc : 0.5529
     Batch 050 | Loss : 0.6269 | Acc : 0.5827
     Batch 075 | Loss : 0.5907 | Acc : 0.6043
     Batch 100 | Loss : 0.6295 | Acc : 0.5809
     Batch 125 | Loss : 0.5874 | Acc : 0.6034
     Batch 150 | Loss : 0.6365 | Acc : 0.5631
     Batch 175 | Loss : 0.5931 | Acc : 0.5999
     Batch 200 | Loss : 0.6405 | Acc : 0.5595
     Batch 225 | Loss : 0.6527 | Acc : 0.5545
     Batch 250 | Loss : 0.6531 | Acc : 0.5515
     Batch 275 | Loss : 0.6112 | Acc : 0.5842
     Batch 300 | Loss : 0.6151 | Acc : 0.5851
Epoch 00187 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6255 | Acc : 0.5856
     Batch 025 | Loss : 0.6108 | Acc : 0.5942
     Batch 050 | Loss : 0.6513 | Acc : 0.5548
     Batch 075 | Loss : 0.6248 | Acc : 0.5765
     Batch 100 | Loss : 0.5906 | Acc : 0.6021
     Batch 125 | Loss : 0.6554 | Acc : 0.5434
     Batch 150 | Loss : 0.6559 | Acc : 0.5403
     Batch 175 | Loss : 0.6299 | Acc : 0.5725
     Batch 200 | Loss : 0.6323 | Acc : 0.5641
     Batch 225 | Loss : 0.6374 | Acc : 0.5566
     Batch 250 | Loss : 0.6415 | Acc : 0.5583
     Batch 275 | Loss : 0.6173 | Acc : 0.5870
     Batch 300 | Loss : 0.6244 | Acc : 0.5755
Epoch 00188 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5967 | Acc : 0.5955
     Batch 025 | Loss : 0.6534 | Acc : 0.5502
     Batch 050 | Loss : 0.6391 | Acc : 0.5737
     Batch 075 | Loss : 0.6403 | Acc : 0.5662
     Batch 100 | Loss : 0.6537 | Acc : 0.5459
     Batch 125 | Loss : 0.6306 | Acc : 0.5723
     Batch 150 | Loss : 0.5827 | Acc : 0.6098
     Batch 175 | Loss : 0.5792 | Acc : 0.6095
     Batch 200 | Loss : 0.6150 | Acc : 0.5851
     Batch 225 | Loss : 0.6323 | Acc : 0.5721
     Batch 250 | Loss : 0.6457 | Acc : 0.5541
     Batch 275 | Loss : 0.6258 | Acc : 0.5818
     Batch 300 | Loss : 0.6531 | Acc : 0.5451
Epoch 00189 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5926 | Acc : 0.5932
     Batch 025 | Loss : 0.6443 | Acc : 0.5582
     Batch 050 | Loss : 0.5885 | Acc : 0.6167
     Batch 075 | Loss : 0.6423 | Acc : 0.5616
     Batch 100 | Loss : 0.6404 | Acc : 0.5574
     Batch 125 | Loss : 0.5931 | Acc : 0.6004
     Batch 150 | Loss : 0.6115 | Acc : 0.5897
     Batch 175 | Loss : 0.6221 | Acc : 0.5813
     Batch 200 | Loss : 0.6261 | Acc : 0.5836
     Batch 225 | Loss : 0.6392 | Acc : 0.5630
     Batch 250 | Loss : 0.6398 | Acc : 0.5577
     Batch 275 | Loss : 0.6314 | Acc : 0.5736
     Batch 300 | Loss : 0.6227 | Acc : 0.5845
Epoch 00190 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6536 | Acc : 0.5571
     Batch 025 | Loss : 0.5828 | Acc : 0.6024
     Batch 050 | Loss : 0.6536 | Acc : 0.5507
     Batch 075 | Loss : 0.6307 | Acc : 0.5656
     Batch 100 | Loss : 0.6298 | Acc : 0.5688
     Batch 125 | Loss : 0.5997 | Acc : 0.5885
     Batch 150 | Loss : 0.6366 | Acc : 0.5655
     Batch 175 | Loss : 0.5983 | Acc : 0.6013
     Batch 200 | Loss : 0.6531 | Acc : 0.5515
     Batch 225 | Loss : 0.5983 | Acc : 0.5919
     Batch 250 | Loss : 0.6279 | Acc : 0.5775
     Batch 275 | Loss : 0.5931 | Acc : 0.5999
     Batch 300 | Loss : 0.6499 | Acc : 0.5524
Epoch 00191 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5940 | Acc : 0.5926
     Batch 025 | Loss : 0.6468 | Acc : 0.5587
     Batch 050 | Loss : 0.5900 | Acc : 0.6035
     Batch 075 | Loss : 0.6260 | Acc : 0.5677
     Batch 100 | Loss : 0.6187 | Acc : 0.5841
     Batch 125 | Loss : 0.6299 | Acc : 0.5725
     Batch 150 | Loss : 0.6112 | Acc : 0.5842
     Batch 175 | Loss : 0.6248 | Acc : 0.5765
     Batch 200 | Loss : 0.5902 | Acc : 0.5978
     Batch 225 | Loss : 0.6194 | Acc : 0.5814
     Batch 250 | Loss : 0.6175 | Acc : 0.5827
     Batch 275 | Loss : 0.6488 | Acc : 0.5562
     Batch 300 | Loss : 0.6675 | Acc : 0.5363
Epoch 00192 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6406 | Acc : 0.5502
     Batch 025 | Loss : 0.6183 | Acc : 0.5826
     Batch 050 | Loss : 0.6558 | Acc : 0.5403
     Batch 075 | Loss : 0.5930 | Acc : 0.6004
     Batch 100 | Loss : 0.6401 | Acc : 0.5688
     Batch 125 | Loss : 0.6398 | Acc : 0.5658
     Batch 150 | Loss : 0.6305 | Acc : 0.5742
     Batch 175 | Loss : 0.6324 | Acc : 0.5721
     Batch 200 | Loss : 0.6174 | Acc : 0.5827
     Batch 225 | Loss : 0.5986 | Acc : 0.6021
     Batch 250 | Loss : 0.6362 | Acc : 0.5631
     Batch 275 | Loss : 0.6164 | Acc : 0.5763
     Batch 300 | Loss : 0.6307 | Acc : 0.5811
Epoch 00193 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6476 | Acc : 0.5515
     Batch 025 | Loss : 0.6395 | Acc : 0.5550
     Batch 050 | Loss : 0.6365 | Acc : 0.5710
     Batch 075 | Loss : 0.6318 | Acc : 0.5696
     Batch 100 | Loss : 0.6444 | Acc : 0.5582
     Batch 125 | Loss : 0.6530 | Acc : 0.5529
     Batch 150 | Loss : 0.6508 | Acc : 0.5535
     Batch 175 | Loss : 0.5940 | Acc : 0.6011
     Batch 200 | Loss : 0.5987 | Acc : 0.5894
     Batch 225 | Loss : 0.6394 | Acc : 0.5630
     Batch 250 | Loss : 0.6478 | Acc : 0.5566
     Batch 275 | Loss : 0.6566 | Acc : 0.5475
     Batch 300 | Loss : 0.6233 | Acc : 0.5886
Epoch 00194 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6364 | Acc : 0.5687
     Batch 025 | Loss : 0.6168 | Acc : 0.5730
     Batch 050 | Loss : 0.5928 | Acc : 0.5940
     Batch 075 | Loss : 0.6549 | Acc : 0.5421
     Batch 100 | Loss : 0.6347 | Acc : 0.5649
     Batch 125 | Loss : 0.5954 | Acc : 0.6074
     Batch 150 | Loss : 0.6542 | Acc : 0.5508
     Batch 175 | Loss : 0.6486 | Acc : 0.5504
     Batch 200 | Loss : 0.6488 | Acc : 0.5562
     Batch 225 | Loss : 0.6529 | Acc : 0.5451
     Batch 250 | Loss : 0.6560 | Acc : 0.5490
     Batch 275 | Loss : 0.6528 | Acc : 0.5649
     Batch 300 | Loss : 0.6513 | Acc : 0.5479
Epoch 00195 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6476 | Acc : 0.5594
     Batch 025 | Loss : 0.6325 | Acc : 0.5630
     Batch 050 | Loss : 0.5928 | Acc : 0.5940
     Batch 075 | Loss : 0.6257 | Acc : 0.5818
     Batch 100 | Loss : 0.6087 | Acc : 0.5920
     Batch 125 | Loss : 0.6113 | Acc : 0.5894
     Batch 150 | Loss : 0.6558 | Acc : 0.5503
     Batch 175 | Loss : 0.6002 | Acc : 0.5947
     Batch 200 | Loss : 0.5923 | Acc : 0.6005
     Batch 225 | Loss : 0.6146 | Acc : 0.5790
     Batch 250 | Loss : 0.6335 | Acc : 0.5630
     Batch 275 | Loss : 0.6398 | Acc : 0.5582
     Batch 300 | Loss : 0.6144 | Acc : 0.5969
Epoch 00196 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6402 | Acc : 0.5595
     Batch 025 | Loss : 0.6461 | Acc : 0.5570
     Batch 050 | Loss : 0.5987 | Acc : 0.5894
     Batch 075 | Loss : 0.5936 | Acc : 0.6010
     Batch 100 | Loss : 0.6176 | Acc : 0.5864
     Batch 125 | Loss : 0.5876 | Acc : 0.5970
     Batch 150 | Loss : 0.6402 | Acc : 0.5574
     Batch 175 | Loss : 0.6112 | Acc : 0.5842
     Batch 200 | Loss : 0.6677 | Acc : 0.5363
     Batch 225 | Loss : 0.6560 | Acc : 0.5487
     Batch 250 | Loss : 0.6513 | Acc : 0.5548
     Batch 275 | Loss : 0.6403 | Acc : 0.5643
     Batch 300 | Loss : 0.6364 | Acc : 0.5710
Epoch 00197 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6325 | Acc : 0.5659
     Batch 025 | Loss : 0.6194 | Acc : 0.5814
     Batch 050 | Loss : 0.6542 | Acc : 0.5508
     Batch 075 | Loss : 0.6128 | Acc : 0.5776
     Batch 100 | Loss : 0.6501 | Acc : 0.5524
     Batch 125 | Loss : 0.6409 | Acc : 0.5645
     Batch 150 | Loss : 0.6106 | Acc : 0.5895
     Batch 175 | Loss : 0.6176 | Acc : 0.5864
     Batch 200 | Loss : 0.6314 | Acc : 0.5736
     Batch 225 | Loss : 0.6274 | Acc : 0.5725
     Batch 250 | Loss : 0.6562 | Acc : 0.5490
     Batch 275 | Loss : 0.6231 | Acc : 0.5826
     Batch 300 | Loss : 0.6175 | Acc : 0.5816
Epoch 00198 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6502 | Acc : 0.5469
     Batch 025 | Loss : 0.6411 | Acc : 0.5585
     Batch 050 | Loss : 0.6515 | Acc : 0.5610
     Batch 075 | Loss : 0.6306 | Acc : 0.5723
     Batch 100 | Loss : 0.6145 | Acc : 0.5790
     Batch 125 | Loss : 0.6257 | Acc : 0.5678
     Batch 150 | Loss : 0.6513 | Acc : 0.5479
     Batch 175 | Loss : 0.6247 | Acc : 0.5722
     Batch 200 | Loss : 0.6232 | Acc : 0.5826
     Batch 225 | Loss : 0.6336 | Acc : 0.5630
     Batch 250 | Loss : 0.6367 | Acc : 0.5655
     Batch 275 | Loss : 0.6315 | Acc : 0.5650
     Batch 300 | Loss : 0.5741 | Acc : 0.6252
Epoch 00199 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6364 | Acc : 0.5687
     Batch 025 | Loss : 0.6574 | Acc : 0.5477
     Batch 050 | Loss : 0.5983 | Acc : 0.5919
     Batch 075 | Loss : 0.5867 | Acc : 0.6049
     Batch 100 | Loss : 0.6296 | Acc : 0.5809
     Batch 125 | Loss : 0.6392 | Acc : 0.5630
     Batch 150 | Loss : 0.6302 | Acc : 0.5753
     Batch 175 | Loss : 0.5854 | Acc : 0.6000
     Batch 200 | Loss : 0.6105 | Acc : 0.5942
     Batch 225 | Loss : 0.6353 | Acc : 0.5680
     Batch 250 | Loss : 0.5906 | Acc : 0.5974
     Batch 275 | Loss : 0.6176 | Acc : 0.5864
     Batch 300 | Loss : 0.5997 | Acc : 0.5997
Epoch 00200 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6116 | Acc : 0.5897
     Batch 025 | Loss : 0.6135 | Acc : 0.5871
     Batch 050 | Loss : 0.5957 | Acc : 0.6074
     Batch 075 | Loss : 0.6418 | Acc : 0.5582
     Batch 100 | Loss : 0.5996 | Acc : 0.5885
     Batch 125 | Loss : 0.6163 | Acc : 0.5763
     Batch 150 | Loss : 0.6364 | Acc : 0.5687
     Batch 175 | Loss : 0.6147 | Acc : 0.5832
     Batch 200 | Loss : 0.6326 | Acc : 0.5650
     Batch 225 | Loss : 0.6287 | Acc : 0.5826
     Batch 250 | Loss : 0.6406 | Acc : 0.5584
     Batch 275 | Loss : 0.6398 | Acc : 0.5658
     Batch 300 | Loss : 0.5923 | Acc : 0.6005
Epoch 00201 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6371 | Acc : 0.5566
     Batch 025 | Loss : 0.6564 | Acc : 0.5453
     Batch 050 | Loss : 0.5735 | Acc : 0.6252
     Batch 075 | Loss : 0.6173 | Acc : 0.5778
     Batch 100 | Loss : 0.6278 | Acc : 0.5775
     Batch 125 | Loss : 0.6420 | Acc : 0.5655
     Batch 150 | Loss : 0.5784 | Acc : 0.6138
     Batch 175 | Loss : 0.6303 | Acc : 0.5698
     Batch 200 | Loss : 0.6198 | Acc : 0.5780
     Batch 225 | Loss : 0.6415 | Acc : 0.5589
     Batch 250 | Loss : 0.6395 | Acc : 0.5550
     Batch 275 | Loss : 0.6403 | Acc : 0.5574
     Batch 300 | Loss : 0.5983 | Acc : 0.5919
Epoch 00202 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5917 | Acc : 0.6024
     Batch 025 | Loss : 0.5800 | Acc : 0.6186
     Batch 050 | Loss : 0.6554 | Acc : 0.5434
     Batch 075 | Loss : 0.6112 | Acc : 0.5842
     Batch 100 | Loss : 0.5908 | Acc : 0.6043
     Batch 125 | Loss : 0.6404 | Acc : 0.5662
     Batch 150 | Loss : 0.6526 | Acc : 0.5541
     Batch 175 | Loss : 0.5827 | Acc : 0.6098
     Batch 200 | Loss : 0.5866 | Acc : 0.6041
     Batch 225 | Loss : 0.6350 | Acc : 0.5612
     Batch 250 | Loss : 0.6520 | Acc : 0.5539
     Batch 275 | Loss : 0.6365 | Acc : 0.5631
     Batch 300 | Loss : 0.6305 | Acc : 0.5742
Epoch 00203 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6479 | Acc : 0.5608
     Batch 025 | Loss : 0.5841 | Acc : 0.6137
     Batch 050 | Loss : 0.5775 | Acc : 0.6179
     Batch 075 | Loss : 0.6262 | Acc : 0.5836
     Batch 100 | Loss : 0.6106 | Acc : 0.5942
     Batch 125 | Loss : 0.6350 | Acc : 0.5571
     Batch 150 | Loss : 0.5952 | Acc : 0.6074
     Batch 175 | Loss : 0.6257 | Acc : 0.5818
     Batch 200 | Loss : 0.6415 | Acc : 0.5589
     Batch 225 | Loss : 0.6198 | Acc : 0.5780
     Batch 250 | Loss : 0.5899 | Acc : 0.6035
     Batch 275 | Loss : 0.5931 | Acc : 0.6004
     Batch 300 | Loss : 0.5867 | Acc : 0.6049
Epoch 00204 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6565 | Acc : 0.5475
     Batch 025 | Loss : 0.6502 | Acc : 0.5585
     Batch 050 | Loss : 0.5861 | Acc : 0.6218
     Batch 075 | Loss : 0.6515 | Acc : 0.5610
     Batch 100 | Loss : 0.5862 | Acc : 0.6208
     Batch 125 | Loss : 0.6576 | Acc : 0.5438
     Batch 150 | Loss : 0.6580 | Acc : 0.5478
     Batch 175 | Loss : 0.5961 | Acc : 0.5987
     Batch 200 | Loss : 0.6174 | Acc : 0.5870
     Batch 225 | Loss : 0.6402 | Acc : 0.5541
     Batch 250 | Loss : 0.6557 | Acc : 0.5503
     Batch 275 | Loss : 0.5940 | Acc : 0.5961
     Batch 300 | Loss : 0.6362 | Acc : 0.5631
Epoch 00205 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6565 | Acc : 0.5453
     Batch 025 | Loss : 0.5997 | Acc : 0.5885
     Batch 050 | Loss : 0.6524 | Acc : 0.5476
     Batch 075 | Loss : 0.6401 | Acc : 0.5595
     Batch 100 | Loss : 0.6331 | Acc : 0.5724
     Batch 125 | Loss : 0.6302 | Acc : 0.5753
     Batch 150 | Loss : 0.6121 | Acc : 0.5819
     Batch 175 | Loss : 0.6299 | Acc : 0.5725
     Batch 200 | Loss : 0.6337 | Acc : 0.5630
     Batch 225 | Loss : 0.6135 | Acc : 0.5871
     Batch 250 | Loss : 0.6112 | Acc : 0.5842
     Batch 275 | Loss : 0.6473 | Acc : 0.5626
     Batch 300 | Loss : 0.6306 | Acc : 0.5723
Epoch 00206 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6159 | Acc : 0.5818
     Batch 025 | Loss : 0.6405 | Acc : 0.5613
     Batch 050 | Loss : 0.6479 | Acc : 0.5608
     Batch 075 | Loss : 0.6420 | Acc : 0.5635
     Batch 100 | Loss : 0.6112 | Acc : 0.5954
     Batch 125 | Loss : 0.5785 | Acc : 0.6138
     Batch 150 | Loss : 0.5811 | Acc : 0.6159
     Batch 175 | Loss : 0.6265 | Acc : 0.5757
     Batch 200 | Loss : 0.6261 | Acc : 0.5836
     Batch 225 | Loss : 0.6476 | Acc : 0.5515
     Batch 250 | Loss : 0.6456 | Acc : 0.5539
     Batch 275 | Loss : 0.6404 | Acc : 0.5643
     Batch 300 | Loss : 0.6170 | Acc : 0.5931
Epoch 00207 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6397 | Acc : 0.5550
     Batch 025 | Loss : 0.5839 | Acc : 0.6137
     Batch 050 | Loss : 0.6363 | Acc : 0.5710
     Batch 075 | Loss : 0.6080 | Acc : 0.5903
     Batch 100 | Loss : 0.6479 | Acc : 0.5608
     Batch 125 | Loss : 0.6114 | Acc : 0.5897
     Batch 150 | Loss : 0.5873 | Acc : 0.6034
     Batch 175 | Loss : 0.6580 | Acc : 0.5478
     Batch 200 | Loss : 0.5852 | Acc : 0.6208
     Batch 225 | Loss : 0.5778 | Acc : 0.6179
     Batch 250 | Loss : 0.6397 | Acc : 0.5577
     Batch 275 | Loss : 0.6159 | Acc : 0.5818
     Batch 300 | Loss : 0.6145 | Acc : 0.5790
Epoch 00208 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6545 | Acc : 0.5571
     Batch 025 | Loss : 0.6473 | Acc : 0.5591
     Batch 050 | Loss : 0.6392 | Acc : 0.5630
     Batch 075 | Loss : 0.6139 | Acc : 0.5969
     Batch 100 | Loss : 0.6332 | Acc : 0.5724
     Batch 125 | Loss : 0.6457 | Acc : 0.5541
     Batch 150 | Loss : 0.6397 | Acc : 0.5577
     Batch 175 | Loss : 0.6537 | Acc : 0.5507
     Batch 200 | Loss : 0.6181 | Acc : 0.5772
     Batch 225 | Loss : 0.6300 | Acc : 0.5707
     Batch 250 | Loss : 0.6287 | Acc : 0.5826
     Batch 275 | Loss : 0.6401 | Acc : 0.5595
     Batch 300 | Loss : 0.5866 | Acc : 0.6041
Epoch 00209 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5928 | Acc : 0.5976
     Batch 025 | Loss : 0.6306 | Acc : 0.5723
     Batch 050 | Loss : 0.5907 | Acc : 0.6043
     Batch 075 | Loss : 0.6455 | Acc : 0.5618
     Batch 100 | Loss : 0.6365 | Acc : 0.5710
     Batch 125 | Loss : 0.6533 | Acc : 0.5535
     Batch 150 | Loss : 0.6404 | Acc : 0.5574
     Batch 175 | Loss : 0.6394 | Acc : 0.5550
     Batch 200 | Loss : 0.6433 | Acc : 0.5568
     Batch 225 | Loss : 0.6579 | Acc : 0.5462
     Batch 250 | Loss : 0.6479 | Acc : 0.5566
     Batch 275 | Loss : 0.5739 | Acc : 0.6252
     Batch 300 | Loss : 0.6561 | Acc : 0.5487
Epoch 00210 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6366 | Acc : 0.5655
     Batch 025 | Loss : 0.6380 | Acc : 0.5660
     Batch 050 | Loss : 0.6455 | Acc : 0.5618
     Batch 075 | Loss : 0.5853 | Acc : 0.5964
     Batch 100 | Loss : 0.6298 | Acc : 0.5688
     Batch 125 | Loss : 0.6503 | Acc : 0.5469
     Batch 150 | Loss : 0.6561 | Acc : 0.5490
     Batch 175 | Loss : 0.6247 | Acc : 0.5722
     Batch 200 | Loss : 0.6255 | Acc : 0.5856
     Batch 225 | Loss : 0.6513 | Acc : 0.5479
     Batch 250 | Loss : 0.6538 | Acc : 0.5767
     Batch 275 | Loss : 0.6475 | Acc : 0.5515
     Batch 300 | Loss : 0.6506 | Acc : 0.5563
Epoch 00211 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5873 | Acc : 0.6034
     Batch 025 | Loss : 0.6457 | Acc : 0.5539
     Batch 050 | Loss : 0.5963 | Acc : 0.5996
     Batch 075 | Loss : 0.6398 | Acc : 0.5658
     Batch 100 | Loss : 0.6690 | Acc : 0.5296
     Batch 125 | Loss : 0.6403 | Acc : 0.5662
     Batch 150 | Loss : 0.6150 | Acc : 0.5851
     Batch 175 | Loss : 0.6380 | Acc : 0.5660
     Batch 200 | Loss : 0.5835 | Acc : 0.6109
     Batch 225 | Loss : 0.6261 | Acc : 0.5836
     Batch 250 | Loss : 0.6460 | Acc : 0.5570
     Batch 275 | Loss : 0.6422 | Acc : 0.5565
     Batch 300 | Loss : 0.5854 | Acc : 0.6044
Epoch 00212 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6587 | Acc : 0.5456
     Batch 025 | Loss : 0.5876 | Acc : 0.6011
     Batch 050 | Loss : 0.5941 | Acc : 0.6011
     Batch 075 | Loss : 0.6503 | Acc : 0.5748
     Batch 100 | Loss : 0.6256 | Acc : 0.5818
     Batch 125 | Loss : 0.6264 | Acc : 0.5729
     Batch 150 | Loss : 0.5807 | Acc : 0.6159
     Batch 175 | Loss : 0.5918 | Acc : 0.6024
     Batch 200 | Loss : 0.6335 | Acc : 0.5652
     Batch 225 | Loss : 0.6287 | Acc : 0.5826
     Batch 250 | Loss : 0.6530 | Acc : 0.5529
     Batch 275 | Loss : 0.6419 | Acc : 0.5565
     Batch 300 | Loss : 0.6305 | Acc : 0.5742
Epoch 00213 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6526 | Acc : 0.5545
     Batch 025 | Loss : 0.6121 | Acc : 0.5819
     Batch 050 | Loss : 0.5899 | Acc : 0.6035
     Batch 075 | Loss : 0.5999 | Acc : 0.5997
     Batch 100 | Loss : 0.6288 | Acc : 0.5767
     Batch 125 | Loss : 0.6145 | Acc : 0.5790
     Batch 150 | Loss : 0.6549 | Acc : 0.5421
     Batch 175 | Loss : 0.5792 | Acc : 0.6095
     Batch 200 | Loss : 0.6589 | Acc : 0.5456
     Batch 225 | Loss : 0.6467 | Acc : 0.5587
     Batch 250 | Loss : 0.6462 | Acc : 0.5514
     Batch 275 | Loss : 0.6560 | Acc : 0.5487
     Batch 300 | Loss : 0.5823 | Acc : 0.6023
Epoch 00214 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5977 | Acc : 0.6061
     Batch 025 | Loss : 0.5877 | Acc : 0.6064
     Batch 050 | Loss : 0.6559 | Acc : 0.5432
     Batch 075 | Loss : 0.5819 | Acc : 0.6111
     Batch 100 | Loss : 0.6235 | Acc : 0.5886
     Batch 125 | Loss : 0.6479 | Acc : 0.5608
     Batch 150 | Loss : 0.6588 | Acc : 0.5456
     Batch 175 | Loss : 0.6515 | Acc : 0.5479
     Batch 200 | Loss : 0.5985 | Acc : 0.6013
     Batch 225 | Loss : 0.5933 | Acc : 0.6071
     Batch 250 | Loss : 0.6132 | Acc : 0.5837
     Batch 275 | Loss : 0.6266 | Acc : 0.5718
     Batch 300 | Loss : 0.5773 | Acc : 0.6179
Epoch 00215 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6364 | Acc : 0.5631
     Batch 025 | Loss : 0.6079 | Acc : 0.5903
     Batch 050 | Loss : 0.6488 | Acc : 0.5570
     Batch 075 | Loss : 0.6403 | Acc : 0.5658
     Batch 100 | Loss : 0.6363 | Acc : 0.5723
     Batch 125 | Loss : 0.6513 | Acc : 0.5479
     Batch 150 | Loss : 0.5854 | Acc : 0.6044
     Batch 175 | Loss : 0.6007 | Acc : 0.5960
     Batch 200 | Loss : 0.6478 | Acc : 0.5566
     Batch 225 | Loss : 0.6323 | Acc : 0.5721
     Batch 250 | Loss : 0.6254 | Acc : 0.5856
     Batch 275 | Loss : 0.6159 | Acc : 0.5818
     Batch 300 | Loss : 0.6354 | Acc : 0.5680
Epoch 00216 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6368 | Acc : 0.5647
     Batch 025 | Loss : 0.5931 | Acc : 0.5999
     Batch 050 | Loss : 0.6345 | Acc : 0.5649
     Batch 075 | Loss : 0.5959 | Acc : 0.5953
     Batch 100 | Loss : 0.6279 | Acc : 0.5775
     Batch 125 | Loss : 0.6152 | Acc : 0.5851
     Batch 150 | Loss : 0.6289 | Acc : 0.5767
     Batch 175 | Loss : 0.6491 | Acc : 0.5627
     Batch 200 | Loss : 0.6331 | Acc : 0.5724
     Batch 225 | Loss : 0.6501 | Acc : 0.5516
     Batch 250 | Loss : 0.6409 | Acc : 0.5585
     Batch 275 | Loss : 0.6335 | Acc : 0.5652
     Batch 300 | Loss : 0.5953 | Acc : 0.6074
Epoch 00217 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5928 | Acc : 0.5940
     Batch 025 | Loss : 0.5795 | Acc : 0.6186
     Batch 050 | Loss : 0.5976 | Acc : 0.6061
     Batch 075 | Loss : 0.6315 | Acc : 0.5650
     Batch 100 | Loss : 0.6105 | Acc : 0.5895
     Batch 125 | Loss : 0.5983 | Acc : 0.5919
     Batch 150 | Loss : 0.6434 | Acc : 0.5568
     Batch 175 | Loss : 0.6364 | Acc : 0.5687
     Batch 200 | Loss : 0.5942 | Acc : 0.5986
     Batch 225 | Loss : 0.6688 | Acc : 0.5296
     Batch 250 | Loss : 0.6558 | Acc : 0.5503
     Batch 275 | Loss : 0.6424 | Acc : 0.5590
     Batch 300 | Loss : 0.6327 | Acc : 0.5798
Epoch 00218 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6531 | Acc : 0.5515
     Batch 025 | Loss : 0.5972 | Acc : 0.5930
     Batch 050 | Loss : 0.5854 | Acc : 0.6044
     Batch 075 | Loss : 0.6176 | Acc : 0.5864
     Batch 100 | Loss : 0.6336 | Acc : 0.5630
     Batch 125 | Loss : 0.6231 | Acc : 0.5826
     Batch 150 | Loss : 0.5987 | Acc : 0.6021
     Batch 175 | Loss : 0.5914 | Acc : 0.5951
     Batch 200 | Loss : 0.6409 | Acc : 0.5585
     Batch 225 | Loss : 0.6459 | Acc : 0.5510
     Batch 250 | Loss : 0.5876 | Acc : 0.6011
     Batch 275 | Loss : 0.6396 | Acc : 0.5599
     Batch 300 | Loss : 0.6271 | Acc : 0.5685
Epoch 00219 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6405 | Acc : 0.5613
     Batch 025 | Loss : 0.6135 | Acc : 0.5871
     Batch 050 | Loss : 0.5783 | Acc : 0.6138
     Batch 075 | Loss : 0.6323 | Acc : 0.5641
     Batch 100 | Loss : 0.5847 | Acc : 0.6120
     Batch 125 | Loss : 0.5928 | Acc : 0.5940
     Batch 150 | Loss : 0.6327 | Acc : 0.5659
     Batch 175 | Loss : 0.6527 | Acc : 0.5541
     Batch 200 | Loss : 0.6266 | Acc : 0.5757
     Batch 225 | Loss : 0.6524 | Acc : 0.5476
     Batch 250 | Loss : 0.6520 | Acc : 0.5539
     Batch 275 | Loss : 0.6347 | Acc : 0.5586
     Batch 300 | Loss : 0.6424 | Acc : 0.5616
Epoch 00220 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5793 | Acc : 0.6008
     Batch 025 | Loss : 0.6262 | Acc : 0.5737
     Batch 050 | Loss : 0.6391 | Acc : 0.5550
     Batch 075 | Loss : 0.5940 | Acc : 0.6011
     Batch 100 | Loss : 0.5820 | Acc : 0.6111
     Batch 125 | Loss : 0.6278 | Acc : 0.5775
     Batch 150 | Loss : 0.5846 | Acc : 0.6028
     Batch 175 | Loss : 0.6136 | Acc : 0.5871
     Batch 200 | Loss : 0.6262 | Acc : 0.5749
     Batch 225 | Loss : 0.6366 | Acc : 0.5655
     Batch 250 | Loss : 0.6172 | Acc : 0.5931
     Batch 275 | Loss : 0.6234 | Acc : 0.5886
     Batch 300 | Loss : 0.6154 | Acc : 0.5874
Epoch 00221 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6458 | Acc : 0.5539
     Batch 025 | Loss : 0.6185 | Acc : 0.5869
     Batch 050 | Loss : 0.6226 | Acc : 0.5845
     Batch 075 | Loss : 0.6222 | Acc : 0.5813
     Batch 100 | Loss : 0.6198 | Acc : 0.5780
     Batch 125 | Loss : 0.6247 | Acc : 0.5722
     Batch 150 | Loss : 0.6331 | Acc : 0.5724
     Batch 175 | Loss : 0.6398 | Acc : 0.5541
     Batch 200 | Loss : 0.6270 | Acc : 0.5827
     Batch 225 | Loss : 0.6175 | Acc : 0.5816
     Batch 250 | Loss : 0.5823 | Acc : 0.6023
     Batch 275 | Loss : 0.6347 | Acc : 0.5755
     Batch 300 | Loss : 0.6324 | Acc : 0.5630
Epoch 00222 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6326 | Acc : 0.5659
     Batch 025 | Loss : 0.6244 | Acc : 0.5755
     Batch 050 | Loss : 0.6587 | Acc : 0.5456
     Batch 075 | Loss : 0.6247 | Acc : 0.5722
     Batch 100 | Loss : 0.6335 | Acc : 0.5652
     Batch 125 | Loss : 0.6424 | Acc : 0.5616
     Batch 150 | Loss : 0.6513 | Acc : 0.5548
     Batch 175 | Loss : 0.6403 | Acc : 0.5574
     Batch 200 | Loss : 0.6488 | Acc : 0.5570
     Batch 225 | Loss : 0.6377 | Acc : 0.5599
     Batch 250 | Loss : 0.6173 | Acc : 0.5778
     Batch 275 | Loss : 0.5914 | Acc : 0.5951
     Batch 300 | Loss : 0.6303 | Acc : 0.5698
Epoch 00223 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6423 | Acc : 0.5616
     Batch 025 | Loss : 0.5785 | Acc : 0.6138
     Batch 050 | Loss : 0.6109 | Acc : 0.5904
     Batch 075 | Loss : 0.5786 | Acc : 0.6170
     Batch 100 | Loss : 0.5972 | Acc : 0.5943
     Batch 125 | Loss : 0.6376 | Acc : 0.5745
     Batch 150 | Loss : 0.6325 | Acc : 0.5630
     Batch 175 | Loss : 0.6281 | Acc : 0.5692
     Batch 200 | Loss : 0.6278 | Acc : 0.5775
     Batch 225 | Loss : 0.6323 | Acc : 0.5650
     Batch 250 | Loss : 0.6567 | Acc : 0.5441
     Batch 275 | Loss : 0.6244 | Acc : 0.5755
     Batch 300 | Loss : 0.5739 | Acc : 0.6252
Epoch 00224 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5993 | Acc : 0.5940
     Batch 025 | Loss : 0.6540 | Acc : 0.5487
     Batch 050 | Loss : 0.5964 | Acc : 0.5945
     Batch 075 | Loss : 0.6325 | Acc : 0.5721
     Batch 100 | Loss : 0.6531 | Acc : 0.5515
     Batch 125 | Loss : 0.6527 | Acc : 0.5541
     Batch 150 | Loss : 0.6174 | Acc : 0.5778
     Batch 175 | Loss : 0.5859 | Acc : 0.6218
     Batch 200 | Loss : 0.5821 | Acc : 0.6111
     Batch 225 | Loss : 0.6332 | Acc : 0.5724
     Batch 250 | Loss : 0.6136 | Acc : 0.5812
     Batch 275 | Loss : 0.6502 | Acc : 0.5469
     Batch 300 | Loss : 0.5856 | Acc : 0.6208
Epoch 00225 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6248 | Acc : 0.5722
     Batch 025 | Loss : 0.5876 | Acc : 0.6064
     Batch 050 | Loss : 0.6269 | Acc : 0.5722
     Batch 075 | Loss : 0.6306 | Acc : 0.5811
     Batch 100 | Loss : 0.6114 | Acc : 0.5897
     Batch 125 | Loss : 0.5978 | Acc : 0.6061
     Batch 150 | Loss : 0.6173 | Acc : 0.5778
     Batch 175 | Loss : 0.6514 | Acc : 0.5529
     Batch 200 | Loss : 0.6192 | Acc : 0.5795
     Batch 225 | Loss : 0.6403 | Acc : 0.5658
     Batch 250 | Loss : 0.6363 | Acc : 0.5723
     Batch 275 | Loss : 0.5926 | Acc : 0.5932
     Batch 300 | Loss : 0.6510 | Acc : 0.5535
Epoch 00226 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6112 | Acc : 0.5842
     Batch 025 | Loss : 0.6520 | Acc : 0.5539
     Batch 050 | Loss : 0.6406 | Acc : 0.5613
     Batch 075 | Loss : 0.5774 | Acc : 0.6179
     Batch 100 | Loss : 0.6495 | Acc : 0.5498
     Batch 125 | Loss : 0.6376 | Acc : 0.5745
     Batch 150 | Loss : 0.5999 | Acc : 0.5997
     Batch 175 | Loss : 0.6398 | Acc : 0.5658
     Batch 200 | Loss : 0.6331 | Acc : 0.5724
     Batch 225 | Loss : 0.6173 | Acc : 0.5778
     Batch 250 | Loss : 0.6513 | Acc : 0.5479
     Batch 275 | Loss : 0.6557 | Acc : 0.5503
     Batch 300 | Loss : 0.6173 | Acc : 0.5870
Epoch 00227 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5782 | Acc : 0.6170
     Batch 025 | Loss : 0.5828 | Acc : 0.6024
     Batch 050 | Loss : 0.6393 | Acc : 0.5619
     Batch 075 | Loss : 0.6536 | Acc : 0.5571
     Batch 100 | Loss : 0.6528 | Acc : 0.5649
     Batch 125 | Loss : 0.6500 | Acc : 0.5516
     Batch 150 | Loss : 0.5918 | Acc : 0.5989
     Batch 175 | Loss : 0.5922 | Acc : 0.6005
     Batch 200 | Loss : 0.6254 | Acc : 0.5778
     Batch 225 | Loss : 0.5918 | Acc : 0.6024
     Batch 250 | Loss : 0.6540 | Acc : 0.5767
     Batch 275 | Loss : 0.6509 | Acc : 0.5580
     Batch 300 | Loss : 0.6115 | Acc : 0.5897
Epoch 00228 | Train Loss : 0.6250 | Eval Loss : 0.6244 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6193 | Acc : 0.5795
     Batch 025 | Loss : 0.6488 | Acc : 0.5570
     Batch 050 | Loss : 0.6402 | Acc : 0.5658
     Batch 075 | Loss : 0.6587 | Acc : 0.5456
     Batch 100 | Loss : 0.6499 | Acc : 0.5594
     Batch 125 | Loss : 0.6271 | Acc : 0.5792
     Batch 150 | Loss : 0.6173 | Acc : 0.5778
     Batch 175 | Loss : 0.6351 | Acc : 0.5612
     Batch 200 | Loss : 0.6401 | Acc : 0.5688
     Batch 225 | Loss : 0.5954 | Acc : 0.6074
     Batch 250 | Loss : 0.6334 | Acc : 0.5725
     Batch 275 | Loss : 0.6398 | Acc : 0.5658
     Batch 300 | Loss : 0.6132 | Acc : 0.5837
Epoch 00229 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.6576 | Acc : 0.5477
     Batch 025 | Loss : 0.6401 | Acc : 0.5688
     Batch 050 | Loss : 0.6580 | Acc : 0.5478
     Batch 075 | Loss : 0.6534 | Acc : 0.5502
     Batch 100 | Loss : 0.6319 | Acc : 0.5696
     Batch 125 | Loss : 0.6402 | Acc : 0.5595
     Batch 150 | Loss : 0.5931 | Acc : 0.5999
     Batch 175 | Loss : 0.6230 | Acc : 0.5742
     Batch 200 | Loss : 0.6217 | Acc : 0.5818
     Batch 225 | Loss : 0.6396 | Acc : 0.5599
     Batch 250 | Loss : 0.6262 | Acc : 0.5749
     Batch 275 | Loss : 0.6220 | Acc : 0.5730
     Batch 300 | Loss : 0.5986 | Acc : 0.6021
Epoch 00230 | Train Loss : 0.6250 | Eval Loss : 0.6243 | Train acc : 0.5750 | Eval Acc : 0.5757
     Batch 000 | Loss : 0.5828 | Acc : 0.6024
     Batch 025 | Loss : 0.6145 | Acc : 0.5969
     Batch 050 | Loss : 0.5854 | Acc : 0.5964
     Batch 075 | Loss : 0.5835 | Acc : 0.6109
     Batch 100 | Loss : 0.6503 | Acc : 0.5532
     Batch 125 | Loss : 0.6319 | Acc : 0.5696
     Batch 150 | Loss : 0.6135 | Acc : 0.5871
     Batch 175 | Loss : 0.6575 | Acc : 0.5477
     Batch 200 | Loss : 0.6153 | Acc : 0.5874
     Batch 225 | Loss : 0.6488 | Acc : 0.5570
     Batch 250 | Loss : 0.6303 | Acc : 0.5698
