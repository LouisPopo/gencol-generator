Done loading data from cached files.
Training ...
     Batch 000 | Loss : 0.6949 | Acc : 0.5123
     Batch 025 | Loss : 0.6566 | Acc : 0.6950
     Batch 050 | Loss : 0.5401 | Acc : 0.7295
     Batch 075 | Loss : 0.5181 | Acc : 0.7414
     Batch 100 | Loss : 0.4166 | Acc : 0.8138
     Batch 125 | Loss : 0.3711 | Acc : 0.8420
     Batch 150 | Loss : 0.4279 | Acc : 0.7953
     Batch 175 | Loss : 0.4052 | Acc : 0.8145
     Batch 200 | Loss : 0.4266 | Acc : 0.7958
     Batch 225 | Loss : 0.4084 | Acc : 0.8151
     Batch 250 | Loss : 0.4224 | Acc : 0.8028
     Batch 275 | Loss : 0.4384 | Acc : 0.7836
     Batch 300 | Loss : 0.4100 | Acc : 0.8054
Epoch 00000 | Train Loss : 0.4590 | Eval Loss : 0.3755 | Train acc : 0.7726 | Eval Acc : 0.8244 | Eval Log. Respected : 0.9464
     Batch 000 | Loss : 0.3875 | Acc : 0.8195
     Batch 025 | Loss : 0.4016 | Acc : 0.8123
     Batch 050 | Loss : 0.3820 | Acc : 0.8269
     Batch 075 | Loss : 0.3747 | Acc : 0.8271
     Batch 100 | Loss : 0.4041 | Acc : 0.8002
     Batch 125 | Loss : 0.4505 | Acc : 0.7892
     Batch 150 | Loss : 0.3688 | Acc : 0.8270
     Batch 175 | Loss : 0.3335 | Acc : 0.8497
     Batch 200 | Loss : 0.3301 | Acc : 0.8503
     Batch 225 | Loss : 0.3547 | Acc : 0.8374
     Batch 250 | Loss : 0.3172 | Acc : 0.8582
     Batch 275 | Loss : 0.4362 | Acc : 0.8070
     Batch 300 | Loss : 0.3533 | Acc : 0.8333
Epoch 00001 | Train Loss : 0.3770 | Eval Loss : 0.3752 | Train acc : 0.8263 | Eval Acc : 0.8257 | Eval Log. Respected : 0.9403
     Batch 000 | Loss : 0.3111 | Acc : 0.8670
     Batch 025 | Loss : 0.4038 | Acc : 0.8057
     Batch 050 | Loss : 0.2930 | Acc : 0.8690
     Batch 075 | Loss : 0.3626 | Acc : 0.8343
     Batch 100 | Loss : 0.3845 | Acc : 0.8175
     Batch 125 | Loss : 0.3139 | Acc : 0.8537
     Batch 150 | Loss : 0.3761 | Acc : 0.8160
     Batch 175 | Loss : 0.3446 | Acc : 0.8367
     Batch 200 | Loss : 0.3875 | Acc : 0.8190
     Batch 225 | Loss : 0.4264 | Acc : 0.7859
     Batch 250 | Loss : 0.3359 | Acc : 0.8510
     Batch 275 | Loss : 0.2905 | Acc : 0.8702
     Batch 300 | Loss : 0.3622 | Acc : 0.8243
Epoch 00002 | Train Loss : 0.3662 | Eval Loss : 0.3564 | Train acc : 0.8307 | Eval Acc : 0.8312 | Eval Log. Respected : 0.9295
     Batch 000 | Loss : 0.3403 | Acc : 0.8436
     Batch 025 | Loss : 0.3242 | Acc : 0.8533
     Batch 050 | Loss : 0.4035 | Acc : 0.8202
     Batch 075 | Loss : 0.4275 | Acc : 0.7898
     Batch 100 | Loss : 0.3395 | Acc : 0.8448
     Batch 125 | Loss : 0.3724 | Acc : 0.8298
     Batch 150 | Loss : 0.3653 | Acc : 0.8246
     Batch 175 | Loss : 0.4057 | Acc : 0.8108
     Batch 200 | Loss : 0.3420 | Acc : 0.8456
     Batch 225 | Loss : 0.3755 | Acc : 0.8192
     Batch 250 | Loss : 0.4781 | Acc : 0.7938
     Batch 275 | Loss : 0.3514 | Acc : 0.8296
     Batch 300 | Loss : 0.3708 | Acc : 0.8206
Epoch 00003 | Train Loss : 0.3576 | Eval Loss : 0.3452 | Train acc : 0.8350 | Eval Acc : 0.8382 | Eval Log. Respected : 0.9525
     Batch 000 | Loss : 0.3113 | Acc : 0.8613
     Batch 025 | Loss : 0.3174 | Acc : 0.8517
     Batch 050 | Loss : 0.3303 | Acc : 0.8532
     Batch 075 | Loss : 0.4133 | Acc : 0.8064
     Batch 100 | Loss : 0.3079 | Acc : 0.8654
     Batch 125 | Loss : 0.3466 | Acc : 0.8411
     Batch 150 | Loss : 0.3931 | Acc : 0.8082
     Batch 175 | Loss : 0.3447 | Acc : 0.8435
     Batch 200 | Loss : 0.3824 | Acc : 0.8230
     Batch 225 | Loss : 0.3564 | Acc : 0.8296
     Batch 250 | Loss : 0.3125 | Acc : 0.8586
     Batch 275 | Loss : 0.4481 | Acc : 0.7897
     Batch 300 | Loss : 0.3350 | Acc : 0.8511
Epoch 00004 | Train Loss : 0.3504 | Eval Loss : 0.3438 | Train acc : 0.8385 | Eval Acc : 0.8389 | Eval Log. Respected : 0.9320
     Batch 000 | Loss : 0.4474 | Acc : 0.7817
     Batch 025 | Loss : 0.2881 | Acc : 0.8729
     Batch 050 | Loss : 0.3577 | Acc : 0.8358
     Batch 075 | Loss : 0.3087 | Acc : 0.8610
     Batch 100 | Loss : 0.3323 | Acc : 0.8452
     Batch 125 | Loss : 0.3496 | Acc : 0.8394
     Batch 150 | Loss : 0.2864 | Acc : 0.8762
     Batch 175 | Loss : 0.4002 | Acc : 0.8132
     Batch 200 | Loss : 0.4425 | Acc : 0.7889
     Batch 225 | Loss : 0.2973 | Acc : 0.8675
     Batch 250 | Loss : 0.3386 | Acc : 0.8396
     Batch 275 | Loss : 0.3095 | Acc : 0.8645
     Batch 300 | Loss : 0.2977 | Acc : 0.8672
Epoch 00005 | Train Loss : 0.3467 | Eval Loss : 0.3471 | Train acc : 0.8405 | Eval Acc : 0.8356 | Eval Log. Respected : 0.9567
     Batch 000 | Loss : 0.2990 | Acc : 0.8641
     Batch 025 | Loss : 0.3486 | Acc : 0.8364
     Batch 050 | Loss : 0.3474 | Acc : 0.8401
     Batch 075 | Loss : 0.3528 | Acc : 0.8369
     Batch 100 | Loss : 0.2893 | Acc : 0.8700
     Batch 125 | Loss : 0.3696 | Acc : 0.8204
     Batch 150 | Loss : 0.4771 | Acc : 0.7846
     Batch 175 | Loss : 0.3065 | Acc : 0.8652
     Batch 200 | Loss : 0.3028 | Acc : 0.8698
     Batch 225 | Loss : 0.3291 | Acc : 0.8449
     Batch 250 | Loss : 0.3015 | Acc : 0.8612
     Batch 275 | Loss : 0.4202 | Acc : 0.8021
     Batch 300 | Loss : 0.2770 | Acc : 0.8784
Epoch 00006 | Train Loss : 0.3467 | Eval Loss : 0.3388 | Train acc : 0.8403 | Eval Acc : 0.8415 | Eval Log. Respected : 0.9326
     Batch 000 | Loss : 0.2812 | Acc : 0.8723
     Batch 025 | Loss : 0.2911 | Acc : 0.8709
     Batch 050 | Loss : 0.3215 | Acc : 0.8523
     Batch 075 | Loss : 0.3716 | Acc : 0.8258
     Batch 100 | Loss : 0.3289 | Acc : 0.8476
     Batch 125 | Loss : 0.4334 | Acc : 0.7875
     Batch 150 | Loss : 0.3805 | Acc : 0.8199
     Batch 175 | Loss : 0.2998 | Acc : 0.8684
     Batch 200 | Loss : 0.3249 | Acc : 0.8552
     Batch 225 | Loss : 0.4645 | Acc : 0.7885
     Batch 250 | Loss : 0.2954 | Acc : 0.8666
     Batch 275 | Loss : 0.4564 | Acc : 0.7847
     Batch 300 | Loss : 0.3995 | Acc : 0.8169
Epoch 00007 | Train Loss : 0.3434 | Eval Loss : 0.3435 | Train acc : 0.8424 | Eval Acc : 0.8391 | Eval Log. Respected : 0.9212
     Batch 000 | Loss : 0.2909 | Acc : 0.8705
     Batch 025 | Loss : 0.3324 | Acc : 0.8476
     Batch 050 | Loss : 0.3603 | Acc : 0.8299
     Batch 075 | Loss : 0.3791 | Acc : 0.8237
     Batch 100 | Loss : 0.3311 | Acc : 0.8489
     Batch 125 | Loss : 0.2717 | Acc : 0.8776
     Batch 150 | Loss : 0.3492 | Acc : 0.8430
     Batch 175 | Loss : 0.4343 | Acc : 0.7928
     Batch 200 | Loss : 0.4441 | Acc : 0.7974
     Batch 225 | Loss : 0.3502 | Acc : 0.8374
     Batch 250 | Loss : 0.2924 | Acc : 0.8723
     Batch 275 | Loss : 0.3287 | Acc : 0.8462
     Batch 300 | Loss : 0.3358 | Acc : 0.8439
Epoch 00008 | Train Loss : 0.3410 | Eval Loss : 0.3348 | Train acc : 0.8433 | Eval Acc : 0.8424 | Eval Log. Respected : 0.9288
     Batch 000 | Loss : 0.2832 | Acc : 0.8781
     Batch 025 | Loss : 0.3066 | Acc : 0.8614
     Batch 050 | Loss : 0.2963 | Acc : 0.8670
     Batch 075 | Loss : 0.2913 | Acc : 0.8699
     Batch 100 | Loss : 0.2843 | Acc : 0.8720
     Batch 125 | Loss : 0.3413 | Acc : 0.8416
     Batch 150 | Loss : 0.4276 | Acc : 0.8051
     Batch 175 | Loss : 0.3300 | Acc : 0.8458
     Batch 200 | Loss : 0.2875 | Acc : 0.8730
     Batch 225 | Loss : 0.3027 | Acc : 0.8623
     Batch 250 | Loss : 0.3538 | Acc : 0.8335
     Batch 275 | Loss : 0.3101 | Acc : 0.8567
     Batch 300 | Loss : 0.3002 | Acc : 0.8599
Epoch 00009 | Train Loss : 0.3402 | Eval Loss : 0.3413 | Train acc : 0.8439 | Eval Acc : 0.8394 | Eval Log. Respected : 0.9372
     Batch 000 | Loss : 0.4057 | Acc : 0.8120
     Batch 025 | Loss : 0.4103 | Acc : 0.8067
     Batch 050 | Loss : 0.3693 | Acc : 0.8327
     Batch 075 | Loss : 0.3401 | Acc : 0.8386
     Batch 100 | Loss : 0.3185 | Acc : 0.8546
     Batch 125 | Loss : 0.2866 | Acc : 0.8698
     Batch 150 | Loss : 0.3856 | Acc : 0.8245
     Batch 175 | Loss : 0.2901 | Acc : 0.8692
     Batch 200 | Loss : 0.3286 | Acc : 0.8473
     Batch 225 | Loss : 0.3029 | Acc : 0.8645
     Batch 250 | Loss : 0.3426 | Acc : 0.8384
     Batch 275 | Loss : 0.3530 | Acc : 0.8297
     Batch 300 | Loss : 0.3345 | Acc : 0.8444
Epoch 00010 | Train Loss : 0.3377 | Eval Loss : 0.3371 | Train acc : 0.8446 | Eval Acc : 0.8423 | Eval Log. Respected : 0.9307
     Batch 000 | Loss : 0.3166 | Acc : 0.8502
     Batch 025 | Loss : 0.3739 | Acc : 0.8313
     Batch 050 | Loss : 0.3800 | Acc : 0.8283
     Batch 075 | Loss : 0.4390 | Acc : 0.7845
     Batch 100 | Loss : 0.3895 | Acc : 0.8162
     Batch 125 | Loss : 0.3066 | Acc : 0.8660
     Batch 150 | Loss : 0.2973 | Acc : 0.8660
     Batch 175 | Loss : 0.2942 | Acc : 0.8639
     Batch 200 | Loss : 0.3612 | Acc : 0.8311
     Batch 225 | Loss : 0.3468 | Acc : 0.8323
     Batch 250 | Loss : 0.3032 | Acc : 0.8617
     Batch 275 | Loss : 0.3277 | Acc : 0.8470
     Batch 300 | Loss : 0.3108 | Acc : 0.8611
Epoch 00011 | Train Loss : 0.3363 | Eval Loss : 0.3376 | Train acc : 0.8450 | Eval Acc : 0.8420 | Eval Log. Respected : 0.9345
     Batch 000 | Loss : 0.3832 | Acc : 0.8222
     Batch 025 | Loss : 0.3928 | Acc : 0.8253
     Batch 050 | Loss : 0.3441 | Acc : 0.8381
     Batch 075 | Loss : 0.3404 | Acc : 0.8444
     Batch 100 | Loss : 0.2736 | Acc : 0.8801
     Batch 125 | Loss : 0.3333 | Acc : 0.8421
     Batch 150 | Loss : 0.3098 | Acc : 0.8637
     Batch 175 | Loss : 0.3494 | Acc : 0.8402
     Batch 200 | Loss : 0.3743 | Acc : 0.8246
     Batch 225 | Loss : 0.4274 | Acc : 0.8009
     Batch 250 | Loss : 0.2745 | Acc : 0.8755
     Batch 275 | Loss : 0.3479 | Acc : 0.8388
     Batch 300 | Loss : 0.4495 | Acc : 0.7803
Epoch 00012 | Train Loss : 0.3356 | Eval Loss : 0.3407 | Train acc : 0.8456 | Eval Acc : 0.8407 | Eval Log. Respected : 0.9261
     Batch 000 | Loss : 0.3325 | Acc : 0.8472
     Batch 025 | Loss : 0.4086 | Acc : 0.8105
     Batch 050 | Loss : 0.3588 | Acc : 0.8228
     Batch 075 | Loss : 0.3827 | Acc : 0.8298
     Batch 100 | Loss : 0.4337 | Acc : 0.7930
     Batch 125 | Loss : 0.4306 | Acc : 0.7884
     Batch 150 | Loss : 0.3509 | Acc : 0.8343
     Batch 175 | Loss : 0.2864 | Acc : 0.8686
     Batch 200 | Loss : 0.3601 | Acc : 0.8362
     Batch 225 | Loss : 0.3087 | Acc : 0.8565
     Batch 250 | Loss : 0.3255 | Acc : 0.8559
     Batch 275 | Loss : 0.3652 | Acc : 0.8366
     Batch 300 | Loss : 0.3071 | Acc : 0.8606
Epoch 00013 | Train Loss : 0.3336 | Eval Loss : 0.3346 | Train acc : 0.8464 | Eval Acc : 0.8417 | Eval Log. Respected : 0.9312
     Batch 000 | Loss : 0.3288 | Acc : 0.8431
     Batch 025 | Loss : 0.3575 | Acc : 0.8310
     Batch 050 | Loss : 0.3265 | Acc : 0.8569
     Batch 075 | Loss : 0.2635 | Acc : 0.8829
     Batch 100 | Loss : 0.3022 | Acc : 0.8643
     Batch 125 | Loss : 0.2870 | Acc : 0.8732
     Batch 150 | Loss : 0.3014 | Acc : 0.8601
     Batch 175 | Loss : 0.3076 | Acc : 0.8642
     Batch 200 | Loss : 0.3094 | Acc : 0.8553
     Batch 225 | Loss : 0.3112 | Acc : 0.8526
     Batch 250 | Loss : 0.3270 | Acc : 0.8469
     Batch 275 | Loss : 0.3415 | Acc : 0.8399
     Batch 300 | Loss : 0.2973 | Acc : 0.8645
Epoch 00014 | Train Loss : 0.3333 | Eval Loss : 0.3358 | Train acc : 0.8468 | Eval Acc : 0.8418 | Eval Log. Respected : 0.9258
     Batch 000 | Loss : 0.3491 | Acc : 0.8326
     Batch 025 | Loss : 0.2955 | Acc : 0.8651
     Batch 050 | Loss : 0.3183 | Acc : 0.8532
     Batch 075 | Loss : 0.3082 | Acc : 0.8594
     Batch 100 | Loss : 0.2863 | Acc : 0.8760
     Batch 125 | Loss : 0.3215 | Acc : 0.8533
     Batch 150 | Loss : 0.4128 | Acc : 0.8093
     Batch 175 | Loss : 0.3038 | Acc : 0.8665
     Batch 200 | Loss : 0.3820 | Acc : 0.8173
     Batch 225 | Loss : 0.3022 | Acc : 0.8632
     Batch 250 | Loss : 0.2886 | Acc : 0.8724
     Batch 275 | Loss : 0.3034 | Acc : 0.8625
     Batch 300 | Loss : 0.3138 | Acc : 0.8548
Epoch 00015 | Train Loss : 0.3342 | Eval Loss : 0.3345 | Train acc : 0.8465 | Eval Acc : 0.8424 | Eval Log. Respected : 0.9319
     Batch 000 | Loss : 0.2832 | Acc : 0.8733
     Batch 025 | Loss : 0.3469 | Acc : 0.8423
     Batch 050 | Loss : 0.2933 | Acc : 0.8685
     Batch 075 | Loss : 0.3750 | Acc : 0.8312
     Batch 100 | Loss : 0.2673 | Acc : 0.8818
     Batch 125 | Loss : 0.3824 | Acc : 0.8188
     Batch 150 | Loss : 0.3679 | Acc : 0.8324
     Batch 175 | Loss : 0.3545 | Acc : 0.8283
     Batch 200 | Loss : 0.3433 | Acc : 0.8399
     Batch 225 | Loss : 0.3955 | Acc : 0.8093
     Batch 250 | Loss : 0.3407 | Acc : 0.8419
     Batch 275 | Loss : 0.4323 | Acc : 0.7957
     Batch 300 | Loss : 0.3534 | Acc : 0.8325
Epoch 00016 | Train Loss : 0.3320 | Eval Loss : 0.3311 | Train acc : 0.8472 | Eval Acc : 0.8448 | Eval Log. Respected : 0.9229
     Batch 000 | Loss : 0.4334 | Acc : 0.7974
     Batch 025 | Loss : 0.3434 | Acc : 0.8359
     Batch 050 | Loss : 0.2774 | Acc : 0.8748
     Batch 075 | Loss : 0.3243 | Acc : 0.8442
     Batch 100 | Loss : 0.3703 | Acc : 0.8309
     Batch 125 | Loss : 0.3482 | Acc : 0.8339
     Batch 150 | Loss : 0.3300 | Acc : 0.8494
     Batch 175 | Loss : 0.3154 | Acc : 0.8523
     Batch 200 | Loss : 0.3707 | Acc : 0.8246
     Batch 225 | Loss : 0.3528 | Acc : 0.8336
     Batch 250 | Loss : 0.3565 | Acc : 0.8324
     Batch 275 | Loss : 0.3731 | Acc : 0.8254
     Batch 300 | Loss : 0.3734 | Acc : 0.8213
Epoch 00017 | Train Loss : 0.3325 | Eval Loss : 0.3337 | Train acc : 0.8472 | Eval Acc : 0.8436 | Eval Log. Respected : 0.9344
     Batch 000 | Loss : 0.2871 | Acc : 0.8744
     Batch 025 | Loss : 0.3773 | Acc : 0.8251
     Batch 050 | Loss : 0.3055 | Acc : 0.8614
     Batch 075 | Loss : 0.3072 | Acc : 0.8557
     Batch 100 | Loss : 0.3705 | Acc : 0.8256
     Batch 125 | Loss : 0.3343 | Acc : 0.8479
     Batch 150 | Loss : 0.2958 | Acc : 0.8628
     Batch 175 | Loss : 0.3695 | Acc : 0.8260
     Batch 200 | Loss : 0.2913 | Acc : 0.8744
     Batch 225 | Loss : 0.3168 | Acc : 0.8540
     Batch 250 | Loss : 0.2750 | Acc : 0.8765
     Batch 275 | Loss : 0.2869 | Acc : 0.8733
     Batch 300 | Loss : 0.3362 | Acc : 0.8479
Epoch 00018 | Train Loss : 0.3298 | Eval Loss : 0.3353 | Train acc : 0.8483 | Eval Acc : 0.8425 | Eval Log. Respected : 0.9318
     Batch 000 | Loss : 0.3656 | Acc : 0.8346
     Batch 025 | Loss : 0.2737 | Acc : 0.8740
     Batch 050 | Loss : 0.3580 | Acc : 0.8334
     Batch 075 | Loss : 0.3327 | Acc : 0.8415
     Batch 100 | Loss : 0.3098 | Acc : 0.8620
     Batch 125 | Loss : 0.4104 | Acc : 0.8053
     Batch 150 | Loss : 0.3155 | Acc : 0.8597
     Batch 175 | Loss : 0.4192 | Acc : 0.8006
     Batch 200 | Loss : 0.3423 | Acc : 0.8391
     Batch 225 | Loss : 0.2996 | Acc : 0.8617
     Batch 250 | Loss : 0.2960 | Acc : 0.8633
     Batch 275 | Loss : 0.2881 | Acc : 0.8696
     Batch 300 | Loss : 0.3292 | Acc : 0.8416
Epoch 00019 | Train Loss : 0.3301 | Eval Loss : 0.3619 | Train acc : 0.8481 | Eval Acc : 0.8405 | Eval Log. Respected : 0.9411
     Batch 000 | Loss : 0.2998 | Acc : 0.8618
     Batch 025 | Loss : 0.2719 | Acc : 0.8774
     Batch 050 | Loss : 0.3765 | Acc : 0.8202
     Batch 075 | Loss : 0.3458 | Acc : 0.8470
     Batch 100 | Loss : 0.2982 | Acc : 0.8687
     Batch 125 | Loss : 0.3252 | Acc : 0.8622
     Batch 150 | Loss : 0.3681 | Acc : 0.8318
     Batch 175 | Loss : 0.3497 | Acc : 0.8363
     Batch 200 | Loss : 0.3416 | Acc : 0.8441
     Batch 225 | Loss : 0.3216 | Acc : 0.8626
     Batch 250 | Loss : 0.3841 | Acc : 0.8284
     Batch 275 | Loss : 0.4209 | Acc : 0.8042
     Batch 300 | Loss : 0.3809 | Acc : 0.8258
Epoch 00020 | Train Loss : 0.3304 | Eval Loss : 0.3324 | Train acc : 0.8482 | Eval Acc : 0.8431 | Eval Log. Respected : 0.9266
     Batch 000 | Loss : 0.2807 | Acc : 0.8789
     Batch 025 | Loss : 0.2995 | Acc : 0.8622
     Batch 050 | Loss : 0.3102 | Acc : 0.8570
     Batch 075 | Loss : 0.2991 | Acc : 0.8655
     Batch 100 | Loss : 0.3440 | Acc : 0.8450
     Batch 125 | Loss : 0.3603 | Acc : 0.8309
     Batch 150 | Loss : 0.4368 | Acc : 0.7907
     Batch 175 | Loss : 0.3207 | Acc : 0.8517
     Batch 200 | Loss : 0.3312 | Acc : 0.8410
     Batch 225 | Loss : 0.2892 | Acc : 0.8642
     Batch 250 | Loss : 0.3604 | Acc : 0.8324
     Batch 275 | Loss : 0.3024 | Acc : 0.8591
     Batch 300 | Loss : 0.3076 | Acc : 0.8588
Epoch 00021 | Train Loss : 0.3301 | Eval Loss : 0.3378 | Train acc : 0.8480 | Eval Acc : 0.8416 | Eval Log. Respected : 0.9477
     Batch 000 | Loss : 0.3463 | Acc : 0.8464
     Batch 025 | Loss : 0.2981 | Acc : 0.8677
     Batch 050 | Loss : 0.3369 | Acc : 0.8411
     Batch 075 | Loss : 0.2965 | Acc : 0.8642
     Batch 100 | Loss : 0.3565 | Acc : 0.8342
     Batch 125 | Loss : 0.3089 | Acc : 0.8612
     Batch 150 | Loss : 0.3243 | Acc : 0.8463
     Batch 175 | Loss : 0.4058 | Acc : 0.8191
     Batch 200 | Loss : 0.3104 | Acc : 0.8580
     Batch 225 | Loss : 0.2972 | Acc : 0.8646
     Batch 250 | Loss : 0.3341 | Acc : 0.8508
     Batch 275 | Loss : 0.4348 | Acc : 0.7867
     Batch 300 | Loss : 0.3779 | Acc : 0.8165
Epoch 00022 | Train Loss : 0.3290 | Eval Loss : 0.3330 | Train acc : 0.8489 | Eval Acc : 0.8436 | Eval Log. Respected : 0.9297
     Batch 000 | Loss : 0.2878 | Acc : 0.8676
     Batch 025 | Loss : 0.2825 | Acc : 0.8718
     Batch 050 | Loss : 0.2580 | Acc : 0.8906
     Batch 075 | Loss : 0.3053 | Acc : 0.8559
     Batch 100 | Loss : 0.3630 | Acc : 0.8280
     Batch 125 | Loss : 0.4420 | Acc : 0.7986
     Batch 150 | Loss : 0.2868 | Acc : 0.8761
     Batch 175 | Loss : 0.3274 | Acc : 0.8437
     Batch 200 | Loss : 0.3314 | Acc : 0.8450
     Batch 225 | Loss : 0.2773 | Acc : 0.8762
     Batch 250 | Loss : 0.3047 | Acc : 0.8667
     Batch 275 | Loss : 0.3029 | Acc : 0.8573
     Batch 300 | Loss : 0.3309 | Acc : 0.8452
Epoch 00023 | Train Loss : 0.3279 | Eval Loss : 0.3323 | Train acc : 0.8491 | Eval Acc : 0.8432 | Eval Log. Respected : 0.9322
     Batch 000 | Loss : 0.3036 | Acc : 0.8564
     Batch 025 | Loss : 0.4500 | Acc : 0.7907
     Batch 050 | Loss : 0.3729 | Acc : 0.8231
     Batch 075 | Loss : 0.2821 | Acc : 0.8748
     Batch 100 | Loss : 0.2825 | Acc : 0.8727
     Batch 125 | Loss : 0.3462 | Acc : 0.8407
     Batch 150 | Loss : 0.2951 | Acc : 0.8650
     Batch 175 | Loss : 0.3458 | Acc : 0.8369
     Batch 200 | Loss : 0.3621 | Acc : 0.8334
     Batch 225 | Loss : 0.2747 | Acc : 0.8722
     Batch 250 | Loss : 0.2862 | Acc : 0.8722
     Batch 275 | Loss : 0.2798 | Acc : 0.8755
     Batch 300 | Loss : 0.3162 | Acc : 0.8535
Epoch 00024 | Train Loss : 0.3274 | Eval Loss : 0.3374 | Train acc : 0.8495 | Eval Acc : 0.8447 | Eval Log. Respected : 0.9313
     Batch 000 | Loss : 0.3005 | Acc : 0.8674
     Batch 025 | Loss : 0.2862 | Acc : 0.8728
     Batch 050 | Loss : 0.3397 | Acc : 0.8429
     Batch 075 | Loss : 0.2686 | Acc : 0.8786
     Batch 100 | Loss : 0.3223 | Acc : 0.8476
     Batch 125 | Loss : 0.2942 | Acc : 0.8619
     Batch 150 | Loss : 0.4195 | Acc : 0.8010
     Batch 175 | Loss : 0.2801 | Acc : 0.8708
     Batch 200 | Loss : 0.2979 | Acc : 0.8636
     Batch 225 | Loss : 0.2911 | Acc : 0.8726
     Batch 250 | Loss : 0.3248 | Acc : 0.8556
     Batch 275 | Loss : 0.3668 | Acc : 0.8242
     Batch 300 | Loss : 0.3199 | Acc : 0.8479
Epoch 00025 | Train Loss : 0.3256 | Eval Loss : 0.3356 | Train acc : 0.8501 | Eval Acc : 0.8434 | Eval Log. Respected : 0.9306
     Batch 000 | Loss : 0.3217 | Acc : 0.8499
     Batch 025 | Loss : 0.3073 | Acc : 0.8537
     Batch 050 | Loss : 0.3474 | Acc : 0.8396
     Batch 075 | Loss : 0.3361 | Acc : 0.8427
     Batch 100 | Loss : 0.2952 | Acc : 0.8625
     Batch 125 | Loss : 0.3669 | Acc : 0.8296
     Batch 150 | Loss : 0.3067 | Acc : 0.8618
     Batch 175 | Loss : 0.2888 | Acc : 0.8690
     Batch 200 | Loss : 0.3158 | Acc : 0.8565
     Batch 225 | Loss : 0.3409 | Acc : 0.8439
     Batch 250 | Loss : 0.3090 | Acc : 0.8603
     Batch 275 | Loss : 0.3096 | Acc : 0.8592
     Batch 300 | Loss : 0.3414 | Acc : 0.8418
Epoch 00026 | Train Loss : 0.3262 | Eval Loss : 0.3448 | Train acc : 0.8500 | Eval Acc : 0.8343 | Eval Log. Respected : 0.9319
Early Stopping
Testing...
Test Loss 0.5932 | Test Acc 0.8321 | Test Log. Res. 0.9306
