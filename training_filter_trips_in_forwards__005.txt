Done loading data from cached files.
Training ...
     Batch 000 | Loss : 0.9752 | Acc : 0.5148
     Batch 025 | Loss : 0.6863 | Acc : 0.5436
     Batch 050 | Loss : 0.6856 | Acc : 0.5584
     Batch 075 | Loss : 0.6811 | Acc : 0.5601
     Batch 100 | Loss : 0.6840 | Acc : 0.5565
     Batch 125 | Loss : 0.6692 | Acc : 0.5897
     Batch 150 | Loss : 0.6855 | Acc : 0.5549
     Batch 175 | Loss : 0.6910 | Acc : 0.5564
     Batch 200 | Loss : 0.6857 | Acc : 0.5476
     Batch 225 | Loss : 0.6773 | Acc : 0.6008
     Batch 250 | Loss : 0.6788 | Acc : 0.5670
     Batch 275 | Loss : 0.6778 | Acc : 0.5541
     Batch 300 | Loss : 0.6695 | Acc : 0.5948
Epoch 00000 | Train Loss : 0.6838 | Eval Loss : 0.6712 | Train acc : 0.5572 | Eval Acc : 0.5735
     Batch 000 | Loss : 0.6611 | Acc : 0.5837
     Batch 025 | Loss : 0.6874 | Acc : 0.5544
     Batch 050 | Loss : 0.6492 | Acc : 0.6063
     Batch 075 | Loss : 0.6101 | Acc : 0.6502
     Batch 100 | Loss : 0.6598 | Acc : 0.6010
     Batch 125 | Loss : 0.6641 | Acc : 0.5951
     Batch 150 | Loss : 0.6617 | Acc : 0.6017
     Batch 175 | Loss : 0.6508 | Acc : 0.6057
     Batch 200 | Loss : 0.6502 | Acc : 0.6303
     Batch 225 | Loss : 0.6203 | Acc : 0.6381
     Batch 250 | Loss : 0.5984 | Acc : 0.6824
     Batch 275 | Loss : 0.6261 | Acc : 0.6307
     Batch 300 | Loss : 0.6154 | Acc : 0.6525
Epoch 00001 | Train Loss : 0.6516 | Eval Loss : 0.6366 | Train acc : 0.6063 | Eval Acc : 0.6244
     Batch 000 | Loss : 0.5869 | Acc : 0.6725
     Batch 025 | Loss : 0.6241 | Acc : 0.6451
     Batch 050 | Loss : 0.6677 | Acc : 0.5981
     Batch 075 | Loss : 0.6207 | Acc : 0.6516
     Batch 100 | Loss : 0.5823 | Acc : 0.6742
     Batch 125 | Loss : 0.5539 | Acc : 0.7147
     Batch 150 | Loss : 0.6012 | Acc : 0.6744
     Batch 175 | Loss : 0.5219 | Acc : 0.7381
     Batch 200 | Loss : 0.5675 | Acc : 0.6903
     Batch 225 | Loss : 0.4829 | Acc : 0.7677
     Batch 250 | Loss : 0.5323 | Acc : 0.7270
     Batch 275 | Loss : 0.5180 | Acc : 0.7427
     Batch 300 | Loss : 0.5329 | Acc : 0.7258
Epoch 00002 | Train Loss : 0.5875 | Eval Loss : 0.5706 | Train acc : 0.6785 | Eval Acc : 0.7121
     Batch 000 | Loss : 0.6395 | Acc : 0.6735
     Batch 025 | Loss : 0.5373 | Acc : 0.7176
     Batch 050 | Loss : 0.5547 | Acc : 0.7133
     Batch 075 | Loss : 0.5970 | Acc : 0.6946
     Batch 100 | Loss : 0.5258 | Acc : 0.7417
     Batch 125 | Loss : 0.5231 | Acc : 0.7201
     Batch 150 | Loss : 0.4552 | Acc : 0.7820
     Batch 175 | Loss : 0.5244 | Acc : 0.7233
     Batch 200 | Loss : 0.4507 | Acc : 0.7818
     Batch 225 | Loss : 0.5333 | Acc : 0.7370
     Batch 250 | Loss : 0.4342 | Acc : 0.7931
     Batch 275 | Loss : 0.4274 | Acc : 0.7960
     Batch 300 | Loss : 0.4557 | Acc : 0.7742
Epoch 00003 | Train Loss : 0.5123 | Eval Loss : 0.4805 | Train acc : 0.7412 | Eval Acc : 0.7594
     Batch 000 | Loss : 0.4294 | Acc : 0.8010
     Batch 025 | Loss : 0.4278 | Acc : 0.8016
     Batch 050 | Loss : 0.5562 | Acc : 0.6862
     Batch 075 | Loss : 0.4813 | Acc : 0.7606
     Batch 100 | Loss : 0.4707 | Acc : 0.7664
     Batch 125 | Loss : 0.4084 | Acc : 0.8151
     Batch 150 | Loss : 0.4213 | Acc : 0.7984
     Batch 175 | Loss : 0.5669 | Acc : 0.6935
     Batch 200 | Loss : 0.5156 | Acc : 0.7487
     Batch 225 | Loss : 0.3802 | Acc : 0.8276
     Batch 250 | Loss : 0.4368 | Acc : 0.8010
     Batch 275 | Loss : 0.4456 | Acc : 0.7868
     Batch 300 | Loss : 0.5290 | Acc : 0.7253
Epoch 00004 | Train Loss : 0.4862 | Eval Loss : 0.5089 | Train acc : 0.7584 | Eval Acc : 0.7428
     Batch 000 | Loss : 0.5759 | Acc : 0.7025
     Batch 025 | Loss : 0.4414 | Acc : 0.7770
     Batch 050 | Loss : 0.3973 | Acc : 0.8188
     Batch 075 | Loss : 0.4808 | Acc : 0.7573
     Batch 100 | Loss : 0.4504 | Acc : 0.7791
     Batch 125 | Loss : 0.5078 | Acc : 0.7442
     Batch 150 | Loss : 0.4255 | Acc : 0.7950
     Batch 175 | Loss : 0.4267 | Acc : 0.8063
     Batch 200 | Loss : 0.4258 | Acc : 0.7944
     Batch 225 | Loss : 0.5463 | Acc : 0.7402
     Batch 250 | Loss : 0.3803 | Acc : 0.8293
     Batch 275 | Loss : 0.4362 | Acc : 0.7861
     Batch 300 | Loss : 0.4150 | Acc : 0.8116
Epoch 00005 | Train Loss : 0.4532 | Eval Loss : 0.4596 | Train acc : 0.7813 | Eval Acc : 0.7763
     Batch 000 | Loss : 0.5007 | Acc : 0.7541
     Batch 025 | Loss : 0.4744 | Acc : 0.7741
     Batch 050 | Loss : 0.5168 | Acc : 0.7343
     Batch 075 | Loss : 0.5298 | Acc : 0.7299
     Batch 100 | Loss : 0.5690 | Acc : 0.7060
     Batch 125 | Loss : 0.4569 | Acc : 0.7777
     Batch 150 | Loss : 0.3923 | Acc : 0.8151
     Batch 175 | Loss : 0.4992 | Acc : 0.7489
     Batch 200 | Loss : 0.5096 | Acc : 0.7430
     Batch 225 | Loss : 0.4457 | Acc : 0.7802
     Batch 250 | Loss : 0.5199 | Acc : 0.7395
     Batch 275 | Loss : 0.4235 | Acc : 0.7977
     Batch 300 | Loss : 0.4610 | Acc : 0.7790
Epoch 00006 | Train Loss : 0.4465 | Eval Loss : 0.4490 | Train acc : 0.7855 | Eval Acc : 0.7817
     Batch 000 | Loss : 0.3909 | Acc : 0.8222
     Batch 025 | Loss : 0.4069 | Acc : 0.8069
     Batch 050 | Loss : 0.3960 | Acc : 0.8230
     Batch 075 | Loss : 0.4597 | Acc : 0.7687
     Batch 100 | Loss : 0.5079 | Acc : 0.7401
     Batch 125 | Loss : 0.3681 | Acc : 0.8299
     Batch 150 | Loss : 0.3838 | Acc : 0.8279
     Batch 175 | Loss : 0.4301 | Acc : 0.8017
     Batch 200 | Loss : 0.4865 | Acc : 0.7566
     Batch 225 | Loss : 0.4063 | Acc : 0.8100
     Batch 250 | Loss : 0.4915 | Acc : 0.7663
     Batch 275 | Loss : 0.4574 | Acc : 0.7660
     Batch 300 | Loss : 0.4780 | Acc : 0.7629
Epoch 00007 | Train Loss : 0.4364 | Eval Loss : 0.4632 | Train acc : 0.7903 | Eval Acc : 0.7723
     Batch 000 | Loss : 0.5145 | Acc : 0.7334
     Batch 025 | Loss : 0.5266 | Acc : 0.7454
     Batch 050 | Loss : 0.3908 | Acc : 0.8270
     Batch 075 | Loss : 0.4818 | Acc : 0.7598
     Batch 100 | Loss : 0.4591 | Acc : 0.7700
     Batch 125 | Loss : 0.3935 | Acc : 0.8142
     Batch 150 | Loss : 0.4157 | Acc : 0.7937
     Batch 175 | Loss : 0.4154 | Acc : 0.8118
     Batch 200 | Loss : 0.5111 | Acc : 0.7407
     Batch 225 | Loss : 0.3874 | Acc : 0.8296
     Batch 250 | Loss : 0.3860 | Acc : 0.8260
     Batch 275 | Loss : 0.4938 | Acc : 0.7471
     Batch 300 | Loss : 0.4156 | Acc : 0.7949
Epoch 00008 | Train Loss : 0.4290 | Eval Loss : 0.4320 | Train acc : 0.7936 | Eval Acc : 0.7868
     Batch 000 | Loss : 0.3776 | Acc : 0.8205
     Batch 025 | Loss : 0.3836 | Acc : 0.8210
     Batch 050 | Loss : 0.3973 | Acc : 0.8194
     Batch 075 | Loss : 0.4669 | Acc : 0.7657
     Batch 100 | Loss : 0.3895 | Acc : 0.8094
     Batch 125 | Loss : 0.4118 | Acc : 0.7994
     Batch 150 | Loss : 0.4766 | Acc : 0.7587
     Batch 175 | Loss : 0.4296 | Acc : 0.7943
     Batch 200 | Loss : 0.4269 | Acc : 0.7944
     Batch 225 | Loss : 0.4950 | Acc : 0.7616
     Batch 250 | Loss : 0.4711 | Acc : 0.7698
     Batch 275 | Loss : 0.5200 | Acc : 0.7461
     Batch 300 | Loss : 0.4010 | Acc : 0.8272
Epoch 00009 | Train Loss : 0.4276 | Eval Loss : 0.4519 | Train acc : 0.7941 | Eval Acc : 0.7836
     Batch 000 | Loss : 0.4180 | Acc : 0.8003
     Batch 025 | Loss : 0.3910 | Acc : 0.8177
     Batch 050 | Loss : 0.4398 | Acc : 0.7658
     Batch 075 | Loss : 0.4622 | Acc : 0.7774
     Batch 100 | Loss : 0.3909 | Acc : 0.8223
     Batch 125 | Loss : 0.3790 | Acc : 0.8195
     Batch 150 | Loss : 0.4174 | Acc : 0.7987
     Batch 175 | Loss : 0.4366 | Acc : 0.7904
     Batch 200 | Loss : 0.5093 | Acc : 0.7338
     Batch 225 | Loss : 0.3834 | Acc : 0.8248
     Batch 250 | Loss : 0.4621 | Acc : 0.7693
     Batch 275 | Loss : 0.4001 | Acc : 0.8085
     Batch 300 | Loss : 0.4458 | Acc : 0.7898
Epoch 00010 | Train Loss : 0.4209 | Eval Loss : 0.4372 | Train acc : 0.7984 | Eval Acc : 0.7906
     Batch 000 | Loss : 0.3545 | Acc : 0.8404
     Batch 025 | Loss : 0.3872 | Acc : 0.8208
     Batch 050 | Loss : 0.3599 | Acc : 0.8404
     Batch 075 | Loss : 0.3438 | Acc : 0.8475
     Batch 100 | Loss : 0.3801 | Acc : 0.8257
     Batch 125 | Loss : 0.4731 | Acc : 0.7710
     Batch 150 | Loss : 0.4109 | Acc : 0.8146
     Batch 175 | Loss : 0.3530 | Acc : 0.8376
     Batch 200 | Loss : 0.5144 | Acc : 0.7537
     Batch 225 | Loss : 0.4529 | Acc : 0.7673
     Batch 250 | Loss : 0.3971 | Acc : 0.8139
     Batch 275 | Loss : 0.4522 | Acc : 0.7778
     Batch 300 | Loss : 0.5156 | Acc : 0.7319
Epoch 00011 | Train Loss : 0.4274 | Eval Loss : 0.4715 | Train acc : 0.7941 | Eval Acc : 0.7704
     Batch 000 | Loss : 0.4896 | Acc : 0.7597
     Batch 025 | Loss : 0.4657 | Acc : 0.7637
     Batch 050 | Loss : 0.4065 | Acc : 0.8087
     Batch 075 | Loss : 0.4398 | Acc : 0.7833
     Batch 100 | Loss : 0.5380 | Acc : 0.7291
     Batch 125 | Loss : 0.4790 | Acc : 0.7512
     Batch 150 | Loss : 0.5639 | Acc : 0.7247
     Batch 175 | Loss : 0.3639 | Acc : 0.8356
     Batch 200 | Loss : 0.4363 | Acc : 0.7813
     Batch 225 | Loss : 0.4131 | Acc : 0.7957
     Batch 250 | Loss : 0.3640 | Acc : 0.8294
     Batch 275 | Loss : 0.3805 | Acc : 0.8265
     Batch 300 | Loss : 0.4626 | Acc : 0.7662
Epoch 00012 | Train Loss : 0.4275 | Eval Loss : 0.4496 | Train acc : 0.7949 | Eval Acc : 0.7841
     Batch 000 | Loss : 0.3660 | Acc : 0.8409
     Batch 025 | Loss : 0.4494 | Acc : 0.7749
     Batch 050 | Loss : 0.4176 | Acc : 0.8006
     Batch 075 | Loss : 0.4614 | Acc : 0.7711
     Batch 100 | Loss : 0.3676 | Acc : 0.8249
     Batch 125 | Loss : 0.4006 | Acc : 0.8052
     Batch 150 | Loss : 0.5140 | Acc : 0.7427
     Batch 175 | Loss : 0.3773 | Acc : 0.8257
     Batch 200 | Loss : 0.4564 | Acc : 0.7754
     Batch 225 | Loss : 0.4686 | Acc : 0.7702
     Batch 250 | Loss : 0.4164 | Acc : 0.7965
     Batch 275 | Loss : 0.5469 | Acc : 0.7344
     Batch 300 | Loss : 0.3899 | Acc : 0.8119
Epoch 00013 | Train Loss : 0.4217 | Eval Loss : 0.4188 | Train acc : 0.7970 | Eval Acc : 0.7974
     Batch 000 | Loss : 0.3518 | Acc : 0.8379
     Batch 025 | Loss : 0.4932 | Acc : 0.7586
     Batch 050 | Loss : 0.3654 | Acc : 0.8295
     Batch 075 | Loss : 0.4856 | Acc : 0.7706
     Batch 100 | Loss : 0.3972 | Acc : 0.8205
     Batch 125 | Loss : 0.3450 | Acc : 0.8606
     Batch 150 | Loss : 0.3613 | Acc : 0.8391
     Batch 175 | Loss : 0.4427 | Acc : 0.7874
     Batch 200 | Loss : 0.3901 | Acc : 0.8212
     Batch 225 | Loss : 0.4733 | Acc : 0.7591
     Batch 250 | Loss : 0.4614 | Acc : 0.7695
     Batch 275 | Loss : 0.4693 | Acc : 0.7708
     Batch 300 | Loss : 0.3903 | Acc : 0.8072
Epoch 00014 | Train Loss : 0.4177 | Eval Loss : 0.4324 | Train acc : 0.7998 | Eval Acc : 0.7908
     Batch 000 | Loss : 0.4006 | Acc : 0.8166
     Batch 025 | Loss : 0.4475 | Acc : 0.7883
     Batch 050 | Loss : 0.4379 | Acc : 0.7788
     Batch 075 | Loss : 0.4675 | Acc : 0.7795
     Batch 100 | Loss : 0.4302 | Acc : 0.7938
     Batch 125 | Loss : 0.3979 | Acc : 0.8120
     Batch 150 | Loss : 0.3825 | Acc : 0.8216
     Batch 175 | Loss : 0.4160 | Acc : 0.8027
     Batch 200 | Loss : 0.3988 | Acc : 0.8120
     Batch 225 | Loss : 0.5218 | Acc : 0.7262
     Batch 250 | Loss : 0.3623 | Acc : 0.8325
     Batch 275 | Loss : 0.4276 | Acc : 0.7878
     Batch 300 | Loss : 0.3631 | Acc : 0.8304
Epoch 00015 | Train Loss : 0.4197 | Eval Loss : 0.4353 | Train acc : 0.7986 | Eval Acc : 0.7912
     Batch 000 | Loss : 0.4639 | Acc : 0.7820
     Batch 025 | Loss : 0.4257 | Acc : 0.7884
     Batch 050 | Loss : 0.4669 | Acc : 0.7757
     Batch 075 | Loss : 0.4415 | Acc : 0.7812
     Batch 100 | Loss : 0.3334 | Acc : 0.8496
     Batch 125 | Loss : 0.3720 | Acc : 0.8264
     Batch 150 | Loss : 0.4580 | Acc : 0.7655
     Batch 175 | Loss : 0.4272 | Acc : 0.7910
     Batch 200 | Loss : 0.4504 | Acc : 0.7822
     Batch 225 | Loss : 0.4769 | Acc : 0.7699
     Batch 250 | Loss : 0.4273 | Acc : 0.7960
     Batch 275 | Loss : 0.4091 | Acc : 0.8075
     Batch 300 | Loss : 0.3700 | Acc : 0.8317
Epoch 00016 | Train Loss : 0.4141 | Eval Loss : 0.4657 | Train acc : 0.8015 | Eval Acc : 0.7717
     Batch 000 | Loss : 0.4795 | Acc : 0.7691
     Batch 025 | Loss : 0.3704 | Acc : 0.8198
     Batch 050 | Loss : 0.4672 | Acc : 0.7754
     Batch 075 | Loss : 0.5234 | Acc : 0.7324
     Batch 100 | Loss : 0.4990 | Acc : 0.7628
     Batch 125 | Loss : 0.3788 | Acc : 0.8231
     Batch 150 | Loss : 0.5088 | Acc : 0.7542
     Batch 175 | Loss : 0.4545 | Acc : 0.7755
     Batch 200 | Loss : 0.4226 | Acc : 0.8027
     Batch 225 | Loss : 0.3955 | Acc : 0.8050
     Batch 250 | Loss : 0.4131 | Acc : 0.8059
     Batch 275 | Loss : 0.4453 | Acc : 0.7853
     Batch 300 | Loss : 0.4228 | Acc : 0.7962
Epoch 00017 | Train Loss : 0.4241 | Eval Loss : 0.4278 | Train acc : 0.7981 | Eval Acc : 0.7919
     Batch 000 | Loss : 0.4055 | Acc : 0.8077
     Batch 025 | Loss : 0.4187 | Acc : 0.8007
     Batch 050 | Loss : 0.4061 | Acc : 0.8076
     Batch 075 | Loss : 0.3991 | Acc : 0.8078
     Batch 100 | Loss : 0.5403 | Acc : 0.7396
     Batch 125 | Loss : 0.4560 | Acc : 0.7723
     Batch 150 | Loss : 0.4031 | Acc : 0.7992
     Batch 175 | Loss : 0.3598 | Acc : 0.8378
     Batch 200 | Loss : 0.4609 | Acc : 0.7694
     Batch 225 | Loss : 0.3606 | Acc : 0.8301
     Batch 250 | Loss : 0.3935 | Acc : 0.8110
     Batch 275 | Loss : 0.5438 | Acc : 0.7217
     Batch 300 | Loss : 0.3755 | Acc : 0.8204
Epoch 00018 | Train Loss : 0.4160 | Eval Loss : 0.4214 | Train acc : 0.8004 | Eval Acc : 0.7941
     Batch 000 | Loss : 0.4834 | Acc : 0.7506
     Batch 025 | Loss : 0.3777 | Acc : 0.8254
     Batch 050 | Loss : 0.3956 | Acc : 0.8260
     Batch 075 | Loss : 0.3867 | Acc : 0.8244
     Batch 100 | Loss : 0.3626 | Acc : 0.8453
     Batch 125 | Loss : 0.3961 | Acc : 0.8074
     Batch 150 | Loss : 0.3775 | Acc : 0.8244
     Batch 175 | Loss : 0.3662 | Acc : 0.8311
     Batch 200 | Loss : 0.3976 | Acc : 0.8039
     Batch 225 | Loss : 0.4841 | Acc : 0.7548
     Batch 250 | Loss : 0.5013 | Acc : 0.7481
     Batch 275 | Loss : 0.3690 | Acc : 0.8277
     Batch 300 | Loss : 0.4123 | Acc : 0.7987
Epoch 00019 | Train Loss : 0.4124 | Eval Loss : 0.4153 | Train acc : 0.8033 | Eval Acc : 0.8010
     Batch 000 | Loss : 0.3749 | Acc : 0.8309
     Batch 025 | Loss : 0.3734 | Acc : 0.8325
     Batch 050 | Loss : 0.3797 | Acc : 0.8215
     Batch 075 | Loss : 0.3643 | Acc : 0.8192
     Batch 100 | Loss : 0.4950 | Acc : 0.7480
     Batch 125 | Loss : 0.4347 | Acc : 0.7847
     Batch 150 | Loss : 0.3802 | Acc : 0.8263
     Batch 175 | Loss : 0.4632 | Acc : 0.7688
     Batch 200 | Loss : 0.4460 | Acc : 0.7761
     Batch 225 | Loss : 0.4041 | Acc : 0.8027
     Batch 250 | Loss : 0.3674 | Acc : 0.8268
     Batch 275 | Loss : 0.4928 | Acc : 0.7520
     Batch 300 | Loss : 0.5026 | Acc : 0.7558
Epoch 00020 | Train Loss : 0.4152 | Eval Loss : 0.4380 | Train acc : 0.8013 | Eval Acc : 0.7839
     Batch 000 | Loss : 0.3711 | Acc : 0.8269
     Batch 025 | Loss : 0.5603 | Acc : 0.7356
     Batch 050 | Loss : 0.3427 | Acc : 0.8531
     Batch 075 | Loss : 0.4402 | Acc : 0.7870
     Batch 100 | Loss : 0.3419 | Acc : 0.8436
     Batch 125 | Loss : 0.5637 | Acc : 0.7146
     Batch 150 | Loss : 0.3795 | Acc : 0.8224
     Batch 175 | Loss : 0.4757 | Acc : 0.7646
     Batch 200 | Loss : 0.3521 | Acc : 0.8392
     Batch 225 | Loss : 0.4213 | Acc : 0.8036
     Batch 250 | Loss : 0.3888 | Acc : 0.8086
     Batch 275 | Loss : 0.3946 | Acc : 0.8102
     Batch 300 | Loss : 0.4495 | Acc : 0.7922
Epoch 00021 | Train Loss : 0.4149 | Eval Loss : 0.4196 | Train acc : 0.8018 | Eval Acc : 0.7971
     Batch 000 | Loss : 0.3796 | Acc : 0.8180
     Batch 025 | Loss : 0.3752 | Acc : 0.8308
     Batch 050 | Loss : 0.4074 | Acc : 0.8046
     Batch 075 | Loss : 0.4228 | Acc : 0.7843
     Batch 100 | Loss : 0.4818 | Acc : 0.7604
     Batch 125 | Loss : 0.4559 | Acc : 0.7692
     Batch 150 | Loss : 0.3371 | Acc : 0.8521
     Batch 175 | Loss : 0.4945 | Acc : 0.7603
     Batch 200 | Loss : 0.4932 | Acc : 0.7452
     Batch 225 | Loss : 0.4465 | Acc : 0.7896
     Batch 250 | Loss : 0.4594 | Acc : 0.7726
     Batch 275 | Loss : 0.4433 | Acc : 0.7763
     Batch 300 | Loss : 0.4518 | Acc : 0.7646
Epoch 00022 | Train Loss : 0.4314 | Eval Loss : 0.4327 | Train acc : 0.7930 | Eval Acc : 0.7884
     Batch 000 | Loss : 0.4562 | Acc : 0.7739
     Batch 025 | Loss : 0.5001 | Acc : 0.7459
     Batch 050 | Loss : 0.3941 | Acc : 0.8119
     Batch 075 | Loss : 0.4674 | Acc : 0.7667
     Batch 100 | Loss : 0.4635 | Acc : 0.7808
     Batch 125 | Loss : 0.5118 | Acc : 0.7480
     Batch 150 | Loss : 0.5402 | Acc : 0.7354
     Batch 175 | Loss : 0.3919 | Acc : 0.8193
     Batch 200 | Loss : 0.3641 | Acc : 0.8282
     Batch 225 | Loss : 0.4334 | Acc : 0.7870
     Batch 250 | Loss : 0.3387 | Acc : 0.8470
     Batch 275 | Loss : 0.3711 | Acc : 0.8243
     Batch 300 | Loss : 0.4160 | Acc : 0.7957
Epoch 00023 | Train Loss : 0.4211 | Eval Loss : 0.4307 | Train acc : 0.7975 | Eval Acc : 0.7882
     Batch 000 | Loss : 0.3608 | Acc : 0.8373
     Batch 025 | Loss : 0.3695 | Acc : 0.8243
     Batch 050 | Loss : 0.4145 | Acc : 0.7930
     Batch 075 | Loss : 0.4206 | Acc : 0.7917
     Batch 100 | Loss : 0.3763 | Acc : 0.8299
     Batch 125 | Loss : 0.4028 | Acc : 0.7974
     Batch 150 | Loss : 0.5438 | Acc : 0.7388
     Batch 175 | Loss : 0.4465 | Acc : 0.7832
     Batch 200 | Loss : 0.4122 | Acc : 0.8087
     Batch 225 | Loss : 0.3610 | Acc : 0.8319
     Batch 250 | Loss : 0.4034 | Acc : 0.8060
     Batch 275 | Loss : 0.3698 | Acc : 0.8343
     Batch 300 | Loss : 0.3655 | Acc : 0.8367
Epoch 00024 | Train Loss : 0.4149 | Eval Loss : 0.4342 | Train acc : 0.8013 | Eval Acc : 0.7913
     Batch 000 | Loss : 0.3620 | Acc : 0.8311
     Batch 025 | Loss : 0.3757 | Acc : 0.8153
     Batch 050 | Loss : 0.4581 | Acc : 0.7704
     Batch 075 | Loss : 0.4366 | Acc : 0.7914
     Batch 100 | Loss : 0.3537 | Acc : 0.8362
     Batch 125 | Loss : 0.4635 | Acc : 0.7745
     Batch 150 | Loss : 0.3566 | Acc : 0.8337
     Batch 175 | Loss : 0.3898 | Acc : 0.8126
     Batch 200 | Loss : 0.4913 | Acc : 0.7687
     Batch 225 | Loss : 0.4497 | Acc : 0.7688
     Batch 250 | Loss : 0.4361 | Acc : 0.7833
     Batch 275 | Loss : 0.3878 | Acc : 0.8108
     Batch 300 | Loss : 0.4759 | Acc : 0.7561
Epoch 00025 | Train Loss : 0.4136 | Eval Loss : 0.4204 | Train acc : 0.8010 | Eval Acc : 0.7954
     Batch 000 | Loss : 0.3895 | Acc : 0.8164
     Batch 025 | Loss : 0.3503 | Acc : 0.8422
     Batch 050 | Loss : 0.4541 | Acc : 0.7686
     Batch 075 | Loss : 0.4290 | Acc : 0.7846
     Batch 100 | Loss : 0.4354 | Acc : 0.7945
     Batch 125 | Loss : 0.4219 | Acc : 0.7856
     Batch 150 | Loss : 0.3935 | Acc : 0.8114
     Batch 175 | Loss : 0.3705 | Acc : 0.8235
     Batch 200 | Loss : 0.3782 | Acc : 0.8268
     Batch 225 | Loss : 0.3734 | Acc : 0.8308
     Batch 250 | Loss : 0.3513 | Acc : 0.8411
     Batch 275 | Loss : 0.5086 | Acc : 0.7594
     Batch 300 | Loss : 0.4231 | Acc : 0.8007
Epoch 00026 | Train Loss : 0.4140 | Eval Loss : 0.4316 | Train acc : 0.8007 | Eval Acc : 0.7941
     Batch 000 | Loss : 0.4107 | Acc : 0.8063
     Batch 025 | Loss : 0.3483 | Acc : 0.8435
     Batch 050 | Loss : 0.3352 | Acc : 0.8540
     Batch 075 | Loss : 0.4219 | Acc : 0.8006
     Batch 100 | Loss : 0.4031 | Acc : 0.8108
     Batch 125 | Loss : 0.4170 | Acc : 0.7976
     Batch 150 | Loss : 0.4158 | Acc : 0.8057
     Batch 175 | Loss : 0.4496 | Acc : 0.7803
     Batch 200 | Loss : 0.4503 | Acc : 0.7745
     Batch 225 | Loss : 0.3805 | Acc : 0.8187
     Batch 250 | Loss : 0.4191 | Acc : 0.8041
     Batch 275 | Loss : 0.4791 | Acc : 0.7518
     Batch 300 | Loss : 0.3588 | Acc : 0.8370
Epoch 00027 | Train Loss : 0.4134 | Eval Loss : 0.4202 | Train acc : 0.8014 | Eval Acc : 0.7958
     Batch 000 | Loss : 0.3454 | Acc : 0.8378
     Batch 025 | Loss : 0.4267 | Acc : 0.7867
     Batch 050 | Loss : 0.4391 | Acc : 0.7828
     Batch 075 | Loss : 0.4509 | Acc : 0.7744
     Batch 100 | Loss : 0.4299 | Acc : 0.7842
     Batch 125 | Loss : 0.4330 | Acc : 0.7842
     Batch 150 | Loss : 0.4749 | Acc : 0.7677
     Batch 175 | Loss : 0.4080 | Acc : 0.8014
     Batch 200 | Loss : 0.4868 | Acc : 0.7655
     Batch 225 | Loss : 0.3930 | Acc : 0.8168
     Batch 250 | Loss : 0.4391 | Acc : 0.7784
     Batch 275 | Loss : 0.4904 | Acc : 0.7668
     Batch 300 | Loss : 0.3531 | Acc : 0.8334
Epoch 00028 | Train Loss : 0.4137 | Eval Loss : 0.4159 | Train acc : 0.8012 | Eval Acc : 0.7987
     Batch 000 | Loss : 0.3657 | Acc : 0.8324
     Batch 025 | Loss : 0.5009 | Acc : 0.7461
     Batch 050 | Loss : 0.4552 | Acc : 0.7740
     Batch 075 | Loss : 0.4385 | Acc : 0.7888
     Batch 100 | Loss : 0.3663 | Acc : 0.8233
     Batch 125 | Loss : 0.3990 | Acc : 0.8060
     Batch 150 | Loss : 0.3990 | Acc : 0.8065
     Batch 175 | Loss : 0.3755 | Acc : 0.8295
     Batch 200 | Loss : 0.3343 | Acc : 0.8510
     Batch 225 | Loss : 0.4224 | Acc : 0.7918
     Batch 250 | Loss : 0.3872 | Acc : 0.8201
     Batch 275 | Loss : 0.4839 | Acc : 0.7508
     Batch 300 | Loss : 0.4551 | Acc : 0.7850
Epoch 00029 | Train Loss : 0.4072 | Eval Loss : 0.4204 | Train acc : 0.8048 | Eval Acc : 0.7964
     Batch 000 | Loss : 0.3485 | Acc : 0.8387
     Batch 025 | Loss : 0.3837 | Acc : 0.8203
     Batch 050 | Loss : 0.3835 | Acc : 0.8179
     Batch 075 | Loss : 0.4186 | Acc : 0.7932
     Batch 100 | Loss : 0.3377 | Acc : 0.8483
     Batch 125 | Loss : 0.3910 | Acc : 0.8095
     Batch 150 | Loss : 0.4436 | Acc : 0.7827
     Batch 175 | Loss : 0.4830 | Acc : 0.7599
     Batch 200 | Loss : 0.4269 | Acc : 0.7863
     Batch 225 | Loss : 0.4040 | Acc : 0.8052
     Batch 250 | Loss : 0.4511 | Acc : 0.7810
     Batch 275 | Loss : 0.4536 | Acc : 0.7740
     Batch 300 | Loss : 0.4118 | Acc : 0.8090
Epoch 00030 | Train Loss : 0.4130 | Eval Loss : 0.4230 | Train acc : 0.8018 | Eval Acc : 0.7928
     Batch 000 | Loss : 0.3771 | Acc : 0.8317
     Batch 025 | Loss : 0.3363 | Acc : 0.8571
     Batch 050 | Loss : 0.3493 | Acc : 0.8363
     Batch 075 | Loss : 0.3479 | Acc : 0.8406
     Batch 100 | Loss : 0.3950 | Acc : 0.8220
     Batch 125 | Loss : 0.3963 | Acc : 0.8155
     Batch 150 | Loss : 0.3606 | Acc : 0.8289
     Batch 175 | Loss : 0.4077 | Acc : 0.8013
     Batch 200 | Loss : 0.3250 | Acc : 0.8523
     Batch 225 | Loss : 0.4663 | Acc : 0.7801
     Batch 250 | Loss : 0.3926 | Acc : 0.8149
     Batch 275 | Loss : 0.4579 | Acc : 0.7610
     Batch 300 | Loss : 0.4369 | Acc : 0.7846
Epoch 00031 | Train Loss : 0.4113 | Eval Loss : 0.4134 | Train acc : 0.8033 | Eval Acc : 0.7998
     Batch 000 | Loss : 0.3760 | Acc : 0.8308
     Batch 025 | Loss : 0.3356 | Acc : 0.8618
     Batch 050 | Loss : 0.3933 | Acc : 0.8183
     Batch 075 | Loss : 0.4073 | Acc : 0.8003
     Batch 100 | Loss : 0.4462 | Acc : 0.7796
     Batch 125 | Loss : 0.4255 | Acc : 0.7926
     Batch 150 | Loss : 0.3927 | Acc : 0.8073
     Batch 175 | Loss : 0.4589 | Acc : 0.7757
     Batch 200 | Loss : 0.3852 | Acc : 0.8190
     Batch 225 | Loss : 0.3815 | Acc : 0.8200
     Batch 250 | Loss : 0.3649 | Acc : 0.8303
     Batch 275 | Loss : 0.4034 | Acc : 0.8015
     Batch 300 | Loss : 0.4321 | Acc : 0.7930
Epoch 00032 | Train Loss : 0.4077 | Eval Loss : 0.4191 | Train acc : 0.8048 | Eval Acc : 0.7976
     Batch 000 | Loss : 0.3742 | Acc : 0.8162
     Batch 025 | Loss : 0.3868 | Acc : 0.8182
     Batch 050 | Loss : 0.4088 | Acc : 0.7997
     Batch 075 | Loss : 0.4601 | Acc : 0.7762
     Batch 100 | Loss : 0.4068 | Acc : 0.8075
     Batch 125 | Loss : 0.4876 | Acc : 0.7686
     Batch 150 | Loss : 0.4348 | Acc : 0.7858
     Batch 175 | Loss : 0.4217 | Acc : 0.7956
     Batch 200 | Loss : 0.3655 | Acc : 0.8334
     Batch 225 | Loss : 0.3838 | Acc : 0.8228
     Batch 250 | Loss : 0.4544 | Acc : 0.7636
     Batch 275 | Loss : 0.3613 | Acc : 0.8375
     Batch 300 | Loss : 0.3844 | Acc : 0.8318
Epoch 00033 | Train Loss : 0.4098 | Eval Loss : 0.4141 | Train acc : 0.8038 | Eval Acc : 0.8000
     Batch 000 | Loss : 0.3498 | Acc : 0.8400
     Batch 025 | Loss : 0.4084 | Acc : 0.7843
     Batch 050 | Loss : 0.3680 | Acc : 0.8293
     Batch 075 | Loss : 0.3917 | Acc : 0.8120
     Batch 100 | Loss : 0.3540 | Acc : 0.8318
     Batch 125 | Loss : 0.4006 | Acc : 0.8069
     Batch 150 | Loss : 0.3985 | Acc : 0.8145
     Batch 175 | Loss : 0.4430 | Acc : 0.7842
     Batch 200 | Loss : 0.4942 | Acc : 0.7711
     Batch 225 | Loss : 0.4229 | Acc : 0.7985
     Batch 250 | Loss : 0.4471 | Acc : 0.7760
     Batch 275 | Loss : 0.5875 | Acc : 0.7058
     Batch 300 | Loss : 0.4228 | Acc : 0.7943
Epoch 00034 | Train Loss : 0.4094 | Eval Loss : 0.4277 | Train acc : 0.8038 | Eval Acc : 0.7901
     Batch 000 | Loss : 0.4193 | Acc : 0.7941
     Batch 025 | Loss : 0.4200 | Acc : 0.7913
     Batch 050 | Loss : 0.3696 | Acc : 0.8317
     Batch 075 | Loss : 0.3722 | Acc : 0.8295
     Batch 100 | Loss : 0.3879 | Acc : 0.8204
     Batch 125 | Loss : 0.4262 | Acc : 0.7803
     Batch 150 | Loss : 0.3789 | Acc : 0.8288
     Batch 175 | Loss : 0.3539 | Acc : 0.8440
     Batch 200 | Loss : 0.3712 | Acc : 0.8341
     Batch 225 | Loss : 0.4668 | Acc : 0.7645
     Batch 250 | Loss : 0.3635 | Acc : 0.8304
     Batch 275 | Loss : 0.3971 | Acc : 0.8197
     Batch 300 | Loss : 0.4393 | Acc : 0.7873
Epoch 00035 | Train Loss : 0.4142 | Eval Loss : 0.4227 | Train acc : 0.8010 | Eval Acc : 0.7972
     Batch 000 | Loss : 0.3487 | Acc : 0.8470
     Batch 025 | Loss : 0.3790 | Acc : 0.8232
     Batch 050 | Loss : 0.5690 | Acc : 0.7454
     Batch 075 | Loss : 0.4113 | Acc : 0.7957
     Batch 100 | Loss : 0.4549 | Acc : 0.7706
     Batch 125 | Loss : 0.4151 | Acc : 0.8092
     Batch 150 | Loss : 0.4235 | Acc : 0.7960
     Batch 175 | Loss : 0.4272 | Acc : 0.7927
     Batch 200 | Loss : 0.3450 | Acc : 0.8436
     Batch 225 | Loss : 0.3521 | Acc : 0.8391
     Batch 250 | Loss : 0.3903 | Acc : 0.8139
     Batch 275 | Loss : 0.4154 | Acc : 0.7983
     Batch 300 | Loss : 0.4672 | Acc : 0.7655
Epoch 00036 | Train Loss : 0.4081 | Eval Loss : 0.4161 | Train acc : 0.8046 | Eval Acc : 0.7978
     Batch 000 | Loss : 0.4890 | Acc : 0.7547
     Batch 025 | Loss : 0.3510 | Acc : 0.8399
     Batch 050 | Loss : 0.3858 | Acc : 0.8202
     Batch 075 | Loss : 0.4069 | Acc : 0.8098
     Batch 100 | Loss : 0.3579 | Acc : 0.8298
     Batch 125 | Loss : 0.3788 | Acc : 0.8269
     Batch 150 | Loss : 0.4383 | Acc : 0.7847
     Batch 175 | Loss : 0.3776 | Acc : 0.8388
     Batch 200 | Loss : 0.4120 | Acc : 0.7999
     Batch 225 | Loss : 0.4938 | Acc : 0.7707
     Batch 250 | Loss : 0.4180 | Acc : 0.7965
     Batch 275 | Loss : 0.3863 | Acc : 0.8226
     Batch 300 | Loss : 0.4073 | Acc : 0.8004
Epoch 00037 | Train Loss : 0.4066 | Eval Loss : 0.4142 | Train acc : 0.8052 | Eval Acc : 0.7987
     Batch 000 | Loss : 0.4345 | Acc : 0.7882
     Batch 025 | Loss : 0.3485 | Acc : 0.8404
     Batch 050 | Loss : 0.3668 | Acc : 0.8290
     Batch 075 | Loss : 0.4839 | Acc : 0.7470
     Batch 100 | Loss : 0.3483 | Acc : 0.8355
     Batch 125 | Loss : 0.3853 | Acc : 0.8104
     Batch 150 | Loss : 0.3493 | Acc : 0.8393
     Batch 175 | Loss : 0.4227 | Acc : 0.7931
     Batch 200 | Loss : 0.4063 | Acc : 0.8071
     Batch 225 | Loss : 0.3948 | Acc : 0.8127
     Batch 250 | Loss : 0.4450 | Acc : 0.7732
     Batch 275 | Loss : 0.3884 | Acc : 0.8231
     Batch 300 | Loss : 0.4064 | Acc : 0.8107
Epoch 00038 | Train Loss : 0.4060 | Eval Loss : 0.4151 | Train acc : 0.8057 | Eval Acc : 0.8007
     Batch 000 | Loss : 0.3923 | Acc : 0.8131
     Batch 025 | Loss : 0.4447 | Acc : 0.7770
     Batch 050 | Loss : 0.3808 | Acc : 0.8094
     Batch 075 | Loss : 0.5161 | Acc : 0.7537
     Batch 100 | Loss : 0.3585 | Acc : 0.8351
     Batch 125 | Loss : 0.4843 | Acc : 0.7567
     Batch 150 | Loss : 0.4726 | Acc : 0.7715
     Batch 175 | Loss : 0.4086 | Acc : 0.7958
     Batch 200 | Loss : 0.3507 | Acc : 0.8451
     Batch 225 | Loss : 0.4757 | Acc : 0.7680
     Batch 250 | Loss : 0.3827 | Acc : 0.8318
     Batch 275 | Loss : 0.4183 | Acc : 0.7928
     Batch 300 | Loss : 0.3719 | Acc : 0.8206
Epoch 00039 | Train Loss : 0.4044 | Eval Loss : 0.4152 | Train acc : 0.8066 | Eval Acc : 0.8015
     Batch 000 | Loss : 0.3515 | Acc : 0.8404
     Batch 025 | Loss : 0.3853 | Acc : 0.8238
     Batch 050 | Loss : 0.3580 | Acc : 0.8398
     Batch 075 | Loss : 0.4362 | Acc : 0.7837
     Batch 100 | Loss : 0.3775 | Acc : 0.8224
     Batch 125 | Loss : 0.3764 | Acc : 0.8311
     Batch 150 | Loss : 0.3861 | Acc : 0.8224
     Batch 175 | Loss : 0.4566 | Acc : 0.7733
     Batch 200 | Loss : 0.3960 | Acc : 0.8136
     Batch 225 | Loss : 0.3724 | Acc : 0.8228
     Batch 250 | Loss : 0.3691 | Acc : 0.8344
     Batch 275 | Loss : 0.3690 | Acc : 0.8187
     Batch 300 | Loss : 0.5217 | Acc : 0.7488
Epoch 00040 | Train Loss : 0.4081 | Eval Loss : 0.4292 | Train acc : 0.8045 | Eval Acc : 0.7938
     Batch 000 | Loss : 0.3890 | Acc : 0.8271
     Batch 025 | Loss : 0.3955 | Acc : 0.8028
     Batch 050 | Loss : 0.3624 | Acc : 0.8371
     Batch 075 | Loss : 0.4998 | Acc : 0.7435
     Batch 100 | Loss : 0.4131 | Acc : 0.7982
     Batch 125 | Loss : 0.3743 | Acc : 0.8263
     Batch 150 | Loss : 0.4324 | Acc : 0.7954
     Batch 175 | Loss : 0.3676 | Acc : 0.8344
     Batch 200 | Loss : 0.4220 | Acc : 0.7938
     Batch 225 | Loss : 0.3867 | Acc : 0.8155
     Batch 250 | Loss : 0.4204 | Acc : 0.7922
     Batch 275 | Loss : 0.3599 | Acc : 0.8410
     Batch 300 | Loss : 0.5276 | Acc : 0.7407
Epoch 00041 | Train Loss : 0.4103 | Eval Loss : 0.4174 | Train acc : 0.8041 | Eval Acc : 0.7989
     Batch 000 | Loss : 0.3811 | Acc : 0.8286
     Batch 025 | Loss : 0.4064 | Acc : 0.7972
     Batch 050 | Loss : 0.3391 | Acc : 0.8574
     Batch 075 | Loss : 0.4133 | Acc : 0.8025
     Batch 100 | Loss : 0.4268 | Acc : 0.7851
     Batch 125 | Loss : 0.3552 | Acc : 0.8374
     Batch 150 | Loss : 0.4471 | Acc : 0.7735
     Batch 175 | Loss : 0.4088 | Acc : 0.7962
     Batch 200 | Loss : 0.4648 | Acc : 0.7637
     Batch 225 | Loss : 0.3518 | Acc : 0.8432
     Batch 250 | Loss : 0.3955 | Acc : 0.8065
     Batch 275 | Loss : 0.4567 | Acc : 0.7559
     Batch 300 | Loss : 0.4304 | Acc : 0.7810
Epoch 00042 | Train Loss : 0.4092 | Eval Loss : 0.4277 | Train acc : 0.8043 | Eval Acc : 0.7913
     Batch 000 | Loss : 0.4515 | Acc : 0.7745
     Batch 025 | Loss : 0.3956 | Acc : 0.8195
     Batch 050 | Loss : 0.4267 | Acc : 0.8029
     Batch 075 | Loss : 0.3731 | Acc : 0.8273
     Batch 100 | Loss : 0.3890 | Acc : 0.8159
     Batch 125 | Loss : 0.4359 | Acc : 0.7840
     Batch 150 | Loss : 0.3734 | Acc : 0.8232
     Batch 175 | Loss : 0.3813 | Acc : 0.8232
     Batch 200 | Loss : 0.3551 | Acc : 0.8421
     Batch 225 | Loss : 0.3690 | Acc : 0.8260
     Batch 250 | Loss : 0.4713 | Acc : 0.7721
     Batch 275 | Loss : 0.4024 | Acc : 0.8038
     Batch 300 | Loss : 0.3970 | Acc : 0.8115
Epoch 00043 | Train Loss : 0.4105 | Eval Loss : 0.4185 | Train acc : 0.8034 | Eval Acc : 0.7978
     Batch 000 | Loss : 0.4696 | Acc : 0.7746
     Batch 025 | Loss : 0.3745 | Acc : 0.8385
     Batch 050 | Loss : 0.3481 | Acc : 0.8381
     Batch 075 | Loss : 0.4054 | Acc : 0.8009
     Batch 100 | Loss : 0.3838 | Acc : 0.8158
     Batch 125 | Loss : 0.3963 | Acc : 0.8143
     Batch 150 | Loss : 0.4028 | Acc : 0.8038
     Batch 175 | Loss : 0.3702 | Acc : 0.8339
     Batch 200 | Loss : 0.4106 | Acc : 0.7969
     Batch 225 | Loss : 0.3701 | Acc : 0.8320
     Batch 250 | Loss : 0.3884 | Acc : 0.8113
     Batch 275 | Loss : 0.3489 | Acc : 0.8447
     Batch 300 | Loss : 0.3799 | Acc : 0.8237
Epoch 00044 | Train Loss : 0.4057 | Eval Loss : 0.4205 | Train acc : 0.8063 | Eval Acc : 0.7976
     Batch 000 | Loss : 0.3895 | Acc : 0.8171
     Batch 025 | Loss : 0.3507 | Acc : 0.8438
     Batch 050 | Loss : 0.4474 | Acc : 0.7775
     Batch 075 | Loss : 0.3752 | Acc : 0.8291
     Batch 100 | Loss : 0.3727 | Acc : 0.8224
     Batch 125 | Loss : 0.4068 | Acc : 0.8043
     Batch 150 | Loss : 0.3768 | Acc : 0.8201
     Batch 175 | Loss : 0.4224 | Acc : 0.8034
     Batch 200 | Loss : 0.4472 | Acc : 0.7833
     Batch 225 | Loss : 0.4302 | Acc : 0.7889
     Batch 250 | Loss : 0.3689 | Acc : 0.8291
     Batch 275 | Loss : 0.3460 | Acc : 0.8481
     Batch 300 | Loss : 0.3559 | Acc : 0.8457
Epoch 00045 | Train Loss : 0.4134 | Eval Loss : 0.4187 | Train acc : 0.8027 | Eval Acc : 0.7976
     Batch 000 | Loss : 0.3590 | Acc : 0.8366
     Batch 025 | Loss : 0.3491 | Acc : 0.8455
     Batch 050 | Loss : 0.3733 | Acc : 0.8253
     Batch 075 | Loss : 0.4573 | Acc : 0.7816
     Batch 100 | Loss : 0.4147 | Acc : 0.7935
     Batch 125 | Loss : 0.4786 | Acc : 0.7618
     Batch 150 | Loss : 0.4037 | Acc : 0.8102
     Batch 175 | Loss : 0.3835 | Acc : 0.8159
     Batch 200 | Loss : 0.4801 | Acc : 0.7581
     Batch 225 | Loss : 0.4465 | Acc : 0.7762
     Batch 250 | Loss : 0.4013 | Acc : 0.8086
     Batch 275 | Loss : 0.4877 | Acc : 0.7569
     Batch 300 | Loss : 0.4106 | Acc : 0.8050
Epoch 00046 | Train Loss : 0.4081 | Eval Loss : 0.4151 | Train acc : 0.8054 | Eval Acc : 0.8001
     Batch 000 | Loss : 0.3914 | Acc : 0.8205
     Batch 025 | Loss : 0.4517 | Acc : 0.7752
     Batch 050 | Loss : 0.4261 | Acc : 0.7877
     Batch 075 | Loss : 0.3886 | Acc : 0.8189
     Batch 100 | Loss : 0.3864 | Acc : 0.8184
     Batch 125 | Loss : 0.3747 | Acc : 0.8291
     Batch 150 | Loss : 0.5494 | Acc : 0.7488
     Batch 175 | Loss : 0.4306 | Acc : 0.7899
     Batch 200 | Loss : 0.4415 | Acc : 0.7927
     Batch 225 | Loss : 0.3630 | Acc : 0.8364
     Batch 250 | Loss : 0.4961 | Acc : 0.7565
     Batch 275 | Loss : 0.6465 | Acc : 0.6139
     Batch 300 | Loss : 0.5252 | Acc : 0.7383
Epoch 00047 | Train Loss : 0.4332 | Eval Loss : 0.5334 | Train acc : 0.7856 | Eval Acc : 0.7316
     Batch 000 | Loss : 0.5584 | Acc : 0.7034
     Batch 025 | Loss : 0.4557 | Acc : 0.7868
     Batch 050 | Loss : 0.3760 | Acc : 0.8227
     Batch 075 | Loss : 0.5213 | Acc : 0.7404
     Batch 100 | Loss : 0.5245 | Acc : 0.7478
     Batch 125 | Loss : 0.5008 | Acc : 0.7569
     Batch 150 | Loss : 0.4171 | Acc : 0.8163
     Batch 175 | Loss : 0.4102 | Acc : 0.8069
     Batch 200 | Loss : 0.4416 | Acc : 0.7773
     Batch 225 | Loss : 0.4796 | Acc : 0.7629
     Batch 250 | Loss : 0.4455 | Acc : 0.7838
     Batch 275 | Loss : 0.4537 | Acc : 0.7725
     Batch 300 | Loss : 0.4091 | Acc : 0.8083
Epoch 00048 | Train Loss : 0.4691 | Eval Loss : 0.4513 | Train acc : 0.7720 | Eval Acc : 0.7771
     Batch 000 | Loss : 0.4407 | Acc : 0.7892
     Batch 025 | Loss : 0.3814 | Acc : 0.8195
     Batch 050 | Loss : 0.5295 | Acc : 0.7368
     Batch 075 | Loss : 0.3941 | Acc : 0.8078
     Batch 100 | Loss : 0.4051 | Acc : 0.8108
     Batch 125 | Loss : 0.3988 | Acc : 0.8150
     Batch 150 | Loss : 0.4602 | Acc : 0.7710
     Batch 175 | Loss : 0.4248 | Acc : 0.7967
     Batch 200 | Loss : 0.4280 | Acc : 0.7944
     Batch 225 | Loss : 0.3848 | Acc : 0.8220
     Batch 250 | Loss : 0.3806 | Acc : 0.8221
     Batch 275 | Loss : 0.5267 | Acc : 0.7339
     Batch 300 | Loss : 0.4844 | Acc : 0.7641
Epoch 00049 | Train Loss : 0.4377 | Eval Loss : 0.4453 | Train acc : 0.7898 | Eval Acc : 0.7854
     Batch 000 | Loss : 0.4199 | Acc : 0.8092
     Batch 025 | Loss : 0.4127 | Acc : 0.8013
     Batch 050 | Loss : 0.4982 | Acc : 0.7432
     Batch 075 | Loss : 0.3624 | Acc : 0.8319
     Batch 100 | Loss : 0.4581 | Acc : 0.7767
     Batch 125 | Loss : 0.4057 | Acc : 0.8056
     Batch 150 | Loss : 0.3678 | Acc : 0.8375
     Batch 175 | Loss : 0.5314 | Acc : 0.7271
     Batch 200 | Loss : 0.4515 | Acc : 0.7616
     Batch 225 | Loss : 0.3688 | Acc : 0.8388
     Batch 250 | Loss : 0.4324 | Acc : 0.7872
     Batch 275 | Loss : 0.4592 | Acc : 0.7679
     Batch 300 | Loss : 0.4771 | Acc : 0.7607
Epoch 00050 | Train Loss : 0.4248 | Eval Loss : 0.4443 | Train acc : 0.7962 | Eval Acc : 0.7857
     Batch 000 | Loss : 0.3810 | Acc : 0.8245
     Batch 025 | Loss : 0.3940 | Acc : 0.8082
     Batch 050 | Loss : 0.4922 | Acc : 0.7514
     Batch 075 | Loss : 0.4226 | Acc : 0.7971
     Batch 100 | Loss : 0.4467 | Acc : 0.7771
     Batch 125 | Loss : 0.4279 | Acc : 0.7924
     Batch 150 | Loss : 0.3672 | Acc : 0.8329
     Batch 175 | Loss : 0.3945 | Acc : 0.8143
     Batch 200 | Loss : 0.4424 | Acc : 0.7808
     Batch 225 | Loss : 0.4272 | Acc : 0.7959
     Batch 250 | Loss : 0.3552 | Acc : 0.8450
     Batch 275 | Loss : 0.3695 | Acc : 0.8421
     Batch 300 | Loss : 0.3905 | Acc : 0.8153
Epoch 00051 | Train Loss : 0.4212 | Eval Loss : 0.4405 | Train acc : 0.7984 | Eval Acc : 0.7873
     Batch 000 | Loss : 0.4912 | Acc : 0.7556
     Batch 025 | Loss : 0.5543 | Acc : 0.7277
     Batch 050 | Loss : 0.4727 | Acc : 0.7612
     Batch 075 | Loss : 0.3809 | Acc : 0.8151
     Batch 100 | Loss : 0.3909 | Acc : 0.8125
     Batch 125 | Loss : 0.3909 | Acc : 0.8261
     Batch 150 | Loss : 0.3743 | Acc : 0.8318
     Batch 175 | Loss : 0.4599 | Acc : 0.7696
     Batch 200 | Loss : 0.3626 | Acc : 0.8338
     Batch 225 | Loss : 0.4238 | Acc : 0.7901
     Batch 250 | Loss : 0.4929 | Acc : 0.7559
     Batch 275 | Loss : 0.4618 | Acc : 0.7765
     Batch 300 | Loss : 0.4095 | Acc : 0.7962
Epoch 00052 | Train Loss : 0.4162 | Eval Loss : 0.4163 | Train acc : 0.8009 | Eval Acc : 0.7983
     Batch 000 | Loss : 0.3508 | Acc : 0.8418
     Batch 025 | Loss : 0.3815 | Acc : 0.8191
     Batch 050 | Loss : 0.4334 | Acc : 0.7881
     Batch 075 | Loss : 0.4168 | Acc : 0.8029
     Batch 100 | Loss : 0.3600 | Acc : 0.8494
     Batch 125 | Loss : 0.3825 | Acc : 0.8158
     Batch 150 | Loss : 0.3648 | Acc : 0.8354
     Batch 175 | Loss : 0.3690 | Acc : 0.8300
     Batch 200 | Loss : 0.4674 | Acc : 0.7700
     Batch 225 | Loss : 0.5094 | Acc : 0.7372
     Batch 250 | Loss : 0.3780 | Acc : 0.8161
     Batch 275 | Loss : 0.4907 | Acc : 0.7472
     Batch 300 | Loss : 0.3692 | Acc : 0.8390
Epoch 00053 | Train Loss : 0.4134 | Eval Loss : 0.4174 | Train acc : 0.8027 | Eval Acc : 0.7995
     Batch 000 | Loss : 0.4480 | Acc : 0.7803
     Batch 025 | Loss : 0.5011 | Acc : 0.7599
     Batch 050 | Loss : 0.3643 | Acc : 0.8306
     Batch 075 | Loss : 0.4499 | Acc : 0.7802
     Batch 100 | Loss : 0.4082 | Acc : 0.8151
     Batch 125 | Loss : 0.5113 | Acc : 0.7455
     Batch 150 | Loss : 0.4119 | Acc : 0.7996
     Batch 175 | Loss : 0.3830 | Acc : 0.8201
     Batch 200 | Loss : 0.3553 | Acc : 0.8358
     Batch 225 | Loss : 0.3686 | Acc : 0.8284
     Batch 250 | Loss : 0.3580 | Acc : 0.8454
     Batch 275 | Loss : 0.4261 | Acc : 0.7925
     Batch 300 | Loss : 0.4105 | Acc : 0.7901
Epoch 00054 | Train Loss : 0.4128 | Eval Loss : 0.4179 | Train acc : 0.8031 | Eval Acc : 0.7974
     Batch 000 | Loss : 0.3836 | Acc : 0.8158
     Batch 025 | Loss : 0.3980 | Acc : 0.8154
     Batch 050 | Loss : 0.3979 | Acc : 0.8051
     Batch 075 | Loss : 0.3803 | Acc : 0.8282
     Batch 100 | Loss : 0.5306 | Acc : 0.7435
     Batch 125 | Loss : 0.3421 | Acc : 0.8428
     Batch 150 | Loss : 0.3680 | Acc : 0.8407
     Batch 175 | Loss : 0.4040 | Acc : 0.8120
     Batch 200 | Loss : 0.4294 | Acc : 0.7919
     Batch 225 | Loss : 0.3764 | Acc : 0.8334
     Batch 250 | Loss : 0.3730 | Acc : 0.8287
     Batch 275 | Loss : 0.4068 | Acc : 0.7972
     Batch 300 | Loss : 0.4650 | Acc : 0.7661
Epoch 00055 | Train Loss : 0.4130 | Eval Loss : 0.4379 | Train acc : 0.8028 | Eval Acc : 0.7857
     Batch 000 | Loss : 0.3873 | Acc : 0.8220
     Batch 025 | Loss : 0.3875 | Acc : 0.8247
     Batch 050 | Loss : 0.3818 | Acc : 0.8153
     Batch 075 | Loss : 0.4944 | Acc : 0.7636
     Batch 100 | Loss : 0.4219 | Acc : 0.7932
     Batch 125 | Loss : 0.4567 | Acc : 0.7680
     Batch 150 | Loss : 0.4517 | Acc : 0.7822
     Batch 175 | Loss : 0.3836 | Acc : 0.8294
     Batch 200 | Loss : 0.4750 | Acc : 0.7631
     Batch 225 | Loss : 0.3873 | Acc : 0.8210
     Batch 250 | Loss : 0.4891 | Acc : 0.7500
     Batch 275 | Loss : 0.4059 | Acc : 0.8097
     Batch 300 | Loss : 0.3758 | Acc : 0.8205
Epoch 00056 | Train Loss : 0.4129 | Eval Loss : 0.4161 | Train acc : 0.8033 | Eval Acc : 0.7986
     Batch 000 | Loss : 0.3375 | Acc : 0.8507
     Batch 025 | Loss : 0.4145 | Acc : 0.8000
     Batch 050 | Loss : 0.4061 | Acc : 0.8027
     Batch 075 | Loss : 0.4435 | Acc : 0.7812
     Batch 100 | Loss : 0.5026 | Acc : 0.7491
     Batch 125 | Loss : 0.4793 | Acc : 0.7587
     Batch 150 | Loss : 0.3832 | Acc : 0.8188
     Batch 175 | Loss : 0.4114 | Acc : 0.7946
     Batch 200 | Loss : 0.4816 | Acc : 0.7662
     Batch 225 | Loss : 0.3962 | Acc : 0.8145
     Batch 250 | Loss : 0.3768 | Acc : 0.8284
     Batch 275 | Loss : 0.4595 | Acc : 0.7677
     Batch 300 | Loss : 0.3266 | Acc : 0.8578
Epoch 00057 | Train Loss : 0.4072 | Eval Loss : 0.4155 | Train acc : 0.8060 | Eval Acc : 0.7982
     Batch 000 | Loss : 0.4841 | Acc : 0.7612
     Batch 025 | Loss : 0.4125 | Acc : 0.7961
     Batch 050 | Loss : 0.4070 | Acc : 0.8044
     Batch 075 | Loss : 0.4115 | Acc : 0.8007
     Batch 100 | Loss : 0.4341 | Acc : 0.7870
     Batch 125 | Loss : 0.3471 | Acc : 0.8450
     Batch 150 | Loss : 0.3909 | Acc : 0.8143
     Batch 175 | Loss : 0.3939 | Acc : 0.8190
     Batch 200 | Loss : 0.4794 | Acc : 0.7631
     Batch 225 | Loss : 0.3858 | Acc : 0.8252
     Batch 250 | Loss : 0.4474 | Acc : 0.7801
     Batch 275 | Loss : 0.4211 | Acc : 0.7977
     Batch 300 | Loss : 0.4864 | Acc : 0.7645
Epoch 00058 | Train Loss : 0.4069 | Eval Loss : 0.4156 | Train acc : 0.8061 | Eval Acc : 0.7983
     Batch 000 | Loss : 0.4708 | Acc : 0.7600
     Batch 025 | Loss : 0.3917 | Acc : 0.8196
     Batch 050 | Loss : 0.4516 | Acc : 0.7795
     Batch 075 | Loss : 0.3439 | Acc : 0.8446
     Batch 100 | Loss : 0.3311 | Acc : 0.8502
     Batch 125 | Loss : 0.3584 | Acc : 0.8336
     Batch 150 | Loss : 0.4474 | Acc : 0.7775
     Batch 175 | Loss : 0.3845 | Acc : 0.8386
     Batch 200 | Loss : 0.3317 | Acc : 0.8452
     Batch 225 | Loss : 0.4348 | Acc : 0.7898
     Batch 250 | Loss : 0.4578 | Acc : 0.7768
     Batch 275 | Loss : 0.3948 | Acc : 0.8202
     Batch 300 | Loss : 0.3415 | Acc : 0.8505
Epoch 00059 | Train Loss : 0.4069 | Eval Loss : 0.4132 | Train acc : 0.8065 | Eval Acc : 0.8007
     Batch 000 | Loss : 0.3678 | Acc : 0.8274
     Batch 025 | Loss : 0.3611 | Acc : 0.8308
     Batch 050 | Loss : 0.4363 | Acc : 0.7871
     Batch 075 | Loss : 0.3565 | Acc : 0.8473
     Batch 100 | Loss : 0.3402 | Acc : 0.8505
     Batch 125 | Loss : 0.3686 | Acc : 0.8326
     Batch 150 | Loss : 0.4145 | Acc : 0.8038
     Batch 175 | Loss : 0.3398 | Acc : 0.8387
     Batch 200 | Loss : 0.3335 | Acc : 0.8482
     Batch 225 | Loss : 0.4930 | Acc : 0.7435
     Batch 250 | Loss : 0.4489 | Acc : 0.7819
     Batch 275 | Loss : 0.3671 | Acc : 0.8324
     Batch 300 | Loss : 0.3957 | Acc : 0.8088
Epoch 00060 | Train Loss : 0.4053 | Eval Loss : 0.4117 | Train acc : 0.8066 | Eval Acc : 0.8011
     Batch 000 | Loss : 0.4753 | Acc : 0.7740
     Batch 025 | Loss : 0.3821 | Acc : 0.8248
     Batch 050 | Loss : 0.3609 | Acc : 0.8353
     Batch 075 | Loss : 0.4424 | Acc : 0.7817
     Batch 100 | Loss : 0.5701 | Acc : 0.7214
     Batch 125 | Loss : 0.3476 | Acc : 0.8438
     Batch 150 | Loss : 0.4009 | Acc : 0.8095
     Batch 175 | Loss : 0.3678 | Acc : 0.8356
     Batch 200 | Loss : 0.3710 | Acc : 0.8280
     Batch 225 | Loss : 0.3922 | Acc : 0.8152
     Batch 250 | Loss : 0.3915 | Acc : 0.8191
     Batch 275 | Loss : 0.3796 | Acc : 0.8229
     Batch 300 | Loss : 0.3494 | Acc : 0.8485
Epoch 00061 | Train Loss : 0.4054 | Eval Loss : 0.4146 | Train acc : 0.8070 | Eval Acc : 0.7989
     Batch 000 | Loss : 0.3925 | Acc : 0.8064
     Batch 025 | Loss : 0.4413 | Acc : 0.7803
     Batch 050 | Loss : 0.4026 | Acc : 0.8102
     Batch 075 | Loss : 0.5563 | Acc : 0.7465
     Batch 100 | Loss : 0.4273 | Acc : 0.7949
     Batch 125 | Loss : 0.3640 | Acc : 0.8226
     Batch 150 | Loss : 0.4015 | Acc : 0.8166
     Batch 175 | Loss : 0.3906 | Acc : 0.8182
     Batch 200 | Loss : 0.3754 | Acc : 0.8253
     Batch 225 | Loss : 0.3430 | Acc : 0.8487
     Batch 250 | Loss : 0.3763 | Acc : 0.8301
     Batch 275 | Loss : 0.3853 | Acc : 0.8200
     Batch 300 | Loss : 0.4516 | Acc : 0.7746
Epoch 00062 | Train Loss : 0.4050 | Eval Loss : 0.4107 | Train acc : 0.8071 | Eval Acc : 0.8018
     Batch 000 | Loss : 0.4390 | Acc : 0.7768
     Batch 025 | Loss : 0.4130 | Acc : 0.7911
     Batch 050 | Loss : 0.4996 | Acc : 0.7694
     Batch 075 | Loss : 0.3566 | Acc : 0.8411
     Batch 100 | Loss : 0.3726 | Acc : 0.8235
     Batch 125 | Loss : 0.3899 | Acc : 0.8144
     Batch 150 | Loss : 0.3711 | Acc : 0.8282
     Batch 175 | Loss : 0.3870 | Acc : 0.8134
     Batch 200 | Loss : 0.4719 | Acc : 0.7647
     Batch 225 | Loss : 0.3775 | Acc : 0.8217
     Batch 250 | Loss : 0.3623 | Acc : 0.8371
     Batch 275 | Loss : 0.4437 | Acc : 0.7866
     Batch 300 | Loss : 0.4570 | Acc : 0.7729
Epoch 00063 | Train Loss : 0.4068 | Eval Loss : 0.4318 | Train acc : 0.8068 | Eval Acc : 0.7900
     Batch 000 | Loss : 0.4196 | Acc : 0.7947
     Batch 025 | Loss : 0.3814 | Acc : 0.8291
     Batch 050 | Loss : 0.3889 | Acc : 0.8121
     Batch 075 | Loss : 0.4042 | Acc : 0.8032
     Batch 100 | Loss : 0.3518 | Acc : 0.8427
     Batch 125 | Loss : 0.3819 | Acc : 0.8202
     Batch 150 | Loss : 0.3758 | Acc : 0.8353
     Batch 175 | Loss : 0.4184 | Acc : 0.7944
     Batch 200 | Loss : 0.3803 | Acc : 0.8373
     Batch 225 | Loss : 0.3315 | Acc : 0.8529
     Batch 250 | Loss : 0.3555 | Acc : 0.8380
     Batch 275 | Loss : 0.4455 | Acc : 0.7854
     Batch 300 | Loss : 0.5803 | Acc : 0.7051
Epoch 00064 | Train Loss : 0.4041 | Eval Loss : 0.4406 | Train acc : 0.8075 | Eval Acc : 0.7836
     Batch 000 | Loss : 0.4570 | Acc : 0.7682
     Batch 025 | Loss : 0.5913 | Acc : 0.7087
     Batch 050 | Loss : 0.3610 | Acc : 0.8266
     Batch 075 | Loss : 0.4156 | Acc : 0.8006
     Batch 100 | Loss : 0.4161 | Acc : 0.7904
     Batch 125 | Loss : 0.4027 | Acc : 0.8105
     Batch 150 | Loss : 0.4407 | Acc : 0.7845
     Batch 175 | Loss : 0.3762 | Acc : 0.8183
     Batch 200 | Loss : 0.4788 | Acc : 0.7502
     Batch 225 | Loss : 0.3770 | Acc : 0.8273
     Batch 250 | Loss : 0.3838 | Acc : 0.8270
     Batch 275 | Loss : 0.3675 | Acc : 0.8271
     Batch 300 | Loss : 0.3487 | Acc : 0.8386
Epoch 00065 | Train Loss : 0.4063 | Eval Loss : 0.4308 | Train acc : 0.8068 | Eval Acc : 0.7920
     Batch 000 | Loss : 0.3867 | Acc : 0.8127
     Batch 025 | Loss : 0.3758 | Acc : 0.8342
     Batch 050 | Loss : 0.4195 | Acc : 0.7997
     Batch 075 | Loss : 0.3907 | Acc : 0.8199
     Batch 100 | Loss : 0.3580 | Acc : 0.8461
     Batch 125 | Loss : 0.3770 | Acc : 0.8363
     Batch 150 | Loss : 0.4428 | Acc : 0.7946
     Batch 175 | Loss : 0.4280 | Acc : 0.7899
     Batch 200 | Loss : 0.4780 | Acc : 0.7618
     Batch 225 | Loss : 0.4969 | Acc : 0.7508
     Batch 250 | Loss : 0.4321 | Acc : 0.7999
     Batch 275 | Loss : 0.4769 | Acc : 0.7709
     Batch 300 | Loss : 0.3670 | Acc : 0.8325
Epoch 00066 | Train Loss : 0.4051 | Eval Loss : 0.4083 | Train acc : 0.8073 | Eval Acc : 0.8031
     Batch 000 | Loss : 0.3787 | Acc : 0.8279
     Batch 025 | Loss : 0.4066 | Acc : 0.8059
     Batch 050 | Loss : 0.3749 | Acc : 0.8204
     Batch 075 | Loss : 0.4177 | Acc : 0.7946
     Batch 100 | Loss : 0.3983 | Acc : 0.8156
     Batch 125 | Loss : 0.4442 | Acc : 0.7955
     Batch 150 | Loss : 0.4136 | Acc : 0.7967
     Batch 175 | Loss : 0.3834 | Acc : 0.8155
     Batch 200 | Loss : 0.4334 | Acc : 0.8050
     Batch 225 | Loss : 0.4203 | Acc : 0.7905
     Batch 250 | Loss : 0.3981 | Acc : 0.8167
     Batch 275 | Loss : 0.3546 | Acc : 0.8462
     Batch 300 | Loss : 0.3505 | Acc : 0.8445
Epoch 00067 | Train Loss : 0.4088 | Eval Loss : 0.4147 | Train acc : 0.8059 | Eval Acc : 0.7992
     Batch 000 | Loss : 0.4723 | Acc : 0.7682
     Batch 025 | Loss : 0.4644 | Acc : 0.7783
     Batch 050 | Loss : 0.4357 | Acc : 0.7823
     Batch 075 | Loss : 0.3424 | Acc : 0.8481
     Batch 100 | Loss : 0.3810 | Acc : 0.8139
     Batch 125 | Loss : 0.3878 | Acc : 0.8200
     Batch 150 | Loss : 0.6194 | Acc : 0.7094
     Batch 175 | Loss : 0.4637 | Acc : 0.7796
     Batch 200 | Loss : 0.4111 | Acc : 0.8040
     Batch 225 | Loss : 0.4572 | Acc : 0.7786
     Batch 250 | Loss : 0.3818 | Acc : 0.8363
     Batch 275 | Loss : 0.3495 | Acc : 0.8512
     Batch 300 | Loss : 0.3566 | Acc : 0.8317
Epoch 00068 | Train Loss : 0.4022 | Eval Loss : 0.4107 | Train acc : 0.8090 | Eval Acc : 0.8022
     Batch 000 | Loss : 0.3895 | Acc : 0.8185
     Batch 025 | Loss : 0.4737 | Acc : 0.7716
     Batch 050 | Loss : 0.5068 | Acc : 0.7530
     Batch 075 | Loss : 0.3711 | Acc : 0.8313
     Batch 100 | Loss : 0.3543 | Acc : 0.8351
     Batch 125 | Loss : 0.3434 | Acc : 0.8401
     Batch 150 | Loss : 0.4386 | Acc : 0.7815
     Batch 175 | Loss : 0.3928 | Acc : 0.8100
     Batch 200 | Loss : 0.4125 | Acc : 0.7968
     Batch 225 | Loss : 0.3553 | Acc : 0.8357
     Batch 250 | Loss : 0.4050 | Acc : 0.8000
     Batch 275 | Loss : 0.3933 | Acc : 0.8145
     Batch 300 | Loss : 0.4257 | Acc : 0.7885
Epoch 00069 | Train Loss : 0.4040 | Eval Loss : 0.4313 | Train acc : 0.8081 | Eval Acc : 0.7918
     Batch 000 | Loss : 0.4188 | Acc : 0.8006
     Batch 025 | Loss : 0.4173 | Acc : 0.7980
     Batch 050 | Loss : 0.4505 | Acc : 0.7860
     Batch 075 | Loss : 0.3746 | Acc : 0.8330
     Batch 100 | Loss : 0.3694 | Acc : 0.8283
     Batch 125 | Loss : 0.3813 | Acc : 0.8220
     Batch 150 | Loss : 0.3868 | Acc : 0.8219
     Batch 175 | Loss : 0.3745 | Acc : 0.8263
     Batch 200 | Loss : 0.3604 | Acc : 0.8292
     Batch 225 | Loss : 0.4251 | Acc : 0.7862
     Batch 250 | Loss : 0.3464 | Acc : 0.8525
     Batch 275 | Loss : 0.4331 | Acc : 0.7836
     Batch 300 | Loss : 0.4010 | Acc : 0.8032
Epoch 00070 | Train Loss : 0.4033 | Eval Loss : 0.4163 | Train acc : 0.8080 | Eval Acc : 0.8004
     Batch 000 | Loss : 0.4123 | Acc : 0.7968
     Batch 025 | Loss : 0.4303 | Acc : 0.7969
     Batch 050 | Loss : 0.4652 | Acc : 0.7739
     Batch 075 | Loss : 0.3822 | Acc : 0.8201
     Batch 100 | Loss : 0.4062 | Acc : 0.8135
     Batch 125 | Loss : 0.4238 | Acc : 0.7966
     Batch 150 | Loss : 0.3998 | Acc : 0.8010
     Batch 175 | Loss : 0.3851 | Acc : 0.8251
     Batch 200 | Loss : 0.4391 | Acc : 0.7877
     Batch 225 | Loss : 0.4407 | Acc : 0.7810
     Batch 250 | Loss : 0.3623 | Acc : 0.8296
     Batch 275 | Loss : 0.3299 | Acc : 0.8486
     Batch 300 | Loss : 0.4210 | Acc : 0.7966
Epoch 00071 | Train Loss : 0.4021 | Eval Loss : 0.4171 | Train acc : 0.8091 | Eval Acc : 0.7993
     Batch 000 | Loss : 0.4375 | Acc : 0.7869
     Batch 025 | Loss : 0.4317 | Acc : 0.7868
     Batch 050 | Loss : 0.4496 | Acc : 0.7853
     Batch 075 | Loss : 0.4606 | Acc : 0.7687
     Batch 100 | Loss : 0.3596 | Acc : 0.8311
     Batch 125 | Loss : 0.4648 | Acc : 0.7808
     Batch 150 | Loss : 0.5109 | Acc : 0.7587
     Batch 175 | Loss : 0.4382 | Acc : 0.7809
     Batch 200 | Loss : 0.3199 | Acc : 0.8625
     Batch 225 | Loss : 0.4712 | Acc : 0.7617
     Batch 250 | Loss : 0.3638 | Acc : 0.8325
     Batch 275 | Loss : 0.5127 | Acc : 0.7414
     Batch 300 | Loss : 0.3652 | Acc : 0.8361
Epoch 00072 | Train Loss : 0.4023 | Eval Loss : 0.4241 | Train acc : 0.8083 | Eval Acc : 0.7943
     Batch 000 | Loss : 0.4052 | Acc : 0.8168
     Batch 025 | Loss : 0.4270 | Acc : 0.7960
     Batch 050 | Loss : 0.4724 | Acc : 0.7799
     Batch 075 | Loss : 0.4140 | Acc : 0.7942
     Batch 100 | Loss : 0.3807 | Acc : 0.8172
     Batch 125 | Loss : 0.3797 | Acc : 0.8236
     Batch 150 | Loss : 0.4135 | Acc : 0.8053
     Batch 175 | Loss : 0.4535 | Acc : 0.7835
     Batch 200 | Loss : 0.4375 | Acc : 0.7861
     Batch 225 | Loss : 0.4414 | Acc : 0.7683
     Batch 250 | Loss : 0.4800 | Acc : 0.7557
     Batch 275 | Loss : 0.4381 | Acc : 0.7850
     Batch 300 | Loss : 0.3450 | Acc : 0.8529
Epoch 00073 | Train Loss : 0.4032 | Eval Loss : 0.4137 | Train acc : 0.8084 | Eval Acc : 0.8009
     Batch 000 | Loss : 0.3753 | Acc : 0.8209
     Batch 025 | Loss : 0.3712 | Acc : 0.8327
     Batch 050 | Loss : 0.4670 | Acc : 0.7621
     Batch 075 | Loss : 0.4154 | Acc : 0.7935
     Batch 100 | Loss : 0.3807 | Acc : 0.8267
     Batch 125 | Loss : 0.3520 | Acc : 0.8300
     Batch 150 | Loss : 0.3934 | Acc : 0.8162
     Batch 175 | Loss : 0.3951 | Acc : 0.8140
     Batch 200 | Loss : 0.4249 | Acc : 0.7921
     Batch 225 | Loss : 0.3706 | Acc : 0.8202
     Batch 250 | Loss : 0.4099 | Acc : 0.7969
     Batch 275 | Loss : 0.4998 | Acc : 0.7578
     Batch 300 | Loss : 0.4069 | Acc : 0.8104
Epoch 00074 | Train Loss : 0.4024 | Eval Loss : 0.4067 | Train acc : 0.8086 | Eval Acc : 0.8033
     Batch 000 | Loss : 0.3851 | Acc : 0.8220
     Batch 025 | Loss : 0.4251 | Acc : 0.7942
     Batch 050 | Loss : 0.3472 | Acc : 0.8417
     Batch 075 | Loss : 0.4039 | Acc : 0.8025
     Batch 100 | Loss : 0.4282 | Acc : 0.7870
     Batch 125 | Loss : 0.4424 | Acc : 0.7857
     Batch 150 | Loss : 0.3826 | Acc : 0.8217
     Batch 175 | Loss : 0.3676 | Acc : 0.8307
     Batch 200 | Loss : 0.3816 | Acc : 0.8298
     Batch 225 | Loss : 0.3412 | Acc : 0.8471
     Batch 250 | Loss : 0.4789 | Acc : 0.7608
     Batch 275 | Loss : 0.3359 | Acc : 0.8443
     Batch 300 | Loss : 0.3537 | Acc : 0.8353
Epoch 00075 | Train Loss : 0.4012 | Eval Loss : 0.4113 | Train acc : 0.8092 | Eval Acc : 0.8017
     Batch 000 | Loss : 0.4616 | Acc : 0.7758
     Batch 025 | Loss : 0.4863 | Acc : 0.7587
     Batch 050 | Loss : 0.4811 | Acc : 0.7547
     Batch 075 | Loss : 0.4662 | Acc : 0.7642
     Batch 100 | Loss : 0.4270 | Acc : 0.7916
     Batch 125 | Loss : 0.3452 | Acc : 0.8401
     Batch 150 | Loss : 0.3702 | Acc : 0.8257
     Batch 175 | Loss : 0.3647 | Acc : 0.8292
     Batch 200 | Loss : 0.4218 | Acc : 0.7975
     Batch 225 | Loss : 0.3958 | Acc : 0.8136
     Batch 250 | Loss : 0.4125 | Acc : 0.8013
     Batch 275 | Loss : 0.4007 | Acc : 0.8008
     Batch 300 | Loss : 0.3908 | Acc : 0.8177
Epoch 00076 | Train Loss : 0.4028 | Eval Loss : 0.4113 | Train acc : 0.8086 | Eval Acc : 0.8027
     Batch 000 | Loss : 0.4743 | Acc : 0.7632
     Batch 025 | Loss : 0.3557 | Acc : 0.8367
     Batch 050 | Loss : 0.4521 | Acc : 0.7689
     Batch 075 | Loss : 0.4393 | Acc : 0.7890
     Batch 100 | Loss : 0.3795 | Acc : 0.8167
     Batch 125 | Loss : 0.3263 | Acc : 0.8575
     Batch 150 | Loss : 0.3777 | Acc : 0.8228
     Batch 175 | Loss : 0.4463 | Acc : 0.7857
     Batch 200 | Loss : 0.3568 | Acc : 0.8381
     Batch 225 | Loss : 0.4415 | Acc : 0.7904
     Batch 250 | Loss : 0.3286 | Acc : 0.8582
     Batch 275 | Loss : 0.3467 | Acc : 0.8433
     Batch 300 | Loss : 0.4836 | Acc : 0.7572
Epoch 00077 | Train Loss : 0.4028 | Eval Loss : 0.4195 | Train acc : 0.8087 | Eval Acc : 0.7973
     Batch 000 | Loss : 0.3671 | Acc : 0.8268
     Batch 025 | Loss : 0.3497 | Acc : 0.8405
     Batch 050 | Loss : 0.4237 | Acc : 0.7994
     Batch 075 | Loss : 0.5249 | Acc : 0.7392
     Batch 100 | Loss : 0.3446 | Acc : 0.8458
     Batch 125 | Loss : 0.3773 | Acc : 0.8209
     Batch 150 | Loss : 0.3718 | Acc : 0.8316
     Batch 175 | Loss : 0.4142 | Acc : 0.8003
     Batch 200 | Loss : 0.3749 | Acc : 0.8196
     Batch 225 | Loss : 0.3569 | Acc : 0.8478
     Batch 250 | Loss : 0.3604 | Acc : 0.8367
     Batch 275 | Loss : 0.5025 | Acc : 0.7504
     Batch 300 | Loss : 0.4387 | Acc : 0.7866
Epoch 00078 | Train Loss : 0.4021 | Eval Loss : 0.4073 | Train acc : 0.8090 | Eval Acc : 0.8034
     Batch 000 | Loss : 0.3449 | Acc : 0.8459
     Batch 025 | Loss : 0.3644 | Acc : 0.8347
     Batch 050 | Loss : 0.3848 | Acc : 0.8161
     Batch 075 | Loss : 0.4305 | Acc : 0.7852
     Batch 100 | Loss : 0.3364 | Acc : 0.8527
     Batch 125 | Loss : 0.3508 | Acc : 0.8412
     Batch 150 | Loss : 0.4388 | Acc : 0.7802
     Batch 175 | Loss : 0.4078 | Acc : 0.8052
     Batch 200 | Loss : 0.3332 | Acc : 0.8537
     Batch 225 | Loss : 0.3716 | Acc : 0.8301
     Batch 250 | Loss : 0.3838 | Acc : 0.8140
     Batch 275 | Loss : 0.3349 | Acc : 0.8502
     Batch 300 | Loss : 0.4123 | Acc : 0.8043
Epoch 00079 | Train Loss : 0.4024 | Eval Loss : 0.4229 | Train acc : 0.8089 | Eval Acc : 0.7970
     Batch 000 | Loss : 0.3507 | Acc : 0.8473
     Batch 025 | Loss : 0.3753 | Acc : 0.8351
     Batch 050 | Loss : 0.4444 | Acc : 0.7732
     Batch 075 | Loss : 0.3481 | Acc : 0.8425
     Batch 100 | Loss : 0.4118 | Acc : 0.7962
     Batch 125 | Loss : 0.4038 | Acc : 0.8054
     Batch 150 | Loss : 0.4591 | Acc : 0.7679
     Batch 175 | Loss : 0.4111 | Acc : 0.8118
     Batch 200 | Loss : 0.4364 | Acc : 0.7874
     Batch 225 | Loss : 0.3592 | Acc : 0.8385
     Batch 250 | Loss : 0.4061 | Acc : 0.8048
     Batch 275 | Loss : 0.4473 | Acc : 0.7821
     Batch 300 | Loss : 0.3984 | Acc : 0.8104
Epoch 00080 | Train Loss : 0.4018 | Eval Loss : 0.4116 | Train acc : 0.8093 | Eval Acc : 0.8025
     Batch 000 | Loss : 0.3417 | Acc : 0.8442
     Batch 025 | Loss : 0.3792 | Acc : 0.8145
     Batch 050 | Loss : 0.3869 | Acc : 0.8160
     Batch 075 | Loss : 0.3523 | Acc : 0.8433
     Batch 100 | Loss : 0.3572 | Acc : 0.8311
     Batch 125 | Loss : 0.4044 | Acc : 0.8153
     Batch 150 | Loss : 0.4266 | Acc : 0.7874
     Batch 175 | Loss : 0.3688 | Acc : 0.8355
     Batch 200 | Loss : 0.3826 | Acc : 0.8189
     Batch 225 | Loss : 0.4069 | Acc : 0.7995
     Batch 250 | Loss : 0.3340 | Acc : 0.8533
     Batch 275 | Loss : 0.3794 | Acc : 0.8266
     Batch 300 | Loss : 0.4387 | Acc : 0.7873
Epoch 00081 | Train Loss : 0.4001 | Eval Loss : 0.4177 | Train acc : 0.8099 | Eval Acc : 0.7983
     Batch 000 | Loss : 0.4613 | Acc : 0.7734
     Batch 025 | Loss : 0.4210 | Acc : 0.7925
     Batch 050 | Loss : 0.4249 | Acc : 0.7927
     Batch 075 | Loss : 0.3885 | Acc : 0.8388
     Batch 100 | Loss : 0.5686 | Acc : 0.7133
     Batch 125 | Loss : 0.3293 | Acc : 0.8541
     Batch 150 | Loss : 0.3969 | Acc : 0.8114
     Batch 175 | Loss : 0.4238 | Acc : 0.7879
     Batch 200 | Loss : 0.3887 | Acc : 0.8186
     Batch 225 | Loss : 0.3493 | Acc : 0.8587
     Batch 250 | Loss : 0.4723 | Acc : 0.7697
     Batch 275 | Loss : 0.4467 | Acc : 0.7757
     Batch 300 | Loss : 0.4188 | Acc : 0.7880
Epoch 00082 | Train Loss : 0.4037 | Eval Loss : 0.4098 | Train acc : 0.8083 | Eval Acc : 0.8031
     Batch 000 | Loss : 0.3532 | Acc : 0.8506
     Batch 025 | Loss : 0.4349 | Acc : 0.7856
     Batch 050 | Loss : 0.3785 | Acc : 0.8182
     Batch 075 | Loss : 0.3598 | Acc : 0.8261
     Batch 100 | Loss : 0.3539 | Acc : 0.8385
     Batch 125 | Loss : 0.3610 | Acc : 0.8326
     Batch 150 | Loss : 0.3557 | Acc : 0.8392
     Batch 175 | Loss : 0.3966 | Acc : 0.8113
     Batch 200 | Loss : 0.4341 | Acc : 0.7880
     Batch 225 | Loss : 0.3749 | Acc : 0.8195
     Batch 250 | Loss : 0.3535 | Acc : 0.8428
     Batch 275 | Loss : 0.3590 | Acc : 0.8411
     Batch 300 | Loss : 0.3663 | Acc : 0.8307
Epoch 00083 | Train Loss : 0.4000 | Eval Loss : 0.4152 | Train acc : 0.8101 | Eval Acc : 0.8007
     Batch 000 | Loss : 0.4709 | Acc : 0.7636
     Batch 025 | Loss : 0.4174 | Acc : 0.7971
     Batch 050 | Loss : 0.3434 | Acc : 0.8483
     Batch 075 | Loss : 0.3767 | Acc : 0.8221
     Batch 100 | Loss : 0.3765 | Acc : 0.8155
     Batch 125 | Loss : 0.4041 | Acc : 0.8065
     Batch 150 | Loss : 0.3676 | Acc : 0.8297
     Batch 175 | Loss : 0.4141 | Acc : 0.7958
     Batch 200 | Loss : 0.4448 | Acc : 0.7855
     Batch 225 | Loss : 0.3772 | Acc : 0.8285
     Batch 250 | Loss : 0.3634 | Acc : 0.8359
     Batch 275 | Loss : 0.3596 | Acc : 0.8277
     Batch 300 | Loss : 0.3380 | Acc : 0.8421
Epoch 00084 | Train Loss : 0.4011 | Eval Loss : 0.4065 | Train acc : 0.8096 | Eval Acc : 0.8039
     Batch 000 | Loss : 0.3305 | Acc : 0.8580
     Batch 025 | Loss : 0.3424 | Acc : 0.8458
     Batch 050 | Loss : 0.3476 | Acc : 0.8395
     Batch 075 | Loss : 0.3700 | Acc : 0.8269
     Batch 100 | Loss : 0.4010 | Acc : 0.8164
     Batch 125 | Loss : 0.3355 | Acc : 0.8522
     Batch 150 | Loss : 0.3565 | Acc : 0.8381
     Batch 175 | Loss : 0.3644 | Acc : 0.8271
     Batch 200 | Loss : 0.4221 | Acc : 0.7923
     Batch 225 | Loss : 0.4196 | Acc : 0.7909
     Batch 250 | Loss : 0.4159 | Acc : 0.8068
     Batch 275 | Loss : 0.4239 | Acc : 0.7934
     Batch 300 | Loss : 0.4149 | Acc : 0.7934
Epoch 00085 | Train Loss : 0.4031 | Eval Loss : 0.4064 | Train acc : 0.8085 | Eval Acc : 0.8044
     Batch 000 | Loss : 0.4169 | Acc : 0.7897
     Batch 025 | Loss : 0.4101 | Acc : 0.7991
     Batch 050 | Loss : 0.3934 | Acc : 0.8209
     Batch 075 | Loss : 0.3467 | Acc : 0.8425
     Batch 100 | Loss : 0.3776 | Acc : 0.8227
     Batch 125 | Loss : 0.3417 | Acc : 0.8415
     Batch 150 | Loss : 0.3295 | Acc : 0.8541
     Batch 175 | Loss : 0.4818 | Acc : 0.7582
     Batch 200 | Loss : 0.4632 | Acc : 0.7765
     Batch 225 | Loss : 0.4134 | Acc : 0.7946
     Batch 250 | Loss : 0.4196 | Acc : 0.7957
     Batch 275 | Loss : 0.3958 | Acc : 0.8147
     Batch 300 | Loss : 0.3658 | Acc : 0.8370
Epoch 00086 | Train Loss : 0.4002 | Eval Loss : 0.4068 | Train acc : 0.8096 | Eval Acc : 0.8029
     Batch 000 | Loss : 0.3957 | Acc : 0.8064
     Batch 025 | Loss : 0.5390 | Acc : 0.7214
     Batch 050 | Loss : 0.4464 | Acc : 0.7884
     Batch 075 | Loss : 0.3915 | Acc : 0.8101
     Batch 100 | Loss : 0.3547 | Acc : 0.8346
     Batch 125 | Loss : 0.4753 | Acc : 0.7636
     Batch 150 | Loss : 0.3679 | Acc : 0.8224
     Batch 175 | Loss : 0.3745 | Acc : 0.8254
     Batch 200 | Loss : 0.4133 | Acc : 0.8093
     Batch 225 | Loss : 0.4705 | Acc : 0.7740
     Batch 250 | Loss : 0.3777 | Acc : 0.8144
     Batch 275 | Loss : 0.3672 | Acc : 0.8364
     Batch 300 | Loss : 0.3749 | Acc : 0.8294
Epoch 00087 | Train Loss : 0.3998 | Eval Loss : 0.4319 | Train acc : 0.8101 | Eval Acc : 0.7942
     Batch 000 | Loss : 0.3735 | Acc : 0.8413
     Batch 025 | Loss : 0.3877 | Acc : 0.8310
     Batch 050 | Loss : 0.4453 | Acc : 0.7629
     Batch 075 | Loss : 0.3448 | Acc : 0.8385
     Batch 100 | Loss : 0.3937 | Acc : 0.8148
     Batch 125 | Loss : 0.4028 | Acc : 0.8031
     Batch 150 | Loss : 0.3956 | Acc : 0.8110
     Batch 175 | Loss : 0.4069 | Acc : 0.8030
     Batch 200 | Loss : 0.4049 | Acc : 0.8218
     Batch 225 | Loss : 0.4160 | Acc : 0.8043
     Batch 250 | Loss : 0.3957 | Acc : 0.8117
     Batch 275 | Loss : 0.4014 | Acc : 0.8049
     Batch 300 | Loss : 0.3921 | Acc : 0.8155
Epoch 00088 | Train Loss : 0.4026 | Eval Loss : 0.4243 | Train acc : 0.8089 | Eval Acc : 0.7924
     Batch 000 | Loss : 0.4674 | Acc : 0.7631
     Batch 025 | Loss : 0.4096 | Acc : 0.7962
     Batch 050 | Loss : 0.3760 | Acc : 0.8214
     Batch 075 | Loss : 0.4134 | Acc : 0.8028
     Batch 100 | Loss : 0.3580 | Acc : 0.8340
     Batch 125 | Loss : 0.3771 | Acc : 0.8262
     Batch 150 | Loss : 0.3495 | Acc : 0.8410
     Batch 175 | Loss : 0.3771 | Acc : 0.8167
     Batch 200 | Loss : 0.3898 | Acc : 0.8223
     Batch 225 | Loss : 0.3683 | Acc : 0.8253
     Batch 250 | Loss : 0.3981 | Acc : 0.8027
     Batch 275 | Loss : 0.4884 | Acc : 0.7598
     Batch 300 | Loss : 0.3904 | Acc : 0.8191
Epoch 00089 | Train Loss : 0.4027 | Eval Loss : 0.4122 | Train acc : 0.8086 | Eval Acc : 0.8008
     Batch 000 | Loss : 0.3990 | Acc : 0.8012
     Batch 025 | Loss : 0.4192 | Acc : 0.7903
     Batch 050 | Loss : 0.3494 | Acc : 0.8415
     Batch 075 | Loss : 0.4237 | Acc : 0.7858
     Batch 100 | Loss : 0.3571 | Acc : 0.8339
     Batch 125 | Loss : 0.4323 | Acc : 0.7832
     Batch 150 | Loss : 0.4917 | Acc : 0.7596
     Batch 175 | Loss : 0.3961 | Acc : 0.8181
     Batch 200 | Loss : 0.3849 | Acc : 0.8214
     Batch 225 | Loss : 0.4355 | Acc : 0.7957
     Batch 250 | Loss : 0.3992 | Acc : 0.8041
     Batch 275 | Loss : 0.3869 | Acc : 0.8127
     Batch 300 | Loss : 0.4427 | Acc : 0.7978
Epoch 00090 | Train Loss : 0.4014 | Eval Loss : 0.4085 | Train acc : 0.8093 | Eval Acc : 0.8026
     Batch 000 | Loss : 0.4953 | Acc : 0.7538
     Batch 025 | Loss : 0.4102 | Acc : 0.8033
     Batch 050 | Loss : 0.3623 | Acc : 0.8304
     Batch 075 | Loss : 0.4490 | Acc : 0.7768
     Batch 100 | Loss : 0.3912 | Acc : 0.8130
     Batch 125 | Loss : 0.4324 | Acc : 0.7945
     Batch 150 | Loss : 0.3411 | Acc : 0.8444
     Batch 175 | Loss : 0.4106 | Acc : 0.7997
     Batch 200 | Loss : 0.4254 | Acc : 0.7858
     Batch 225 | Loss : 0.4522 | Acc : 0.7804
     Batch 250 | Loss : 0.3710 | Acc : 0.8274
     Batch 275 | Loss : 0.4392 | Acc : 0.7891
     Batch 300 | Loss : 0.3691 | Acc : 0.8260
Epoch 00091 | Train Loss : 0.3977 | Eval Loss : 0.4053 | Train acc : 0.8113 | Eval Acc : 0.8051
     Batch 000 | Loss : 0.4158 | Acc : 0.7931
     Batch 025 | Loss : 0.3605 | Acc : 0.8332
     Batch 050 | Loss : 0.5367 | Acc : 0.7572
     Batch 075 | Loss : 0.4675 | Acc : 0.7644
     Batch 100 | Loss : 0.4314 | Acc : 0.7882
     Batch 125 | Loss : 0.4181 | Acc : 0.7933
     Batch 150 | Loss : 0.3382 | Acc : 0.8472
     Batch 175 | Loss : 0.4615 | Acc : 0.7768
     Batch 200 | Loss : 0.3427 | Acc : 0.8438
     Batch 225 | Loss : 0.3890 | Acc : 0.8140
     Batch 250 | Loss : 0.3834 | Acc : 0.8172
     Batch 275 | Loss : 0.3717 | Acc : 0.8296
     Batch 300 | Loss : 0.4696 | Acc : 0.7690
Epoch 00092 | Train Loss : 0.3990 | Eval Loss : 0.4065 | Train acc : 0.8107 | Eval Acc : 0.8055
     Batch 000 | Loss : 0.5268 | Acc : 0.7530
     Batch 025 | Loss : 0.4693 | Acc : 0.7724
     Batch 050 | Loss : 0.4438 | Acc : 0.7812
     Batch 075 | Loss : 0.4173 | Acc : 0.7962
     Batch 100 | Loss : 0.3458 | Acc : 0.8540
     Batch 125 | Loss : 0.3784 | Acc : 0.8165
     Batch 150 | Loss : 0.3671 | Acc : 0.8323
     Batch 175 | Loss : 0.3731 | Acc : 0.8211
     Batch 200 | Loss : 0.3943 | Acc : 0.8151
     Batch 225 | Loss : 0.3744 | Acc : 0.8390
     Batch 250 | Loss : 0.3609 | Acc : 0.8362
     Batch 275 | Loss : 0.4076 | Acc : 0.7986
     Batch 300 | Loss : 0.3996 | Acc : 0.8049
Epoch 00093 | Train Loss : 0.3969 | Eval Loss : 0.4267 | Train acc : 0.8117 | Eval Acc : 0.7942
     Batch 000 | Loss : 0.3773 | Acc : 0.8104
     Batch 025 | Loss : 0.4522 | Acc : 0.7845
     Batch 050 | Loss : 0.3585 | Acc : 0.8432
     Batch 075 | Loss : 0.3662 | Acc : 0.8293
     Batch 100 | Loss : 0.4330 | Acc : 0.7961
     Batch 125 | Loss : 0.3608 | Acc : 0.8355
     Batch 150 | Loss : 0.4838 | Acc : 0.7651
     Batch 175 | Loss : 0.4165 | Acc : 0.8045
     Batch 200 | Loss : 0.3554 | Acc : 0.8381
     Batch 225 | Loss : 0.5101 | Acc : 0.7520
     Batch 250 | Loss : 0.4987 | Acc : 0.7627
     Batch 275 | Loss : 0.3621 | Acc : 0.8299
     Batch 300 | Loss : 0.3581 | Acc : 0.8296
Epoch 00094 | Train Loss : 0.4021 | Eval Loss : 0.4075 | Train acc : 0.8093 | Eval Acc : 0.8046
     Batch 000 | Loss : 0.3928 | Acc : 0.8169
     Batch 025 | Loss : 0.3503 | Acc : 0.8398
     Batch 050 | Loss : 0.3482 | Acc : 0.8425
     Batch 075 | Loss : 0.4402 | Acc : 0.7885
     Batch 100 | Loss : 0.5677 | Acc : 0.7487
     Batch 125 | Loss : 0.4887 | Acc : 0.7662
     Batch 150 | Loss : 0.3440 | Acc : 0.8431
     Batch 175 | Loss : 0.3686 | Acc : 0.8252
     Batch 200 | Loss : 0.4987 | Acc : 0.7630
     Batch 225 | Loss : 0.3832 | Acc : 0.8267
     Batch 250 | Loss : 0.4482 | Acc : 0.7895
     Batch 275 | Loss : 0.3448 | Acc : 0.8412
     Batch 300 | Loss : 0.3285 | Acc : 0.8506
Epoch 00095 | Train Loss : 0.3995 | Eval Loss : 0.4128 | Train acc : 0.8108 | Eval Acc : 0.8044
     Batch 000 | Loss : 0.4179 | Acc : 0.8000
     Batch 025 | Loss : 0.4114 | Acc : 0.8104
     Batch 050 | Loss : 0.3616 | Acc : 0.8303
     Batch 075 | Loss : 0.4244 | Acc : 0.7884
     Batch 100 | Loss : 0.4369 | Acc : 0.7861
     Batch 125 | Loss : 0.4351 | Acc : 0.7853
     Batch 150 | Loss : 0.4088 | Acc : 0.8022
     Batch 175 | Loss : 0.3660 | Acc : 0.8384
     Batch 200 | Loss : 0.3627 | Acc : 0.8356
     Batch 225 | Loss : 0.4125 | Acc : 0.7959
     Batch 250 | Loss : 0.4399 | Acc : 0.7849
     Batch 275 | Loss : 0.3438 | Acc : 0.8455
     Batch 300 | Loss : 0.3509 | Acc : 0.8423
Epoch 00096 | Train Loss : 0.3968 | Eval Loss : 0.4196 | Train acc : 0.8118 | Eval Acc : 0.8017
     Batch 000 | Loss : 0.3569 | Acc : 0.8341
     Batch 025 | Loss : 0.3979 | Acc : 0.8128
     Batch 050 | Loss : 0.5213 | Acc : 0.7537
     Batch 075 | Loss : 0.4067 | Acc : 0.8037
     Batch 100 | Loss : 0.3406 | Acc : 0.8429
     Batch 125 | Loss : 0.3593 | Acc : 0.8296
     Batch 150 | Loss : 0.4717 | Acc : 0.7742
     Batch 175 | Loss : 0.3544 | Acc : 0.8386
     Batch 200 | Loss : 0.4270 | Acc : 0.7947
     Batch 225 | Loss : 0.3261 | Acc : 0.8562
     Batch 250 | Loss : 0.4137 | Acc : 0.8074
     Batch 275 | Loss : 0.4253 | Acc : 0.7925
     Batch 300 | Loss : 0.3635 | Acc : 0.8341
Epoch 00097 | Train Loss : 0.4011 | Eval Loss : 0.4075 | Train acc : 0.8098 | Eval Acc : 0.8052
     Batch 000 | Loss : 0.4105 | Acc : 0.8034
     Batch 025 | Loss : 0.4677 | Acc : 0.7617
     Batch 050 | Loss : 0.3476 | Acc : 0.8448
     Batch 075 | Loss : 0.4352 | Acc : 0.7901
     Batch 100 | Loss : 0.4007 | Acc : 0.8100
     Batch 125 | Loss : 0.3274 | Acc : 0.8531
     Batch 150 | Loss : 0.3578 | Acc : 0.8372
     Batch 175 | Loss : 0.4418 | Acc : 0.7874
     Batch 200 | Loss : 0.4692 | Acc : 0.7654
     Batch 225 | Loss : 0.4483 | Acc : 0.7873
     Batch 250 | Loss : 0.4625 | Acc : 0.7899
     Batch 275 | Loss : 0.4819 | Acc : 0.7668
     Batch 300 | Loss : 0.4675 | Acc : 0.7663
Epoch 00098 | Train Loss : 0.3983 | Eval Loss : 0.4153 | Train acc : 0.8115 | Eval Acc : 0.8017
     Batch 000 | Loss : 0.3710 | Acc : 0.8318
     Batch 025 | Loss : 0.3796 | Acc : 0.8200
     Batch 050 | Loss : 0.4116 | Acc : 0.7963
     Batch 075 | Loss : 0.4649 | Acc : 0.7679
     Batch 100 | Loss : 0.4423 | Acc : 0.7802
     Batch 125 | Loss : 0.3955 | Acc : 0.8077
     Batch 150 | Loss : 0.4613 | Acc : 0.7641
     Batch 175 | Loss : 0.5006 | Acc : 0.7616
     Batch 200 | Loss : 0.3420 | Acc : 0.8392
     Batch 225 | Loss : 0.3518 | Acc : 0.8433
     Batch 250 | Loss : 0.4358 | Acc : 0.7883
     Batch 275 | Loss : 0.4052 | Acc : 0.8125
     Batch 300 | Loss : 0.4247 | Acc : 0.7963
Epoch 00099 | Train Loss : 0.3999 | Eval Loss : 0.4098 | Train acc : 0.8104 | Eval Acc : 0.8025
     Batch 000 | Loss : 0.4689 | Acc : 0.7680
     Batch 025 | Loss : 0.6275 | Acc : 0.7045
     Batch 050 | Loss : 0.4028 | Acc : 0.8004
     Batch 075 | Loss : 0.4763 | Acc : 0.7532
     Batch 100 | Loss : 0.4225 | Acc : 0.8028
     Batch 125 | Loss : 0.3473 | Acc : 0.8427
     Batch 150 | Loss : 0.4304 | Acc : 0.7868
     Batch 175 | Loss : 0.3152 | Acc : 0.8637
     Batch 200 | Loss : 0.4468 | Acc : 0.7878
     Batch 225 | Loss : 0.4429 | Acc : 0.7854
     Batch 250 | Loss : 0.3868 | Acc : 0.8118
     Batch 275 | Loss : 0.3755 | Acc : 0.8229
     Batch 300 | Loss : 0.4165 | Acc : 0.8018
Epoch 00100 | Train Loss : 0.4014 | Eval Loss : 0.4102 | Train acc : 0.8097 | Eval Acc : 0.8009
     Batch 000 | Loss : 0.3997 | Acc : 0.8070
     Batch 025 | Loss : 0.4168 | Acc : 0.7956
     Batch 050 | Loss : 0.3958 | Acc : 0.8099
     Batch 075 | Loss : 0.3683 | Acc : 0.8237
     Batch 100 | Loss : 0.4162 | Acc : 0.7976
     Batch 125 | Loss : 0.3431 | Acc : 0.8471
     Batch 150 | Loss : 0.3911 | Acc : 0.8176
     Batch 175 | Loss : 0.4213 | Acc : 0.7917
     Batch 200 | Loss : 0.4704 | Acc : 0.7561
     Batch 225 | Loss : 0.3875 | Acc : 0.8138
     Batch 250 | Loss : 0.3610 | Acc : 0.8333
     Batch 275 | Loss : 0.3566 | Acc : 0.8426
     Batch 300 | Loss : 0.3681 | Acc : 0.8326
Epoch 00101 | Train Loss : 0.3970 | Eval Loss : 0.4107 | Train acc : 0.8113 | Eval Acc : 0.8027
     Batch 000 | Loss : 0.4416 | Acc : 0.7739
     Batch 025 | Loss : 0.3567 | Acc : 0.8318
     Batch 050 | Loss : 0.3518 | Acc : 0.8436
     Batch 075 | Loss : 0.3631 | Acc : 0.8390
     Batch 100 | Loss : 0.3378 | Acc : 0.8516
     Batch 125 | Loss : 0.4730 | Acc : 0.7740
     Batch 150 | Loss : 0.4247 | Acc : 0.7959
     Batch 175 | Loss : 0.4685 | Acc : 0.7686
     Batch 200 | Loss : 0.3423 | Acc : 0.8469
     Batch 225 | Loss : 0.3937 | Acc : 0.8221
     Batch 250 | Loss : 0.4247 | Acc : 0.7900
     Batch 275 | Loss : 0.3874 | Acc : 0.8184
     Batch 300 | Loss : 0.3783 | Acc : 0.8169
Epoch 00102 | Train Loss : 0.3984 | Eval Loss : 0.4074 | Train acc : 0.8112 | Eval Acc : 0.8048
     Batch 000 | Loss : 0.4554 | Acc : 0.7708
     Batch 025 | Loss : 0.4002 | Acc : 0.8022
     Batch 050 | Loss : 0.3768 | Acc : 0.8261
     Batch 075 | Loss : 0.3894 | Acc : 0.8149
     Batch 100 | Loss : 0.3667 | Acc : 0.8281
     Batch 125 | Loss : 0.3692 | Acc : 0.8264
     Batch 150 | Loss : 0.4483 | Acc : 0.7809
     Batch 175 | Loss : 0.4349 | Acc : 0.7849
     Batch 200 | Loss : 0.3881 | Acc : 0.8155
     Batch 225 | Loss : 0.3583 | Acc : 0.8452
     Batch 250 | Loss : 0.3666 | Acc : 0.8458
     Batch 275 | Loss : 0.3531 | Acc : 0.8479
     Batch 300 | Loss : 0.3489 | Acc : 0.8423
Epoch 00103 | Train Loss : 0.3973 | Eval Loss : 0.4097 | Train acc : 0.8114 | Eval Acc : 0.8021
     Batch 000 | Loss : 0.3831 | Acc : 0.8205
     Batch 025 | Loss : 0.3664 | Acc : 0.8273
     Batch 050 | Loss : 0.3832 | Acc : 0.8192
     Batch 075 | Loss : 0.4086 | Acc : 0.8085
     Batch 100 | Loss : 0.3707 | Acc : 0.8212
     Batch 125 | Loss : 0.3497 | Acc : 0.8491
     Batch 150 | Loss : 0.4764 | Acc : 0.7765
     Batch 175 | Loss : 0.3836 | Acc : 0.8145
     Batch 200 | Loss : 0.4867 | Acc : 0.7610
     Batch 225 | Loss : 0.4139 | Acc : 0.8045
     Batch 250 | Loss : 0.4297 | Acc : 0.7855
     Batch 275 | Loss : 0.4108 | Acc : 0.8015
     Batch 300 | Loss : 0.3557 | Acc : 0.8342
Epoch 00104 | Train Loss : 0.3966 | Eval Loss : 0.4045 | Train acc : 0.8117 | Eval Acc : 0.8062
     Batch 000 | Loss : 0.4753 | Acc : 0.7714
     Batch 025 | Loss : 0.4615 | Acc : 0.7594
     Batch 050 | Loss : 0.3683 | Acc : 0.8266
     Batch 075 | Loss : 0.4928 | Acc : 0.7721
     Batch 100 | Loss : 0.4870 | Acc : 0.7542
     Batch 125 | Loss : 0.3512 | Acc : 0.8337
     Batch 150 | Loss : 0.4430 | Acc : 0.7786
     Batch 175 | Loss : 0.3651 | Acc : 0.8288
     Batch 200 | Loss : 0.3937 | Acc : 0.8060
     Batch 225 | Loss : 0.3568 | Acc : 0.8380
     Batch 250 | Loss : 0.3700 | Acc : 0.8237
     Batch 275 | Loss : 0.3715 | Acc : 0.8227
     Batch 300 | Loss : 0.3806 | Acc : 0.8133
Epoch 00105 | Train Loss : 0.3959 | Eval Loss : 0.4103 | Train acc : 0.8120 | Eval Acc : 0.8016
     Batch 000 | Loss : 0.3748 | Acc : 0.8285
     Batch 025 | Loss : 0.4752 | Acc : 0.7578
     Batch 050 | Loss : 0.3609 | Acc : 0.8407
     Batch 075 | Loss : 0.3928 | Acc : 0.8133
     Batch 100 | Loss : 0.4024 | Acc : 0.8087
     Batch 125 | Loss : 0.4244 | Acc : 0.7975
     Batch 150 | Loss : 0.3724 | Acc : 0.8231
     Batch 175 | Loss : 0.3698 | Acc : 0.8362
     Batch 200 | Loss : 0.3958 | Acc : 0.8204
     Batch 225 | Loss : 0.4321 | Acc : 0.7867
     Batch 250 | Loss : 0.5037 | Acc : 0.7602
     Batch 275 | Loss : 0.3525 | Acc : 0.8407
     Batch 300 | Loss : 0.3460 | Acc : 0.8474
Epoch 00106 | Train Loss : 0.3987 | Eval Loss : 0.4058 | Train acc : 0.8108 | Eval Acc : 0.8049
     Batch 000 | Loss : 0.3586 | Acc : 0.8398
     Batch 025 | Loss : 0.5118 | Acc : 0.7533
     Batch 050 | Loss : 0.3900 | Acc : 0.8112
     Batch 075 | Loss : 0.3556 | Acc : 0.8372
     Batch 100 | Loss : 0.4295 | Acc : 0.7917
     Batch 125 | Loss : 0.4059 | Acc : 0.8084
     Batch 150 | Loss : 0.3811 | Acc : 0.8225
     Batch 175 | Loss : 0.3298 | Acc : 0.8521
     Batch 200 | Loss : 0.4029 | Acc : 0.8035
     Batch 225 | Loss : 0.3477 | Acc : 0.8387
     Batch 250 | Loss : 0.3995 | Acc : 0.8110
     Batch 275 | Loss : 0.3602 | Acc : 0.8452
     Batch 300 | Loss : 0.3629 | Acc : 0.8289
Epoch 00107 | Train Loss : 0.3989 | Eval Loss : 0.4086 | Train acc : 0.8105 | Eval Acc : 0.8024
     Batch 000 | Loss : 0.4037 | Acc : 0.8023
     Batch 025 | Loss : 0.3794 | Acc : 0.8361
     Batch 050 | Loss : 0.3613 | Acc : 0.8344
     Batch 075 | Loss : 0.3903 | Acc : 0.8140
     Batch 100 | Loss : 0.3373 | Acc : 0.8487
     Batch 125 | Loss : 0.3753 | Acc : 0.8409
     Batch 150 | Loss : 0.4398 | Acc : 0.7731
     Batch 175 | Loss : 0.3499 | Acc : 0.8348
     Batch 200 | Loss : 0.4347 | Acc : 0.7860
     Batch 225 | Loss : 0.4268 | Acc : 0.7944
     Batch 250 | Loss : 0.3678 | Acc : 0.8455
     Batch 275 | Loss : 0.4370 | Acc : 0.7920
     Batch 300 | Loss : 0.3674 | Acc : 0.8328
Epoch 00108 | Train Loss : 0.3993 | Eval Loss : 0.4180 | Train acc : 0.8108 | Eval Acc : 0.8013
     Batch 000 | Loss : 0.3815 | Acc : 0.8177
     Batch 025 | Loss : 0.4463 | Acc : 0.7886
     Batch 050 | Loss : 0.4279 | Acc : 0.7894
     Batch 075 | Loss : 0.3895 | Acc : 0.8164
     Batch 100 | Loss : 0.3323 | Acc : 0.8499
     Batch 125 | Loss : 0.3301 | Acc : 0.8572
     Batch 150 | Loss : 0.4378 | Acc : 0.7871
     Batch 175 | Loss : 0.3752 | Acc : 0.8247
     Batch 200 | Loss : 0.3372 | Acc : 0.8496
     Batch 225 | Loss : 0.3655 | Acc : 0.8267
     Batch 250 | Loss : 0.3475 | Acc : 0.8469
     Batch 275 | Loss : 0.4571 | Acc : 0.7725
     Batch 300 | Loss : 0.3358 | Acc : 0.8478
Epoch 00109 | Train Loss : 0.3975 | Eval Loss : 0.4225 | Train acc : 0.8108 | Eval Acc : 0.7966
     Batch 000 | Loss : 0.3334 | Acc : 0.8603
     Batch 025 | Loss : 0.4117 | Acc : 0.8001
     Batch 050 | Loss : 0.4070 | Acc : 0.8038
     Batch 075 | Loss : 0.3745 | Acc : 0.8307
     Batch 100 | Loss : 0.4902 | Acc : 0.7524
     Batch 125 | Loss : 0.4504 | Acc : 0.7843
     Batch 150 | Loss : 0.3456 | Acc : 0.8436
     Batch 175 | Loss : 0.3657 | Acc : 0.8426
     Batch 200 | Loss : 0.3555 | Acc : 0.8352
     Batch 225 | Loss : 0.3491 | Acc : 0.8389
     Batch 250 | Loss : 0.3882 | Acc : 0.8271
     Batch 275 | Loss : 0.5799 | Acc : 0.6979
     Batch 300 | Loss : 0.4035 | Acc : 0.8085
Epoch 00110 | Train Loss : 0.4018 | Eval Loss : 0.4085 | Train acc : 0.8095 | Eval Acc : 0.8025
     Batch 000 | Loss : 0.3960 | Acc : 0.8119
     Batch 025 | Loss : 0.3520 | Acc : 0.8368
     Batch 050 | Loss : 0.4451 | Acc : 0.7923
     Batch 075 | Loss : 0.3608 | Acc : 0.8252
     Batch 100 | Loss : 0.3672 | Acc : 0.8290
     Batch 125 | Loss : 0.4970 | Acc : 0.7494
     Batch 150 | Loss : 0.4609 | Acc : 0.7667
     Batch 175 | Loss : 0.3433 | Acc : 0.8479
     Batch 200 | Loss : 0.3650 | Acc : 0.8283
     Batch 225 | Loss : 0.3698 | Acc : 0.8261
     Batch 250 | Loss : 0.3959 | Acc : 0.8058
     Batch 275 | Loss : 0.3590 | Acc : 0.8331
     Batch 300 | Loss : 0.4398 | Acc : 0.7833
Epoch 00111 | Train Loss : 0.3998 | Eval Loss : 0.4031 | Train acc : 0.8103 | Eval Acc : 0.8060
     Batch 000 | Loss : 0.3596 | Acc : 0.8428
     Batch 025 | Loss : 0.3482 | Acc : 0.8370
     Batch 050 | Loss : 0.3883 | Acc : 0.8120
     Batch 075 | Loss : 0.4627 | Acc : 0.7715
     Batch 100 | Loss : 0.3512 | Acc : 0.8460
     Batch 125 | Loss : 0.3688 | Acc : 0.8317
     Batch 150 | Loss : 0.5021 | Acc : 0.7468
     Batch 175 | Loss : 0.3638 | Acc : 0.8267
     Batch 200 | Loss : 0.4117 | Acc : 0.7990
     Batch 225 | Loss : 0.4515 | Acc : 0.7814
     Batch 250 | Loss : 0.3930 | Acc : 0.8104
     Batch 275 | Loss : 0.4398 | Acc : 0.7904
     Batch 300 | Loss : 0.3449 | Acc : 0.8351
Epoch 00112 | Train Loss : 0.3965 | Eval Loss : 0.4127 | Train acc : 0.8119 | Eval Acc : 0.8018
     Batch 000 | Loss : 0.3908 | Acc : 0.8131
     Batch 025 | Loss : 0.3550 | Acc : 0.8395
     Batch 050 | Loss : 0.4136 | Acc : 0.7967
     Batch 075 | Loss : 0.3788 | Acc : 0.8293
     Batch 100 | Loss : 0.3963 | Acc : 0.8156
     Batch 125 | Loss : 0.3713 | Acc : 0.8261
     Batch 150 | Loss : 0.3744 | Acc : 0.8208
     Batch 175 | Loss : 0.4251 | Acc : 0.7934
     Batch 200 | Loss : 0.4617 | Acc : 0.7710
     Batch 225 | Loss : 0.3991 | Acc : 0.8087
     Batch 250 | Loss : 0.3742 | Acc : 0.8253
     Batch 275 | Loss : 0.4181 | Acc : 0.8015
     Batch 300 | Loss : 0.3975 | Acc : 0.8106
Epoch 00113 | Train Loss : 0.3986 | Eval Loss : 0.4065 | Train acc : 0.8112 | Eval Acc : 0.8043
     Batch 000 | Loss : 0.4192 | Acc : 0.7950
     Batch 025 | Loss : 0.3763 | Acc : 0.8311
     Batch 050 | Loss : 0.4144 | Acc : 0.7944
     Batch 075 | Loss : 0.4537 | Acc : 0.7705
     Batch 100 | Loss : 0.3693 | Acc : 0.8292
     Batch 125 | Loss : 0.3486 | Acc : 0.8489
     Batch 150 | Loss : 0.4463 | Acc : 0.7754
     Batch 175 | Loss : 0.3792 | Acc : 0.8163
     Batch 200 | Loss : 0.3847 | Acc : 0.8119
     Batch 225 | Loss : 0.3324 | Acc : 0.8620
     Batch 250 | Loss : 0.3693 | Acc : 0.8321
     Batch 275 | Loss : 0.4495 | Acc : 0.7823
     Batch 300 | Loss : 0.4786 | Acc : 0.7623
Epoch 00114 | Train Loss : 0.4016 | Eval Loss : 0.4026 | Train acc : 0.8096 | Eval Acc : 0.8063
     Batch 000 | Loss : 0.4343 | Acc : 0.7884
     Batch 025 | Loss : 0.4527 | Acc : 0.7728
     Batch 050 | Loss : 0.3980 | Acc : 0.8128
     Batch 075 | Loss : 0.3467 | Acc : 0.8420
     Batch 100 | Loss : 0.3368 | Acc : 0.8496
     Batch 125 | Loss : 0.3735 | Acc : 0.8240
     Batch 150 | Loss : 0.4258 | Acc : 0.7999
     Batch 175 | Loss : 0.3531 | Acc : 0.8372
     Batch 200 | Loss : 0.3825 | Acc : 0.8195
     Batch 225 | Loss : 0.3765 | Acc : 0.8399
     Batch 250 | Loss : 0.3689 | Acc : 0.8228
     Batch 275 | Loss : 0.3999 | Acc : 0.8149
     Batch 300 | Loss : 0.4367 | Acc : 0.7855
Epoch 00115 | Train Loss : 0.3961 | Eval Loss : 0.4056 | Train acc : 0.8122 | Eval Acc : 0.8035
     Batch 000 | Loss : 0.3424 | Acc : 0.8449
     Batch 025 | Loss : 0.3548 | Acc : 0.8447
     Batch 050 | Loss : 0.3456 | Acc : 0.8468
     Batch 075 | Loss : 0.4273 | Acc : 0.7908
     Batch 100 | Loss : 0.3571 | Acc : 0.8357
     Batch 125 | Loss : 0.3775 | Acc : 0.8251
     Batch 150 | Loss : 0.4451 | Acc : 0.7933
     Batch 175 | Loss : 0.3672 | Acc : 0.8225
     Batch 200 | Loss : 0.4451 | Acc : 0.7797
     Batch 225 | Loss : 0.5335 | Acc : 0.7435
     Batch 250 | Loss : 0.4309 | Acc : 0.7891
     Batch 275 | Loss : 0.4213 | Acc : 0.7931
     Batch 300 | Loss : 0.3546 | Acc : 0.8318
Epoch 00116 | Train Loss : 0.3970 | Eval Loss : 0.4041 | Train acc : 0.8115 | Eval Acc : 0.8058
     Batch 000 | Loss : 0.3702 | Acc : 0.8254
     Batch 025 | Loss : 0.4353 | Acc : 0.7839
     Batch 050 | Loss : 0.3946 | Acc : 0.8188
     Batch 075 | Loss : 0.3598 | Acc : 0.8464
     Batch 100 | Loss : 0.4487 | Acc : 0.7686
     Batch 125 | Loss : 0.4744 | Acc : 0.7638
     Batch 150 | Loss : 0.3564 | Acc : 0.8317
     Batch 175 | Loss : 0.3940 | Acc : 0.8105
     Batch 200 | Loss : 0.3390 | Acc : 0.8376
     Batch 225 | Loss : 0.3490 | Acc : 0.8478
     Batch 250 | Loss : 0.3642 | Acc : 0.8297
     Batch 275 | Loss : 0.3526 | Acc : 0.8341
     Batch 300 | Loss : 0.4238 | Acc : 0.7975
Epoch 00117 | Train Loss : 0.3973 | Eval Loss : 0.4030 | Train acc : 0.8113 | Eval Acc : 0.8065
     Batch 000 | Loss : 0.4068 | Acc : 0.7990
     Batch 025 | Loss : 0.3932 | Acc : 0.8079
     Batch 050 | Loss : 0.3743 | Acc : 0.8300
     Batch 075 | Loss : 0.3418 | Acc : 0.8447
     Batch 100 | Loss : 0.4136 | Acc : 0.7980
     Batch 125 | Loss : 0.3196 | Acc : 0.8623
     Batch 150 | Loss : 0.3923 | Acc : 0.8149
     Batch 175 | Loss : 0.4471 | Acc : 0.7820
     Batch 200 | Loss : 0.3739 | Acc : 0.8319
     Batch 225 | Loss : 0.3648 | Acc : 0.8314
     Batch 250 | Loss : 0.3533 | Acc : 0.8387
     Batch 275 | Loss : 0.3964 | Acc : 0.8106
     Batch 300 | Loss : 0.3839 | Acc : 0.8259
Epoch 00118 | Train Loss : 0.4004 | Eval Loss : 0.4196 | Train acc : 0.8106 | Eval Acc : 0.7959
     Batch 000 | Loss : 0.4458 | Acc : 0.7740
     Batch 025 | Loss : 0.4065 | Acc : 0.8046
     Batch 050 | Loss : 0.4179 | Acc : 0.7932
     Batch 075 | Loss : 0.5379 | Acc : 0.7266
     Batch 100 | Loss : 0.4714 | Acc : 0.7656
     Batch 125 | Loss : 0.4041 | Acc : 0.7978
     Batch 150 | Loss : 0.3837 | Acc : 0.8090
     Batch 175 | Loss : 0.4275 | Acc : 0.7943
     Batch 200 | Loss : 0.5514 | Acc : 0.7304
     Batch 225 | Loss : 0.4155 | Acc : 0.7990
     Batch 250 | Loss : 0.3786 | Acc : 0.8292
     Batch 275 | Loss : 0.3446 | Acc : 0.8426
     Batch 300 | Loss : 0.3845 | Acc : 0.8205
Epoch 00119 | Train Loss : 0.3992 | Eval Loss : 0.4263 | Train acc : 0.8105 | Eval Acc : 0.7965
     Batch 000 | Loss : 0.3988 | Acc : 0.8129
     Batch 025 | Loss : 0.3549 | Acc : 0.8357
     Batch 050 | Loss : 0.3684 | Acc : 0.8246
     Batch 075 | Loss : 0.3588 | Acc : 0.8367
     Batch 100 | Loss : 0.3462 | Acc : 0.8438
     Batch 125 | Loss : 0.3593 | Acc : 0.8434
     Batch 150 | Loss : 0.4365 | Acc : 0.7805
     Batch 175 | Loss : 0.4400 | Acc : 0.7882
     Batch 200 | Loss : 0.3814 | Acc : 0.8248
     Batch 225 | Loss : 0.3167 | Acc : 0.8589
     Batch 250 | Loss : 0.3923 | Acc : 0.8114
     Batch 275 | Loss : 0.4328 | Acc : 0.7919
     Batch 300 | Loss : 0.3468 | Acc : 0.8363
Epoch 00120 | Train Loss : 0.3984 | Eval Loss : 0.4067 | Train acc : 0.8106 | Eval Acc : 0.8037
     Batch 000 | Loss : 0.3323 | Acc : 0.8510
     Batch 025 | Loss : 0.3978 | Acc : 0.8096
     Batch 050 | Loss : 0.3827 | Acc : 0.8183
     Batch 075 | Loss : 0.3304 | Acc : 0.8517
     Batch 100 | Loss : 0.3883 | Acc : 0.8173
     Batch 125 | Loss : 0.4067 | Acc : 0.8036
     Batch 150 | Loss : 0.4329 | Acc : 0.7934
     Batch 175 | Loss : 0.3258 | Acc : 0.8557
     Batch 200 | Loss : 0.4446 | Acc : 0.7796
     Batch 225 | Loss : 0.3789 | Acc : 0.8188
     Batch 250 | Loss : 0.4959 | Acc : 0.7696
     Batch 275 | Loss : 0.3478 | Acc : 0.8445
     Batch 300 | Loss : 0.4085 | Acc : 0.8044
Epoch 00121 | Train Loss : 0.3973 | Eval Loss : 0.4127 | Train acc : 0.8114 | Eval Acc : 0.8015
     Batch 000 | Loss : 0.3683 | Acc : 0.8342
     Batch 025 | Loss : 0.3727 | Acc : 0.8289
     Batch 050 | Loss : 0.3977 | Acc : 0.8099
     Batch 075 | Loss : 0.3482 | Acc : 0.8325
     Batch 100 | Loss : 0.3485 | Acc : 0.8422
     Batch 125 | Loss : 0.3415 | Acc : 0.8469
     Batch 150 | Loss : 0.3524 | Acc : 0.8349
     Batch 175 | Loss : 0.3562 | Acc : 0.8310
     Batch 200 | Loss : 0.3849 | Acc : 0.8140
     Batch 225 | Loss : 0.3263 | Acc : 0.8560
     Batch 250 | Loss : 0.4610 | Acc : 0.7712
     Batch 275 | Loss : 0.3303 | Acc : 0.8602
     Batch 300 | Loss : 0.3996 | Acc : 0.8138
Epoch 00122 | Train Loss : 0.3964 | Eval Loss : 0.4130 | Train acc : 0.8120 | Eval Acc : 0.8005
     Batch 000 | Loss : 0.3456 | Acc : 0.8428
     Batch 025 | Loss : 0.3834 | Acc : 0.8140
     Batch 050 | Loss : 0.3379 | Acc : 0.8475
     Batch 075 | Loss : 0.3759 | Acc : 0.8233
     Batch 100 | Loss : 0.3913 | Acc : 0.8118
     Batch 125 | Loss : 0.4331 | Acc : 0.7882
     Batch 150 | Loss : 0.3496 | Acc : 0.8338
     Batch 175 | Loss : 0.3729 | Acc : 0.8209
     Batch 200 | Loss : 0.3756 | Acc : 0.8281
     Batch 225 | Loss : 0.4407 | Acc : 0.7843
     Batch 250 | Loss : 0.3503 | Acc : 0.8392
     Batch 275 | Loss : 0.3782 | Acc : 0.8158
     Batch 300 | Loss : 0.4034 | Acc : 0.8043
Epoch 00123 | Train Loss : 0.3968 | Eval Loss : 0.4193 | Train acc : 0.8115 | Eval Acc : 0.8031
     Batch 000 | Loss : 0.3567 | Acc : 0.8359
     Batch 025 | Loss : 0.4372 | Acc : 0.7836
     Batch 050 | Loss : 0.4916 | Acc : 0.7510
     Batch 075 | Loss : 0.4190 | Acc : 0.7976
     Batch 100 | Loss : 0.4305 | Acc : 0.7884
     Batch 125 | Loss : 0.3488 | Acc : 0.8371
     Batch 150 | Loss : 0.3995 | Acc : 0.8054
     Batch 175 | Loss : 0.3329 | Acc : 0.8521
     Batch 200 | Loss : 0.3866 | Acc : 0.8223
     Batch 225 | Loss : 0.4339 | Acc : 0.7932
     Batch 250 | Loss : 0.3614 | Acc : 0.8324
     Batch 275 | Loss : 0.4014 | Acc : 0.8096
     Batch 300 | Loss : 0.3899 | Acc : 0.8105
Epoch 00124 | Train Loss : 0.3950 | Eval Loss : 0.4111 | Train acc : 0.8131 | Eval Acc : 0.8046
     Batch 000 | Loss : 0.3757 | Acc : 0.8208
     Batch 025 | Loss : 0.3374 | Acc : 0.8513
     Batch 050 | Loss : 0.3436 | Acc : 0.8413
     Batch 075 | Loss : 0.3501 | Acc : 0.8370
     Batch 100 | Loss : 0.3783 | Acc : 0.8182
     Batch 125 | Loss : 0.5470 | Acc : 0.7225
     Batch 150 | Loss : 0.4033 | Acc : 0.8021
     Batch 175 | Loss : 0.4144 | Acc : 0.7958
     Batch 200 | Loss : 0.4467 | Acc : 0.7754
     Batch 225 | Loss : 0.4076 | Acc : 0.8066
     Batch 250 | Loss : 0.4245 | Acc : 0.7818
     Batch 275 | Loss : 0.4310 | Acc : 0.7947
     Batch 300 | Loss : 0.3908 | Acc : 0.8152
Epoch 00125 | Train Loss : 0.3975 | Eval Loss : 0.4139 | Train acc : 0.8112 | Eval Acc : 0.7994
     Batch 000 | Loss : 0.4472 | Acc : 0.7705
     Batch 025 | Loss : 0.4199 | Acc : 0.7958
     Batch 050 | Loss : 0.3992 | Acc : 0.8056
     Batch 075 | Loss : 0.3341 | Acc : 0.8459
     Batch 100 | Loss : 0.4707 | Acc : 0.7655
     Batch 125 | Loss : 0.3249 | Acc : 0.8595
     Batch 150 | Loss : 0.3471 | Acc : 0.8315
     Batch 175 | Loss : 0.3864 | Acc : 0.8152
     Batch 200 | Loss : 0.3779 | Acc : 0.8261
     Batch 225 | Loss : 0.3739 | Acc : 0.8269
     Batch 250 | Loss : 0.3633 | Acc : 0.8318
     Batch 275 | Loss : 0.4092 | Acc : 0.8030
     Batch 300 | Loss : 0.4376 | Acc : 0.7862
Epoch 00126 | Train Loss : 0.3970 | Eval Loss : 0.4074 | Train acc : 0.8118 | Eval Acc : 0.8046
     Batch 000 | Loss : 0.4003 | Acc : 0.8063
     Batch 025 | Loss : 0.3660 | Acc : 0.8316
     Batch 050 | Loss : 0.3209 | Acc : 0.8637
     Batch 075 | Loss : 0.4329 | Acc : 0.7901
     Batch 100 | Loss : 0.3580 | Acc : 0.8413
     Batch 125 | Loss : 0.4356 | Acc : 0.7895
     Batch 150 | Loss : 0.3312 | Acc : 0.8537
     Batch 175 | Loss : 0.3521 | Acc : 0.8459
     Batch 200 | Loss : 0.3648 | Acc : 0.8287
     Batch 225 | Loss : 0.4200 | Acc : 0.7979
     Batch 250 | Loss : 0.4216 | Acc : 0.7911
     Batch 275 | Loss : 0.4990 | Acc : 0.7552
     Batch 300 | Loss : 0.5362 | Acc : 0.7386
Epoch 00127 | Train Loss : 0.3982 | Eval Loss : 0.4160 | Train acc : 0.8113 | Eval Acc : 0.7989
     Batch 000 | Loss : 0.3939 | Acc : 0.8123
     Batch 025 | Loss : 0.3663 | Acc : 0.8315
     Batch 050 | Loss : 0.3106 | Acc : 0.8657
     Batch 075 | Loss : 0.3433 | Acc : 0.8457
     Batch 100 | Loss : 0.4275 | Acc : 0.7933
     Batch 125 | Loss : 0.3730 | Acc : 0.8328
     Batch 150 | Loss : 0.3643 | Acc : 0.8277
     Batch 175 | Loss : 0.3557 | Acc : 0.8483
     Batch 200 | Loss : 0.4099 | Acc : 0.8004
     Batch 225 | Loss : 0.3696 | Acc : 0.8241
     Batch 250 | Loss : 0.4247 | Acc : 0.8013
     Batch 275 | Loss : 0.4270 | Acc : 0.7905
     Batch 300 | Loss : 0.4227 | Acc : 0.7904
Epoch 00128 | Train Loss : 0.3961 | Eval Loss : 0.4021 | Train acc : 0.8120 | Eval Acc : 0.8070
     Batch 000 | Loss : 0.3354 | Acc : 0.8524
     Batch 025 | Loss : 0.3326 | Acc : 0.8547
     Batch 050 | Loss : 0.3453 | Acc : 0.8519
     Batch 075 | Loss : 0.3825 | Acc : 0.8291
     Batch 100 | Loss : 0.4395 | Acc : 0.7804
     Batch 125 | Loss : 0.3395 | Acc : 0.8501
     Batch 150 | Loss : 0.3389 | Acc : 0.8409
     Batch 175 | Loss : 0.4125 | Acc : 0.7965
     Batch 200 | Loss : 0.4397 | Acc : 0.7867
     Batch 225 | Loss : 0.4109 | Acc : 0.8018
     Batch 250 | Loss : 0.4311 | Acc : 0.7931
     Batch 275 | Loss : 0.4292 | Acc : 0.7883
     Batch 300 | Loss : 0.3821 | Acc : 0.8241
Epoch 00129 | Train Loss : 0.3963 | Eval Loss : 0.4098 | Train acc : 0.8120 | Eval Acc : 0.8029
     Batch 000 | Loss : 0.3504 | Acc : 0.8488
     Batch 025 | Loss : 0.4141 | Acc : 0.7964
     Batch 050 | Loss : 0.3511 | Acc : 0.8384
     Batch 075 | Loss : 0.4024 | Acc : 0.8066
     Batch 100 | Loss : 0.3887 | Acc : 0.8084
     Batch 125 | Loss : 0.3453 | Acc : 0.8499
     Batch 150 | Loss : 0.3917 | Acc : 0.8202
     Batch 175 | Loss : 0.3504 | Acc : 0.8427
     Batch 200 | Loss : 0.4275 | Acc : 0.7930
     Batch 225 | Loss : 0.4335 | Acc : 0.7958
     Batch 250 | Loss : 0.4106 | Acc : 0.7999
     Batch 275 | Loss : 0.3767 | Acc : 0.8230
     Batch 300 | Loss : 0.4100 | Acc : 0.8052
Epoch 00130 | Train Loss : 0.3960 | Eval Loss : 0.4061 | Train acc : 0.8118 | Eval Acc : 0.8052
     Batch 000 | Loss : 0.3680 | Acc : 0.8392
     Batch 025 | Loss : 0.3859 | Acc : 0.8174
     Batch 050 | Loss : 0.3935 | Acc : 0.8130
     Batch 075 | Loss : 0.3893 | Acc : 0.8204
     Batch 100 | Loss : 0.3444 | Acc : 0.8516
     Batch 125 | Loss : 0.4344 | Acc : 0.7874
     Batch 150 | Loss : 0.4358 | Acc : 0.7795
     Batch 175 | Loss : 0.3558 | Acc : 0.8315
     Batch 200 | Loss : 0.3577 | Acc : 0.8328
     Batch 225 | Loss : 0.4417 | Acc : 0.7804
     Batch 250 | Loss : 0.3955 | Acc : 0.8124
     Batch 275 | Loss : 0.3561 | Acc : 0.8267
     Batch 300 | Loss : 0.5066 | Acc : 0.7490
Epoch 00131 | Train Loss : 0.3973 | Eval Loss : 0.4053 | Train acc : 0.8116 | Eval Acc : 0.8056
     Batch 000 | Loss : 0.4440 | Acc : 0.7816
     Batch 025 | Loss : 0.3546 | Acc : 0.8292
     Batch 050 | Loss : 0.4523 | Acc : 0.7771
     Batch 075 | Loss : 0.3687 | Acc : 0.8283
     Batch 100 | Loss : 0.4951 | Acc : 0.7531
     Batch 125 | Loss : 0.3968 | Acc : 0.8158
     Batch 150 | Loss : 0.3889 | Acc : 0.8130
     Batch 175 | Loss : 0.4676 | Acc : 0.7647
     Batch 200 | Loss : 0.3743 | Acc : 0.8252
     Batch 225 | Loss : 0.3583 | Acc : 0.8386
     Batch 250 | Loss : 0.3406 | Acc : 0.8439
     Batch 275 | Loss : 0.4170 | Acc : 0.7997
     Batch 300 | Loss : 0.3928 | Acc : 0.8099
Epoch 00132 | Train Loss : 0.3984 | Eval Loss : 0.4186 | Train acc : 0.8102 | Eval Acc : 0.8006
     Batch 000 | Loss : 0.3478 | Acc : 0.8393
     Batch 025 | Loss : 0.3831 | Acc : 0.8278
     Batch 050 | Loss : 0.3277 | Acc : 0.8570
     Batch 075 | Loss : 0.3615 | Acc : 0.8321
     Batch 100 | Loss : 0.3954 | Acc : 0.8127
     Batch 125 | Loss : 0.4068 | Acc : 0.8032
     Batch 150 | Loss : 0.3440 | Acc : 0.8466
     Batch 175 | Loss : 0.3903 | Acc : 0.8129
     Batch 200 | Loss : 0.4378 | Acc : 0.7810
     Batch 225 | Loss : 0.3667 | Acc : 0.8333
     Batch 250 | Loss : 0.4394 | Acc : 0.7865
     Batch 275 | Loss : 0.4300 | Acc : 0.7920
     Batch 300 | Loss : 0.4342 | Acc : 0.7852
Epoch 00133 | Train Loss : 0.3949 | Eval Loss : 0.4160 | Train acc : 0.8125 | Eval Acc : 0.8013
     Batch 000 | Loss : 0.3586 | Acc : 0.8398
     Batch 025 | Loss : 0.3809 | Acc : 0.8161
     Batch 050 | Loss : 0.3433 | Acc : 0.8467
     Batch 075 | Loss : 0.4631 | Acc : 0.7706
     Batch 100 | Loss : 0.3619 | Acc : 0.8311
     Batch 125 | Loss : 0.4132 | Acc : 0.8045
     Batch 150 | Loss : 0.4379 | Acc : 0.7912
     Batch 175 | Loss : 0.4438 | Acc : 0.7800
     Batch 200 | Loss : 0.3566 | Acc : 0.8303
     Batch 225 | Loss : 0.4248 | Acc : 0.8005
     Batch 250 | Loss : 0.4024 | Acc : 0.8090
     Batch 275 | Loss : 0.4656 | Acc : 0.7641
     Batch 300 | Loss : 0.4438 | Acc : 0.7864
Epoch 00134 | Train Loss : 0.3945 | Eval Loss : 0.4044 | Train acc : 0.8126 | Eval Acc : 0.8070
     Batch 000 | Loss : 0.4293 | Acc : 0.7880
     Batch 025 | Loss : 0.4058 | Acc : 0.8080
     Batch 050 | Loss : 0.4551 | Acc : 0.7701
     Batch 075 | Loss : 0.3464 | Acc : 0.8340
     Batch 100 | Loss : 0.3554 | Acc : 0.8331
     Batch 125 | Loss : 0.3674 | Acc : 0.8372
     Batch 150 | Loss : 0.3702 | Acc : 0.8332
     Batch 175 | Loss : 0.3895 | Acc : 0.8211
     Batch 200 | Loss : 0.3582 | Acc : 0.8392
     Batch 225 | Loss : 0.3555 | Acc : 0.8326
     Batch 250 | Loss : 0.3445 | Acc : 0.8380
     Batch 275 | Loss : 0.4795 | Acc : 0.7699
     Batch 300 | Loss : 0.3557 | Acc : 0.8376
Epoch 00135 | Train Loss : 0.3947 | Eval Loss : 0.4008 | Train acc : 0.8125 | Eval Acc : 0.8072
     Batch 000 | Loss : 0.3667 | Acc : 0.8266
     Batch 025 | Loss : 0.3561 | Acc : 0.8396
     Batch 050 | Loss : 0.3855 | Acc : 0.8261
     Batch 075 | Loss : 0.4105 | Acc : 0.8007
     Batch 100 | Loss : 0.4418 | Acc : 0.7891
     Batch 125 | Loss : 0.4298 | Acc : 0.7928
     Batch 150 | Loss : 0.3663 | Acc : 0.8230
     Batch 175 | Loss : 0.4335 | Acc : 0.7935
     Batch 200 | Loss : 0.4077 | Acc : 0.8093
     Batch 225 | Loss : 0.3759 | Acc : 0.8279
     Batch 250 | Loss : 0.3793 | Acc : 0.8275
     Batch 275 | Loss : 0.3852 | Acc : 0.8258
     Batch 300 | Loss : 0.3751 | Acc : 0.8269
Epoch 00136 | Train Loss : 0.3940 | Eval Loss : 0.4110 | Train acc : 0.8130 | Eval Acc : 0.8031
     Batch 000 | Loss : 0.3906 | Acc : 0.8188
     Batch 025 | Loss : 0.3714 | Acc : 0.8365
     Batch 050 | Loss : 0.3575 | Acc : 0.8395
     Batch 075 | Loss : 0.3417 | Acc : 0.8374
     Batch 100 | Loss : 0.3954 | Acc : 0.8094
     Batch 125 | Loss : 0.3960 | Acc : 0.8093
     Batch 150 | Loss : 0.4152 | Acc : 0.7970
     Batch 175 | Loss : 0.4275 | Acc : 0.7943
     Batch 200 | Loss : 0.4534 | Acc : 0.7807
     Batch 225 | Loss : 0.4120 | Acc : 0.7995
     Batch 250 | Loss : 0.8405 | Acc : 0.6433
     Batch 275 | Loss : 0.3623 | Acc : 0.8278
     Batch 300 | Loss : 0.4229 | Acc : 0.7937
Epoch 00137 | Train Loss : 0.3966 | Eval Loss : 0.4124 | Train acc : 0.8122 | Eval Acc : 0.8014
     Batch 000 | Loss : 0.3722 | Acc : 0.8310
     Batch 025 | Loss : 0.3948 | Acc : 0.8077
     Batch 050 | Loss : 0.4104 | Acc : 0.7905
     Batch 075 | Loss : 0.4372 | Acc : 0.7843
     Batch 100 | Loss : 0.3817 | Acc : 0.8217
     Batch 125 | Loss : 0.3482 | Acc : 0.8393
     Batch 150 | Loss : 0.4191 | Acc : 0.7938
     Batch 175 | Loss : 0.3395 | Acc : 0.8442
     Batch 200 | Loss : 0.4145 | Acc : 0.8023
     Batch 225 | Loss : 0.3425 | Acc : 0.8423
     Batch 250 | Loss : 0.5095 | Acc : 0.7452
     Batch 275 | Loss : 0.3607 | Acc : 0.8348
     Batch 300 | Loss : 0.3981 | Acc : 0.8105
Epoch 00138 | Train Loss : 0.3959 | Eval Loss : 0.4095 | Train acc : 0.8115 | Eval Acc : 0.8038
     Batch 000 | Loss : 0.3951 | Acc : 0.8067
     Batch 025 | Loss : 0.4519 | Acc : 0.7812
     Batch 050 | Loss : 0.4069 | Acc : 0.8023
     Batch 075 | Loss : 0.4567 | Acc : 0.7815
     Batch 100 | Loss : 0.4301 | Acc : 0.7932
     Batch 125 | Loss : 0.3517 | Acc : 0.8379
     Batch 150 | Loss : 0.3326 | Acc : 0.8432
     Batch 175 | Loss : 0.4142 | Acc : 0.7941
     Batch 200 | Loss : 0.4020 | Acc : 0.8037
     Batch 225 | Loss : 0.4416 | Acc : 0.7912
     Batch 250 | Loss : 0.3293 | Acc : 0.8626
     Batch 275 | Loss : 0.4486 | Acc : 0.7683
     Batch 300 | Loss : 0.3742 | Acc : 0.8235
Epoch 00139 | Train Loss : 0.3951 | Eval Loss : 0.4155 | Train acc : 0.8121 | Eval Acc : 0.8036
     Batch 000 | Loss : 0.3575 | Acc : 0.8292
     Batch 025 | Loss : 0.4622 | Acc : 0.7718
     Batch 050 | Loss : 0.4237 | Acc : 0.7986
     Batch 075 | Loss : 0.4182 | Acc : 0.7969
     Batch 100 | Loss : 0.3739 | Acc : 0.8237
     Batch 125 | Loss : 0.4705 | Acc : 0.7591
     Batch 150 | Loss : 0.3481 | Acc : 0.8444
     Batch 175 | Loss : 0.3455 | Acc : 0.8502
     Batch 200 | Loss : 0.5148 | Acc : 0.7557
     Batch 225 | Loss : 0.3329 | Acc : 0.8480
     Batch 250 | Loss : 0.3781 | Acc : 0.8306
     Batch 275 | Loss : 0.3197 | Acc : 0.8524
     Batch 300 | Loss : 0.4117 | Acc : 0.8036
Epoch 00140 | Train Loss : 0.3972 | Eval Loss : 0.4104 | Train acc : 0.8115 | Eval Acc : 0.8038
     Batch 000 | Loss : 0.3763 | Acc : 0.8221
     Batch 025 | Loss : 0.3597 | Acc : 0.8357
     Batch 050 | Loss : 0.3953 | Acc : 0.8126
     Batch 075 | Loss : 0.4580 | Acc : 0.7776
     Batch 100 | Loss : 0.3426 | Acc : 0.8383
     Batch 125 | Loss : 0.3460 | Acc : 0.8503
     Batch 150 | Loss : 0.4106 | Acc : 0.8027
     Batch 175 | Loss : 0.3278 | Acc : 0.8610
     Batch 200 | Loss : 0.3917 | Acc : 0.8182
     Batch 225 | Loss : 0.4184 | Acc : 0.7983
     Batch 250 | Loss : 0.3810 | Acc : 0.8172
     Batch 275 | Loss : 0.3559 | Acc : 0.8308
     Batch 300 | Loss : 0.3153 | Acc : 0.8585
Epoch 00141 | Train Loss : 0.3958 | Eval Loss : 0.4036 | Train acc : 0.8121 | Eval Acc : 0.8071
     Batch 000 | Loss : 0.4180 | Acc : 0.7960
     Batch 025 | Loss : 0.3734 | Acc : 0.8295
     Batch 050 | Loss : 0.3501 | Acc : 0.8394
     Batch 075 | Loss : 0.3531 | Acc : 0.8369
     Batch 100 | Loss : 0.3845 | Acc : 0.8248
     Batch 125 | Loss : 0.3955 | Acc : 0.8160
     Batch 150 | Loss : 0.3734 | Acc : 0.8262
     Batch 175 | Loss : 0.5044 | Acc : 0.7503
     Batch 200 | Loss : 0.4608 | Acc : 0.7799
     Batch 225 | Loss : 0.3989 | Acc : 0.8078
     Batch 250 | Loss : 0.3429 | Acc : 0.8476
     Batch 275 | Loss : 0.3344 | Acc : 0.8420
     Batch 300 | Loss : 0.3144 | Acc : 0.8649
Epoch 00142 | Train Loss : 0.3923 | Eval Loss : 0.4226 | Train acc : 0.8137 | Eval Acc : 0.8016
     Batch 000 | Loss : 0.3745 | Acc : 0.8260
     Batch 025 | Loss : 0.3823 | Acc : 0.8263
     Batch 050 | Loss : 0.3483 | Acc : 0.8453
     Batch 075 | Loss : 0.4065 | Acc : 0.8012
     Batch 100 | Loss : 0.3610 | Acc : 0.8272
     Batch 125 | Loss : 0.3727 | Acc : 0.8216
     Batch 150 | Loss : 0.3557 | Acc : 0.8403
     Batch 175 | Loss : 0.3965 | Acc : 0.8081
     Batch 200 | Loss : 0.3500 | Acc : 0.8419
     Batch 225 | Loss : 0.3602 | Acc : 0.8302
     Batch 250 | Loss : 0.4130 | Acc : 0.8076
     Batch 275 | Loss : 0.3445 | Acc : 0.8478
     Batch 300 | Loss : 0.4289 | Acc : 0.7952
Epoch 00143 | Train Loss : 0.3951 | Eval Loss : 0.4050 | Train acc : 0.8126 | Eval Acc : 0.8061
     Batch 000 | Loss : 0.4249 | Acc : 0.7950
     Batch 025 | Loss : 0.4650 | Acc : 0.7665
     Batch 050 | Loss : 0.4087 | Acc : 0.7979
     Batch 075 | Loss : 0.4678 | Acc : 0.7635
     Batch 100 | Loss : 0.3766 | Acc : 0.8141
     Batch 125 | Loss : 0.3956 | Acc : 0.8070
     Batch 150 | Loss : 0.4293 | Acc : 0.7845
     Batch 175 | Loss : 0.4071 | Acc : 0.7961
     Batch 200 | Loss : 0.3639 | Acc : 0.8296
     Batch 225 | Loss : 0.3915 | Acc : 0.8148
     Batch 250 | Loss : 0.3399 | Acc : 0.8398
     Batch 275 | Loss : 0.4287 | Acc : 0.7799
     Batch 300 | Loss : 0.3876 | Acc : 0.8255
Epoch 00144 | Train Loss : 0.3925 | Eval Loss : 0.4026 | Train acc : 0.8136 | Eval Acc : 0.8062
     Batch 000 | Loss : 0.3852 | Acc : 0.8149
     Batch 025 | Loss : 0.3891 | Acc : 0.8177
     Batch 050 | Loss : 0.4070 | Acc : 0.7995
     Batch 075 | Loss : 0.3197 | Acc : 0.8597
     Batch 100 | Loss : 0.4360 | Acc : 0.7902
     Batch 125 | Loss : 0.3407 | Acc : 0.8424
     Batch 150 | Loss : 0.4486 | Acc : 0.7838
     Batch 175 | Loss : 0.3646 | Acc : 0.8323
     Batch 200 | Loss : 0.3565 | Acc : 0.8347
     Batch 225 | Loss : 0.3788 | Acc : 0.8202
     Batch 250 | Loss : 0.3580 | Acc : 0.8277
     Batch 275 | Loss : 0.3588 | Acc : 0.8279
     Batch 300 | Loss : 0.4120 | Acc : 0.7953
Epoch 00145 | Train Loss : 0.3932 | Eval Loss : 0.4160 | Train acc : 0.8132 | Eval Acc : 0.8004
     Batch 000 | Loss : 0.3492 | Acc : 0.8357
     Batch 025 | Loss : 0.4801 | Acc : 0.7636
     Batch 050 | Loss : 0.4380 | Acc : 0.7866
     Batch 075 | Loss : 0.5111 | Acc : 0.7597
     Batch 100 | Loss : 0.3708 | Acc : 0.8264
     Batch 125 | Loss : 0.4090 | Acc : 0.7990
     Batch 150 | Loss : 0.4477 | Acc : 0.7772
     Batch 175 | Loss : 0.3544 | Acc : 0.8382
     Batch 200 | Loss : 0.3677 | Acc : 0.8273
     Batch 225 | Loss : 0.4486 | Acc : 0.7835
     Batch 250 | Loss : 0.3666 | Acc : 0.8310
     Batch 275 | Loss : 0.3757 | Acc : 0.8267
     Batch 300 | Loss : 0.3714 | Acc : 0.8235
Epoch 00146 | Train Loss : 0.3936 | Eval Loss : 0.4105 | Train acc : 0.8131 | Eval Acc : 0.8037
     Batch 000 | Loss : 0.3647 | Acc : 0.8321
     Batch 025 | Loss : 0.4061 | Acc : 0.8104
     Batch 050 | Loss : 0.3899 | Acc : 0.8206
     Batch 075 | Loss : 0.3966 | Acc : 0.8157
     Batch 100 | Loss : 0.3899 | Acc : 0.8162
     Batch 125 | Loss : 0.3539 | Acc : 0.8424
     Batch 150 | Loss : 0.4449 | Acc : 0.7800
     Batch 175 | Loss : 0.4032 | Acc : 0.8087
     Batch 200 | Loss : 0.4086 | Acc : 0.8035
     Batch 225 | Loss : 0.3384 | Acc : 0.8529
     Batch 250 | Loss : 0.4016 | Acc : 0.8049
     Batch 275 | Loss : 0.4459 | Acc : 0.7754
     Batch 300 | Loss : 0.4314 | Acc : 0.7874
Epoch 00147 | Train Loss : 0.3947 | Eval Loss : 0.4054 | Train acc : 0.8131 | Eval Acc : 0.8058
     Batch 000 | Loss : 0.4016 | Acc : 0.8059
     Batch 025 | Loss : 0.3814 | Acc : 0.8176
     Batch 050 | Loss : 0.3786 | Acc : 0.8198
     Batch 075 | Loss : 0.4700 | Acc : 0.7743
     Batch 100 | Loss : 0.3885 | Acc : 0.8157
     Batch 125 | Loss : 0.4539 | Acc : 0.7885
     Batch 150 | Loss : 0.5045 | Acc : 0.7556
     Batch 175 | Loss : 0.3949 | Acc : 0.8104
     Batch 200 | Loss : 0.3628 | Acc : 0.8248
     Batch 225 | Loss : 0.3437 | Acc : 0.8505
     Batch 250 | Loss : 0.4113 | Acc : 0.7993
     Batch 275 | Loss : 0.4487 | Acc : 0.7775
     Batch 300 | Loss : 0.3891 | Acc : 0.8144
Epoch 00148 | Train Loss : 0.3931 | Eval Loss : 0.4032 | Train acc : 0.8134 | Eval Acc : 0.8062
     Batch 000 | Loss : 0.4084 | Acc : 0.8043
     Batch 025 | Loss : 0.4581 | Acc : 0.7736
     Batch 050 | Loss : 0.3700 | Acc : 0.8304
     Batch 075 | Loss : 0.4770 | Acc : 0.7640
     Batch 100 | Loss : 0.3929 | Acc : 0.8116
     Batch 125 | Loss : 0.3541 | Acc : 0.8344
     Batch 150 | Loss : 0.3612 | Acc : 0.8282
     Batch 175 | Loss : 0.5069 | Acc : 0.7619
     Batch 200 | Loss : 0.3570 | Acc : 0.8415
     Batch 225 | Loss : 0.3766 | Acc : 0.8223
     Batch 250 | Loss : 0.4617 | Acc : 0.7738
     Batch 275 | Loss : 0.3516 | Acc : 0.8417
     Batch 300 | Loss : 0.3438 | Acc : 0.8369
Epoch 00149 | Train Loss : 0.3929 | Eval Loss : 0.4104 | Train acc : 0.8134 | Eval Acc : 0.8044
     Batch 000 | Loss : 0.4133 | Acc : 0.8020
     Batch 025 | Loss : 0.3648 | Acc : 0.8284
     Batch 050 | Loss : 0.3345 | Acc : 0.8523
     Batch 075 | Loss : 0.3615 | Acc : 0.8300
     Batch 100 | Loss : 0.3690 | Acc : 0.8301
     Batch 125 | Loss : 0.3404 | Acc : 0.8459
     Batch 150 | Loss : 0.4289 | Acc : 0.7942
     Batch 175 | Loss : 0.3661 | Acc : 0.8343
     Batch 200 | Loss : 0.4472 | Acc : 0.7745
     Batch 225 | Loss : 0.3352 | Acc : 0.8442
     Batch 250 | Loss : 0.4478 | Acc : 0.7847
     Batch 275 | Loss : 0.3847 | Acc : 0.8136
     Batch 300 | Loss : 0.4299 | Acc : 0.7878
Epoch 00150 | Train Loss : 0.3935 | Eval Loss : 0.4057 | Train acc : 0.8133 | Eval Acc : 0.8048
     Batch 000 | Loss : 0.3866 | Acc : 0.8187
     Batch 025 | Loss : 0.3751 | Acc : 0.8211
     Batch 050 | Loss : 0.3691 | Acc : 0.8270
     Batch 075 | Loss : 0.4018 | Acc : 0.8107
     Batch 100 | Loss : 0.3583 | Acc : 0.8375
     Batch 125 | Loss : 0.3641 | Acc : 0.8337
     Batch 150 | Loss : 0.4260 | Acc : 0.7898
     Batch 175 | Loss : 0.4635 | Acc : 0.7746
     Batch 200 | Loss : 0.3542 | Acc : 0.8332
     Batch 225 | Loss : 0.4037 | Acc : 0.8062
     Batch 250 | Loss : 0.3911 | Acc : 0.8235
     Batch 275 | Loss : 0.3573 | Acc : 0.8387
     Batch 300 | Loss : 0.3509 | Acc : 0.8416
Epoch 00151 | Train Loss : 0.3955 | Eval Loss : 0.4026 | Train acc : 0.8123 | Eval Acc : 0.8062
     Batch 000 | Loss : 0.3399 | Acc : 0.8406
     Batch 025 | Loss : 0.3412 | Acc : 0.8490
     Batch 050 | Loss : 0.4634 | Acc : 0.7691
     Batch 075 | Loss : 0.4203 | Acc : 0.8054
     Batch 100 | Loss : 0.4740 | Acc : 0.7733
     Batch 125 | Loss : 0.4082 | Acc : 0.8011
     Batch 150 | Loss : 0.3993 | Acc : 0.8118
     Batch 175 | Loss : 0.3648 | Acc : 0.8425
     Batch 200 | Loss : 0.3458 | Acc : 0.8435
     Batch 225 | Loss : 0.3716 | Acc : 0.8288
     Batch 250 | Loss : 0.3576 | Acc : 0.8358
     Batch 275 | Loss : 0.4704 | Acc : 0.7620
     Batch 300 | Loss : 0.3360 | Acc : 0.8512
Epoch 00152 | Train Loss : 0.3975 | Eval Loss : 0.4121 | Train acc : 0.8115 | Eval Acc : 0.8034
     Batch 000 | Loss : 0.3618 | Acc : 0.8325
     Batch 025 | Loss : 0.3691 | Acc : 0.8365
     Batch 050 | Loss : 0.3897 | Acc : 0.8172
     Batch 075 | Loss : 0.3791 | Acc : 0.8213
     Batch 100 | Loss : 0.3661 | Acc : 0.8252
     Batch 125 | Loss : 0.4114 | Acc : 0.7937
     Batch 150 | Loss : 0.3513 | Acc : 0.8368
     Batch 175 | Loss : 0.3566 | Acc : 0.8440
     Batch 200 | Loss : 0.4292 | Acc : 0.7865
     Batch 225 | Loss : 0.3815 | Acc : 0.8196
     Batch 250 | Loss : 0.3644 | Acc : 0.8288
     Batch 275 | Loss : 0.3635 | Acc : 0.8337
     Batch 300 | Loss : 0.4998 | Acc : 0.7573
Epoch 00153 | Train Loss : 0.3960 | Eval Loss : 0.4020 | Train acc : 0.8122 | Eval Acc : 0.8063
     Batch 000 | Loss : 0.3608 | Acc : 0.8341
     Batch 025 | Loss : 0.4381 | Acc : 0.7934
     Batch 050 | Loss : 0.4920 | Acc : 0.7635
     Batch 075 | Loss : 0.4720 | Acc : 0.7667
     Batch 100 | Loss : 0.3533 | Acc : 0.8398
     Batch 125 | Loss : 0.4243 | Acc : 0.7927
     Batch 150 | Loss : 0.3310 | Acc : 0.8476
     Batch 175 | Loss : 0.3882 | Acc : 0.8144
     Batch 200 | Loss : 0.4289 | Acc : 0.7976
     Batch 225 | Loss : 0.3667 | Acc : 0.8357
     Batch 250 | Loss : 0.3495 | Acc : 0.8469
     Batch 275 | Loss : 0.3700 | Acc : 0.8295
     Batch 300 | Loss : 0.4353 | Acc : 0.7953
Epoch 00154 | Train Loss : 0.3945 | Eval Loss : 0.4053 | Train acc : 0.8130 | Eval Acc : 0.8052
     Batch 000 | Loss : 0.4142 | Acc : 0.7941
     Batch 025 | Loss : 0.4262 | Acc : 0.7959
     Batch 050 | Loss : 0.3792 | Acc : 0.8150
     Batch 075 | Loss : 0.4399 | Acc : 0.7778
     Batch 100 | Loss : 0.3614 | Acc : 0.8293
     Batch 125 | Loss : 0.3602 | Acc : 0.8361
     Batch 150 | Loss : 0.3939 | Acc : 0.8094
     Batch 175 | Loss : 0.4210 | Acc : 0.7979
     Batch 200 | Loss : 0.4521 | Acc : 0.7772
     Batch 225 | Loss : 0.3429 | Acc : 0.8424
     Batch 250 | Loss : 0.3774 | Acc : 0.8248
     Batch 275 | Loss : 0.4688 | Acc : 0.7593
     Batch 300 | Loss : 0.4749 | Acc : 0.7669
Epoch 00155 | Train Loss : 0.3958 | Eval Loss : 0.4052 | Train acc : 0.8125 | Eval Acc : 0.8053
     Batch 000 | Loss : 0.4376 | Acc : 0.7869
     Batch 025 | Loss : 0.3974 | Acc : 0.8110
     Batch 050 | Loss : 0.4200 | Acc : 0.7923
     Batch 075 | Loss : 0.3943 | Acc : 0.8242
     Batch 100 | Loss : 0.4299 | Acc : 0.7892
     Batch 125 | Loss : 0.4808 | Acc : 0.7717
     Batch 150 | Loss : 0.3443 | Acc : 0.8402
     Batch 175 | Loss : 0.4195 | Acc : 0.7982
     Batch 200 | Loss : 0.4276 | Acc : 0.7968
     Batch 225 | Loss : 0.4771 | Acc : 0.7656
     Batch 250 | Loss : 0.4099 | Acc : 0.8068
     Batch 275 | Loss : 0.3877 | Acc : 0.8250
     Batch 300 | Loss : 0.3434 | Acc : 0.8462
Epoch 00156 | Train Loss : 0.3932 | Eval Loss : 0.4094 | Train acc : 0.8134 | Eval Acc : 0.8037
     Batch 000 | Loss : 0.3757 | Acc : 0.8336
     Batch 025 | Loss : 0.3608 | Acc : 0.8344
     Batch 050 | Loss : 0.4130 | Acc : 0.8004
     Batch 075 | Loss : 0.3828 | Acc : 0.8125
     Batch 100 | Loss : 0.4133 | Acc : 0.8005
     Batch 125 | Loss : 0.3700 | Acc : 0.8257
     Batch 150 | Loss : 0.4350 | Acc : 0.7825
     Batch 175 | Loss : 0.3656 | Acc : 0.8225
     Batch 200 | Loss : 0.3692 | Acc : 0.8331
     Batch 225 | Loss : 0.3923 | Acc : 0.8141
     Batch 250 | Loss : 0.4315 | Acc : 0.7887
     Batch 275 | Loss : 0.4166 | Acc : 0.7990
     Batch 300 | Loss : 0.3640 | Acc : 0.8336
Epoch 00157 | Train Loss : 0.3927 | Eval Loss : 0.4155 | Train acc : 0.8137 | Eval Acc : 0.8063
     Batch 000 | Loss : 0.3418 | Acc : 0.8406
     Batch 025 | Loss : 0.3263 | Acc : 0.8580
     Batch 050 | Loss : 0.3122 | Acc : 0.8647
     Batch 075 | Loss : 0.4175 | Acc : 0.7985
     Batch 100 | Loss : 0.4214 | Acc : 0.8065
     Batch 125 | Loss : 0.4628 | Acc : 0.7650
     Batch 150 | Loss : 0.3612 | Acc : 0.8313
     Batch 175 | Loss : 0.4006 | Acc : 0.8090
     Batch 200 | Loss : 0.3357 | Acc : 0.8515
     Batch 225 | Loss : 0.3846 | Acc : 0.8218
     Batch 250 | Loss : 0.3546 | Acc : 0.8344
     Batch 275 | Loss : 0.4075 | Acc : 0.8039
     Batch 300 | Loss : 0.5710 | Acc : 0.7194
Epoch 00158 | Train Loss : 0.3975 | Eval Loss : 0.3994 | Train acc : 0.8130 | Eval Acc : 0.8086
     Batch 000 | Loss : 0.3759 | Acc : 0.8271
     Batch 025 | Loss : 0.4234 | Acc : 0.7994
     Batch 050 | Loss : 0.4064 | Acc : 0.8015
     Batch 075 | Loss : 0.4329 | Acc : 0.7820
     Batch 100 | Loss : 0.4106 | Acc : 0.7997
     Batch 125 | Loss : 0.4109 | Acc : 0.7985
     Batch 150 | Loss : 0.3998 | Acc : 0.8167
     Batch 175 | Loss : 0.4457 | Acc : 0.7771
     Batch 200 | Loss : 0.3541 | Acc : 0.8428
     Batch 225 | Loss : 0.3708 | Acc : 0.8230
     Batch 250 | Loss : 0.4530 | Acc : 0.7763
     Batch 275 | Loss : 0.4891 | Acc : 0.7686
     Batch 300 | Loss : 0.4980 | Acc : 0.7563
Epoch 00159 | Train Loss : 0.3946 | Eval Loss : 0.4110 | Train acc : 0.8129 | Eval Acc : 0.8035
     Batch 000 | Loss : 0.4017 | Acc : 0.8018
     Batch 025 | Loss : 0.3275 | Acc : 0.8552
     Batch 050 | Loss : 0.4054 | Acc : 0.8092
     Batch 075 | Loss : 0.4234 | Acc : 0.7915
     Batch 100 | Loss : 0.3853 | Acc : 0.8146
     Batch 125 | Loss : 0.4383 | Acc : 0.7885
     Batch 150 | Loss : 0.3879 | Acc : 0.8171
     Batch 175 | Loss : 0.3675 | Acc : 0.8280
     Batch 200 | Loss : 0.3868 | Acc : 0.8123
     Batch 225 | Loss : 0.3605 | Acc : 0.8345
     Batch 250 | Loss : 0.3927 | Acc : 0.8101
     Batch 275 | Loss : 0.3744 | Acc : 0.8214
     Batch 300 | Loss : 0.3737 | Acc : 0.8245
Epoch 00160 | Train Loss : 0.3921 | Eval Loss : 0.4040 | Train acc : 0.8138 | Eval Acc : 0.8080
     Batch 000 | Loss : 0.3536 | Acc : 0.8502
     Batch 025 | Loss : 0.4204 | Acc : 0.7960
     Batch 050 | Loss : 0.3550 | Acc : 0.8407
     Batch 075 | Loss : 0.4335 | Acc : 0.7845
     Batch 100 | Loss : 0.4096 | Acc : 0.7997
     Batch 125 | Loss : 0.3837 | Acc : 0.8226
     Batch 150 | Loss : 0.4619 | Acc : 0.7665
     Batch 175 | Loss : 0.3928 | Acc : 0.8104
     Batch 200 | Loss : 0.3968 | Acc : 0.8122
     Batch 225 | Loss : 0.4225 | Acc : 0.7926
     Batch 250 | Loss : 0.3507 | Acc : 0.8300
     Batch 275 | Loss : 0.3497 | Acc : 0.8438
     Batch 300 | Loss : 0.3801 | Acc : 0.8228
Epoch 00161 | Train Loss : 0.3931 | Eval Loss : 0.4027 | Train acc : 0.8136 | Eval Acc : 0.8066
     Batch 000 | Loss : 0.3675 | Acc : 0.8302
     Batch 025 | Loss : 0.4128 | Acc : 0.8018
     Batch 050 | Loss : 0.4007 | Acc : 0.8347
     Batch 075 | Loss : 0.3682 | Acc : 0.8276
     Batch 100 | Loss : 0.4393 | Acc : 0.7872
     Batch 125 | Loss : 0.5508 | Acc : 0.7453
     Batch 150 | Loss : 0.3510 | Acc : 0.8533
     Batch 175 | Loss : 0.4228 | Acc : 0.7954
     Batch 200 | Loss : 0.3395 | Acc : 0.8484
     Batch 225 | Loss : 0.3611 | Acc : 0.8397
     Batch 250 | Loss : 0.3497 | Acc : 0.8465
     Batch 275 | Loss : 0.4372 | Acc : 0.7846
     Batch 300 | Loss : 0.3570 | Acc : 0.8276
Epoch 00162 | Train Loss : 0.3988 | Eval Loss : 0.4099 | Train acc : 0.8110 | Eval Acc : 0.8039
     Batch 000 | Loss : 0.3998 | Acc : 0.8102
     Batch 025 | Loss : 0.3489 | Acc : 0.8437
     Batch 050 | Loss : 0.3301 | Acc : 0.8493
     Batch 075 | Loss : 0.4062 | Acc : 0.8014
     Batch 100 | Loss : 0.3375 | Acc : 0.8435
     Batch 125 | Loss : 0.3641 | Acc : 0.8316
     Batch 150 | Loss : 0.4298 | Acc : 0.7903
     Batch 175 | Loss : 0.3919 | Acc : 0.8148
     Batch 200 | Loss : 0.3591 | Acc : 0.8258
     Batch 225 | Loss : 0.5148 | Acc : 0.7673
     Batch 250 | Loss : 0.4309 | Acc : 0.7830
     Batch 275 | Loss : 0.3539 | Acc : 0.8333
     Batch 300 | Loss : 0.4050 | Acc : 0.8082
Epoch 00163 | Train Loss : 0.3930 | Eval Loss : 0.4025 | Train acc : 0.8134 | Eval Acc : 0.8068
     Batch 000 | Loss : 0.4132 | Acc : 0.7907
     Batch 025 | Loss : 0.3539 | Acc : 0.8362
     Batch 050 | Loss : 0.4132 | Acc : 0.8015
     Batch 075 | Loss : 0.3723 | Acc : 0.8240
     Batch 100 | Loss : 0.5429 | Acc : 0.7550
     Batch 125 | Loss : 0.4937 | Acc : 0.7762
     Batch 150 | Loss : 0.4322 | Acc : 0.7908
     Batch 175 | Loss : 0.3473 | Acc : 0.8415
     Batch 200 | Loss : 0.3765 | Acc : 0.8179
     Batch 225 | Loss : 0.4741 | Acc : 0.7550
     Batch 250 | Loss : 0.3604 | Acc : 0.8333
     Batch 275 | Loss : 0.4048 | Acc : 0.8024
     Batch 300 | Loss : 0.3461 | Acc : 0.8434
Epoch 00164 | Train Loss : 0.3930 | Eval Loss : 0.4039 | Train acc : 0.8135 | Eval Acc : 0.8071
     Batch 000 | Loss : 0.4288 | Acc : 0.7896
     Batch 025 | Loss : 0.3688 | Acc : 0.8231
     Batch 050 | Loss : 0.3513 | Acc : 0.8366
     Batch 075 | Loss : 0.3647 | Acc : 0.8312
     Batch 100 | Loss : 0.4351 | Acc : 0.7825
     Batch 125 | Loss : 0.3814 | Acc : 0.8222
     Batch 150 | Loss : 0.3419 | Acc : 0.8457
     Batch 175 | Loss : 0.4482 | Acc : 0.7892
     Batch 200 | Loss : 0.4022 | Acc : 0.8025
     Batch 225 | Loss : 0.3633 | Acc : 0.8293
     Batch 250 | Loss : 0.4098 | Acc : 0.8036
     Batch 275 | Loss : 0.4340 | Acc : 0.7825
     Batch 300 | Loss : 0.4498 | Acc : 0.7696
Epoch 00165 | Train Loss : 0.3934 | Eval Loss : 0.4094 | Train acc : 0.8137 | Eval Acc : 0.8027
     Batch 000 | Loss : 0.4316 | Acc : 0.7884
     Batch 025 | Loss : 0.3513 | Acc : 0.8351
     Batch 050 | Loss : 0.3919 | Acc : 0.8203
     Batch 075 | Loss : 0.4701 | Acc : 0.7638
     Batch 100 | Loss : 0.3486 | Acc : 0.8400
     Batch 125 | Loss : 0.3559 | Acc : 0.8309
     Batch 150 | Loss : 0.3897 | Acc : 0.8147
     Batch 175 | Loss : 0.3199 | Acc : 0.8562
     Batch 200 | Loss : 0.3418 | Acc : 0.8392
     Batch 225 | Loss : 0.3399 | Acc : 0.8438
     Batch 250 | Loss : 0.3685 | Acc : 0.8295
     Batch 275 | Loss : 0.4132 | Acc : 0.7977
     Batch 300 | Loss : 0.3761 | Acc : 0.8244
Epoch 00166 | Train Loss : 0.3943 | Eval Loss : 0.4061 | Train acc : 0.8130 | Eval Acc : 0.8056
     Batch 000 | Loss : 0.3804 | Acc : 0.8236
     Batch 025 | Loss : 0.4344 | Acc : 0.7775
     Batch 050 | Loss : 0.3959 | Acc : 0.8114
     Batch 075 | Loss : 0.4438 | Acc : 0.7816
     Batch 100 | Loss : 0.4047 | Acc : 0.8084
     Batch 125 | Loss : 0.4267 | Acc : 0.7929
     Batch 150 | Loss : 0.3657 | Acc : 0.8230
     Batch 175 | Loss : 0.5266 | Acc : 0.7559
     Batch 200 | Loss : 0.4304 | Acc : 0.7948
     Batch 225 | Loss : 0.3997 | Acc : 0.8125
     Batch 250 | Loss : 0.3995 | Acc : 0.8059
     Batch 275 | Loss : 0.3603 | Acc : 0.8330
     Batch 300 | Loss : 0.3724 | Acc : 0.8263
Epoch 00167 | Train Loss : 0.3940 | Eval Loss : 0.3994 | Train acc : 0.8129 | Eval Acc : 0.8081
     Batch 000 | Loss : 0.3533 | Acc : 0.8316
     Batch 025 | Loss : 0.4002 | Acc : 0.8053
     Batch 050 | Loss : 0.3303 | Acc : 0.8486
     Batch 075 | Loss : 0.4379 | Acc : 0.7845
     Batch 100 | Loss : 0.3295 | Acc : 0.8431
     Batch 125 | Loss : 0.4365 | Acc : 0.7855
     Batch 150 | Loss : 0.3554 | Acc : 0.8326
     Batch 175 | Loss : 0.3424 | Acc : 0.8433
     Batch 200 | Loss : 0.4378 | Acc : 0.7896
     Batch 225 | Loss : 0.3341 | Acc : 0.8485
     Batch 250 | Loss : 0.3578 | Acc : 0.8384
     Batch 275 | Loss : 0.3437 | Acc : 0.8417
     Batch 300 | Loss : 0.3650 | Acc : 0.8302
Epoch 00168 | Train Loss : 0.3940 | Eval Loss : 0.4009 | Train acc : 0.8131 | Eval Acc : 0.8071
     Batch 000 | Loss : 0.4225 | Acc : 0.7881
     Batch 025 | Loss : 0.3475 | Acc : 0.8459
     Batch 050 | Loss : 0.4060 | Acc : 0.7992
     Batch 075 | Loss : 0.3924 | Acc : 0.8087
     Batch 100 | Loss : 0.4608 | Acc : 0.7717
     Batch 125 | Loss : 0.3620 | Acc : 0.8380
     Batch 150 | Loss : 0.4357 | Acc : 0.7847
     Batch 175 | Loss : 0.3424 | Acc : 0.8399
     Batch 200 | Loss : 0.4814 | Acc : 0.7751
     Batch 225 | Loss : 0.3339 | Acc : 0.8522
     Batch 250 | Loss : 0.4172 | Acc : 0.7989
     Batch 275 | Loss : 0.4251 | Acc : 0.7901
     Batch 300 | Loss : 0.4467 | Acc : 0.7814
Epoch 00169 | Train Loss : 0.3947 | Eval Loss : 0.4145 | Train acc : 0.8126 | Eval Acc : 0.7994
     Batch 000 | Loss : 0.3524 | Acc : 0.8436
     Batch 025 | Loss : 0.3702 | Acc : 0.8271
     Batch 050 | Loss : 0.3878 | Acc : 0.8141
     Batch 075 | Loss : 0.3884 | Acc : 0.8204
     Batch 100 | Loss : 0.3813 | Acc : 0.8157
     Batch 125 | Loss : 0.4419 | Acc : 0.7753
     Batch 150 | Loss : 0.3675 | Acc : 0.8309
     Batch 175 | Loss : 0.4843 | Acc : 0.7730
     Batch 200 | Loss : 0.5079 | Acc : 0.7524
     Batch 225 | Loss : 0.4339 | Acc : 0.7951
     Batch 250 | Loss : 0.4193 | Acc : 0.7955
     Batch 275 | Loss : 0.4276 | Acc : 0.7928
     Batch 300 | Loss : 0.3697 | Acc : 0.8269
Epoch 00170 | Train Loss : 0.3933 | Eval Loss : 0.4043 | Train acc : 0.8137 | Eval Acc : 0.8083
     Batch 000 | Loss : 0.3887 | Acc : 0.8083
     Batch 025 | Loss : 0.4688 | Acc : 0.7643
     Batch 050 | Loss : 0.4115 | Acc : 0.8079
     Batch 075 | Loss : 0.3582 | Acc : 0.8266
     Batch 100 | Loss : 0.3863 | Acc : 0.8160
     Batch 125 | Loss : 0.3351 | Acc : 0.8506
     Batch 150 | Loss : 0.3972 | Acc : 0.8097
     Batch 175 | Loss : 0.3844 | Acc : 0.8174
     Batch 200 | Loss : 0.4603 | Acc : 0.7755
     Batch 225 | Loss : 0.3708 | Acc : 0.8247
     Batch 250 | Loss : 0.3384 | Acc : 0.8487
     Batch 275 | Loss : 0.4233 | Acc : 0.7875
     Batch 300 | Loss : 0.3280 | Acc : 0.8530
Epoch 00171 | Train Loss : 0.3921 | Eval Loss : 0.4075 | Train acc : 0.8138 | Eval Acc : 0.8047
     Batch 000 | Loss : 0.4414 | Acc : 0.7949
     Batch 025 | Loss : 0.3293 | Acc : 0.8556
     Batch 050 | Loss : 0.4401 | Acc : 0.7918
     Batch 075 | Loss : 0.3507 | Acc : 0.8425
     Batch 100 | Loss : 0.4689 | Acc : 0.7564
     Batch 125 | Loss : 0.4303 | Acc : 0.7876
     Batch 150 | Loss : 0.4128 | Acc : 0.7986
     Batch 175 | Loss : 0.3648 | Acc : 0.8272
     Batch 200 | Loss : 0.4574 | Acc : 0.7815
     Batch 225 | Loss : 0.4895 | Acc : 0.7740
     Batch 250 | Loss : 0.4235 | Acc : 0.7946
     Batch 275 | Loss : 0.3510 | Acc : 0.8338
     Batch 300 | Loss : 0.3355 | Acc : 0.8527
Epoch 00172 | Train Loss : 0.3931 | Eval Loss : 0.3988 | Train acc : 0.8138 | Eval Acc : 0.8089
     Batch 000 | Loss : 0.3403 | Acc : 0.8450
     Batch 025 | Loss : 0.3588 | Acc : 0.8328
     Batch 050 | Loss : 0.3683 | Acc : 0.8293
     Batch 075 | Loss : 0.3891 | Acc : 0.8110
     Batch 100 | Loss : 0.3984 | Acc : 0.8109
     Batch 125 | Loss : 0.3466 | Acc : 0.8414
     Batch 150 | Loss : 0.4303 | Acc : 0.7948
     Batch 175 | Loss : 0.3991 | Acc : 0.8091
     Batch 200 | Loss : 0.4414 | Acc : 0.7881
     Batch 225 | Loss : 0.4545 | Acc : 0.7714
     Batch 250 | Loss : 0.4654 | Acc : 0.7766
     Batch 275 | Loss : 0.4249 | Acc : 0.7885
     Batch 300 | Loss : 0.4366 | Acc : 0.7851
Epoch 00173 | Train Loss : 0.3928 | Eval Loss : 0.4068 | Train acc : 0.8133 | Eval Acc : 0.8066
     Batch 000 | Loss : 0.3578 | Acc : 0.8265
     Batch 025 | Loss : 0.3459 | Acc : 0.8351
     Batch 050 | Loss : 0.3950 | Acc : 0.8102
     Batch 075 | Loss : 0.4249 | Acc : 0.7860
     Batch 100 | Loss : 0.3792 | Acc : 0.8160
     Batch 125 | Loss : 0.4255 | Acc : 0.7850
     Batch 150 | Loss : 0.3619 | Acc : 0.8277
     Batch 175 | Loss : 0.4059 | Acc : 0.8060
     Batch 200 | Loss : 0.3723 | Acc : 0.8197
     Batch 225 | Loss : 0.4017 | Acc : 0.8045
     Batch 250 | Loss : 0.3792 | Acc : 0.8162
     Batch 275 | Loss : 0.3555 | Acc : 0.8363
     Batch 300 | Loss : 0.4120 | Acc : 0.8046
Epoch 00174 | Train Loss : 0.3936 | Eval Loss : 0.4182 | Train acc : 0.8131 | Eval Acc : 0.8023
     Batch 000 | Loss : 0.3435 | Acc : 0.8439
     Batch 025 | Loss : 0.3731 | Acc : 0.8244
     Batch 050 | Loss : 0.3149 | Acc : 0.8632
     Batch 075 | Loss : 0.3797 | Acc : 0.8165
     Batch 100 | Loss : 0.4205 | Acc : 0.7930
     Batch 125 | Loss : 0.3410 | Acc : 0.8394
     Batch 150 | Loss : 0.3963 | Acc : 0.8086
     Batch 175 | Loss : 0.3395 | Acc : 0.8448
     Batch 200 | Loss : 0.3662 | Acc : 0.8271
     Batch 225 | Loss : 0.3521 | Acc : 0.8343
     Batch 250 | Loss : 0.4088 | Acc : 0.8015
     Batch 275 | Loss : 0.3855 | Acc : 0.8177
     Batch 300 | Loss : 0.3586 | Acc : 0.8348
Epoch 00175 | Train Loss : 0.3938 | Eval Loss : 0.4039 | Train acc : 0.8131 | Eval Acc : 0.8052
     Batch 000 | Loss : 0.4195 | Acc : 0.7973
     Batch 025 | Loss : 0.3803 | Acc : 0.8120
     Batch 050 | Loss : 0.3447 | Acc : 0.8515
     Batch 075 | Loss : 0.4079 | Acc : 0.8037
     Batch 100 | Loss : 0.4562 | Acc : 0.7748
     Batch 125 | Loss : 0.3681 | Acc : 0.8275
     Batch 150 | Loss : 0.4006 | Acc : 0.8048
     Batch 175 | Loss : 0.3795 | Acc : 0.8287
     Batch 200 | Loss : 0.3490 | Acc : 0.8397
     Batch 225 | Loss : 0.4221 | Acc : 0.7945
     Batch 250 | Loss : 0.3569 | Acc : 0.8345
     Batch 275 | Loss : 0.4061 | Acc : 0.8028
     Batch 300 | Loss : 0.3815 | Acc : 0.8167
Epoch 00176 | Train Loss : 0.3921 | Eval Loss : 0.4073 | Train acc : 0.8142 | Eval Acc : 0.8034
     Batch 000 | Loss : 0.3798 | Acc : 0.8221
     Batch 025 | Loss : 0.4313 | Acc : 0.7874
     Batch 050 | Loss : 0.3544 | Acc : 0.8420
     Batch 075 | Loss : 0.3622 | Acc : 0.8305
     Batch 100 | Loss : 0.3649 | Acc : 0.8297
     Batch 125 | Loss : 0.4537 | Acc : 0.7802
     Batch 150 | Loss : 0.3970 | Acc : 0.8046
     Batch 175 | Loss : 0.3454 | Acc : 0.8406
     Batch 200 | Loss : 0.3654 | Acc : 0.8294
     Batch 225 | Loss : 0.3852 | Acc : 0.8111
     Batch 250 | Loss : 0.4168 | Acc : 0.7993
     Batch 275 | Loss : 0.3301 | Acc : 0.8510
     Batch 300 | Loss : 0.3612 | Acc : 0.8305
Epoch 00177 | Train Loss : 0.3948 | Eval Loss : 0.4015 | Train acc : 0.8129 | Eval Acc : 0.8079
     Batch 000 | Loss : 0.3793 | Acc : 0.8212
     Batch 025 | Loss : 0.4059 | Acc : 0.8112
     Batch 050 | Loss : 0.3647 | Acc : 0.8287
     Batch 075 | Loss : 0.3816 | Acc : 0.8225
     Batch 100 | Loss : 0.3717 | Acc : 0.8259
     Batch 125 | Loss : 0.3391 | Acc : 0.8436
     Batch 150 | Loss : 0.3594 | Acc : 0.8347
     Batch 175 | Loss : 0.3394 | Acc : 0.8511
     Batch 200 | Loss : 0.3473 | Acc : 0.8432
     Batch 225 | Loss : 0.3610 | Acc : 0.8242
     Batch 250 | Loss : 0.3812 | Acc : 0.8170
     Batch 275 | Loss : 0.3866 | Acc : 0.8146
     Batch 300 | Loss : 0.4559 | Acc : 0.7692
Epoch 00178 | Train Loss : 0.3903 | Eval Loss : 0.4037 | Train acc : 0.8149 | Eval Acc : 0.8063
     Batch 000 | Loss : 0.3943 | Acc : 0.8121
     Batch 025 | Loss : 0.4242 | Acc : 0.7988
     Batch 050 | Loss : 0.4030 | Acc : 0.8098
     Batch 075 | Loss : 0.3414 | Acc : 0.8434
     Batch 100 | Loss : 0.4554 | Acc : 0.7943
     Batch 125 | Loss : 0.3724 | Acc : 0.8265
     Batch 150 | Loss : 0.4162 | Acc : 0.7987
     Batch 175 | Loss : 0.3584 | Acc : 0.8417
     Batch 200 | Loss : 0.4680 | Acc : 0.7697
     Batch 225 | Loss : 0.4473 | Acc : 0.7873
     Batch 250 | Loss : 0.5543 | Acc : 0.7268
     Batch 275 | Loss : 0.3551 | Acc : 0.8371
     Batch 300 | Loss : 0.4247 | Acc : 0.7877
Epoch 00179 | Train Loss : 0.3949 | Eval Loss : 0.4234 | Train acc : 0.8128 | Eval Acc : 0.8005
     Batch 000 | Loss : 0.3785 | Acc : 0.8244
     Batch 025 | Loss : 0.3764 | Acc : 0.8196
     Batch 050 | Loss : 0.3888 | Acc : 0.8119
     Batch 075 | Loss : 0.4419 | Acc : 0.7929
     Batch 100 | Loss : 0.4561 | Acc : 0.7729
     Batch 125 | Loss : 0.4439 | Acc : 0.7815
     Batch 150 | Loss : 0.4100 | Acc : 0.8089
     Batch 175 | Loss : 0.4152 | Acc : 0.7999
     Batch 200 | Loss : 0.3708 | Acc : 0.8238
     Batch 225 | Loss : 0.3944 | Acc : 0.8064
     Batch 250 | Loss : 0.4961 | Acc : 0.7620
     Batch 275 | Loss : 0.3360 | Acc : 0.8459
     Batch 300 | Loss : 0.3619 | Acc : 0.8313
Epoch 00180 | Train Loss : 0.4065 | Eval Loss : 0.4056 | Train acc : 0.8094 | Eval Acc : 0.8068
     Batch 000 | Loss : 0.4500 | Acc : 0.7891
     Batch 025 | Loss : 0.3545 | Acc : 0.8342
     Batch 050 | Loss : 0.3532 | Acc : 0.8408
     Batch 075 | Loss : 0.3926 | Acc : 0.8117
     Batch 100 | Loss : 0.3211 | Acc : 0.8533
     Batch 125 | Loss : 0.4549 | Acc : 0.7896
     Batch 150 | Loss : 0.3965 | Acc : 0.8092
     Batch 175 | Loss : 0.3911 | Acc : 0.8304
     Batch 200 | Loss : 0.4292 | Acc : 0.7954
     Batch 225 | Loss : 0.3786 | Acc : 0.8222
     Batch 250 | Loss : 0.4178 | Acc : 0.7920
     Batch 275 | Loss : 0.4503 | Acc : 0.7728
     Batch 300 | Loss : 0.3523 | Acc : 0.8339
Epoch 00181 | Train Loss : 0.3931 | Eval Loss : 0.4031 | Train acc : 0.8135 | Eval Acc : 0.8065
     Batch 000 | Loss : 0.4189 | Acc : 0.7920
     Batch 025 | Loss : 0.4084 | Acc : 0.8135
     Batch 050 | Loss : 0.4015 | Acc : 0.8051
     Batch 075 | Loss : 0.3550 | Acc : 0.8322
     Batch 100 | Loss : 0.3749 | Acc : 0.8189
     Batch 125 | Loss : 0.3763 | Acc : 0.8262
     Batch 150 | Loss : 0.4457 | Acc : 0.7923
     Batch 175 | Loss : 0.3402 | Acc : 0.8459
     Batch 200 | Loss : 0.4331 | Acc : 0.7835
     Batch 225 | Loss : 0.3357 | Acc : 0.8534
     Batch 250 | Loss : 0.3569 | Acc : 0.8321
     Batch 275 | Loss : 0.4034 | Acc : 0.7994
     Batch 300 | Loss : 0.4312 | Acc : 0.7937
Epoch 00182 | Train Loss : 0.3940 | Eval Loss : 0.4105 | Train acc : 0.8131 | Eval Acc : 0.8025
     Batch 000 | Loss : 0.3444 | Acc : 0.8358
     Batch 025 | Loss : 0.3622 | Acc : 0.8317
     Batch 050 | Loss : 0.3743 | Acc : 0.8258
     Batch 075 | Loss : 0.4239 | Acc : 0.7869
     Batch 100 | Loss : 0.3639 | Acc : 0.8315
     Batch 125 | Loss : 0.4346 | Acc : 0.7969
     Batch 150 | Loss : 0.4811 | Acc : 0.7612
     Batch 175 | Loss : 0.3533 | Acc : 0.8322
     Batch 200 | Loss : 0.3832 | Acc : 0.8183
     Batch 225 | Loss : 0.4776 | Acc : 0.7648
     Batch 250 | Loss : 0.3546 | Acc : 0.8352
     Batch 275 | Loss : 0.4487 | Acc : 0.7778
     Batch 300 | Loss : 0.3363 | Acc : 0.8427
Epoch 00183 | Train Loss : 0.3949 | Eval Loss : 0.4085 | Train acc : 0.8129 | Eval Acc : 0.8027
     Batch 000 | Loss : 0.3416 | Acc : 0.8394
     Batch 025 | Loss : 0.3199 | Acc : 0.8568
     Batch 050 | Loss : 0.3605 | Acc : 0.8285
     Batch 075 | Loss : 0.3453 | Acc : 0.8393
     Batch 100 | Loss : 0.4883 | Acc : 0.7402
     Batch 125 | Loss : 0.3865 | Acc : 0.8155
     Batch 150 | Loss : 0.4011 | Acc : 0.8028
     Batch 175 | Loss : 0.4120 | Acc : 0.8003
     Batch 200 | Loss : 0.3463 | Acc : 0.8444
     Batch 225 | Loss : 0.3433 | Acc : 0.8377
     Batch 250 | Loss : 0.3715 | Acc : 0.8274
     Batch 275 | Loss : 0.3642 | Acc : 0.8251
     Batch 300 | Loss : 0.3830 | Acc : 0.8302
Epoch 00184 | Train Loss : 0.3942 | Eval Loss : 0.4010 | Train acc : 0.8133 | Eval Acc : 0.8076
     Batch 000 | Loss : 0.4188 | Acc : 0.7938
     Batch 025 | Loss : 0.3828 | Acc : 0.8155
     Batch 050 | Loss : 0.4868 | Acc : 0.7605
     Batch 075 | Loss : 0.3686 | Acc : 0.8274
     Batch 100 | Loss : 0.3870 | Acc : 0.8141
     Batch 125 | Loss : 0.3683 | Acc : 0.8259
     Batch 150 | Loss : 0.3664 | Acc : 0.8295
     Batch 175 | Loss : 0.4704 | Acc : 0.7603
     Batch 200 | Loss : 0.3278 | Acc : 0.8453
     Batch 225 | Loss : 0.3562 | Acc : 0.8401
     Batch 250 | Loss : 0.4255 | Acc : 0.7945
     Batch 275 | Loss : 0.4005 | Acc : 0.8107
     Batch 300 | Loss : 0.3559 | Acc : 0.8317
Epoch 00185 | Train Loss : 0.3975 | Eval Loss : 0.4280 | Train acc : 0.8112 | Eval Acc : 0.7923
     Batch 000 | Loss : 0.4733 | Acc : 0.7630
     Batch 025 | Loss : 0.3958 | Acc : 0.8156
     Batch 050 | Loss : 0.3282 | Acc : 0.8551
     Batch 075 | Loss : 0.3526 | Acc : 0.8381
     Batch 100 | Loss : 0.4164 | Acc : 0.7954
     Batch 125 | Loss : 0.3755 | Acc : 0.8213
     Batch 150 | Loss : 0.4097 | Acc : 0.7952
     Batch 175 | Loss : 0.4007 | Acc : 0.8043
     Batch 200 | Loss : 0.3630 | Acc : 0.8465
     Batch 225 | Loss : 0.3851 | Acc : 0.8191
     Batch 250 | Loss : 0.3396 | Acc : 0.8429
     Batch 275 | Loss : 0.3604 | Acc : 0.8389
     Batch 300 | Loss : 0.4186 | Acc : 0.7969
Epoch 00186 | Train Loss : 0.3960 | Eval Loss : 0.4162 | Train acc : 0.8120 | Eval Acc : 0.8005
     Batch 000 | Loss : 0.3891 | Acc : 0.8194
     Batch 025 | Loss : 0.3400 | Acc : 0.8500
     Batch 050 | Loss : 0.4265 | Acc : 0.7866
     Batch 075 | Loss : 0.3608 | Acc : 0.8309
     Batch 100 | Loss : 0.4042 | Acc : 0.8060
     Batch 125 | Loss : 0.3353 | Acc : 0.8459
     Batch 150 | Loss : 0.4579 | Acc : 0.7959
     Batch 175 | Loss : 0.3922 | Acc : 0.8318
     Batch 200 | Loss : 0.4007 | Acc : 0.8120
     Batch 225 | Loss : 0.4160 | Acc : 0.7985
     Batch 250 | Loss : 0.3371 | Acc : 0.8534
     Batch 275 | Loss : 0.3955 | Acc : 0.8077
     Batch 300 | Loss : 0.3777 | Acc : 0.8263
Epoch 00187 | Train Loss : 0.3999 | Eval Loss : 0.4177 | Train acc : 0.8108 | Eval Acc : 0.7992
     Batch 000 | Loss : 0.3412 | Acc : 0.8486
     Batch 025 | Loss : 0.3444 | Acc : 0.8379
     Batch 050 | Loss : 0.3984 | Acc : 0.8081
     Batch 075 | Loss : 0.4020 | Acc : 0.8062
     Batch 100 | Loss : 0.3983 | Acc : 0.8189
     Batch 125 | Loss : 0.4500 | Acc : 0.7839
     Batch 150 | Loss : 0.4187 | Acc : 0.7976
     Batch 175 | Loss : 0.4898 | Acc : 0.7468
     Batch 200 | Loss : 0.3578 | Acc : 0.8357
     Batch 225 | Loss : 0.3870 | Acc : 0.8092
     Batch 250 | Loss : 0.4074 | Acc : 0.7958
     Batch 275 | Loss : 0.3388 | Acc : 0.8414
     Batch 300 | Loss : 0.3681 | Acc : 0.8267
Epoch 00188 | Train Loss : 0.3938 | Eval Loss : 0.4025 | Train acc : 0.8131 | Eval Acc : 0.8078
     Batch 000 | Loss : 0.3924 | Acc : 0.8080
     Batch 025 | Loss : 0.3413 | Acc : 0.8475
     Batch 050 | Loss : 0.3270 | Acc : 0.8537
     Batch 075 | Loss : 0.3600 | Acc : 0.8346
     Batch 100 | Loss : 0.3877 | Acc : 0.8037
     Batch 125 | Loss : 0.3868 | Acc : 0.8153
     Batch 150 | Loss : 0.3955 | Acc : 0.8077
     Batch 175 | Loss : 0.3463 | Acc : 0.8433
     Batch 200 | Loss : 0.4206 | Acc : 0.7952
     Batch 225 | Loss : 0.3716 | Acc : 0.8268
     Batch 250 | Loss : 0.4401 | Acc : 0.7881
     Batch 275 | Loss : 0.4039 | Acc : 0.8087
     Batch 300 | Loss : 0.3532 | Acc : 0.8367
Epoch 00189 | Train Loss : 0.3927 | Eval Loss : 0.4015 | Train acc : 0.8137 | Eval Acc : 0.8057
     Batch 000 | Loss : 0.3870 | Acc : 0.8094
     Batch 025 | Loss : 0.4032 | Acc : 0.8069
     Batch 050 | Loss : 0.3365 | Acc : 0.8480
     Batch 075 | Loss : 0.4440 | Acc : 0.7746
     Batch 100 | Loss : 0.3611 | Acc : 0.8326
     Batch 125 | Loss : 0.3800 | Acc : 0.8288
     Batch 150 | Loss : 0.4389 | Acc : 0.7813
     Batch 175 | Loss : 0.4329 | Acc : 0.7868
     Batch 200 | Loss : 0.4716 | Acc : 0.7544
     Batch 225 | Loss : 0.4898 | Acc : 0.7667
     Batch 250 | Loss : 0.3931 | Acc : 0.8147
     Batch 275 | Loss : 0.3184 | Acc : 0.8588
     Batch 300 | Loss : 0.3688 | Acc : 0.8277
Epoch 00190 | Train Loss : 0.3954 | Eval Loss : 0.4071 | Train acc : 0.8125 | Eval Acc : 0.8050
     Batch 000 | Loss : 0.4126 | Acc : 0.7979
     Batch 025 | Loss : 0.3426 | Acc : 0.8449
     Batch 050 | Loss : 0.3654 | Acc : 0.8314
     Batch 075 | Loss : 0.3766 | Acc : 0.8222
     Batch 100 | Loss : 0.3929 | Acc : 0.8064
     Batch 125 | Loss : 0.5354 | Acc : 0.7569
     Batch 150 | Loss : 0.4110 | Acc : 0.8028
     Batch 175 | Loss : 0.4157 | Acc : 0.8002
     Batch 200 | Loss : 0.3609 | Acc : 0.8295
     Batch 225 | Loss : 0.3781 | Acc : 0.8277
     Batch 250 | Loss : 0.3605 | Acc : 0.8349
     Batch 275 | Loss : 0.4162 | Acc : 0.7937
     Batch 300 | Loss : 0.4230 | Acc : 0.7942
Epoch 00191 | Train Loss : 0.3930 | Eval Loss : 0.4023 | Train acc : 0.8135 | Eval Acc : 0.8079
     Batch 000 | Loss : 0.4020 | Acc : 0.8059
     Batch 025 | Loss : 0.3855 | Acc : 0.8210
     Batch 050 | Loss : 0.3619 | Acc : 0.8322
     Batch 075 | Loss : 0.3370 | Acc : 0.8450
     Batch 100 | Loss : 0.3649 | Acc : 0.8294
     Batch 125 | Loss : 0.4165 | Acc : 0.7964
     Batch 150 | Loss : 0.3227 | Acc : 0.8498
     Batch 175 | Loss : 0.4334 | Acc : 0.7933
     Batch 200 | Loss : 0.4158 | Acc : 0.7992
     Batch 225 | Loss : 0.3763 | Acc : 0.8237
     Batch 250 | Loss : 0.3893 | Acc : 0.8190
     Batch 275 | Loss : 0.3984 | Acc : 0.8039
     Batch 300 | Loss : 0.3980 | Acc : 0.8050
Epoch 00192 | Train Loss : 0.3921 | Eval Loss : 0.4052 | Train acc : 0.8139 | Eval Acc : 0.8052
     Batch 000 | Loss : 0.3386 | Acc : 0.8500
     Batch 025 | Loss : 0.3631 | Acc : 0.8282
     Batch 050 | Loss : 0.3647 | Acc : 0.8263
     Batch 075 | Loss : 0.4256 | Acc : 0.7962
     Batch 100 | Loss : 0.3839 | Acc : 0.8199
     Batch 125 | Loss : 0.4301 | Acc : 0.7867
     Batch 150 | Loss : 0.3770 | Acc : 0.8219
     Batch 175 | Loss : 0.3270 | Acc : 0.8541
     Batch 200 | Loss : 0.3371 | Acc : 0.8486
     Batch 225 | Loss : 0.3244 | Acc : 0.8482
     Batch 250 | Loss : 0.3618 | Acc : 0.8280
     Batch 275 | Loss : 0.3973 | Acc : 0.8116
     Batch 300 | Loss : 0.5825 | Acc : 0.7162
Epoch 00193 | Train Loss : 0.3911 | Eval Loss : 0.4103 | Train acc : 0.8143 | Eval Acc : 0.8014
     Batch 000 | Loss : 0.3382 | Acc : 0.8493
     Batch 025 | Loss : 0.3447 | Acc : 0.8450
     Batch 050 | Loss : 0.3556 | Acc : 0.8363
     Batch 075 | Loss : 0.3419 | Acc : 0.8473
     Batch 100 | Loss : 0.3355 | Acc : 0.8402
     Batch 125 | Loss : 0.3767 | Acc : 0.8481
     Batch 150 | Loss : 0.4804 | Acc : 0.7586
     Batch 175 | Loss : 0.3750 | Acc : 0.8249
     Batch 200 | Loss : 0.4193 | Acc : 0.7970
     Batch 225 | Loss : 0.4085 | Acc : 0.8019
     Batch 250 | Loss : 0.4031 | Acc : 0.8078
     Batch 275 | Loss : 0.3667 | Acc : 0.8264
     Batch 300 | Loss : 0.3831 | Acc : 0.8146
Epoch 00194 | Train Loss : 0.3942 | Eval Loss : 0.3985 | Train acc : 0.8135 | Eval Acc : 0.8091
     Batch 000 | Loss : 0.3463 | Acc : 0.8436
     Batch 025 | Loss : 0.3581 | Acc : 0.8276
     Batch 050 | Loss : 0.4608 | Acc : 0.7643
     Batch 075 | Loss : 0.4505 | Acc : 0.7757
     Batch 100 | Loss : 0.4197 | Acc : 0.7976
     Batch 125 | Loss : 0.4697 | Acc : 0.7716
     Batch 150 | Loss : 0.3570 | Acc : 0.8324
     Batch 175 | Loss : 0.3746 | Acc : 0.8211
     Batch 200 | Loss : 0.4076 | Acc : 0.8015
     Batch 225 | Loss : 0.3552 | Acc : 0.8333
     Batch 250 | Loss : 0.4670 | Acc : 0.7834
     Batch 275 | Loss : 0.4346 | Acc : 0.7865
     Batch 300 | Loss : 0.4386 | Acc : 0.7873
Epoch 00195 | Train Loss : 0.3941 | Eval Loss : 0.4007 | Train acc : 0.8129 | Eval Acc : 0.8070
     Batch 000 | Loss : 0.3706 | Acc : 0.8279
     Batch 025 | Loss : 0.3746 | Acc : 0.8239
     Batch 050 | Loss : 0.3467 | Acc : 0.8392
     Batch 075 | Loss : 0.3300 | Acc : 0.8509
     Batch 100 | Loss : 0.3659 | Acc : 0.8340
     Batch 125 | Loss : 0.3607 | Acc : 0.8293
     Batch 150 | Loss : 0.3383 | Acc : 0.8509
     Batch 175 | Loss : 0.4365 | Acc : 0.7870
     Batch 200 | Loss : 0.4191 | Acc : 0.7901
     Batch 225 | Loss : 0.4487 | Acc : 0.7787
     Batch 250 | Loss : 0.4307 | Acc : 0.7895
     Batch 275 | Loss : 0.4192 | Acc : 0.7998
     Batch 300 | Loss : 0.3600 | Acc : 0.8330
Epoch 00196 | Train Loss : 0.3943 | Eval Loss : 0.4135 | Train acc : 0.8129 | Eval Acc : 0.8012
     Batch 000 | Loss : 0.4139 | Acc : 0.8008
     Batch 025 | Loss : 0.3789 | Acc : 0.8266
     Batch 050 | Loss : 0.3472 | Acc : 0.8373
     Batch 075 | Loss : 0.3202 | Acc : 0.8577
     Batch 100 | Loss : 0.4470 | Acc : 0.7748
     Batch 125 | Loss : 0.4589 | Acc : 0.7720
     Batch 150 | Loss : 0.4934 | Acc : 0.7553
     Batch 175 | Loss : 0.3928 | Acc : 0.8128
     Batch 200 | Loss : 0.4024 | Acc : 0.8123
     Batch 225 | Loss : 0.3847 | Acc : 0.8202
     Batch 250 | Loss : 0.3690 | Acc : 0.8237
     Batch 275 | Loss : 0.4064 | Acc : 0.8077
     Batch 300 | Loss : 0.4661 | Acc : 0.7729
Epoch 00197 | Train Loss : 0.3954 | Eval Loss : 0.4012 | Train acc : 0.8127 | Eval Acc : 0.8077
     Batch 000 | Loss : 0.3443 | Acc : 0.8427
     Batch 025 | Loss : 0.3837 | Acc : 0.8205
     Batch 050 | Loss : 0.3647 | Acc : 0.8293
     Batch 075 | Loss : 0.3873 | Acc : 0.8125
     Batch 100 | Loss : 0.4267 | Acc : 0.8038
     Batch 125 | Loss : 0.4362 | Acc : 0.7815
     Batch 150 | Loss : 0.3840 | Acc : 0.8129
     Batch 175 | Loss : 0.3667 | Acc : 0.8312
     Batch 200 | Loss : 0.3230 | Acc : 0.8486
     Batch 225 | Loss : 0.3178 | Acc : 0.8548
     Batch 250 | Loss : 0.4466 | Acc : 0.7755
     Batch 275 | Loss : 0.3752 | Acc : 0.8257
     Batch 300 | Loss : 0.4853 | Acc : 0.7586
Epoch 00198 | Train Loss : 0.3938 | Eval Loss : 0.4015 | Train acc : 0.8131 | Eval Acc : 0.8076
     Batch 000 | Loss : 0.3325 | Acc : 0.8414
     Batch 025 | Loss : 0.3546 | Acc : 0.8414
     Batch 050 | Loss : 0.3216 | Acc : 0.8534
     Batch 075 | Loss : 0.3510 | Acc : 0.8369
     Batch 100 | Loss : 0.4618 | Acc : 0.7866
     Batch 125 | Loss : 0.3747 | Acc : 0.8222
     Batch 150 | Loss : 0.3760 | Acc : 0.8207
     Batch 175 | Loss : 0.4507 | Acc : 0.7858
     Batch 200 | Loss : 0.3667 | Acc : 0.8201
     Batch 225 | Loss : 0.4596 | Acc : 0.7783
     Batch 250 | Loss : 0.3541 | Acc : 0.8354
     Batch 275 | Loss : 0.4154 | Acc : 0.8058
     Batch 300 | Loss : 0.3480 | Acc : 0.8388
Epoch 00199 | Train Loss : 0.3938 | Eval Loss : 0.4021 | Train acc : 0.8132 | Eval Acc : 0.8078
     Batch 000 | Loss : 0.4673 | Acc : 0.7726
     Batch 025 | Loss : 0.3415 | Acc : 0.8426
     Batch 050 | Loss : 0.3588 | Acc : 0.8316
     Batch 075 | Loss : 0.3551 | Acc : 0.8348
     Batch 100 | Loss : 0.4646 | Acc : 0.7731
     Batch 125 | Loss : 0.3798 | Acc : 0.8242
     Batch 150 | Loss : 0.3676 | Acc : 0.8328
     Batch 175 | Loss : 0.3586 | Acc : 0.8412
     Batch 200 | Loss : 0.3825 | Acc : 0.8281
     Batch 225 | Loss : 0.4087 | Acc : 0.7988
     Batch 250 | Loss : 0.4103 | Acc : 0.8031
     Batch 275 | Loss : 0.4093 | Acc : 0.8022
     Batch 300 | Loss : 0.3745 | Acc : 0.8224
Epoch 00200 | Train Loss : 0.3934 | Eval Loss : 0.3980 | Train acc : 0.8135 | Eval Acc : 0.8097
     Batch 000 | Loss : 0.3860 | Acc : 0.8148
     Batch 025 | Loss : 0.5069 | Acc : 0.7546
     Batch 050 | Loss : 0.3343 | Acc : 0.8510
     Batch 075 | Loss : 0.3374 | Acc : 0.8497
     Batch 100 | Loss : 0.4414 | Acc : 0.7779
     Batch 125 | Loss : 0.3713 | Acc : 0.8344
     Batch 150 | Loss : 0.5162 | Acc : 0.7417
     Batch 175 | Loss : 0.3570 | Acc : 0.8297
     Batch 200 | Loss : 0.3861 | Acc : 0.8243
     Batch 225 | Loss : 0.3969 | Acc : 0.8107
     Batch 250 | Loss : 0.3476 | Acc : 0.8405
     Batch 275 | Loss : 0.3702 | Acc : 0.8209
     Batch 300 | Loss : 0.4037 | Acc : 0.8080
Epoch 00201 | Train Loss : 0.3923 | Eval Loss : 0.4039 | Train acc : 0.8139 | Eval Acc : 0.8062
     Batch 000 | Loss : 0.3138 | Acc : 0.8528
     Batch 025 | Loss : 0.3830 | Acc : 0.8193
     Batch 050 | Loss : 0.4159 | Acc : 0.7931
     Batch 075 | Loss : 0.3415 | Acc : 0.8389
     Batch 100 | Loss : 0.4372 | Acc : 0.7903
     Batch 125 | Loss : 0.3525 | Acc : 0.8348
     Batch 150 | Loss : 0.3655 | Acc : 0.8256
     Batch 175 | Loss : 0.4356 | Acc : 0.7811
     Batch 200 | Loss : 0.4365 | Acc : 0.7864
     Batch 225 | Loss : 0.4026 | Acc : 0.7981
     Batch 250 | Loss : 0.3753 | Acc : 0.8192
     Batch 275 | Loss : 0.4066 | Acc : 0.8067
     Batch 300 | Loss : 0.3963 | Acc : 0.8264
Epoch 00202 | Train Loss : 0.3966 | Eval Loss : 0.4057 | Train acc : 0.8119 | Eval Acc : 0.8034
     Batch 000 | Loss : 0.4385 | Acc : 0.7805
     Batch 025 | Loss : 0.4504 | Acc : 0.7840
     Batch 050 | Loss : 0.5116 | Acc : 0.7429
     Batch 075 | Loss : 0.3326 | Acc : 0.8585
     Batch 100 | Loss : 0.3462 | Acc : 0.8407
     Batch 125 | Loss : 0.3396 | Acc : 0.8562
     Batch 150 | Loss : 0.4201 | Acc : 0.7943
     Batch 175 | Loss : 0.3634 | Acc : 0.8308
     Batch 200 | Loss : 0.3461 | Acc : 0.8380
     Batch 225 | Loss : 0.3803 | Acc : 0.8248
     Batch 250 | Loss : 0.4332 | Acc : 0.7859
     Batch 275 | Loss : 0.3563 | Acc : 0.8326
     Batch 300 | Loss : 0.3639 | Acc : 0.8347
Epoch 00203 | Train Loss : 0.3932 | Eval Loss : 0.4011 | Train acc : 0.8134 | Eval Acc : 0.8070
     Batch 000 | Loss : 0.3822 | Acc : 0.8187
     Batch 025 | Loss : 0.4655 | Acc : 0.7787
     Batch 050 | Loss : 0.4293 | Acc : 0.7904
     Batch 075 | Loss : 0.4436 | Acc : 0.7923
     Batch 100 | Loss : 0.4207 | Acc : 0.7958
     Batch 125 | Loss : 0.3314 | Acc : 0.8509
     Batch 150 | Loss : 0.4241 | Acc : 0.7923
     Batch 175 | Loss : 0.4038 | Acc : 0.8049
     Batch 200 | Loss : 0.3800 | Acc : 0.8286
     Batch 225 | Loss : 0.3274 | Acc : 0.8572
     Batch 250 | Loss : 0.3384 | Acc : 0.8426
     Batch 275 | Loss : 0.3747 | Acc : 0.8254
     Batch 300 | Loss : 0.3378 | Acc : 0.8499
Epoch 00204 | Train Loss : 0.3940 | Eval Loss : 0.4001 | Train acc : 0.8131 | Eval Acc : 0.8093
     Batch 000 | Loss : 0.3715 | Acc : 0.8278
     Batch 025 | Loss : 0.3455 | Acc : 0.8428
     Batch 050 | Loss : 0.4281 | Acc : 0.7887
     Batch 075 | Loss : 0.4141 | Acc : 0.8058
     Batch 100 | Loss : 0.3444 | Acc : 0.8437
     Batch 125 | Loss : 0.3817 | Acc : 0.8189
     Batch 150 | Loss : 0.4444 | Acc : 0.7788
     Batch 175 | Loss : 0.3945 | Acc : 0.8144
     Batch 200 | Loss : 0.3453 | Acc : 0.8457
     Batch 225 | Loss : 0.3819 | Acc : 0.8187
     Batch 250 | Loss : 0.4575 | Acc : 0.7672
     Batch 275 | Loss : 0.3866 | Acc : 0.8166
     Batch 300 | Loss : 0.4103 | Acc : 0.8022
Epoch 00205 | Train Loss : 0.3931 | Eval Loss : 0.4078 | Train acc : 0.8135 | Eval Acc : 0.8052
     Batch 000 | Loss : 0.3832 | Acc : 0.8152
     Batch 025 | Loss : 0.5325 | Acc : 0.7501
     Batch 050 | Loss : 0.3573 | Acc : 0.8350
     Batch 075 | Loss : 0.3477 | Acc : 0.8404
     Batch 100 | Loss : 0.4377 | Acc : 0.7859
     Batch 125 | Loss : 0.3667 | Acc : 0.8279
     Batch 150 | Loss : 0.4130 | Acc : 0.7988
     Batch 175 | Loss : 0.4301 | Acc : 0.7868
     Batch 200 | Loss : 0.3873 | Acc : 0.8147
     Batch 225 | Loss : 0.4162 | Acc : 0.7980
     Batch 250 | Loss : 0.3661 | Acc : 0.8315
     Batch 275 | Loss : 0.3687 | Acc : 0.8290
     Batch 300 | Loss : 0.3762 | Acc : 0.8265
Epoch 00206 | Train Loss : 0.3964 | Eval Loss : 0.4014 | Train acc : 0.8122 | Eval Acc : 0.8070
     Batch 000 | Loss : 0.3533 | Acc : 0.8325
     Batch 025 | Loss : 0.3553 | Acc : 0.8352
     Batch 050 | Loss : 0.3561 | Acc : 0.8407
     Batch 075 | Loss : 0.3396 | Acc : 0.8504
     Batch 100 | Loss : 0.3816 | Acc : 0.8156
     Batch 125 | Loss : 0.4384 | Acc : 0.7842
     Batch 150 | Loss : 0.3502 | Acc : 0.8358
     Batch 175 | Loss : 0.4158 | Acc : 0.8005
     Batch 200 | Loss : 0.3492 | Acc : 0.8340
     Batch 225 | Loss : 0.3987 | Acc : 0.8057
     Batch 250 | Loss : 0.3392 | Acc : 0.8407
     Batch 275 | Loss : 0.3786 | Acc : 0.8230
     Batch 300 | Loss : 0.3672 | Acc : 0.8316
Epoch 00207 | Train Loss : 0.3944 | Eval Loss : 0.4022 | Train acc : 0.8126 | Eval Acc : 0.8078
     Batch 000 | Loss : 0.3862 | Acc : 0.8183
     Batch 025 | Loss : 0.4457 | Acc : 0.7836
     Batch 050 | Loss : 0.3900 | Acc : 0.8214
     Batch 075 | Loss : 0.4950 | Acc : 0.7630
     Batch 100 | Loss : 0.3921 | Acc : 0.8124
     Batch 125 | Loss : 0.3714 | Acc : 0.8238
     Batch 150 | Loss : 0.3969 | Acc : 0.8156
     Batch 175 | Loss : 0.3560 | Acc : 0.8305
     Batch 200 | Loss : 0.3530 | Acc : 0.8380
     Batch 225 | Loss : 0.5331 | Acc : 0.7504
     Batch 250 | Loss : 0.3660 | Acc : 0.8268
     Batch 275 | Loss : 0.3430 | Acc : 0.8437
     Batch 300 | Loss : 0.3707 | Acc : 0.8310
Epoch 00208 | Train Loss : 0.3954 | Eval Loss : 0.4023 | Train acc : 0.8125 | Eval Acc : 0.8067
     Batch 000 | Loss : 0.4247 | Acc : 0.7911
     Batch 025 | Loss : 0.3456 | Acc : 0.8430
     Batch 050 | Loss : 0.3590 | Acc : 0.8354
     Batch 075 | Loss : 0.4289 | Acc : 0.7891
     Batch 100 | Loss : 0.3608 | Acc : 0.8387
     Batch 125 | Loss : 0.3623 | Acc : 0.8325
     Batch 150 | Loss : 0.3548 | Acc : 0.8356
     Batch 175 | Loss : 0.3339 | Acc : 0.8456
     Batch 200 | Loss : 0.3915 | Acc : 0.8122
     Batch 225 | Loss : 0.3636 | Acc : 0.8299
     Batch 250 | Loss : 0.3679 | Acc : 0.8290
     Batch 275 | Loss : 0.3788 | Acc : 0.8197
     Batch 300 | Loss : 0.3771 | Acc : 0.8281
Epoch 00209 | Train Loss : 0.3951 | Eval Loss : 0.4088 | Train acc : 0.8126 | Eval Acc : 0.8042
     Batch 000 | Loss : 0.3628 | Acc : 0.8269
     Batch 025 | Loss : 0.4212 | Acc : 0.8092
     Batch 050 | Loss : 0.4787 | Acc : 0.7617
     Batch 075 | Loss : 0.4583 | Acc : 0.7757
     Batch 100 | Loss : 0.6311 | Acc : 0.7259
     Batch 125 | Loss : 0.3591 | Acc : 0.8309
     Batch 150 | Loss : 0.3316 | Acc : 0.8527
     Batch 175 | Loss : 0.3462 | Acc : 0.8348
     Batch 200 | Loss : 0.3828 | Acc : 0.8151
     Batch 225 | Loss : 0.3390 | Acc : 0.8501
     Batch 250 | Loss : 0.3469 | Acc : 0.8435
     Batch 275 | Loss : 0.4533 | Acc : 0.7873
     Batch 300 | Loss : 0.4179 | Acc : 0.7954
Epoch 00210 | Train Loss : 0.3980 | Eval Loss : 0.4144 | Train acc : 0.8113 | Eval Acc : 0.7997
     Batch 000 | Loss : 0.3859 | Acc : 0.8169
     Batch 025 | Loss : 0.3436 | Acc : 0.8481
     Batch 050 | Loss : 0.3719 | Acc : 0.8289
     Batch 075 | Loss : 0.4714 | Acc : 0.7635
     Batch 100 | Loss : 0.3258 | Acc : 0.8484
     Batch 125 | Loss : 0.3534 | Acc : 0.8383
     Batch 150 | Loss : 0.3393 | Acc : 0.8408
     Batch 175 | Loss : 0.3569 | Acc : 0.8315
     Batch 200 | Loss : 0.3790 | Acc : 0.8327
     Batch 225 | Loss : 0.3373 | Acc : 0.8486
     Batch 250 | Loss : 0.4159 | Acc : 0.7888
     Batch 275 | Loss : 0.3690 | Acc : 0.8255
     Batch 300 | Loss : 0.3855 | Acc : 0.8133
Epoch 00211 | Train Loss : 0.3960 | Eval Loss : 0.4037 | Train acc : 0.8119 | Eval Acc : 0.8061
     Batch 000 | Loss : 0.3391 | Acc : 0.8403
     Batch 025 | Loss : 0.4323 | Acc : 0.7864
     Batch 050 | Loss : 0.4238 | Acc : 0.8149
     Batch 075 | Loss : 0.3901 | Acc : 0.8117
     Batch 100 | Loss : 0.3483 | Acc : 0.8412
     Batch 125 | Loss : 0.3299 | Acc : 0.8520
     Batch 150 | Loss : 0.4796 | Acc : 0.7739
     Batch 175 | Loss : 0.3612 | Acc : 0.8340
     Batch 200 | Loss : 0.3393 | Acc : 0.8486
     Batch 225 | Loss : 0.4508 | Acc : 0.7755
     Batch 250 | Loss : 0.3727 | Acc : 0.8275
     Batch 275 | Loss : 0.4094 | Acc : 0.8051
     Batch 300 | Loss : 0.3467 | Acc : 0.8409
Epoch 00212 | Train Loss : 0.3943 | Eval Loss : 0.4035 | Train acc : 0.8127 | Eval Acc : 0.8057
     Batch 000 | Loss : 0.3652 | Acc : 0.8294
     Batch 025 | Loss : 0.3912 | Acc : 0.8155
     Batch 050 | Loss : 0.4371 | Acc : 0.7852
     Batch 075 | Loss : 0.3878 | Acc : 0.8142
     Batch 100 | Loss : 0.4181 | Acc : 0.7953
     Batch 125 | Loss : 0.3798 | Acc : 0.8355
     Batch 150 | Loss : 0.4317 | Acc : 0.7840
     Batch 175 | Loss : 0.3446 | Acc : 0.8488
     Batch 200 | Loss : 0.3560 | Acc : 0.8352
     Batch 225 | Loss : 0.4316 | Acc : 0.7866
     Batch 250 | Loss : 0.4045 | Acc : 0.7983
     Batch 275 | Loss : 0.3703 | Acc : 0.8217
     Batch 300 | Loss : 0.3605 | Acc : 0.8333
Epoch 00213 | Train Loss : 0.3946 | Eval Loss : 0.4028 | Train acc : 0.8125 | Eval Acc : 0.8072
     Batch 000 | Loss : 0.3497 | Acc : 0.8331
     Batch 025 | Loss : 0.4763 | Acc : 0.7673
     Batch 050 | Loss : 0.4311 | Acc : 0.7913
     Batch 075 | Loss : 0.3745 | Acc : 0.8258
     Batch 100 | Loss : 0.4503 | Acc : 0.7816
     Batch 125 | Loss : 0.4468 | Acc : 0.7823
     Batch 150 | Loss : 0.3731 | Acc : 0.8251
     Batch 175 | Loss : 0.4653 | Acc : 0.7732
     Batch 200 | Loss : 0.3643 | Acc : 0.8299
     Batch 225 | Loss : 0.3564 | Acc : 0.8433
     Batch 250 | Loss : 0.4346 | Acc : 0.7994
     Batch 275 | Loss : 0.3493 | Acc : 0.8403
     Batch 300 | Loss : 0.4016 | Acc : 0.8038
Epoch 00214 | Train Loss : 0.3949 | Eval Loss : 0.4244 | Train acc : 0.8129 | Eval Acc : 0.8034
     Batch 000 | Loss : 0.3306 | Acc : 0.8480
     Batch 025 | Loss : 0.3606 | Acc : 0.8312
     Batch 050 | Loss : 0.3614 | Acc : 0.8284
     Batch 075 | Loss : 0.3834 | Acc : 0.8228
     Batch 100 | Loss : 0.3531 | Acc : 0.8443
     Batch 125 | Loss : 0.3622 | Acc : 0.8377
     Batch 150 | Loss : 0.3475 | Acc : 0.8409
     Batch 175 | Loss : 0.3586 | Acc : 0.8351
     Batch 200 | Loss : 0.3327 | Acc : 0.8504
     Batch 225 | Loss : 0.3563 | Acc : 0.8392
     Batch 250 | Loss : 0.3651 | Acc : 0.8403
     Batch 275 | Loss : 0.3936 | Acc : 0.8101
     Batch 300 | Loss : 0.3394 | Acc : 0.8409
Epoch 00215 | Train Loss : 0.3919 | Eval Loss : 0.4017 | Train acc : 0.8139 | Eval Acc : 0.8078
     Batch 000 | Loss : 0.4101 | Acc : 0.7978
     Batch 025 | Loss : 0.3674 | Acc : 0.8345
     Batch 050 | Loss : 0.5054 | Acc : 0.7582
     Batch 075 | Loss : 0.3387 | Acc : 0.8472
     Batch 100 | Loss : 0.4281 | Acc : 0.7895
     Batch 125 | Loss : 0.4350 | Acc : 0.7912
     Batch 150 | Loss : 0.3784 | Acc : 0.8252
     Batch 175 | Loss : 0.3888 | Acc : 0.8201
     Batch 200 | Loss : 0.4108 | Acc : 0.8019
     Batch 225 | Loss : 0.4151 | Acc : 0.7996
     Batch 250 | Loss : 0.5077 | Acc : 0.7685
     Batch 275 | Loss : 0.5386 | Acc : 0.7464
     Batch 300 | Loss : 0.3327 | Acc : 0.8532
Epoch 00216 | Train Loss : 0.3950 | Eval Loss : 0.4031 | Train acc : 0.8129 | Eval Acc : 0.8063
     Batch 000 | Loss : 0.3502 | Acc : 0.8419
     Batch 025 | Loss : 0.4035 | Acc : 0.8130
     Batch 050 | Loss : 0.3716 | Acc : 0.8218
     Batch 075 | Loss : 0.3742 | Acc : 0.8232
     Batch 100 | Loss : 0.3490 | Acc : 0.8387
     Batch 125 | Loss : 0.4434 | Acc : 0.7757
     Batch 150 | Loss : 0.3616 | Acc : 0.8397
     Batch 175 | Loss : 0.3642 | Acc : 0.8309
     Batch 200 | Loss : 0.3705 | Acc : 0.8289
     Batch 225 | Loss : 0.4187 | Acc : 0.8010
     Batch 250 | Loss : 0.3661 | Acc : 0.8403
     Batch 275 | Loss : 0.3426 | Acc : 0.8420
     Batch 300 | Loss : 0.4364 | Acc : 0.7809
Epoch 00217 | Train Loss : 0.3929 | Eval Loss : 0.4077 | Train acc : 0.8139 | Eval Acc : 0.8029
     Batch 000 | Loss : 0.3974 | Acc : 0.8137
     Batch 025 | Loss : 0.3517 | Acc : 0.8357
     Batch 050 | Loss : 0.3541 | Acc : 0.8288
     Batch 075 | Loss : 0.4729 | Acc : 0.7557
     Batch 100 | Loss : 0.4719 | Acc : 0.7696
     Batch 125 | Loss : 0.3426 | Acc : 0.8444
     Batch 150 | Loss : 0.3919 | Acc : 0.8102
     Batch 175 | Loss : 0.4318 | Acc : 0.7888
     Batch 200 | Loss : 0.4140 | Acc : 0.7952
     Batch 225 | Loss : 0.3867 | Acc : 0.8123
     Batch 250 | Loss : 0.3616 | Acc : 0.8226
     Batch 275 | Loss : 0.4173 | Acc : 0.7927
     Batch 300 | Loss : 0.3701 | Acc : 0.8239
Epoch 00218 | Train Loss : 0.3961 | Eval Loss : 0.4044 | Train acc : 0.8120 | Eval Acc : 0.8052
     Batch 000 | Loss : 0.3973 | Acc : 0.8056
     Batch 025 | Loss : 0.4418 | Acc : 0.7803
     Batch 050 | Loss : 0.3896 | Acc : 0.8180
     Batch 075 | Loss : 0.3632 | Acc : 0.8305
     Batch 100 | Loss : 0.3568 | Acc : 0.8470
     Batch 125 | Loss : 0.3589 | Acc : 0.8389
     Batch 150 | Loss : 0.3496 | Acc : 0.8479
     Batch 175 | Loss : 0.3591 | Acc : 0.8388
     Batch 200 | Loss : 0.4029 | Acc : 0.8037
     Batch 225 | Loss : 0.5278 | Acc : 0.7504
     Batch 250 | Loss : 0.3648 | Acc : 0.8304
     Batch 275 | Loss : 0.3525 | Acc : 0.8342
     Batch 300 | Loss : 0.4543 | Acc : 0.7775
Epoch 00219 | Train Loss : 0.3944 | Eval Loss : 0.4007 | Train acc : 0.8128 | Eval Acc : 0.8081
     Batch 000 | Loss : 0.4526 | Acc : 0.7779
     Batch 025 | Loss : 0.3794 | Acc : 0.8297
     Batch 050 | Loss : 0.3702 | Acc : 0.8228
     Batch 075 | Loss : 0.3812 | Acc : 0.8206
     Batch 100 | Loss : 0.3875 | Acc : 0.8137
     Batch 125 | Loss : 0.4081 | Acc : 0.7997
     Batch 150 | Loss : 0.3473 | Acc : 0.8429
     Batch 175 | Loss : 0.4362 | Acc : 0.7844
     Batch 200 | Loss : 0.4297 | Acc : 0.7855
     Batch 225 | Loss : 0.3497 | Acc : 0.8453
     Batch 250 | Loss : 0.4666 | Acc : 0.7813
     Batch 275 | Loss : 0.4454 | Acc : 0.7859
     Batch 300 | Loss : 0.3707 | Acc : 0.8355
Epoch 00220 | Train Loss : 0.3936 | Eval Loss : 0.4106 | Train acc : 0.8128 | Eval Acc : 0.8028
     Batch 000 | Loss : 0.3786 | Acc : 0.8123
     Batch 025 | Loss : 0.5127 | Acc : 0.7442
     Batch 050 | Loss : 0.5009 | Acc : 0.7568
     Batch 075 | Loss : 0.3413 | Acc : 0.8396
     Batch 100 | Loss : 0.3966 | Acc : 0.8128
     Batch 125 | Loss : 0.3574 | Acc : 0.8352
     Batch 150 | Loss : 0.3687 | Acc : 0.8320
     Batch 175 | Loss : 0.4033 | Acc : 0.7989
     Batch 200 | Loss : 0.3705 | Acc : 0.8309
     Batch 225 | Loss : 0.4020 | Acc : 0.8011
     Batch 250 | Loss : 0.3953 | Acc : 0.8065
     Batch 275 | Loss : 0.4611 | Acc : 0.7792
     Batch 300 | Loss : 0.3405 | Acc : 0.8447
Epoch 00221 | Train Loss : 0.3939 | Eval Loss : 0.4065 | Train acc : 0.8130 | Eval Acc : 0.8044
     Batch 000 | Loss : 0.4702 | Acc : 0.7609
     Batch 025 | Loss : 0.3835 | Acc : 0.8118
     Batch 050 | Loss : 0.3528 | Acc : 0.8396
     Batch 075 | Loss : 0.3928 | Acc : 0.8113
     Batch 100 | Loss : 0.3480 | Acc : 0.8441
     Batch 125 | Loss : 0.3749 | Acc : 0.8189
     Batch 150 | Loss : 0.3656 | Acc : 0.8283
     Batch 175 | Loss : 0.3350 | Acc : 0.8466
     Batch 200 | Loss : 0.3567 | Acc : 0.8299
     Batch 225 | Loss : 0.4136 | Acc : 0.8127
     Batch 250 | Loss : 0.3482 | Acc : 0.8440
     Batch 275 | Loss : 0.4110 | Acc : 0.7949
     Batch 300 | Loss : 0.3544 | Acc : 0.8354
Epoch 00222 | Train Loss : 0.3924 | Eval Loss : 0.4082 | Train acc : 0.8136 | Eval Acc : 0.8053
     Batch 000 | Loss : 0.4060 | Acc : 0.8016
     Batch 025 | Loss : 0.4390 | Acc : 0.7962
     Batch 050 | Loss : 0.3482 | Acc : 0.8396
     Batch 075 | Loss : 0.3497 | Acc : 0.8425
     Batch 100 | Loss : 0.3536 | Acc : 0.8387
     Batch 125 | Loss : 0.4408 | Acc : 0.7868
     Batch 150 | Loss : 0.4339 | Acc : 0.7862
     Batch 175 | Loss : 0.3552 | Acc : 0.8309
     Batch 200 | Loss : 0.3670 | Acc : 0.8347
     Batch 225 | Loss : 0.3872 | Acc : 0.8125
     Batch 250 | Loss : 0.3966 | Acc : 0.8081
     Batch 275 | Loss : 0.4167 | Acc : 0.8014
     Batch 300 | Loss : 0.4703 | Acc : 0.7720
Epoch 00223 | Train Loss : 0.3933 | Eval Loss : 0.3983 | Train acc : 0.8137 | Eval Acc : 0.8088
     Batch 000 | Loss : 0.3788 | Acc : 0.8199
     Batch 025 | Loss : 0.4687 | Acc : 0.7575
     Batch 050 | Loss : 0.3691 | Acc : 0.8246
     Batch 075 | Loss : 0.4262 | Acc : 0.7916
     Batch 100 | Loss : 0.3456 | Acc : 0.8439
     Batch 125 | Loss : 0.3830 | Acc : 0.8224
     Batch 150 | Loss : 0.3425 | Acc : 0.8444
     Batch 175 | Loss : 0.3912 | Acc : 0.8149
     Batch 200 | Loss : 0.4387 | Acc : 0.7894
     Batch 225 | Loss : 0.4097 | Acc : 0.7995
     Batch 250 | Loss : 0.3665 | Acc : 0.8266
     Batch 275 | Loss : 0.3549 | Acc : 0.8362
     Batch 300 | Loss : 0.3282 | Acc : 0.8546
Epoch 00224 | Train Loss : 0.3905 | Eval Loss : 0.3991 | Train acc : 0.8147 | Eval Acc : 0.8088
     Batch 000 | Loss : 0.3349 | Acc : 0.8453
     Batch 025 | Loss : 0.3391 | Acc : 0.8389
     Batch 050 | Loss : 0.4240 | Acc : 0.7813
     Batch 075 | Loss : 0.4172 | Acc : 0.7966
     Batch 100 | Loss : 0.3636 | Acc : 0.8254
     Batch 125 | Loss : 0.3490 | Acc : 0.8504
     Batch 150 | Loss : 0.4454 | Acc : 0.7775
     Batch 175 | Loss : 0.3387 | Acc : 0.8378
     Batch 200 | Loss : 0.5002 | Acc : 0.7552
     Batch 225 | Loss : 0.3602 | Acc : 0.8250
     Batch 250 | Loss : 0.3907 | Acc : 0.8130
     Batch 275 | Loss : 0.3986 | Acc : 0.8125
     Batch 300 | Loss : 0.3306 | Acc : 0.8488
Epoch 00225 | Train Loss : 0.3929 | Eval Loss : 0.4123 | Train acc : 0.8138 | Eval Acc : 0.8021
     Batch 000 | Loss : 0.5000 | Acc : 0.7583
     Batch 025 | Loss : 0.3435 | Acc : 0.8425
     Batch 050 | Loss : 0.4127 | Acc : 0.8002
     Batch 075 | Loss : 0.4513 | Acc : 0.7835
     Batch 100 | Loss : 0.4284 | Acc : 0.7863
     Batch 125 | Loss : 0.4113 | Acc : 0.7984
     Batch 150 | Loss : 0.5869 | Acc : 0.7208
     Batch 175 | Loss : 0.3675 | Acc : 0.8271
     Batch 200 | Loss : 0.3348 | Acc : 0.8427
     Batch 225 | Loss : 0.3534 | Acc : 0.8333
     Batch 250 | Loss : 0.4019 | Acc : 0.8022
     Batch 275 | Loss : 0.3649 | Acc : 0.8306
     Batch 300 | Loss : 0.3832 | Acc : 0.8166
Epoch 00226 | Train Loss : 0.3919 | Eval Loss : 0.4089 | Train acc : 0.8140 | Eval Acc : 0.8043
     Batch 000 | Loss : 0.3714 | Acc : 0.8292
     Batch 025 | Loss : 0.4261 | Acc : 0.7968
     Batch 050 | Loss : 0.3314 | Acc : 0.8436
     Batch 075 | Loss : 0.3591 | Acc : 0.8244
     Batch 100 | Loss : 0.4980 | Acc : 0.7593
     Batch 125 | Loss : 0.3440 | Acc : 0.8451
     Batch 150 | Loss : 0.3573 | Acc : 0.8383
     Batch 175 | Loss : 0.3697 | Acc : 0.8272
     Batch 200 | Loss : 0.3308 | Acc : 0.8480
     Batch 225 | Loss : 0.4196 | Acc : 0.7914
     Batch 250 | Loss : 0.3718 | Acc : 0.8350
     Batch 275 | Loss : 0.3651 | Acc : 0.8311
     Batch 300 | Loss : 0.3488 | Acc : 0.8377
Epoch 00227 | Train Loss : 0.3936 | Eval Loss : 0.4053 | Train acc : 0.8134 | Eval Acc : 0.8059
     Batch 000 | Loss : 0.3743 | Acc : 0.8244
     Batch 025 | Loss : 0.4689 | Acc : 0.7702
     Batch 050 | Loss : 0.3663 | Acc : 0.8236
     Batch 075 | Loss : 0.3898 | Acc : 0.8112
     Batch 100 | Loss : 0.3269 | Acc : 0.8545
     Batch 125 | Loss : 0.3482 | Acc : 0.8433
     Batch 150 | Loss : 0.3680 | Acc : 0.8238
     Batch 175 | Loss : 0.4755 | Acc : 0.7764
     Batch 200 | Loss : 0.3381 | Acc : 0.8389
     Batch 225 | Loss : 0.3965 | Acc : 0.8126
     Batch 250 | Loss : 0.4219 | Acc : 0.7970
     Batch 275 | Loss : 0.3810 | Acc : 0.8185
     Batch 300 | Loss : 0.4567 | Acc : 0.7740
Epoch 00228 | Train Loss : 0.3928 | Eval Loss : 0.4031 | Train acc : 0.8138 | Eval Acc : 0.8071
     Batch 000 | Loss : 0.4345 | Acc : 0.7896
     Batch 025 | Loss : 0.3724 | Acc : 0.8312
     Batch 050 | Loss : 0.3421 | Acc : 0.8418
     Batch 075 | Loss : 0.4307 | Acc : 0.7876
     Batch 100 | Loss : 0.3717 | Acc : 0.8253
     Batch 125 | Loss : 0.3520 | Acc : 0.8347
     Batch 150 | Loss : 0.3555 | Acc : 0.8420
     Batch 175 | Loss : 0.3831 | Acc : 0.8262
     Batch 200 | Loss : 0.3575 | Acc : 0.8300
     Batch 225 | Loss : 0.3576 | Acc : 0.8341
     Batch 250 | Loss : 0.4450 | Acc : 0.7814
     Batch 275 | Loss : 0.4483 | Acc : 0.7779
     Batch 300 | Loss : 0.3360 | Acc : 0.8498
Epoch 00229 | Train Loss : 0.3912 | Eval Loss : 0.4031 | Train acc : 0.8144 | Eval Acc : 0.8072
     Batch 000 | Loss : 0.3700 | Acc : 0.8290
     Batch 025 | Loss : 0.4122 | Acc : 0.8000
     Batch 050 | Loss : 0.3717 | Acc : 0.8258
     Batch 075 | Loss : 0.3695 | Acc : 0.8256
     Batch 100 | Loss : 0.3495 | Acc : 0.8347
     Batch 125 | Loss : 0.4195 | Acc : 0.7973
     Batch 150 | Loss : 0.4880 | Acc : 0.7643
     Batch 175 | Loss : 0.3946 | Acc : 0.8117
     Batch 200 | Loss : 0.3774 | Acc : 0.8269
     Batch 225 | Loss : 0.4418 | Acc : 0.7855
     Batch 250 | Loss : 0.3422 | Acc : 0.8428
     Batch 275 | Loss : 0.3468 | Acc : 0.8412
     Batch 300 | Loss : 0.3872 | Acc : 0.8105
Epoch 00230 | Train Loss : 0.3925 | Eval Loss : 0.3995 | Train acc : 0.8137 | Eval Acc : 0.8088
     Batch 000 | Loss : 0.4267 | Acc : 0.7946
     Batch 025 | Loss : 0.3730 | Acc : 0.8239
     Batch 050 | Loss : 0.3680 | Acc : 0.8424
     Batch 075 | Loss : 0.3588 | Acc : 0.8332
     Batch 100 | Loss : 0.3682 | Acc : 0.8287
     Batch 125 | Loss : 0.4524 | Acc : 0.7799
     Batch 150 | Loss : 0.3328 | Acc : 0.8461
     Batch 175 | Loss : 0.3391 | Acc : 0.8448
     Batch 200 | Loss : 0.3293 | Acc : 0.8495
     Batch 225 | Loss : 0.3479 | Acc : 0.8401
     Batch 250 | Loss : 0.3773 | Acc : 0.8236
     Batch 275 | Loss : 0.4687 | Acc : 0.7764
     Batch 300 | Loss : 0.4180 | Acc : 0.7951
Epoch 00231 | Train Loss : 0.3909 | Eval Loss : 0.3990 | Train acc : 0.8149 | Eval Acc : 0.8086
     Batch 000 | Loss : 0.4027 | Acc : 0.8003
     Batch 025 | Loss : 0.3926 | Acc : 0.8281
     Batch 050 | Loss : 0.3698 | Acc : 0.8273
     Batch 075 | Loss : 0.3354 | Acc : 0.8498
     Batch 100 | Loss : 0.3387 | Acc : 0.8502
     Batch 125 | Loss : 0.3945 | Acc : 0.8099
     Batch 150 | Loss : 0.3328 | Acc : 0.8439
     Batch 175 | Loss : 0.3670 | Acc : 0.8301
     Batch 200 | Loss : 0.4404 | Acc : 0.7865
     Batch 225 | Loss : 0.3347 | Acc : 0.8544
     Batch 250 | Loss : 0.3587 | Acc : 0.8333
     Batch 275 | Loss : 0.3590 | Acc : 0.8301
     Batch 300 | Loss : 0.4213 | Acc : 0.7972
Epoch 00232 | Train Loss : 0.3954 | Eval Loss : 0.4226 | Train acc : 0.8124 | Eval Acc : 0.7944
     Batch 000 | Loss : 0.4209 | Acc : 0.7912
     Batch 025 | Loss : 0.4070 | Acc : 0.8006
     Batch 050 | Loss : 0.3792 | Acc : 0.8212
     Batch 075 | Loss : 0.3714 | Acc : 0.8259
     Batch 100 | Loss : 0.3798 | Acc : 0.8204
     Batch 125 | Loss : 0.3912 | Acc : 0.8147
     Batch 150 | Loss : 0.3717 | Acc : 0.8235
     Batch 175 | Loss : 0.3443 | Acc : 0.8453
     Batch 200 | Loss : 0.4083 | Acc : 0.8013
     Batch 225 | Loss : 0.3964 | Acc : 0.8094
     Batch 250 | Loss : 0.4241 | Acc : 0.7969
     Batch 275 | Loss : 0.3580 | Acc : 0.8512
     Batch 300 | Loss : 0.3388 | Acc : 0.8497
Epoch 00233 | Train Loss : 0.3938 | Eval Loss : 0.4045 | Train acc : 0.8132 | Eval Acc : 0.8050
     Batch 000 | Loss : 0.3586 | Acc : 0.8366
     Batch 025 | Loss : 0.4127 | Acc : 0.7945
     Batch 050 | Loss : 0.3831 | Acc : 0.8180
     Batch 075 | Loss : 0.3686 | Acc : 0.8237
     Batch 100 | Loss : 0.4910 | Acc : 0.7478
     Batch 125 | Loss : 0.3764 | Acc : 0.8218
     Batch 150 | Loss : 0.4328 | Acc : 0.7949
     Batch 175 | Loss : 0.4277 | Acc : 0.7907
     Batch 200 | Loss : 0.3725 | Acc : 0.8233
     Batch 225 | Loss : 0.3705 | Acc : 0.8261
     Batch 250 | Loss : 0.3646 | Acc : 0.8326
     Batch 275 | Loss : 0.3612 | Acc : 0.8313
     Batch 300 | Loss : 0.5057 | Acc : 0.7576
Epoch 00234 | Train Loss : 0.3918 | Eval Loss : 0.4005 | Train acc : 0.8143 | Eval Acc : 0.8088
     Batch 000 | Loss : 0.4267 | Acc : 0.7914
     Batch 025 | Loss : 0.4517 | Acc : 0.7861
     Batch 050 | Loss : 0.5002 | Acc : 0.7633
     Batch 075 | Loss : 0.3615 | Acc : 0.8396
     Batch 100 | Loss : 0.3938 | Acc : 0.8102
     Batch 125 | Loss : 0.4604 | Acc : 0.7718
     Batch 150 | Loss : 0.4582 | Acc : 0.7736
     Batch 175 | Loss : 0.3778 | Acc : 0.8214
     Batch 200 | Loss : 0.4278 | Acc : 0.7876
     Batch 225 | Loss : 0.3691 | Acc : 0.8253
     Batch 250 | Loss : 0.4050 | Acc : 0.8036
     Batch 275 | Loss : 0.3684 | Acc : 0.8384
     Batch 300 | Loss : 0.3602 | Acc : 0.8261
Epoch 00235 | Train Loss : 0.3915 | Eval Loss : 0.4002 | Train acc : 0.8145 | Eval Acc : 0.8084
     Batch 000 | Loss : 0.4441 | Acc : 0.7873
     Batch 025 | Loss : 0.4437 | Acc : 0.7835
     Batch 050 | Loss : 0.3848 | Acc : 0.8237
     Batch 075 | Loss : 0.4388 | Acc : 0.7780
     Batch 100 | Loss : 0.3859 | Acc : 0.8184
     Batch 125 | Loss : 0.3356 | Acc : 0.8579
     Batch 150 | Loss : 0.3575 | Acc : 0.8331
     Batch 175 | Loss : 0.3706 | Acc : 0.8254
     Batch 200 | Loss : 0.4174 | Acc : 0.7963
     Batch 225 | Loss : 0.4269 | Acc : 0.7905
     Batch 250 | Loss : 0.3729 | Acc : 0.8216
     Batch 275 | Loss : 0.3777 | Acc : 0.8241
     Batch 300 | Loss : 0.3603 | Acc : 0.8347
Epoch 00236 | Train Loss : 0.3917 | Eval Loss : 0.4033 | Train acc : 0.8144 | Eval Acc : 0.8067
     Batch 000 | Loss : 0.4839 | Acc : 0.7662
     Batch 025 | Loss : 0.4120 | Acc : 0.8023
     Batch 050 | Loss : 0.3544 | Acc : 0.8367
     Batch 075 | Loss : 0.3975 | Acc : 0.8127
     Batch 100 | Loss : 0.4050 | Acc : 0.8057
     Batch 125 | Loss : 0.3317 | Acc : 0.8422
     Batch 150 | Loss : 0.3727 | Acc : 0.8291
     Batch 175 | Loss : 0.3586 | Acc : 0.8299
     Batch 200 | Loss : 0.4117 | Acc : 0.7969
     Batch 225 | Loss : 0.3578 | Acc : 0.8295
     Batch 250 | Loss : 0.3581 | Acc : 0.8371
     Batch 275 | Loss : 0.4863 | Acc : 0.7641
     Batch 300 | Loss : 0.4136 | Acc : 0.8014
Epoch 00237 | Train Loss : 0.3913 | Eval Loss : 0.4078 | Train acc : 0.8142 | Eval Acc : 0.8067
     Batch 000 | Loss : 0.3353 | Acc : 0.8403
     Batch 025 | Loss : 0.3452 | Acc : 0.8393
     Batch 050 | Loss : 0.3822 | Acc : 0.8222
     Batch 075 | Loss : 0.3703 | Acc : 0.8278
     Batch 100 | Loss : 0.4121 | Acc : 0.7959
     Batch 125 | Loss : 0.3565 | Acc : 0.8405
     Batch 150 | Loss : 0.3678 | Acc : 0.8350
     Batch 175 | Loss : 0.3451 | Acc : 0.8387
     Batch 200 | Loss : 0.3260 | Acc : 0.8489
     Batch 225 | Loss : 0.4444 | Acc : 0.7915
     Batch 250 | Loss : 0.4555 | Acc : 0.7773
     Batch 275 | Loss : 0.3393 | Acc : 0.8411
     Batch 300 | Loss : 0.4307 | Acc : 0.7884
Epoch 00238 | Train Loss : 0.3931 | Eval Loss : 0.4038 | Train acc : 0.8134 | Eval Acc : 0.8054
     Batch 000 | Loss : 0.3923 | Acc : 0.8093
     Batch 025 | Loss : 0.3665 | Acc : 0.8267
     Batch 050 | Loss : 0.4007 | Acc : 0.8132
     Batch 075 | Loss : 0.3402 | Acc : 0.8454
     Batch 100 | Loss : 0.4511 | Acc : 0.7683
     Batch 125 | Loss : 0.3806 | Acc : 0.8274
     Batch 150 | Loss : 0.3574 | Acc : 0.8339
     Batch 175 | Loss : 0.3905 | Acc : 0.8067
     Batch 200 | Loss : 0.4081 | Acc : 0.8015
     Batch 225 | Loss : 0.3481 | Acc : 0.8437
     Batch 250 | Loss : 0.3314 | Acc : 0.8485
     Batch 275 | Loss : 0.4654 | Acc : 0.7608
     Batch 300 | Loss : 0.4684 | Acc : 0.7678
Epoch 00239 | Train Loss : 0.3933 | Eval Loss : 0.4055 | Train acc : 0.8135 | Eval Acc : 0.8044
     Batch 000 | Loss : 0.4324 | Acc : 0.7849
     Batch 025 | Loss : 0.4074 | Acc : 0.8015
     Batch 050 | Loss : 0.4071 | Acc : 0.8050
     Batch 075 | Loss : 0.3486 | Acc : 0.8430
     Batch 100 | Loss : 0.4172 | Acc : 0.7926
     Batch 125 | Loss : 0.3568 | Acc : 0.8324
     Batch 150 | Loss : 0.3454 | Acc : 0.8398
     Batch 175 | Loss : 0.3642 | Acc : 0.8279
     Batch 200 | Loss : 0.3471 | Acc : 0.8397
     Batch 225 | Loss : 0.3380 | Acc : 0.8427
     Batch 250 | Loss : 0.4499 | Acc : 0.7774
     Batch 275 | Loss : 0.4456 | Acc : 0.7793
     Batch 300 | Loss : 0.3541 | Acc : 0.8360
Epoch 00240 | Train Loss : 0.3943 | Eval Loss : 0.3997 | Train acc : 0.8129 | Eval Acc : 0.8084
     Batch 000 | Loss : 0.3146 | Acc : 0.8608
     Batch 025 | Loss : 0.4052 | Acc : 0.8032
     Batch 050 | Loss : 0.3890 | Acc : 0.8245
     Batch 075 | Loss : 0.3317 | Acc : 0.8548
     Batch 100 | Loss : 0.4868 | Acc : 0.7658
     Batch 125 | Loss : 0.4328 | Acc : 0.7970
     Batch 150 | Loss : 0.4371 | Acc : 0.7839
     Batch 175 | Loss : 0.3366 | Acc : 0.8496
     Batch 200 | Loss : 0.5426 | Acc : 0.7520
     Batch 225 | Loss : 0.3539 | Acc : 0.8347
     Batch 250 | Loss : 0.3496 | Acc : 0.8395
     Batch 275 | Loss : 0.3741 | Acc : 0.8268
     Batch 300 | Loss : 0.3988 | Acc : 0.8095
Epoch 00241 | Train Loss : 0.3929 | Eval Loss : 0.4044 | Train acc : 0.8141 | Eval Acc : 0.8052
     Batch 000 | Loss : 0.4522 | Acc : 0.7770
     Batch 025 | Loss : 0.3871 | Acc : 0.8178
     Batch 050 | Loss : 0.3791 | Acc : 0.8224
     Batch 075 | Loss : 0.4845 | Acc : 0.7685
     Batch 100 | Loss : 0.3938 | Acc : 0.8073
     Batch 125 | Loss : 0.4206 | Acc : 0.7928
     Batch 150 | Loss : 0.3480 | Acc : 0.8484
     Batch 175 | Loss : 0.4291 | Acc : 0.7847
     Batch 200 | Loss : 0.3549 | Acc : 0.8429
     Batch 225 | Loss : 0.3678 | Acc : 0.8368
     Batch 250 | Loss : 0.3805 | Acc : 0.8229
     Batch 275 | Loss : 0.4053 | Acc : 0.8071
     Batch 300 | Loss : 0.3654 | Acc : 0.8244
Epoch 00242 | Train Loss : 0.3923 | Eval Loss : 0.4106 | Train acc : 0.8140 | Eval Acc : 0.8015
     Batch 000 | Loss : 0.3501 | Acc : 0.8429
     Batch 025 | Loss : 0.4761 | Acc : 0.7679
     Batch 050 | Loss : 0.4427 | Acc : 0.7788
     Batch 075 | Loss : 0.3219 | Acc : 0.8540
     Batch 100 | Loss : 0.4207 | Acc : 0.7939
     Batch 125 | Loss : 0.4178 | Acc : 0.7933
     Batch 150 | Loss : 0.3369 | Acc : 0.8415
     Batch 175 | Loss : 0.3982 | Acc : 0.8045
     Batch 200 | Loss : 0.4211 | Acc : 0.8014
     Batch 225 | Loss : 0.4842 | Acc : 0.7721
     Batch 250 | Loss : 0.4048 | Acc : 0.8057
     Batch 275 | Loss : 0.3621 | Acc : 0.8282
     Batch 300 | Loss : 0.3580 | Acc : 0.8333
Epoch 00243 | Train Loss : 0.3933 | Eval Loss : 0.4044 | Train acc : 0.8136 | Eval Acc : 0.8065
     Batch 000 | Loss : 0.3663 | Acc : 0.8249
     Batch 025 | Loss : 0.3928 | Acc : 0.8156
     Batch 050 | Loss : 0.3430 | Acc : 0.8355
     Batch 075 | Loss : 0.4218 | Acc : 0.7996
     Batch 100 | Loss : 0.3969 | Acc : 0.8077
     Batch 125 | Loss : 0.4145 | Acc : 0.7972
     Batch 150 | Loss : 0.3365 | Acc : 0.8538
     Batch 175 | Loss : 0.3352 | Acc : 0.8479
     Batch 200 | Loss : 0.3455 | Acc : 0.8417
     Batch 225 | Loss : 0.3636 | Acc : 0.8361
     Batch 250 | Loss : 0.3520 | Acc : 0.8308
     Batch 275 | Loss : 0.3436 | Acc : 0.8417
     Batch 300 | Loss : 0.3538 | Acc : 0.8457
Epoch 00244 | Train Loss : 0.3928 | Eval Loss : 0.4055 | Train acc : 0.8134 | Eval Acc : 0.8050
     Batch 000 | Loss : 0.3557 | Acc : 0.8396
     Batch 025 | Loss : 0.3623 | Acc : 0.8260
     Batch 050 | Loss : 0.4732 | Acc : 0.7605
     Batch 075 | Loss : 0.4047 | Acc : 0.7976
     Batch 100 | Loss : 0.3580 | Acc : 0.8337
     Batch 125 | Loss : 0.4317 | Acc : 0.7950
     Batch 150 | Loss : 0.3560 | Acc : 0.8259
     Batch 175 | Loss : 0.5714 | Acc : 0.7186
     Batch 200 | Loss : 0.5516 | Acc : 0.6976
     Batch 225 | Loss : 0.4895 | Acc : 0.7508
     Batch 250 | Loss : 0.4943 | Acc : 0.7650
     Batch 275 | Loss : 0.4913 | Acc : 0.7466
     Batch 300 | Loss : 0.4887 | Acc : 0.7532
Epoch 00245 | Train Loss : 0.4375 | Eval Loss : 0.4588 | Train acc : 0.7850 | Eval Acc : 0.7686
     Batch 000 | Loss : 0.4324 | Acc : 0.7870
     Batch 025 | Loss : 0.5103 | Acc : 0.7378
     Batch 050 | Loss : 0.4257 | Acc : 0.7968
     Batch 075 | Loss : 0.4196 | Acc : 0.8056
     Batch 100 | Loss : 0.3639 | Acc : 0.8329
     Batch 125 | Loss : 0.4642 | Acc : 0.7663
     Batch 150 | Loss : 0.4041 | Acc : 0.8045
     Batch 175 | Loss : 0.4283 | Acc : 0.7897
     Batch 200 | Loss : 0.4612 | Acc : 0.7699
     Batch 225 | Loss : 0.5036 | Acc : 0.7341
     Batch 250 | Loss : 0.3885 | Acc : 0.8145
     Batch 275 | Loss : 0.3562 | Acc : 0.8349
     Batch 300 | Loss : 0.3892 | Acc : 0.8157
Epoch 00246 | Train Loss : 0.4330 | Eval Loss : 0.4347 | Train acc : 0.7884 | Eval Acc : 0.7852
     Batch 000 | Loss : 0.4848 | Acc : 0.7564
     Batch 025 | Loss : 0.4287 | Acc : 0.7848
     Batch 050 | Loss : 0.4520 | Acc : 0.7844
     Batch 075 | Loss : 0.4305 | Acc : 0.7929
     Batch 100 | Loss : 0.4348 | Acc : 0.7877
     Batch 125 | Loss : 0.5091 | Acc : 0.7566
     Batch 150 | Loss : 0.3907 | Acc : 0.8190
     Batch 175 | Loss : 0.4333 | Acc : 0.7835
     Batch 200 | Loss : 0.3989 | Acc : 0.8135
     Batch 225 | Loss : 0.5049 | Acc : 0.7464
     Batch 250 | Loss : 0.4194 | Acc : 0.7869
     Batch 275 | Loss : 0.3987 | Acc : 0.8044
     Batch 300 | Loss : 0.3764 | Acc : 0.8318
Epoch 00247 | Train Loss : 0.4191 | Eval Loss : 0.4339 | Train acc : 0.7961 | Eval Acc : 0.7882
     Batch 000 | Loss : 0.3828 | Acc : 0.8140
     Batch 025 | Loss : 0.3648 | Acc : 0.8238
     Batch 050 | Loss : 0.3437 | Acc : 0.8471
     Batch 075 | Loss : 0.4466 | Acc : 0.7804
     Batch 100 | Loss : 0.3712 | Acc : 0.8168
     Batch 125 | Loss : 0.3964 | Acc : 0.8174
     Batch 150 | Loss : 0.3846 | Acc : 0.8220
     Batch 175 | Loss : 0.4694 | Acc : 0.7478
     Batch 200 | Loss : 0.4706 | Acc : 0.7704
     Batch 225 | Loss : 0.4257 | Acc : 0.7951
     Batch 250 | Loss : 0.3761 | Acc : 0.8314
     Batch 275 | Loss : 0.3857 | Acc : 0.8071
     Batch 300 | Loss : 0.3860 | Acc : 0.8142
Epoch 00248 | Train Loss : 0.4150 | Eval Loss : 0.4199 | Train acc : 0.7987 | Eval Acc : 0.7919
     Batch 000 | Loss : 0.3997 | Acc : 0.8060
     Batch 025 | Loss : 0.4869 | Acc : 0.7521
     Batch 050 | Loss : 0.3695 | Acc : 0.8374
     Batch 075 | Loss : 0.4387 | Acc : 0.7842
     Batch 100 | Loss : 0.4260 | Acc : 0.7889
     Batch 125 | Loss : 0.4476 | Acc : 0.7738
     Batch 150 | Loss : 0.3698 | Acc : 0.8251
     Batch 175 | Loss : 0.4067 | Acc : 0.8112
     Batch 200 | Loss : 0.4767 | Acc : 0.7603
     Batch 225 | Loss : 0.4413 | Acc : 0.7776
     Batch 250 | Loss : 0.3911 | Acc : 0.8038
     Batch 275 | Loss : 0.3642 | Acc : 0.8351
     Batch 300 | Loss : 0.4888 | Acc : 0.7517
Epoch 00249 | Train Loss : 0.4109 | Eval Loss : 0.4210 | Train acc : 0.8008 | Eval Acc : 0.7940
     Batch 000 | Loss : 0.3668 | Acc : 0.8342
     Batch 025 | Loss : 0.4236 | Acc : 0.7903
     Batch 050 | Loss : 0.5006 | Acc : 0.7527
     Batch 075 | Loss : 0.3592 | Acc : 0.8285
     Batch 100 | Loss : 0.4293 | Acc : 0.8079
     Batch 125 | Loss : 0.4317 | Acc : 0.7858
     Batch 150 | Loss : 0.4312 | Acc : 0.7884
     Batch 175 | Loss : 0.4456 | Acc : 0.7675
     Batch 200 | Loss : 0.4842 | Acc : 0.7730
     Batch 225 | Loss : 0.3638 | Acc : 0.8248
     Batch 250 | Loss : 0.5019 | Acc : 0.7459
     Batch 275 | Loss : 0.4418 | Acc : 0.7806
     Batch 300 | Loss : 0.3832 | Acc : 0.8203
Epoch 00250 | Train Loss : 0.4137 | Eval Loss : 0.4269 | Train acc : 0.8004 | Eval Acc : 0.7913
     Batch 000 | Loss : 0.4121 | Acc : 0.7916
     Batch 025 | Loss : 0.3589 | Acc : 0.8286
     Batch 050 | Loss : 0.3850 | Acc : 0.8203
     Batch 075 | Loss : 0.3847 | Acc : 0.8216
     Batch 100 | Loss : 0.4067 | Acc : 0.8182
     Batch 125 | Loss : 0.3907 | Acc : 0.8143
     Batch 150 | Loss : 0.3768 | Acc : 0.8283
     Batch 175 | Loss : 0.3744 | Acc : 0.8190
     Batch 200 | Loss : 0.5046 | Acc : 0.7396
     Batch 225 | Loss : 0.3547 | Acc : 0.8363
     Batch 250 | Loss : 0.3722 | Acc : 0.8224
     Batch 275 | Loss : 0.4622 | Acc : 0.7790
     Batch 300 | Loss : 0.3839 | Acc : 0.8176
Epoch 00251 | Train Loss : 0.4075 | Eval Loss : 0.4173 | Train acc : 0.8035 | Eval Acc : 0.7954
     Batch 000 | Loss : 0.4484 | Acc : 0.7763
     Batch 025 | Loss : 0.3679 | Acc : 0.8295
     Batch 050 | Loss : 0.3758 | Acc : 0.8262
     Batch 075 | Loss : 0.5585 | Acc : 0.7269
     Batch 100 | Loss : 0.3566 | Acc : 0.8327
     Batch 125 | Loss : 0.4438 | Acc : 0.7857
     Batch 150 | Loss : 0.4112 | Acc : 0.7919
     Batch 175 | Loss : 0.4517 | Acc : 0.7728
     Batch 200 | Loss : 0.4810 | Acc : 0.7672
     Batch 225 | Loss : 0.4635 | Acc : 0.7577
     Batch 250 | Loss : 0.3707 | Acc : 0.8183
     Batch 275 | Loss : 0.3866 | Acc : 0.8240
     Batch 300 | Loss : 0.3576 | Acc : 0.8286
Epoch 00252 | Train Loss : 0.4074 | Eval Loss : 0.4204 | Train acc : 0.8035 | Eval Acc : 0.7958
     Batch 000 | Loss : 0.4740 | Acc : 0.7698
     Batch 025 | Loss : 0.3438 | Acc : 0.8412
     Batch 050 | Loss : 0.4146 | Acc : 0.7900
     Batch 075 | Loss : 0.4156 | Acc : 0.8010
     Batch 100 | Loss : 0.3818 | Acc : 0.8236
     Batch 125 | Loss : 0.4839 | Acc : 0.7568
     Batch 150 | Loss : 0.3693 | Acc : 0.8359
     Batch 175 | Loss : 0.4768 | Acc : 0.7746
     Batch 200 | Loss : 0.4952 | Acc : 0.7510
     Batch 225 | Loss : 0.4012 | Acc : 0.8017
     Batch 250 | Loss : 0.4363 | Acc : 0.7807
     Batch 275 | Loss : 0.4267 | Acc : 0.7850
     Batch 300 | Loss : 0.3580 | Acc : 0.8365
Epoch 00253 | Train Loss : 0.4054 | Eval Loss : 0.4147 | Train acc : 0.8044 | Eval Acc : 0.7986
     Batch 000 | Loss : 0.3846 | Acc : 0.8076
     Batch 025 | Loss : 0.4181 | Acc : 0.7965
     Batch 050 | Loss : 0.3675 | Acc : 0.8193
     Batch 075 | Loss : 0.3485 | Acc : 0.8465
     Batch 100 | Loss : 0.4823 | Acc : 0.7756
     Batch 125 | Loss : 0.3558 | Acc : 0.8358
     Batch 150 | Loss : 0.4569 | Acc : 0.7744
     Batch 175 | Loss : 0.3719 | Acc : 0.8213
     Batch 200 | Loss : 0.3644 | Acc : 0.8342
     Batch 225 | Loss : 0.3548 | Acc : 0.8383
     Batch 250 | Loss : 0.4609 | Acc : 0.7732
     Batch 275 | Loss : 0.3683 | Acc : 0.8351
     Batch 300 | Loss : 0.3608 | Acc : 0.8307
Epoch 00254 | Train Loss : 0.4037 | Eval Loss : 0.4116 | Train acc : 0.8053 | Eval Acc : 0.7994
     Batch 000 | Loss : 0.3511 | Acc : 0.8416
     Batch 025 | Loss : 0.4070 | Acc : 0.7910
     Batch 050 | Loss : 0.4671 | Acc : 0.7628
     Batch 075 | Loss : 0.4437 | Acc : 0.7876
     Batch 100 | Loss : 0.3817 | Acc : 0.8138
     Batch 125 | Loss : 0.4177 | Acc : 0.8056
     Batch 150 | Loss : 0.4613 | Acc : 0.7683
     Batch 175 | Loss : 0.3966 | Acc : 0.8085
     Batch 200 | Loss : 0.3532 | Acc : 0.8339
     Batch 225 | Loss : 0.4382 | Acc : 0.7722
     Batch 250 | Loss : 0.3763 | Acc : 0.8189
     Batch 275 | Loss : 0.3621 | Acc : 0.8270
     Batch 300 | Loss : 0.3701 | Acc : 0.8277
Epoch 00255 | Train Loss : 0.4078 | Eval Loss : 0.4297 | Train acc : 0.8042 | Eval Acc : 0.7938
     Batch 000 | Loss : 0.4308 | Acc : 0.7898
     Batch 025 | Loss : 0.4072 | Acc : 0.7917
     Batch 050 | Loss : 0.3816 | Acc : 0.8267
     Batch 075 | Loss : 0.4717 | Acc : 0.7675
     Batch 100 | Loss : 0.4215 | Acc : 0.7959
     Batch 125 | Loss : 0.3836 | Acc : 0.8074
     Batch 150 | Loss : 0.4247 | Acc : 0.7882
     Batch 175 | Loss : 0.3916 | Acc : 0.8284
     Batch 200 | Loss : 0.3820 | Acc : 0.8164
     Batch 225 | Loss : 0.3879 | Acc : 0.8105
     Batch 250 | Loss : 0.3651 | Acc : 0.8257
     Batch 275 | Loss : 0.3386 | Acc : 0.8422
     Batch 300 | Loss : 0.3545 | Acc : 0.8360
Epoch 00256 | Train Loss : 0.4068 | Eval Loss : 0.4259 | Train acc : 0.8047 | Eval Acc : 0.7962
     Batch 000 | Loss : 0.3884 | Acc : 0.8197
     Batch 025 | Loss : 0.4202 | Acc : 0.7952
     Batch 050 | Loss : 0.4527 | Acc : 0.7729
     Batch 075 | Loss : 0.3495 | Acc : 0.8356
     Batch 100 | Loss : 0.4447 | Acc : 0.7744
     Batch 125 | Loss : 0.4277 | Acc : 0.7888
     Batch 150 | Loss : 0.3543 | Acc : 0.8382
     Batch 175 | Loss : 0.4704 | Acc : 0.7606
     Batch 200 | Loss : 0.3360 | Acc : 0.8425
     Batch 225 | Loss : 0.4287 | Acc : 0.7877
     Batch 250 | Loss : 0.3676 | Acc : 0.8246
     Batch 275 | Loss : 0.3912 | Acc : 0.8098
     Batch 300 | Loss : 0.3972 | Acc : 0.8068
Epoch 00257 | Train Loss : 0.4058 | Eval Loss : 0.4177 | Train acc : 0.8048 | Eval Acc : 0.7975
     Batch 000 | Loss : 0.4087 | Acc : 0.8014
     Batch 025 | Loss : 0.3575 | Acc : 0.8356
     Batch 050 | Loss : 0.3984 | Acc : 0.8133
     Batch 075 | Loss : 0.4202 | Acc : 0.7966
     Batch 100 | Loss : 0.3780 | Acc : 0.8159
     Batch 125 | Loss : 0.4721 | Acc : 0.7696
     Batch 150 | Loss : 0.4392 | Acc : 0.7872
     Batch 175 | Loss : 0.3769 | Acc : 0.8176
     Batch 200 | Loss : 0.3651 | Acc : 0.8201
     Batch 225 | Loss : 0.4141 | Acc : 0.7977
     Batch 250 | Loss : 0.4702 | Acc : 0.7590
     Batch 275 | Loss : 0.3730 | Acc : 0.8267
     Batch 300 | Loss : 0.3526 | Acc : 0.8408
Epoch 00258 | Train Loss : 0.4047 | Eval Loss : 0.4182 | Train acc : 0.8054 | Eval Acc : 0.7961
     Batch 000 | Loss : 0.4199 | Acc : 0.7866
     Batch 025 | Loss : 0.4481 | Acc : 0.7703
     Batch 050 | Loss : 0.3318 | Acc : 0.8590
     Batch 075 | Loss : 0.4130 | Acc : 0.8024
     Batch 100 | Loss : 0.4152 | Acc : 0.8072
     Batch 125 | Loss : 0.4769 | Acc : 0.7668
     Batch 150 | Loss : 0.4783 | Acc : 0.7477
     Batch 175 | Loss : 0.3850 | Acc : 0.8299
     Batch 200 | Loss : 0.3786 | Acc : 0.8188
     Batch 225 | Loss : 0.3856 | Acc : 0.8183
     Batch 250 | Loss : 0.4390 | Acc : 0.7872
     Batch 275 | Loss : 0.3900 | Acc : 0.8097
     Batch 300 | Loss : 0.3981 | Acc : 0.8145
Epoch 00259 | Train Loss : 0.4086 | Eval Loss : 0.4112 | Train acc : 0.8033 | Eval Acc : 0.7978
     Batch 000 | Loss : 0.4333 | Acc : 0.7780
     Batch 025 | Loss : 0.3667 | Acc : 0.8220
     Batch 050 | Loss : 0.3425 | Acc : 0.8449
     Batch 075 | Loss : 0.3515 | Acc : 0.8371
     Batch 100 | Loss : 0.3612 | Acc : 0.8455
     Batch 125 | Loss : 0.4327 | Acc : 0.7784
     Batch 150 | Loss : 0.4308 | Acc : 0.7875
     Batch 175 | Loss : 0.4424 | Acc : 0.7841
     Batch 200 | Loss : 0.4702 | Acc : 0.7678
     Batch 225 | Loss : 0.3800 | Acc : 0.8195
     Batch 250 | Loss : 0.3577 | Acc : 0.8365
     Batch 275 | Loss : 0.3705 | Acc : 0.8322
     Batch 300 | Loss : 0.4218 | Acc : 0.7893
Epoch 00260 | Train Loss : 0.4026 | Eval Loss : 0.4109 | Train acc : 0.8063 | Eval Acc : 0.8010
     Batch 000 | Loss : 0.4513 | Acc : 0.7837
     Batch 025 | Loss : 0.4072 | Acc : 0.8003
     Batch 050 | Loss : 0.3647 | Acc : 0.8302
     Batch 075 | Loss : 0.4487 | Acc : 0.7692
     Batch 100 | Loss : 0.4547 | Acc : 0.7668
     Batch 125 | Loss : 0.3868 | Acc : 0.8172
     Batch 150 | Loss : 0.3804 | Acc : 0.8143
     Batch 175 | Loss : 0.3827 | Acc : 0.8140
     Batch 200 | Loss : 0.4499 | Acc : 0.7795
     Batch 225 | Loss : 0.4076 | Acc : 0.8023
     Batch 250 | Loss : 0.3825 | Acc : 0.8207
     Batch 275 | Loss : 0.3448 | Acc : 0.8446
     Batch 300 | Loss : 0.3385 | Acc : 0.8438
Epoch 00261 | Train Loss : 0.4020 | Eval Loss : 0.4080 | Train acc : 0.8065 | Eval Acc : 0.8019
     Batch 000 | Loss : 0.3631 | Acc : 0.8401
     Batch 025 | Loss : 0.4156 | Acc : 0.7924
     Batch 050 | Loss : 0.4243 | Acc : 0.7890
     Batch 075 | Loss : 0.3908 | Acc : 0.8119
     Batch 100 | Loss : 0.4076 | Acc : 0.8005
     Batch 125 | Loss : 0.3846 | Acc : 0.8246
     Batch 150 | Loss : 0.4800 | Acc : 0.7534
     Batch 175 | Loss : 0.4233 | Acc : 0.7931
     Batch 200 | Loss : 0.3976 | Acc : 0.8001
     Batch 225 | Loss : 0.4314 | Acc : 0.7866
     Batch 250 | Loss : 0.3896 | Acc : 0.8164
     Batch 275 | Loss : 0.4829 | Acc : 0.7729
     Batch 300 | Loss : 0.4788 | Acc : 0.7699
Epoch 00262 | Train Loss : 0.4014 | Eval Loss : 0.4075 | Train acc : 0.8070 | Eval Acc : 0.8006
     Batch 000 | Loss : 0.4049 | Acc : 0.7960
     Batch 025 | Loss : 0.3688 | Acc : 0.8345
     Batch 050 | Loss : 0.4025 | Acc : 0.8049
     Batch 075 | Loss : 0.3668 | Acc : 0.8382
     Batch 100 | Loss : 0.4070 | Acc : 0.8074
     Batch 125 | Loss : 0.4371 | Acc : 0.7834
     Batch 150 | Loss : 0.4356 | Acc : 0.7808
     Batch 175 | Loss : 0.4821 | Acc : 0.7510
     Batch 200 | Loss : 0.3664 | Acc : 0.8435
     Batch 225 | Loss : 0.3887 | Acc : 0.8210
     Batch 250 | Loss : 0.3761 | Acc : 0.8341
     Batch 275 | Loss : 0.3805 | Acc : 0.8214
     Batch 300 | Loss : 0.4710 | Acc : 0.7595
Epoch 00263 | Train Loss : 0.4078 | Eval Loss : 0.4100 | Train acc : 0.8046 | Eval Acc : 0.8016
     Batch 000 | Loss : 0.4466 | Acc : 0.7759
     Batch 025 | Loss : 0.4412 | Acc : 0.7926
     Batch 050 | Loss : 0.3773 | Acc : 0.8177
     Batch 075 | Loss : 0.3793 | Acc : 0.8141
     Batch 100 | Loss : 0.3498 | Acc : 0.8304
     Batch 125 | Loss : 0.4300 | Acc : 0.7931
     Batch 150 | Loss : 0.4492 | Acc : 0.7908
     Batch 175 | Loss : 0.4674 | Acc : 0.7708
     Batch 200 | Loss : 0.3740 | Acc : 0.8254
     Batch 225 | Loss : 0.3724 | Acc : 0.8244
     Batch 250 | Loss : 0.4085 | Acc : 0.7995
     Batch 275 | Loss : 0.3676 | Acc : 0.8275
     Batch 300 | Loss : 0.4053 | Acc : 0.8073
Epoch 00264 | Train Loss : 0.4024 | Eval Loss : 0.4116 | Train acc : 0.8065 | Eval Acc : 0.8003
     Batch 000 | Loss : 0.4084 | Acc : 0.7995
     Batch 025 | Loss : 0.4364 | Acc : 0.7880
     Batch 050 | Loss : 0.4844 | Acc : 0.7639
     Batch 075 | Loss : 0.3598 | Acc : 0.8360
     Batch 100 | Loss : 0.4264 | Acc : 0.7849
     Batch 125 | Loss : 0.3491 | Acc : 0.8360
     Batch 150 | Loss : 0.4201 | Acc : 0.7921
     Batch 175 | Loss : 0.4943 | Acc : 0.7634
     Batch 200 | Loss : 0.3784 | Acc : 0.8179
     Batch 225 | Loss : 0.4669 | Acc : 0.7709
     Batch 250 | Loss : 0.4110 | Acc : 0.7986
     Batch 275 | Loss : 0.4080 | Acc : 0.7985
     Batch 300 | Loss : 0.3736 | Acc : 0.8146
Epoch 00265 | Train Loss : 0.4015 | Eval Loss : 0.4107 | Train acc : 0.8068 | Eval Acc : 0.8003
     Batch 000 | Loss : 0.4011 | Acc : 0.8020
     Batch 025 | Loss : 0.4674 | Acc : 0.7589
     Batch 050 | Loss : 0.4141 | Acc : 0.7952
     Batch 075 | Loss : 0.4548 | Acc : 0.7705
     Batch 100 | Loss : 0.3867 | Acc : 0.8149
     Batch 125 | Loss : 0.4188 | Acc : 0.7934
     Batch 150 | Loss : 0.3768 | Acc : 0.8138
     Batch 175 | Loss : 0.3847 | Acc : 0.8140
     Batch 200 | Loss : 0.3674 | Acc : 0.8246
     Batch 225 | Loss : 0.3926 | Acc : 0.8075
     Batch 250 | Loss : 0.3825 | Acc : 0.8124
     Batch 275 | Loss : 0.3893 | Acc : 0.8117
     Batch 300 | Loss : 0.3578 | Acc : 0.8310
Epoch 00266 | Train Loss : 0.4015 | Eval Loss : 0.4247 | Train acc : 0.8069 | Eval Acc : 0.7939
     Batch 000 | Loss : 0.4495 | Acc : 0.7800
     Batch 025 | Loss : 0.3719 | Acc : 0.8216
     Batch 050 | Loss : 0.3710 | Acc : 0.8224
     Batch 075 | Loss : 0.3532 | Acc : 0.8338
     Batch 100 | Loss : 0.4026 | Acc : 0.8063
     Batch 125 | Loss : 0.4290 | Acc : 0.7879
     Batch 150 | Loss : 0.4783 | Acc : 0.7625
     Batch 175 | Loss : 0.5153 | Acc : 0.7647
     Batch 200 | Loss : 0.4686 | Acc : 0.7530
     Batch 225 | Loss : 0.3798 | Acc : 0.8193
     Batch 250 | Loss : 0.3544 | Acc : 0.8384
     Batch 275 | Loss : 0.3819 | Acc : 0.8119
     Batch 300 | Loss : 0.3444 | Acc : 0.8447
Epoch 00267 | Train Loss : 0.4030 | Eval Loss : 0.4114 | Train acc : 0.8056 | Eval Acc : 0.7991
     Batch 000 | Loss : 0.3357 | Acc : 0.8502
     Batch 025 | Loss : 0.4205 | Acc : 0.8118
     Batch 050 | Loss : 0.3771 | Acc : 0.8299
     Batch 075 | Loss : 0.3701 | Acc : 0.8225
     Batch 100 | Loss : 0.4335 | Acc : 0.7842
     Batch 125 | Loss : 0.3847 | Acc : 0.8200
     Batch 150 | Loss : 0.4256 | Acc : 0.7861
     Batch 175 | Loss : 0.3499 | Acc : 0.8369
     Batch 200 | Loss : 0.3664 | Acc : 0.8374
     Batch 225 | Loss : 0.3715 | Acc : 0.8292
     Batch 250 | Loss : 0.4888 | Acc : 0.7560
     Batch 275 | Loss : 0.3362 | Acc : 0.8486
     Batch 300 | Loss : 0.3747 | Acc : 0.8242
Epoch 00268 | Train Loss : 0.4007 | Eval Loss : 0.4135 | Train acc : 0.8073 | Eval Acc : 0.7993
     Batch 000 | Loss : 0.5031 | Acc : 0.7522
     Batch 025 | Loss : 0.4175 | Acc : 0.7869
     Batch 050 | Loss : 0.3873 | Acc : 0.8172
     Batch 075 | Loss : 0.4381 | Acc : 0.7842
     Batch 100 | Loss : 0.3538 | Acc : 0.8347
     Batch 125 | Loss : 0.3637 | Acc : 0.8312
     Batch 150 | Loss : 0.4299 | Acc : 0.7911
     Batch 175 | Loss : 0.4186 | Acc : 0.8008
     Batch 200 | Loss : 0.4919 | Acc : 0.7577
     Batch 225 | Loss : 0.4953 | Acc : 0.7582
     Batch 250 | Loss : 0.3651 | Acc : 0.8249
     Batch 275 | Loss : 0.4116 | Acc : 0.8008
     Batch 300 | Loss : 0.4295 | Acc : 0.7848
Epoch 00269 | Train Loss : 0.3987 | Eval Loss : 0.4166 | Train acc : 0.8079 | Eval Acc : 0.7990
     Batch 000 | Loss : 0.4765 | Acc : 0.7595
     Batch 025 | Loss : 0.4002 | Acc : 0.8169
     Batch 050 | Loss : 0.3796 | Acc : 0.8184
     Batch 075 | Loss : 0.4241 | Acc : 0.7921
     Batch 100 | Loss : 0.3949 | Acc : 0.8104
     Batch 125 | Loss : 0.5341 | Acc : 0.7465
     Batch 150 | Loss : 0.3596 | Acc : 0.8343
     Batch 175 | Loss : 0.3761 | Acc : 0.8240
     Batch 200 | Loss : 0.4128 | Acc : 0.8005
     Batch 225 | Loss : 0.4676 | Acc : 0.7664
     Batch 250 | Loss : 0.3724 | Acc : 0.8275
     Batch 275 | Loss : 0.4182 | Acc : 0.7882
     Batch 300 | Loss : 0.5434 | Acc : 0.7457
Epoch 00270 | Train Loss : 0.4029 | Eval Loss : 0.4122 | Train acc : 0.8061 | Eval Acc : 0.7992
     Batch 000 | Loss : 0.4233 | Acc : 0.7934
     Batch 025 | Loss : 0.3473 | Acc : 0.8403
     Batch 050 | Loss : 0.3970 | Acc : 0.7998
     Batch 075 | Loss : 0.3659 | Acc : 0.8225
     Batch 100 | Loss : 0.3618 | Acc : 0.8341
     Batch 125 | Loss : 0.3755 | Acc : 0.8139
     Batch 150 | Loss : 0.3710 | Acc : 0.8296
     Batch 175 | Loss : 0.4786 | Acc : 0.7692
     Batch 200 | Loss : 0.4525 | Acc : 0.7721
     Batch 225 | Loss : 0.4174 | Acc : 0.7872
     Batch 250 | Loss : 0.4447 | Acc : 0.7709
     Batch 275 | Loss : 0.3952 | Acc : 0.8046
     Batch 300 | Loss : 0.3489 | Acc : 0.8420
Epoch 00271 | Train Loss : 0.4020 | Eval Loss : 0.4193 | Train acc : 0.8070 | Eval Acc : 0.7961
     Batch 000 | Loss : 0.4352 | Acc : 0.7915
     Batch 025 | Loss : 0.3793 | Acc : 0.8198
     Batch 050 | Loss : 0.3777 | Acc : 0.8241
     Batch 075 | Loss : 0.4207 | Acc : 0.7932
     Batch 100 | Loss : 0.3581 | Acc : 0.8344
     Batch 125 | Loss : 0.4437 | Acc : 0.7819
     Batch 150 | Loss : 0.4592 | Acc : 0.7678
     Batch 175 | Loss : 0.4158 | Acc : 0.7988
     Batch 200 | Loss : 0.4012 | Acc : 0.8046
     Batch 225 | Loss : 0.3652 | Acc : 0.8255
     Batch 250 | Loss : 0.4239 | Acc : 0.7937
     Batch 275 | Loss : 0.4676 | Acc : 0.7690
     Batch 300 | Loss : 0.3797 | Acc : 0.8142
Epoch 00272 | Train Loss : 0.4017 | Eval Loss : 0.4196 | Train acc : 0.8072 | Eval Acc : 0.7971
     Batch 000 | Loss : 0.3897 | Acc : 0.8186
     Batch 025 | Loss : 0.3866 | Acc : 0.8129
     Batch 050 | Loss : 0.4061 | Acc : 0.8004
     Batch 075 | Loss : 0.3944 | Acc : 0.8134
     Batch 100 | Loss : 0.3341 | Acc : 0.8492
     Batch 125 | Loss : 0.4826 | Acc : 0.7608
     Batch 150 | Loss : 0.4564 | Acc : 0.7650
     Batch 175 | Loss : 0.3832 | Acc : 0.8134
     Batch 200 | Loss : 0.5874 | Acc : 0.7045
     Batch 225 | Loss : 0.3715 | Acc : 0.8178
     Batch 250 | Loss : 0.4544 | Acc : 0.7790
     Batch 275 | Loss : 0.3896 | Acc : 0.8169
     Batch 300 | Loss : 0.4160 | Acc : 0.7963
Epoch 00273 | Train Loss : 0.3972 | Eval Loss : 0.4226 | Train acc : 0.8093 | Eval Acc : 0.7983
     Batch 000 | Loss : 0.3702 | Acc : 0.8234
     Batch 025 | Loss : 0.3837 | Acc : 0.8254
     Batch 050 | Loss : 0.4462 | Acc : 0.7711
     Batch 075 | Loss : 0.4344 | Acc : 0.7871
     Batch 100 | Loss : 0.4073 | Acc : 0.7930
     Batch 125 | Loss : 0.3961 | Acc : 0.8096
     Batch 150 | Loss : 0.4826 | Acc : 0.7633
     Batch 175 | Loss : 0.4347 | Acc : 0.7851
     Batch 200 | Loss : 0.3754 | Acc : 0.8174
     Batch 225 | Loss : 0.4978 | Acc : 0.7499
     Batch 250 | Loss : 0.3973 | Acc : 0.8014
     Batch 275 | Loss : 0.3363 | Acc : 0.8514
     Batch 300 | Loss : 0.4519 | Acc : 0.7848
Epoch 00274 | Train Loss : 0.3988 | Eval Loss : 0.4133 | Train acc : 0.8085 | Eval Acc : 0.8012
     Batch 000 | Loss : 0.3660 | Acc : 0.8256
     Batch 025 | Loss : 0.4500 | Acc : 0.7860
     Batch 050 | Loss : 0.3924 | Acc : 0.8169
     Batch 075 | Loss : 0.3839 | Acc : 0.8234
     Batch 100 | Loss : 0.4549 | Acc : 0.7632
     Batch 125 | Loss : 0.4007 | Acc : 0.8103
     Batch 150 | Loss : 0.4274 | Acc : 0.7918
     Batch 175 | Loss : 0.4310 | Acc : 0.7901
     Batch 200 | Loss : 0.3948 | Acc : 0.8020
     Batch 225 | Loss : 0.3316 | Acc : 0.8592
     Batch 250 | Loss : 0.4746 | Acc : 0.7547
     Batch 275 | Loss : 0.3730 | Acc : 0.8203
     Batch 300 | Loss : 0.4576 | Acc : 0.7820
Epoch 00275 | Train Loss : 0.3994 | Eval Loss : 0.4097 | Train acc : 0.8080 | Eval Acc : 0.8013
     Batch 000 | Loss : 0.4425 | Acc : 0.7823
     Batch 025 | Loss : 0.3749 | Acc : 0.8194
     Batch 050 | Loss : 0.4765 | Acc : 0.7609
     Batch 075 | Loss : 0.4070 | Acc : 0.8045
     Batch 100 | Loss : 0.4292 | Acc : 0.7961
     Batch 125 | Loss : 0.3711 | Acc : 0.8258
     Batch 150 | Loss : 0.3506 | Acc : 0.8338
     Batch 175 | Loss : 0.4139 | Acc : 0.8023
     Batch 200 | Loss : 0.3588 | Acc : 0.8386
     Batch 225 | Loss : 0.3534 | Acc : 0.8357
     Batch 250 | Loss : 0.4204 | Acc : 0.8012
     Batch 275 | Loss : 0.3560 | Acc : 0.8439
     Batch 300 | Loss : 0.3570 | Acc : 0.8313
Epoch 00276 | Train Loss : 0.4007 | Eval Loss : 0.4118 | Train acc : 0.8082 | Eval Acc : 0.8023
     Batch 000 | Loss : 0.3944 | Acc : 0.8109
     Batch 025 | Loss : 0.3573 | Acc : 0.8272
     Batch 050 | Loss : 0.3650 | Acc : 0.8300
     Batch 075 | Loss : 0.4384 | Acc : 0.7749
     Batch 100 | Loss : 0.3889 | Acc : 0.8152
     Batch 125 | Loss : 0.4101 | Acc : 0.7961
     Batch 150 | Loss : 0.5061 | Acc : 0.7513
     Batch 175 | Loss : 0.3597 | Acc : 0.8279
     Batch 200 | Loss : 0.3985 | Acc : 0.8142
     Batch 225 | Loss : 0.3671 | Acc : 0.8231
     Batch 250 | Loss : 0.3444 | Acc : 0.8483
     Batch 275 | Loss : 0.3749 | Acc : 0.8136
     Batch 300 | Loss : 0.3752 | Acc : 0.8239
Epoch 00277 | Train Loss : 0.3973 | Eval Loss : 0.4090 | Train acc : 0.8087 | Eval Acc : 0.8017
     Batch 000 | Loss : 0.3545 | Acc : 0.8339
     Batch 025 | Loss : 0.3711 | Acc : 0.8321
     Batch 050 | Loss : 0.3494 | Acc : 0.8354
     Batch 075 | Loss : 0.4270 | Acc : 0.7832
     Batch 100 | Loss : 0.3532 | Acc : 0.8439
     Batch 125 | Loss : 0.3824 | Acc : 0.8251
     Batch 150 | Loss : 0.3920 | Acc : 0.8035
     Batch 175 | Loss : 0.4173 | Acc : 0.7997
     Batch 200 | Loss : 0.3663 | Acc : 0.8283
     Batch 225 | Loss : 0.3351 | Acc : 0.8481
     Batch 250 | Loss : 0.4129 | Acc : 0.7985
     Batch 275 | Loss : 0.3476 | Acc : 0.8510
     Batch 300 | Loss : 0.3846 | Acc : 0.8166
Epoch 00278 | Train Loss : 0.3988 | Eval Loss : 0.4122 | Train acc : 0.8084 | Eval Acc : 0.8015
     Batch 000 | Loss : 0.4011 | Acc : 0.8111
     Batch 025 | Loss : 0.4634 | Acc : 0.7763
     Batch 050 | Loss : 0.4919 | Acc : 0.7654
     Batch 075 | Loss : 0.3666 | Acc : 0.8336
     Batch 100 | Loss : 0.3950 | Acc : 0.8146
     Batch 125 | Loss : 0.3758 | Acc : 0.8284
     Batch 150 | Loss : 0.3798 | Acc : 0.8228
     Batch 175 | Loss : 0.4013 | Acc : 0.7996
     Batch 200 | Loss : 0.3552 | Acc : 0.8285
     Batch 225 | Loss : 0.3976 | Acc : 0.8070
     Batch 250 | Loss : 0.4387 | Acc : 0.7848
     Batch 275 | Loss : 0.3694 | Acc : 0.8230
     Batch 300 | Loss : 0.4368 | Acc : 0.7796
Epoch 00279 | Train Loss : 0.3987 | Eval Loss : 0.4057 | Train acc : 0.8090 | Eval Acc : 0.8037
     Batch 000 | Loss : 0.3815 | Acc : 0.8112
     Batch 025 | Loss : 0.4726 | Acc : 0.7653
     Batch 050 | Loss : 0.5244 | Acc : 0.7402
     Batch 075 | Loss : 0.3759 | Acc : 0.8321
     Batch 100 | Loss : 0.3659 | Acc : 0.8217
     Batch 125 | Loss : 0.3654 | Acc : 0.8249
     Batch 150 | Loss : 0.4510 | Acc : 0.7752
     Batch 175 | Loss : 0.4582 | Acc : 0.7799
     Batch 200 | Loss : 0.5451 | Acc : 0.7176
     Batch 225 | Loss : 0.3345 | Acc : 0.8558
     Batch 250 | Loss : 0.4044 | Acc : 0.8096
     Batch 275 | Loss : 0.3975 | Acc : 0.8070
     Batch 300 | Loss : 0.4338 | Acc : 0.7843
Epoch 00280 | Train Loss : 0.4001 | Eval Loss : 0.4141 | Train acc : 0.8087 | Eval Acc : 0.8016
     Batch 000 | Loss : 0.4053 | Acc : 0.7992
     Batch 025 | Loss : 0.3706 | Acc : 0.8236
     Batch 050 | Loss : 0.3280 | Acc : 0.8568
     Batch 075 | Loss : 0.4777 | Acc : 0.7583
     Batch 100 | Loss : 0.3697 | Acc : 0.8173
     Batch 125 | Loss : 0.5392 | Acc : 0.7524
     Batch 150 | Loss : 0.4944 | Acc : 0.7549
     Batch 175 | Loss : 0.3777 | Acc : 0.8200
     Batch 200 | Loss : 0.3944 | Acc : 0.8140
     Batch 225 | Loss : 0.3736 | Acc : 0.8219
     Batch 250 | Loss : 0.3812 | Acc : 0.8181
     Batch 275 | Loss : 0.4241 | Acc : 0.7885
     Batch 300 | Loss : 0.3486 | Acc : 0.8403
Epoch 00281 | Train Loss : 0.3964 | Eval Loss : 0.4215 | Train acc : 0.8106 | Eval Acc : 0.7997
     Batch 000 | Loss : 0.4409 | Acc : 0.7855
     Batch 025 | Loss : 0.3934 | Acc : 0.8059
     Batch 050 | Loss : 0.3394 | Acc : 0.8475
     Batch 075 | Loss : 0.3532 | Acc : 0.8344
     Batch 100 | Loss : 0.5113 | Acc : 0.7535
     Batch 125 | Loss : 0.3832 | Acc : 0.8199
     Batch 150 | Loss : 0.3561 | Acc : 0.8381
     Batch 175 | Loss : 0.3875 | Acc : 0.8142
     Batch 200 | Loss : 0.4520 | Acc : 0.7786
     Batch 225 | Loss : 0.4092 | Acc : 0.8026
     Batch 250 | Loss : 0.4612 | Acc : 0.7818
     Batch 275 | Loss : 0.4581 | Acc : 0.7847
     Batch 300 | Loss : 0.4115 | Acc : 0.8040
Epoch 00282 | Train Loss : 0.3970 | Eval Loss : 0.4059 | Train acc : 0.8107 | Eval Acc : 0.8036
     Batch 000 | Loss : 0.4491 | Acc : 0.7746
     Batch 025 | Loss : 0.4796 | Acc : 0.7706
     Batch 050 | Loss : 0.4059 | Acc : 0.8041
     Batch 075 | Loss : 0.3773 | Acc : 0.8248
     Batch 100 | Loss : 0.3580 | Acc : 0.8260
     Batch 125 | Loss : 0.3428 | Acc : 0.8472
     Batch 150 | Loss : 0.3351 | Acc : 0.8485
     Batch 175 | Loss : 0.5049 | Acc : 0.7630
     Batch 200 | Loss : 0.3467 | Acc : 0.8405
     Batch 225 | Loss : 0.4010 | Acc : 0.8016
     Batch 250 | Loss : 0.4269 | Acc : 0.7944
     Batch 275 | Loss : 0.3665 | Acc : 0.8260
     Batch 300 | Loss : 0.3551 | Acc : 0.8279
Epoch 00283 | Train Loss : 0.3962 | Eval Loss : 0.4070 | Train acc : 0.8105 | Eval Acc : 0.8026
     Batch 000 | Loss : 0.4122 | Acc : 0.8059
     Batch 025 | Loss : 0.5157 | Acc : 0.7419
     Batch 050 | Loss : 0.4249 | Acc : 0.7919
     Batch 075 | Loss : 0.4152 | Acc : 0.8094
     Batch 100 | Loss : 0.3457 | Acc : 0.8529
     Batch 125 | Loss : 0.3776 | Acc : 0.8242
     Batch 150 | Loss : 0.4182 | Acc : 0.7980
     Batch 175 | Loss : 0.3563 | Acc : 0.8314
     Batch 200 | Loss : 0.4880 | Acc : 0.7589
     Batch 225 | Loss : 0.4872 | Acc : 0.7627
     Batch 250 | Loss : 0.4003 | Acc : 0.8015
     Batch 275 | Loss : 0.4418 | Acc : 0.7816
     Batch 300 | Loss : 0.4490 | Acc : 0.7766
Epoch 00284 | Train Loss : 0.3987 | Eval Loss : 0.4085 | Train acc : 0.8094 | Eval Acc : 0.7996
     Batch 000 | Loss : 0.3484 | Acc : 0.8477
     Batch 025 | Loss : 0.3894 | Acc : 0.8119
     Batch 050 | Loss : 0.3984 | Acc : 0.8062
     Batch 075 | Loss : 0.3744 | Acc : 0.8179
     Batch 100 | Loss : 0.3188 | Acc : 0.8558
     Batch 125 | Loss : 0.3315 | Acc : 0.8525
     Batch 150 | Loss : 0.3715 | Acc : 0.8258
     Batch 175 | Loss : 0.3478 | Acc : 0.8416
     Batch 200 | Loss : 0.3330 | Acc : 0.8489
     Batch 225 | Loss : 0.3584 | Acc : 0.8361
     Batch 250 | Loss : 0.3959 | Acc : 0.8061
     Batch 275 | Loss : 0.3659 | Acc : 0.8254
     Batch 300 | Loss : 0.3739 | Acc : 0.8286
Epoch 00285 | Train Loss : 0.3971 | Eval Loss : 0.4089 | Train acc : 0.8105 | Eval Acc : 0.8019
     Batch 000 | Loss : 0.3545 | Acc : 0.8351
     Batch 025 | Loss : 0.3479 | Acc : 0.8410
     Batch 050 | Loss : 0.4111 | Acc : 0.8016
     Batch 075 | Loss : 0.3509 | Acc : 0.8407
     Batch 100 | Loss : 0.4100 | Acc : 0.8006
     Batch 125 | Loss : 0.3811 | Acc : 0.8140
     Batch 150 | Loss : 0.3455 | Acc : 0.8420
     Batch 175 | Loss : 0.3537 | Acc : 0.8378
     Batch 200 | Loss : 0.3789 | Acc : 0.8179
     Batch 225 | Loss : 0.3721 | Acc : 0.8207
     Batch 250 | Loss : 0.4205 | Acc : 0.7911
     Batch 275 | Loss : 0.4074 | Acc : 0.8067
     Batch 300 | Loss : 0.3998 | Acc : 0.8229
Epoch 00286 | Train Loss : 0.3981 | Eval Loss : 0.4313 | Train acc : 0.8098 | Eval Acc : 0.7920
     Batch 000 | Loss : 0.3651 | Acc : 0.8283
     Batch 025 | Loss : 0.4257 | Acc : 0.7931
     Batch 050 | Loss : 0.3807 | Acc : 0.8196
     Batch 075 | Loss : 0.5061 | Acc : 0.7399
     Batch 100 | Loss : 0.3735 | Acc : 0.8418
     Batch 125 | Loss : 0.3480 | Acc : 0.8437
     Batch 150 | Loss : 0.3627 | Acc : 0.8380
     Batch 175 | Loss : 0.3695 | Acc : 0.8299
     Batch 200 | Loss : 0.4421 | Acc : 0.7832
     Batch 225 | Loss : 0.3789 | Acc : 0.8199
     Batch 250 | Loss : 0.3562 | Acc : 0.8354
     Batch 275 | Loss : 0.3389 | Acc : 0.8384
     Batch 300 | Loss : 0.5276 | Acc : 0.7481
Epoch 00287 | Train Loss : 0.4027 | Eval Loss : 0.4215 | Train acc : 0.8083 | Eval Acc : 0.7961
     Batch 000 | Loss : 0.4080 | Acc : 0.8015
     Batch 025 | Loss : 0.3640 | Acc : 0.8260
     Batch 050 | Loss : 0.4080 | Acc : 0.8055
     Batch 075 | Loss : 0.3476 | Acc : 0.8417
     Batch 100 | Loss : 0.3316 | Acc : 0.8586
     Batch 125 | Loss : 0.3947 | Acc : 0.8088
     Batch 150 | Loss : 0.3945 | Acc : 0.8127
     Batch 175 | Loss : 0.4360 | Acc : 0.7829
     Batch 200 | Loss : 0.4337 | Acc : 0.7840
     Batch 225 | Loss : 0.4312 | Acc : 0.7916
     Batch 250 | Loss : 0.4564 | Acc : 0.7732
     Batch 275 | Loss : 0.3692 | Acc : 0.8247
     Batch 300 | Loss : 0.3508 | Acc : 0.8367
Epoch 00288 | Train Loss : 0.3985 | Eval Loss : 0.4183 | Train acc : 0.8099 | Eval Acc : 0.8003
     Batch 000 | Loss : 0.3760 | Acc : 0.8198
     Batch 025 | Loss : 0.3639 | Acc : 0.8256
     Batch 050 | Loss : 0.4751 | Acc : 0.7581
     Batch 075 | Loss : 0.3863 | Acc : 0.8238
     Batch 100 | Loss : 0.4439 | Acc : 0.7746
     Batch 125 | Loss : 0.4447 | Acc : 0.7710
     Batch 150 | Loss : 0.3697 | Acc : 0.8291
     Batch 175 | Loss : 0.3667 | Acc : 0.8251
     Batch 200 | Loss : 0.3614 | Acc : 0.8283
     Batch 225 | Loss : 0.3654 | Acc : 0.8274
     Batch 250 | Loss : 0.3530 | Acc : 0.8382
     Batch 275 | Loss : 0.3667 | Acc : 0.8393
     Batch 300 | Loss : 0.3436 | Acc : 0.8462
Epoch 00289 | Train Loss : 0.3943 | Eval Loss : 0.4051 | Train acc : 0.8111 | Eval Acc : 0.8042
     Batch 000 | Loss : 0.3854 | Acc : 0.8121
     Batch 025 | Loss : 0.3757 | Acc : 0.8226
     Batch 050 | Loss : 0.4281 | Acc : 0.7918
     Batch 075 | Loss : 0.3327 | Acc : 0.8521
     Batch 100 | Loss : 0.3461 | Acc : 0.8426
     Batch 125 | Loss : 0.5147 | Acc : 0.7517
     Batch 150 | Loss : 0.3809 | Acc : 0.8201
     Batch 175 | Loss : 0.4181 | Acc : 0.7975
     Batch 200 | Loss : 0.4610 | Acc : 0.7856
     Batch 225 | Loss : 0.3559 | Acc : 0.8300
     Batch 250 | Loss : 0.3290 | Acc : 0.8498
     Batch 275 | Loss : 0.3500 | Acc : 0.8411
     Batch 300 | Loss : 0.3815 | Acc : 0.8211
Epoch 00290 | Train Loss : 0.3962 | Eval Loss : 0.4033 | Train acc : 0.8112 | Eval Acc : 0.8043
     Batch 000 | Loss : 0.4117 | Acc : 0.7929
     Batch 025 | Loss : 0.4029 | Acc : 0.8037
     Batch 050 | Loss : 0.4535 | Acc : 0.7611
     Batch 075 | Loss : 0.4299 | Acc : 0.7880
     Batch 100 | Loss : 0.4026 | Acc : 0.8088
     Batch 125 | Loss : 0.4154 | Acc : 0.7984
     Batch 150 | Loss : 0.3707 | Acc : 0.8267
     Batch 175 | Loss : 0.4075 | Acc : 0.8027
     Batch 200 | Loss : 0.3779 | Acc : 0.8186
     Batch 225 | Loss : 0.3962 | Acc : 0.8104
     Batch 250 | Loss : 0.3687 | Acc : 0.8189
     Batch 275 | Loss : 0.3386 | Acc : 0.8475
     Batch 300 | Loss : 0.4946 | Acc : 0.7474
Epoch 00291 | Train Loss : 0.3947 | Eval Loss : 0.4020 | Train acc : 0.8116 | Eval Acc : 0.8052
     Batch 000 | Loss : 0.4427 | Acc : 0.7879
     Batch 025 | Loss : 0.3535 | Acc : 0.8335
     Batch 050 | Loss : 0.3853 | Acc : 0.8153
     Batch 075 | Loss : 0.3384 | Acc : 0.8529
     Batch 100 | Loss : 0.3366 | Acc : 0.8481
     Batch 125 | Loss : 0.4021 | Acc : 0.8090
     Batch 150 | Loss : 0.4368 | Acc : 0.7843
     Batch 175 | Loss : 0.5302 | Acc : 0.7281
     Batch 200 | Loss : 0.4090 | Acc : 0.7988
     Batch 225 | Loss : 0.4180 | Acc : 0.7941
     Batch 250 | Loss : 0.3567 | Acc : 0.8368
     Batch 275 | Loss : 0.3481 | Acc : 0.8411
     Batch 300 | Loss : 0.3425 | Acc : 0.8469
Epoch 00292 | Train Loss : 0.3963 | Eval Loss : 0.4121 | Train acc : 0.8105 | Eval Acc : 0.8037
     Batch 000 | Loss : 0.4190 | Acc : 0.8116
     Batch 025 | Loss : 0.4107 | Acc : 0.8012
     Batch 050 | Loss : 0.3540 | Acc : 0.8402
     Batch 075 | Loss : 0.3324 | Acc : 0.8504
     Batch 100 | Loss : 0.3514 | Acc : 0.8363
     Batch 125 | Loss : 0.3796 | Acc : 0.8224
     Batch 150 | Loss : 0.4441 | Acc : 0.7852
     Batch 175 | Loss : 0.3373 | Acc : 0.8467
     Batch 200 | Loss : 0.3242 | Acc : 0.8511
     Batch 225 | Loss : 0.4817 | Acc : 0.7650
     Batch 250 | Loss : 0.3482 | Acc : 0.8418
     Batch 275 | Loss : 0.3725 | Acc : 0.8214
     Batch 300 | Loss : 0.3650 | Acc : 0.8327
Epoch 00293 | Train Loss : 0.3992 | Eval Loss : 0.4091 | Train acc : 0.8097 | Eval Acc : 0.8030
     Batch 000 | Loss : 0.3611 | Acc : 0.8380
     Batch 025 | Loss : 0.3820 | Acc : 0.8165
     Batch 050 | Loss : 0.4300 | Acc : 0.7854
     Batch 075 | Loss : 0.4040 | Acc : 0.8046
     Batch 100 | Loss : 0.5146 | Acc : 0.7313
     Batch 125 | Loss : 0.4845 | Acc : 0.7804
     Batch 150 | Loss : 0.4492 | Acc : 0.7744
     Batch 175 | Loss : 0.3866 | Acc : 0.8233
     Batch 200 | Loss : 0.3493 | Acc : 0.8402
     Batch 225 | Loss : 0.4020 | Acc : 0.8055
     Batch 250 | Loss : 0.4124 | Acc : 0.7976
     Batch 275 | Loss : 0.3615 | Acc : 0.8272
     Batch 300 | Loss : 0.3738 | Acc : 0.8204
Epoch 00294 | Train Loss : 0.4003 | Eval Loss : 0.4037 | Train acc : 0.8096 | Eval Acc : 0.8053
     Batch 000 | Loss : 0.3864 | Acc : 0.8264
     Batch 025 | Loss : 0.3989 | Acc : 0.8032
     Batch 050 | Loss : 0.4066 | Acc : 0.8026
     Batch 075 | Loss : 0.3775 | Acc : 0.8171
     Batch 100 | Loss : 0.3321 | Acc : 0.8583
     Batch 125 | Loss : 0.3600 | Acc : 0.8277
     Batch 150 | Loss : 0.4019 | Acc : 0.8028
     Batch 175 | Loss : 0.3538 | Acc : 0.8298
     Batch 200 | Loss : 0.3741 | Acc : 0.8204
     Batch 225 | Loss : 0.3737 | Acc : 0.8221
     Batch 250 | Loss : 0.4001 | Acc : 0.8087
     Batch 275 | Loss : 0.3843 | Acc : 0.8242
     Batch 300 | Loss : 0.4180 | Acc : 0.7983
Epoch 00295 | Train Loss : 0.3955 | Eval Loss : 0.4066 | Train acc : 0.8112 | Eval Acc : 0.8026
     Batch 000 | Loss : 0.3386 | Acc : 0.8476
     Batch 025 | Loss : 0.3469 | Acc : 0.8417
     Batch 050 | Loss : 0.3806 | Acc : 0.8133
     Batch 075 | Loss : 0.4015 | Acc : 0.8056
     Batch 100 | Loss : 0.4197 | Acc : 0.7951
     Batch 125 | Loss : 0.3675 | Acc : 0.8246
     Batch 150 | Loss : 0.3881 | Acc : 0.8156
     Batch 175 | Loss : 0.3544 | Acc : 0.8333
     Batch 200 | Loss : 0.5030 | Acc : 0.7635
     Batch 225 | Loss : 0.4229 | Acc : 0.7914
     Batch 250 | Loss : 0.4343 | Acc : 0.8008
     Batch 275 | Loss : 0.4622 | Acc : 0.7577
     Batch 300 | Loss : 0.3992 | Acc : 0.8110
Epoch 00296 | Train Loss : 0.3948 | Eval Loss : 0.4138 | Train acc : 0.8114 | Eval Acc : 0.8013
     Batch 000 | Loss : 0.4498 | Acc : 0.7614
     Batch 025 | Loss : 0.4035 | Acc : 0.8002
     Batch 050 | Loss : 0.3375 | Acc : 0.8410
     Batch 075 | Loss : 0.4052 | Acc : 0.8051
     Batch 100 | Loss : 0.3475 | Acc : 0.8442
     Batch 125 | Loss : 0.5351 | Acc : 0.7496
     Batch 150 | Loss : 0.3576 | Acc : 0.8435
     Batch 175 | Loss : 0.4069 | Acc : 0.8070
     Batch 200 | Loss : 0.4802 | Acc : 0.7601
     Batch 225 | Loss : 0.3545 | Acc : 0.8389
     Batch 250 | Loss : 0.4361 | Acc : 0.7754
     Batch 275 | Loss : 0.4110 | Acc : 0.7952
     Batch 300 | Loss : 0.4760 | Acc : 0.7681
Epoch 00297 | Train Loss : 0.3967 | Eval Loss : 0.4041 | Train acc : 0.8105 | Eval Acc : 0.8044
     Batch 000 | Loss : 0.3721 | Acc : 0.8280
     Batch 025 | Loss : 0.3712 | Acc : 0.8362
     Batch 050 | Loss : 0.3499 | Acc : 0.8415
     Batch 075 | Loss : 0.3983 | Acc : 0.7990
     Batch 100 | Loss : 0.3634 | Acc : 0.8283
     Batch 125 | Loss : 0.3311 | Acc : 0.8546
     Batch 150 | Loss : 0.3575 | Acc : 0.8332
     Batch 175 | Loss : 0.3579 | Acc : 0.8321
     Batch 200 | Loss : 0.5344 | Acc : 0.7352
     Batch 225 | Loss : 0.4057 | Acc : 0.8082
     Batch 250 | Loss : 0.3990 | Acc : 0.8092
     Batch 275 | Loss : 0.3864 | Acc : 0.8150
     Batch 300 | Loss : 0.4264 | Acc : 0.7887
Epoch 00298 | Train Loss : 0.3985 | Eval Loss : 0.4034 | Train acc : 0.8100 | Eval Acc : 0.8069
     Batch 000 | Loss : 0.3534 | Acc : 0.8400
     Batch 025 | Loss : 0.3597 | Acc : 0.8330
     Batch 050 | Loss : 0.3738 | Acc : 0.8244
     Batch 075 | Loss : 0.4421 | Acc : 0.7829
     Batch 100 | Loss : 0.3826 | Acc : 0.8268
     Batch 125 | Loss : 0.3864 | Acc : 0.8163
     Batch 150 | Loss : 0.3705 | Acc : 0.8282
     Batch 175 | Loss : 0.4476 | Acc : 0.7744
     Batch 200 | Loss : 0.3222 | Acc : 0.8581
     Batch 225 | Loss : 0.4049 | Acc : 0.8031
     Batch 250 | Loss : 0.4174 | Acc : 0.7994
     Batch 275 | Loss : 0.3824 | Acc : 0.8289
     Batch 300 | Loss : 0.3767 | Acc : 0.8221
Epoch 00299 | Train Loss : 0.3954 | Eval Loss : 0.4115 | Train acc : 0.8113 | Eval Acc : 0.8029
     Batch 000 | Loss : 0.3438 | Acc : 0.8433
     Batch 025 | Loss : 0.3778 | Acc : 0.8229
     Batch 050 | Loss : 0.3654 | Acc : 0.8329
     Batch 075 | Loss : 0.3295 | Acc : 0.8525
     Batch 100 | Loss : 0.3693 | Acc : 0.8305
     Batch 125 | Loss : 0.3738 | Acc : 0.8286
     Batch 150 | Loss : 0.3392 | Acc : 0.8348
     Batch 175 | Loss : 0.3421 | Acc : 0.8409
     Batch 200 | Loss : 0.4819 | Acc : 0.7631
     Batch 225 | Loss : 0.3788 | Acc : 0.8214
     Batch 250 | Loss : 0.4477 | Acc : 0.7784
     Batch 275 | Loss : 0.3714 | Acc : 0.8206
     Batch 300 | Loss : 0.4299 | Acc : 0.7893
Epoch 00300 | Train Loss : 0.3970 | Eval Loss : 0.4034 | Train acc : 0.8105 | Eval Acc : 0.8057
     Batch 000 | Loss : 0.4275 | Acc : 0.7838
     Batch 025 | Loss : 0.3924 | Acc : 0.8211
     Batch 050 | Loss : 0.3734 | Acc : 0.8179
     Batch 075 | Loss : 0.3640 | Acc : 0.8295
     Batch 100 | Loss : 0.4117 | Acc : 0.7989
     Batch 125 | Loss : 0.4508 | Acc : 0.7834
     Batch 150 | Loss : 0.4040 | Acc : 0.8097
     Batch 175 | Loss : 0.3572 | Acc : 0.8296
     Batch 200 | Loss : 0.4185 | Acc : 0.8003
     Batch 225 | Loss : 0.4253 | Acc : 0.7892
     Batch 250 | Loss : 0.3640 | Acc : 0.8292
     Batch 275 | Loss : 0.3475 | Acc : 0.8402
     Batch 300 | Loss : 0.3725 | Acc : 0.8205
Epoch 00301 | Train Loss : 0.3959 | Eval Loss : 0.4145 | Train acc : 0.8113 | Eval Acc : 0.8016
     Batch 000 | Loss : 0.3595 | Acc : 0.8326
     Batch 025 | Loss : 0.3839 | Acc : 0.8213
     Batch 050 | Loss : 0.4105 | Acc : 0.8082
     Batch 075 | Loss : 0.4537 | Acc : 0.7769
     Batch 100 | Loss : 0.3649 | Acc : 0.8227
     Batch 125 | Loss : 0.4035 | Acc : 0.8051
     Batch 150 | Loss : 0.3819 | Acc : 0.8221
     Batch 175 | Loss : 0.3959 | Acc : 0.8087
     Batch 200 | Loss : 0.4665 | Acc : 0.7750
     Batch 225 | Loss : 0.3360 | Acc : 0.8472
     Batch 250 | Loss : 0.3401 | Acc : 0.8438
     Batch 275 | Loss : 0.3636 | Acc : 0.8323
     Batch 300 | Loss : 0.3730 | Acc : 0.8234
Epoch 00302 | Train Loss : 0.3951 | Eval Loss : 0.4339 | Train acc : 0.8114 | Eval Acc : 0.7960
     Batch 000 | Loss : 0.3800 | Acc : 0.8258
     Batch 025 | Loss : 0.3660 | Acc : 0.8296
     Batch 050 | Loss : 0.3903 | Acc : 0.8138
     Batch 075 | Loss : 0.4249 | Acc : 0.7978
     Batch 100 | Loss : 0.4467 | Acc : 0.7843
     Batch 125 | Loss : 0.4310 | Acc : 0.7808
     Batch 150 | Loss : 0.3545 | Acc : 0.8377
     Batch 175 | Loss : 0.3570 | Acc : 0.8292
     Batch 200 | Loss : 0.3481 | Acc : 0.8380
     Batch 225 | Loss : 0.3924 | Acc : 0.8109
     Batch 250 | Loss : 0.3521 | Acc : 0.8428
     Batch 275 | Loss : 0.3291 | Acc : 0.8466
     Batch 300 | Loss : 0.4151 | Acc : 0.7962
Epoch 00303 | Train Loss : 0.3956 | Eval Loss : 0.4038 | Train acc : 0.8119 | Eval Acc : 0.8043
     Batch 000 | Loss : 0.3868 | Acc : 0.8200
     Batch 025 | Loss : 0.4444 | Acc : 0.7826
     Batch 050 | Loss : 0.3440 | Acc : 0.8424
     Batch 075 | Loss : 0.4830 | Acc : 0.7617
     Batch 100 | Loss : 0.3918 | Acc : 0.8095
     Batch 125 | Loss : 0.3429 | Acc : 0.8383
     Batch 150 | Loss : 0.4013 | Acc : 0.8073
     Batch 175 | Loss : 0.4627 | Acc : 0.7723
     Batch 200 | Loss : 0.3980 | Acc : 0.8043
     Batch 225 | Loss : 0.3697 | Acc : 0.8299
     Batch 250 | Loss : 0.3637 | Acc : 0.8241
     Batch 275 | Loss : 0.3677 | Acc : 0.8315
     Batch 300 | Loss : 0.4058 | Acc : 0.8064
Epoch 00304 | Train Loss : 0.3942 | Eval Loss : 0.4152 | Train acc : 0.8121 | Eval Acc : 0.8005
     Batch 000 | Loss : 0.3532 | Acc : 0.8412
     Batch 025 | Loss : 0.4481 | Acc : 0.7860
     Batch 050 | Loss : 0.3501 | Acc : 0.8490
     Batch 075 | Loss : 0.3834 | Acc : 0.8152
     Batch 100 | Loss : 0.3631 | Acc : 0.8200
     Batch 125 | Loss : 0.3557 | Acc : 0.8356
     Batch 150 | Loss : 0.4533 | Acc : 0.7719
     Batch 175 | Loss : 0.3980 | Acc : 0.8038
     Batch 200 | Loss : 0.5138 | Acc : 0.7608
     Batch 225 | Loss : 0.4069 | Acc : 0.7980
     Batch 250 | Loss : 0.4146 | Acc : 0.7978
     Batch 275 | Loss : 0.4391 | Acc : 0.7836
     Batch 300 | Loss : 0.4050 | Acc : 0.8029
Epoch 00305 | Train Loss : 0.3950 | Eval Loss : 0.4115 | Train acc : 0.8119 | Eval Acc : 0.8040
     Batch 000 | Loss : 0.3356 | Acc : 0.8475
     Batch 025 | Loss : 0.5467 | Acc : 0.7406
     Batch 050 | Loss : 0.3841 | Acc : 0.8130
     Batch 075 | Loss : 0.3686 | Acc : 0.8287
     Batch 100 | Loss : 0.4611 | Acc : 0.7728
     Batch 125 | Loss : 0.3549 | Acc : 0.8353
     Batch 150 | Loss : 0.4275 | Acc : 0.7816
     Batch 175 | Loss : 0.3628 | Acc : 0.8261
     Batch 200 | Loss : 0.3605 | Acc : 0.8281
     Batch 225 | Loss : 0.3736 | Acc : 0.8320
     Batch 250 | Loss : 0.3682 | Acc : 0.8296
     Batch 275 | Loss : 0.3430 | Acc : 0.8328
     Batch 300 | Loss : 0.4061 | Acc : 0.8040
Epoch 00306 | Train Loss : 0.3935 | Eval Loss : 0.4026 | Train acc : 0.8123 | Eval Acc : 0.8060
     Batch 000 | Loss : 0.3879 | Acc : 0.8137
     Batch 025 | Loss : 0.3631 | Acc : 0.8336
     Batch 050 | Loss : 0.3713 | Acc : 0.8232
     Batch 075 | Loss : 0.3238 | Acc : 0.8524
     Batch 100 | Loss : 0.3564 | Acc : 0.8372
     Batch 125 | Loss : 0.3739 | Acc : 0.8211
     Batch 150 | Loss : 0.3442 | Acc : 0.8442
     Batch 175 | Loss : 0.3354 | Acc : 0.8580
     Batch 200 | Loss : 0.3688 | Acc : 0.8268
     Batch 225 | Loss : 0.4243 | Acc : 0.7983
     Batch 250 | Loss : 0.3552 | Acc : 0.8322
     Batch 275 | Loss : 0.3524 | Acc : 0.8364
     Batch 300 | Loss : 0.3641 | Acc : 0.8266
Epoch 00307 | Train Loss : 0.3933 | Eval Loss : 0.4042 | Train acc : 0.8126 | Eval Acc : 0.8033
     Batch 000 | Loss : 0.3451 | Acc : 0.8435
     Batch 025 | Loss : 0.4158 | Acc : 0.8099
     Batch 050 | Loss : 0.4926 | Acc : 0.7610
     Batch 075 | Loss : 0.3467 | Acc : 0.8434
     Batch 100 | Loss : 0.3509 | Acc : 0.8360
     Batch 125 | Loss : 0.3664 | Acc : 0.8253
     Batch 150 | Loss : 0.3377 | Acc : 0.8454
     Batch 175 | Loss : 0.4490 | Acc : 0.7769
     Batch 200 | Loss : 0.3660 | Acc : 0.8380
     Batch 225 | Loss : 0.4510 | Acc : 0.7853
     Batch 250 | Loss : 0.4220 | Acc : 0.7886
     Batch 275 | Loss : 0.4088 | Acc : 0.8138
     Batch 300 | Loss : 0.4396 | Acc : 0.7855
Epoch 00308 | Train Loss : 0.3944 | Eval Loss : 0.4023 | Train acc : 0.8123 | Eval Acc : 0.8063
     Batch 000 | Loss : 0.3662 | Acc : 0.8325
     Batch 025 | Loss : 0.4276 | Acc : 0.7870
     Batch 050 | Loss : 0.4939 | Acc : 0.7448
     Batch 075 | Loss : 0.4770 | Acc : 0.7592
     Batch 100 | Loss : 0.5025 | Acc : 0.7433
     Batch 125 | Loss : 0.4157 | Acc : 0.7958
     Batch 150 | Loss : 0.4328 | Acc : 0.7877
     Batch 175 | Loss : 0.3712 | Acc : 0.8283
     Batch 200 | Loss : 0.3875 | Acc : 0.8150
     Batch 225 | Loss : 0.4291 | Acc : 0.7955
     Batch 250 | Loss : 0.3469 | Acc : 0.8400
     Batch 275 | Loss : 0.3562 | Acc : 0.8307
     Batch 300 | Loss : 0.3731 | Acc : 0.8229
Epoch 00309 | Train Loss : 0.3957 | Eval Loss : 0.4079 | Train acc : 0.8109 | Eval Acc : 0.8022
     Batch 000 | Loss : 0.3778 | Acc : 0.8203
     Batch 025 | Loss : 0.3676 | Acc : 0.8328
     Batch 050 | Loss : 0.4844 | Acc : 0.7525
     Batch 075 | Loss : 0.4394 | Acc : 0.7891
     Batch 100 | Loss : 0.3984 | Acc : 0.8107
     Batch 125 | Loss : 0.4665 | Acc : 0.7746
     Batch 150 | Loss : 0.3590 | Acc : 0.8341
     Batch 175 | Loss : 0.4296 | Acc : 0.7902
     Batch 200 | Loss : 0.3633 | Acc : 0.8282
     Batch 225 | Loss : 0.3475 | Acc : 0.8386
     Batch 250 | Loss : 0.3881 | Acc : 0.8134
     Batch 275 | Loss : 0.3630 | Acc : 0.8232
     Batch 300 | Loss : 0.3804 | Acc : 0.8237
Epoch 00310 | Train Loss : 0.3944 | Eval Loss : 0.4135 | Train acc : 0.8123 | Eval Acc : 0.7997
     Batch 000 | Loss : 0.4776 | Acc : 0.7612
     Batch 025 | Loss : 0.4400 | Acc : 0.7866
     Batch 050 | Loss : 0.3326 | Acc : 0.8554
     Batch 075 | Loss : 0.4416 | Acc : 0.7903
     Batch 100 | Loss : 0.3693 | Acc : 0.8263
     Batch 125 | Loss : 0.4287 | Acc : 0.7819
     Batch 150 | Loss : 0.4249 | Acc : 0.7876
     Batch 175 | Loss : 0.4605 | Acc : 0.7708
     Batch 200 | Loss : 0.3641 | Acc : 0.8194
     Batch 225 | Loss : 0.3429 | Acc : 0.8371
     Batch 250 | Loss : 0.3629 | Acc : 0.8311
     Batch 275 | Loss : 0.3880 | Acc : 0.8125
     Batch 300 | Loss : 0.4018 | Acc : 0.8052
Epoch 00311 | Train Loss : 0.3969 | Eval Loss : 0.4283 | Train acc : 0.8107 | Eval Acc : 0.7936
     Batch 000 | Loss : 0.3543 | Acc : 0.8320
     Batch 025 | Loss : 0.3860 | Acc : 0.8189
     Batch 050 | Loss : 0.3947 | Acc : 0.8072
     Batch 075 | Loss : 0.4177 | Acc : 0.8027
     Batch 100 | Loss : 0.4203 | Acc : 0.7964
     Batch 125 | Loss : 0.4475 | Acc : 0.7863
     Batch 150 | Loss : 0.4244 | Acc : 0.7972
     Batch 175 | Loss : 0.3173 | Acc : 0.8559
     Batch 200 | Loss : 0.4550 | Acc : 0.7727
     Batch 225 | Loss : 0.4324 | Acc : 0.7959
     Batch 250 | Loss : 0.3986 | Acc : 0.8059
     Batch 275 | Loss : 0.3950 | Acc : 0.8156
     Batch 300 | Loss : 0.3540 | Acc : 0.8332
Epoch 00312 | Train Loss : 0.4016 | Eval Loss : 0.4371 | Train acc : 0.8090 | Eval Acc : 0.7927
     Batch 000 | Loss : 0.4098 | Acc : 0.8055
     Batch 025 | Loss : 0.4487 | Acc : 0.7765
     Batch 050 | Loss : 0.3681 | Acc : 0.8268
     Batch 075 | Loss : 0.4175 | Acc : 0.7962
     Batch 100 | Loss : 0.3794 | Acc : 0.8189
     Batch 125 | Loss : 0.4136 | Acc : 0.7972
     Batch 150 | Loss : 0.3674 | Acc : 0.8350
     Batch 175 | Loss : 0.4054 | Acc : 0.8180
     Batch 200 | Loss : 0.3922 | Acc : 0.8071
     Batch 225 | Loss : 0.4334 | Acc : 0.7934
     Batch 250 | Loss : 0.3720 | Acc : 0.8270
     Batch 275 | Loss : 0.3870 | Acc : 0.8104
     Batch 300 | Loss : 0.3435 | Acc : 0.8368
Epoch 00313 | Train Loss : 0.3935 | Eval Loss : 0.4044 | Train acc : 0.8126 | Eval Acc : 0.8063
     Batch 000 | Loss : 0.3512 | Acc : 0.8591
     Batch 025 | Loss : 0.3706 | Acc : 0.8339
     Batch 050 | Loss : 0.4287 | Acc : 0.7916
     Batch 075 | Loss : 0.3391 | Acc : 0.8393
     Batch 100 | Loss : 0.4046 | Acc : 0.7980
     Batch 125 | Loss : 0.3527 | Acc : 0.8379
     Batch 150 | Loss : 0.5005 | Acc : 0.7626
     Batch 175 | Loss : 0.3689 | Acc : 0.8304
     Batch 200 | Loss : 0.3773 | Acc : 0.8176
     Batch 225 | Loss : 0.3602 | Acc : 0.8300
     Batch 250 | Loss : 0.4423 | Acc : 0.7753
     Batch 275 | Loss : 0.3792 | Acc : 0.8260
     Batch 300 | Loss : 0.3629 | Acc : 0.8359
Epoch 00314 | Train Loss : 0.3952 | Eval Loss : 0.4004 | Train acc : 0.8118 | Eval Acc : 0.8058
     Batch 000 | Loss : 0.4686 | Acc : 0.7776
     Batch 025 | Loss : 0.3927 | Acc : 0.8175
     Batch 050 | Loss : 0.3529 | Acc : 0.8345
     Batch 075 | Loss : 0.3455 | Acc : 0.8454
     Batch 100 | Loss : 0.3669 | Acc : 0.8339
     Batch 125 | Loss : 0.4181 | Acc : 0.7952
     Batch 150 | Loss : 0.5570 | Acc : 0.7216
     Batch 175 | Loss : 0.3432 | Acc : 0.8365
     Batch 200 | Loss : 0.3256 | Acc : 0.8575
     Batch 225 | Loss : 0.3940 | Acc : 0.8112
     Batch 250 | Loss : 0.4124 | Acc : 0.7974
     Batch 275 | Loss : 0.3342 | Acc : 0.8513
     Batch 300 | Loss : 0.3795 | Acc : 0.8179
Epoch 00315 | Train Loss : 0.3923 | Eval Loss : 0.4059 | Train acc : 0.8129 | Eval Acc : 0.8063
     Batch 000 | Loss : 0.3819 | Acc : 0.8183
     Batch 025 | Loss : 0.4520 | Acc : 0.7749
     Batch 050 | Loss : 0.3588 | Acc : 0.8305
     Batch 075 | Loss : 0.3325 | Acc : 0.8563
     Batch 100 | Loss : 0.4288 | Acc : 0.7886
     Batch 125 | Loss : 0.4932 | Acc : 0.7517
     Batch 150 | Loss : 0.3874 | Acc : 0.8092
     Batch 175 | Loss : 0.4337 | Acc : 0.7868
     Batch 200 | Loss : 0.3648 | Acc : 0.8298
     Batch 225 | Loss : 0.3284 | Acc : 0.8510
     Batch 250 | Loss : 0.3426 | Acc : 0.8390
     Batch 275 | Loss : 0.3377 | Acc : 0.8488
     Batch 300 | Loss : 0.3997 | Acc : 0.8002
Epoch 00316 | Train Loss : 0.3941 | Eval Loss : 0.4195 | Train acc : 0.8127 | Eval Acc : 0.7965
     Batch 000 | Loss : 0.3938 | Acc : 0.8156
     Batch 025 | Loss : 0.4295 | Acc : 0.7884
     Batch 050 | Loss : 0.3587 | Acc : 0.8303
     Batch 075 | Loss : 0.4148 | Acc : 0.8074
     Batch 100 | Loss : 0.3824 | Acc : 0.8193
     Batch 125 | Loss : 0.3654 | Acc : 0.8176
     Batch 150 | Loss : 0.3524 | Acc : 0.8395
     Batch 175 | Loss : 0.4407 | Acc : 0.7821
     Batch 200 | Loss : 0.3603 | Acc : 0.8303
     Batch 225 | Loss : 0.5068 | Acc : 0.7545
     Batch 250 | Loss : 0.5187 | Acc : 0.7532
     Batch 275 | Loss : 0.3625 | Acc : 0.8371
     Batch 300 | Loss : 0.3510 | Acc : 0.8346
Epoch 00317 | Train Loss : 0.3954 | Eval Loss : 0.4120 | Train acc : 0.8118 | Eval Acc : 0.8023
     Batch 000 | Loss : 0.3827 | Acc : 0.8118
     Batch 025 | Loss : 0.3531 | Acc : 0.8397
     Batch 050 | Loss : 0.3893 | Acc : 0.8170
     Batch 075 | Loss : 0.3549 | Acc : 0.8330
     Batch 100 | Loss : 0.4490 | Acc : 0.7774
     Batch 125 | Loss : 0.3707 | Acc : 0.8267
     Batch 150 | Loss : 0.3877 | Acc : 0.8216
     Batch 175 | Loss : 0.3837 | Acc : 0.8231
     Batch 200 | Loss : 0.4843 | Acc : 0.7586
     Batch 225 | Loss : 0.4249 | Acc : 0.7913
     Batch 250 | Loss : 0.3845 | Acc : 0.8182
     Batch 275 | Loss : 0.4387 | Acc : 0.7913
     Batch 300 | Loss : 0.4154 | Acc : 0.7893
Epoch 00318 | Train Loss : 0.3919 | Eval Loss : 0.4070 | Train acc : 0.8135 | Eval Acc : 0.8029
     Batch 000 | Loss : 0.3689 | Acc : 0.8285
     Batch 025 | Loss : 0.3889 | Acc : 0.8152
     Batch 050 | Loss : 0.3807 | Acc : 0.8260
     Batch 075 | Loss : 0.3900 | Acc : 0.8167
     Batch 100 | Loss : 0.4332 | Acc : 0.7897
     Batch 125 | Loss : 0.3281 | Acc : 0.8599
     Batch 150 | Loss : 0.3700 | Acc : 0.8191
     Batch 175 | Loss : 0.3576 | Acc : 0.8346
     Batch 200 | Loss : 0.3559 | Acc : 0.8405
     Batch 225 | Loss : 0.3419 | Acc : 0.8429
     Batch 250 | Loss : 0.3546 | Acc : 0.8448
     Batch 275 | Loss : 0.3526 | Acc : 0.8400
     Batch 300 | Loss : 0.3641 | Acc : 0.8273
Epoch 00319 | Train Loss : 0.3951 | Eval Loss : 0.4048 | Train acc : 0.8117 | Eval Acc : 0.8061
     Batch 000 | Loss : 0.3767 | Acc : 0.8238
     Batch 025 | Loss : 0.4019 | Acc : 0.8130
     Batch 050 | Loss : 0.3518 | Acc : 0.8351
     Batch 075 | Loss : 0.3350 | Acc : 0.8433
     Batch 100 | Loss : 0.3406 | Acc : 0.8449
     Batch 125 | Loss : 0.3507 | Acc : 0.8291
     Batch 150 | Loss : 0.3425 | Acc : 0.8460
     Batch 175 | Loss : 0.3419 | Acc : 0.8422
     Batch 200 | Loss : 0.4166 | Acc : 0.7990
     Batch 225 | Loss : 0.4027 | Acc : 0.8118
     Batch 250 | Loss : 0.4799 | Acc : 0.7612
     Batch 275 | Loss : 0.3613 | Acc : 0.8280
     Batch 300 | Loss : 0.3511 | Acc : 0.8379
Epoch 00320 | Train Loss : 0.3954 | Eval Loss : 0.4082 | Train acc : 0.8116 | Eval Acc : 0.8039
     Batch 000 | Loss : 0.4751 | Acc : 0.7591
     Batch 025 | Loss : 0.4184 | Acc : 0.8004
     Batch 050 | Loss : 0.4035 | Acc : 0.8097
     Batch 075 | Loss : 0.3367 | Acc : 0.8454
     Batch 100 | Loss : 0.3389 | Acc : 0.8483
     Batch 125 | Loss : 0.3516 | Acc : 0.8419
     Batch 150 | Loss : 0.3542 | Acc : 0.8332
     Batch 175 | Loss : 0.3854 | Acc : 0.8167
     Batch 200 | Loss : 0.4176 | Acc : 0.7972
     Batch 225 | Loss : 0.3462 | Acc : 0.8422
     Batch 250 | Loss : 0.3821 | Acc : 0.8109
     Batch 275 | Loss : 0.3250 | Acc : 0.8552
     Batch 300 | Loss : 0.3562 | Acc : 0.8348
Epoch 00321 | Train Loss : 0.3955 | Eval Loss : 0.4032 | Train acc : 0.8116 | Eval Acc : 0.8055
     Batch 000 | Loss : 0.3463 | Acc : 0.8432
     Batch 025 | Loss : 0.4285 | Acc : 0.7846
     Batch 050 | Loss : 0.3559 | Acc : 0.8437
     Batch 075 | Loss : 0.3920 | Acc : 0.8116
     Batch 100 | Loss : 0.4708 | Acc : 0.7689
     Batch 125 | Loss : 0.3532 | Acc : 0.8404
     Batch 150 | Loss : 0.4277 | Acc : 0.7934
     Batch 175 | Loss : 0.3889 | Acc : 0.8160
     Batch 200 | Loss : 0.3157 | Acc : 0.8588
     Batch 225 | Loss : 0.3334 | Acc : 0.8497
     Batch 250 | Loss : 0.3930 | Acc : 0.8090
     Batch 275 | Loss : 0.4474 | Acc : 0.7825
     Batch 300 | Loss : 0.3705 | Acc : 0.8243
Epoch 00322 | Train Loss : 0.3946 | Eval Loss : 0.4065 | Train acc : 0.8122 | Eval Acc : 0.8041
     Batch 000 | Loss : 0.3742 | Acc : 0.8192
     Batch 025 | Loss : 0.3505 | Acc : 0.8425
     Batch 050 | Loss : 0.3635 | Acc : 0.8280
     Batch 075 | Loss : 0.4457 | Acc : 0.7858
     Batch 100 | Loss : 0.3300 | Acc : 0.8547
     Batch 125 | Loss : 0.4312 | Acc : 0.7892
     Batch 150 | Loss : 0.4207 | Acc : 0.7937
     Batch 175 | Loss : 0.3396 | Acc : 0.8492
     Batch 200 | Loss : 0.3567 | Acc : 0.8399
     Batch 225 | Loss : 0.3697 | Acc : 0.8248
     Batch 250 | Loss : 0.3408 | Acc : 0.8478
     Batch 275 | Loss : 0.4258 | Acc : 0.7863
     Batch 300 | Loss : 0.3519 | Acc : 0.8356
Epoch 00323 | Train Loss : 0.3967 | Eval Loss : 0.4126 | Train acc : 0.8114 | Eval Acc : 0.8016
     Batch 000 | Loss : 0.4446 | Acc : 0.7805
     Batch 025 | Loss : 0.3909 | Acc : 0.8194
     Batch 050 | Loss : 0.4326 | Acc : 0.7827
     Batch 075 | Loss : 0.3780 | Acc : 0.8286
     Batch 100 | Loss : 0.3755 | Acc : 0.8250
     Batch 125 | Loss : 0.3691 | Acc : 0.8261
     Batch 150 | Loss : 0.3624 | Acc : 0.8253
     Batch 175 | Loss : 0.4106 | Acc : 0.7996
     Batch 200 | Loss : 0.3829 | Acc : 0.8113
     Batch 225 | Loss : 0.3762 | Acc : 0.8129
     Batch 250 | Loss : 0.3951 | Acc : 0.8116
     Batch 275 | Loss : 0.4216 | Acc : 0.7926
     Batch 300 | Loss : 0.4001 | Acc : 0.8092
Epoch 00324 | Train Loss : 0.3971 | Eval Loss : 0.4042 | Train acc : 0.8111 | Eval Acc : 0.8056
     Batch 000 | Loss : 0.3959 | Acc : 0.8092
     Batch 025 | Loss : 0.3429 | Acc : 0.8395
     Batch 050 | Loss : 0.3610 | Acc : 0.8312
     Batch 075 | Loss : 0.3733 | Acc : 0.8281
     Batch 100 | Loss : 0.3559 | Acc : 0.8394
     Batch 125 | Loss : 0.3930 | Acc : 0.8097
     Batch 150 | Loss : 0.4965 | Acc : 0.7502
     Batch 175 | Loss : 0.3992 | Acc : 0.8062
     Batch 200 | Loss : 0.3520 | Acc : 0.8364
     Batch 225 | Loss : 0.3678 | Acc : 0.8245
     Batch 250 | Loss : 0.3584 | Acc : 0.8331
     Batch 275 | Loss : 0.4485 | Acc : 0.7759
     Batch 300 | Loss : 0.4284 | Acc : 0.7942
Epoch 00325 | Train Loss : 0.3931 | Eval Loss : 0.4068 | Train acc : 0.8133 | Eval Acc : 0.8047
     Batch 000 | Loss : 0.3604 | Acc : 0.8316
     Batch 025 | Loss : 0.4737 | Acc : 0.7779
     Batch 050 | Loss : 0.3774 | Acc : 0.8180
     Batch 075 | Loss : 0.3849 | Acc : 0.8137
     Batch 100 | Loss : 0.4118 | Acc : 0.7963
     Batch 125 | Loss : 0.4299 | Acc : 0.7963
     Batch 150 | Loss : 0.3844 | Acc : 0.8123
     Batch 175 | Loss : 0.3652 | Acc : 0.8277
     Batch 200 | Loss : 0.3960 | Acc : 0.8181
     Batch 225 | Loss : 0.4276 | Acc : 0.7914
     Batch 250 | Loss : 0.3891 | Acc : 0.8053
     Batch 275 | Loss : 0.4497 | Acc : 0.7936
     Batch 300 | Loss : 0.3872 | Acc : 0.8180
Epoch 00326 | Train Loss : 0.3947 | Eval Loss : 0.4003 | Train acc : 0.8129 | Eval Acc : 0.8072
     Batch 000 | Loss : 0.3541 | Acc : 0.8370
     Batch 025 | Loss : 0.4680 | Acc : 0.7660
     Batch 050 | Loss : 0.4125 | Acc : 0.7978
     Batch 075 | Loss : 0.3655 | Acc : 0.8322
     Batch 100 | Loss : 0.3900 | Acc : 0.8197
     Batch 125 | Loss : 0.4306 | Acc : 0.7821
     Batch 150 | Loss : 0.4041 | Acc : 0.8145
     Batch 175 | Loss : 0.3613 | Acc : 0.8315
     Batch 200 | Loss : 0.4009 | Acc : 0.8016
     Batch 225 | Loss : 0.4091 | Acc : 0.8030
     Batch 250 | Loss : 0.3638 | Acc : 0.8250
     Batch 275 | Loss : 0.4192 | Acc : 0.7904
     Batch 300 | Loss : 0.4087 | Acc : 0.8036
Epoch 00327 | Train Loss : 0.3947 | Eval Loss : 0.4053 | Train acc : 0.8122 | Eval Acc : 0.8048
     Batch 000 | Loss : 0.3440 | Acc : 0.8506
     Batch 025 | Loss : 0.3531 | Acc : 0.8310
     Batch 050 | Loss : 0.3913 | Acc : 0.8144
     Batch 075 | Loss : 0.3654 | Acc : 0.8366
     Batch 100 | Loss : 0.3553 | Acc : 0.8335
     Batch 125 | Loss : 0.4257 | Acc : 0.7924
     Batch 150 | Loss : 0.3709 | Acc : 0.8206
     Batch 175 | Loss : 0.3965 | Acc : 0.8126
     Batch 200 | Loss : 0.4264 | Acc : 0.7890
     Batch 225 | Loss : 0.4726 | Acc : 0.7673
     Batch 250 | Loss : 0.4646 | Acc : 0.7737
     Batch 275 | Loss : 0.3480 | Acc : 0.8407
     Batch 300 | Loss : 0.3904 | Acc : 0.8213
Epoch 00328 | Train Loss : 0.3941 | Eval Loss : 0.4137 | Train acc : 0.8126 | Eval Acc : 0.8042
     Batch 000 | Loss : 0.3963 | Acc : 0.8161
     Batch 025 | Loss : 0.4212 | Acc : 0.7960
     Batch 050 | Loss : 0.3551 | Acc : 0.8418
     Batch 075 | Loss : 0.3993 | Acc : 0.8081
     Batch 100 | Loss : 0.4446 | Acc : 0.7751
     Batch 125 | Loss : 0.4229 | Acc : 0.7956
     Batch 150 | Loss : 0.4248 | Acc : 0.7926
     Batch 175 | Loss : 0.3701 | Acc : 0.8261
     Batch 200 | Loss : 0.4784 | Acc : 0.7647
     Batch 225 | Loss : 0.3802 | Acc : 0.8185
     Batch 250 | Loss : 0.3800 | Acc : 0.8112
     Batch 275 | Loss : 0.4648 | Acc : 0.7717
     Batch 300 | Loss : 0.3599 | Acc : 0.8504
Epoch 00329 | Train Loss : 0.3938 | Eval Loss : 0.4014 | Train acc : 0.8125 | Eval Acc : 0.8083
     Batch 000 | Loss : 0.3583 | Acc : 0.8376
     Batch 025 | Loss : 0.3834 | Acc : 0.8226
     Batch 050 | Loss : 0.3411 | Acc : 0.8435
     Batch 075 | Loss : 0.4453 | Acc : 0.7839
     Batch 100 | Loss : 0.3797 | Acc : 0.8204
     Batch 125 | Loss : 0.3541 | Acc : 0.8377
     Batch 150 | Loss : 0.3453 | Acc : 0.8414
     Batch 175 | Loss : 0.4218 | Acc : 0.7939
     Batch 200 | Loss : 0.3663 | Acc : 0.8275
     Batch 225 | Loss : 0.3626 | Acc : 0.8290
     Batch 250 | Loss : 0.3862 | Acc : 0.8180
     Batch 275 | Loss : 0.4214 | Acc : 0.7983
     Batch 300 | Loss : 0.3598 | Acc : 0.8292
Epoch 00330 | Train Loss : 0.3921 | Eval Loss : 0.4259 | Train acc : 0.8137 | Eval Acc : 0.7954
     Batch 000 | Loss : 0.4372 | Acc : 0.7901
     Batch 025 | Loss : 0.5833 | Acc : 0.7211
     Batch 050 | Loss : 0.4443 | Acc : 0.7826
     Batch 075 | Loss : 0.3461 | Acc : 0.8315
     Batch 100 | Loss : 0.4295 | Acc : 0.7886
     Batch 125 | Loss : 0.4599 | Acc : 0.7664
     Batch 150 | Loss : 0.3775 | Acc : 0.8204
     Batch 175 | Loss : 0.3597 | Acc : 0.8300
     Batch 200 | Loss : 0.3174 | Acc : 0.8595
     Batch 225 | Loss : 0.3319 | Acc : 0.8500
     Batch 250 | Loss : 0.4206 | Acc : 0.7960
     Batch 275 | Loss : 0.3621 | Acc : 0.8398
     Batch 300 | Loss : 0.3357 | Acc : 0.8419
Epoch 00331 | Train Loss : 0.3917 | Eval Loss : 0.4089 | Train acc : 0.8140 | Eval Acc : 0.8045
     Batch 000 | Loss : 0.3978 | Acc : 0.8099
     Batch 025 | Loss : 0.3737 | Acc : 0.8274
     Batch 050 | Loss : 0.4771 | Acc : 0.7690
     Batch 075 | Loss : 0.3487 | Acc : 0.8409
     Batch 100 | Loss : 0.4973 | Acc : 0.7478
     Batch 125 | Loss : 0.3836 | Acc : 0.8136
     Batch 150 | Loss : 0.3685 | Acc : 0.8276
     Batch 175 | Loss : 0.5002 | Acc : 0.7604
     Batch 200 | Loss : 0.4135 | Acc : 0.7967
     Batch 225 | Loss : 0.4686 | Acc : 0.7752
     Batch 250 | Loss : 0.3557 | Acc : 0.8379
     Batch 275 | Loss : 0.4129 | Acc : 0.7912
     Batch 300 | Loss : 0.3874 | Acc : 0.8161
Epoch 00332 | Train Loss : 0.3923 | Eval Loss : 0.4069 | Train acc : 0.8133 | Eval Acc : 0.8039
     Batch 000 | Loss : 0.5000 | Acc : 0.7416
     Batch 025 | Loss : 0.3735 | Acc : 0.8290
     Batch 050 | Loss : 0.4238 | Acc : 0.7922
     Batch 075 | Loss : 0.3580 | Acc : 0.8328
     Batch 100 | Loss : 0.3794 | Acc : 0.8221
     Batch 125 | Loss : 0.3696 | Acc : 0.8250
     Batch 150 | Loss : 0.4148 | Acc : 0.7929
     Batch 175 | Loss : 0.3444 | Acc : 0.8418
     Batch 200 | Loss : 0.4029 | Acc : 0.8102
     Batch 225 | Loss : 0.3400 | Acc : 0.8472
     Batch 250 | Loss : 0.4361 | Acc : 0.7919
     Batch 275 | Loss : 0.3718 | Acc : 0.8220
     Batch 300 | Loss : 0.3724 | Acc : 0.8312
Epoch 00333 | Train Loss : 0.3932 | Eval Loss : 0.4079 | Train acc : 0.8131 | Eval Acc : 0.8045
     Batch 000 | Loss : 0.4409 | Acc : 0.7888
     Batch 025 | Loss : 0.4178 | Acc : 0.7899
     Batch 050 | Loss : 0.4310 | Acc : 0.7898
     Batch 075 | Loss : 0.3914 | Acc : 0.8121
     Batch 100 | Loss : 0.3410 | Acc : 0.8570
     Batch 125 | Loss : 0.3412 | Acc : 0.8424
     Batch 150 | Loss : 0.3933 | Acc : 0.8161
     Batch 175 | Loss : 0.3266 | Acc : 0.8510
     Batch 200 | Loss : 0.4204 | Acc : 0.7978
     Batch 225 | Loss : 0.3774 | Acc : 0.8284
     Batch 250 | Loss : 0.3889 | Acc : 0.8213
     Batch 275 | Loss : 0.4291 | Acc : 0.7938
     Batch 300 | Loss : 0.3889 | Acc : 0.8177
Epoch 00334 | Train Loss : 0.3932 | Eval Loss : 0.4045 | Train acc : 0.8127 | Eval Acc : 0.8043
     Batch 000 | Loss : 0.4315 | Acc : 0.7841
     Batch 025 | Loss : 0.4213 | Acc : 0.7952
     Batch 050 | Loss : 0.4388 | Acc : 0.7829
     Batch 075 | Loss : 0.4205 | Acc : 0.7950
     Batch 100 | Loss : 0.3861 | Acc : 0.8115
     Batch 125 | Loss : 0.4354 | Acc : 0.7838
     Batch 150 | Loss : 0.4153 | Acc : 0.7986
     Batch 175 | Loss : 0.3723 | Acc : 0.8298
     Batch 200 | Loss : 0.4380 | Acc : 0.7876
     Batch 225 | Loss : 0.3527 | Acc : 0.8304
     Batch 250 | Loss : 0.4539 | Acc : 0.7737
     Batch 275 | Loss : 0.3604 | Acc : 0.8294
     Batch 300 | Loss : 0.3552 | Acc : 0.8360
Epoch 00335 | Train Loss : 0.3919 | Eval Loss : 0.4042 | Train acc : 0.8135 | Eval Acc : 0.8057
     Batch 000 | Loss : 0.3857 | Acc : 0.8281
     Batch 025 | Loss : 0.4215 | Acc : 0.7949
     Batch 050 | Loss : 0.4250 | Acc : 0.7998
     Batch 075 | Loss : 0.3816 | Acc : 0.8161
     Batch 100 | Loss : 0.4366 | Acc : 0.7905
     Batch 125 | Loss : 0.4104 | Acc : 0.7975
     Batch 150 | Loss : 0.3625 | Acc : 0.8330
     Batch 175 | Loss : 0.3888 | Acc : 0.8149
     Batch 200 | Loss : 0.3937 | Acc : 0.8063
     Batch 225 | Loss : 0.4160 | Acc : 0.7999
     Batch 250 | Loss : 0.4014 | Acc : 0.8066
     Batch 275 | Loss : 0.4313 | Acc : 0.7897
     Batch 300 | Loss : 0.3765 | Acc : 0.8220
Epoch 00336 | Train Loss : 0.3949 | Eval Loss : 0.4139 | Train acc : 0.8120 | Eval Acc : 0.8014
     Batch 000 | Loss : 0.3464 | Acc : 0.8476
     Batch 025 | Loss : 0.4057 | Acc : 0.8017
     Batch 050 | Loss : 0.3848 | Acc : 0.8175
     Batch 075 | Loss : 0.3493 | Acc : 0.8397
     Batch 100 | Loss : 0.3365 | Acc : 0.8446
     Batch 125 | Loss : 0.4290 | Acc : 0.7932
     Batch 150 | Loss : 0.3430 | Acc : 0.8438
     Batch 175 | Loss : 0.4092 | Acc : 0.8009
     Batch 200 | Loss : 0.3375 | Acc : 0.8416
     Batch 225 | Loss : 0.4416 | Acc : 0.7840
     Batch 250 | Loss : 0.4061 | Acc : 0.8060
     Batch 275 | Loss : 0.3556 | Acc : 0.8349
     Batch 300 | Loss : 0.3629 | Acc : 0.8389
Epoch 00337 | Train Loss : 0.3933 | Eval Loss : 0.4043 | Train acc : 0.8130 | Eval Acc : 0.8050
     Batch 000 | Loss : 0.3390 | Acc : 0.8424
     Batch 025 | Loss : 0.3963 | Acc : 0.8160
     Batch 050 | Loss : 0.4228 | Acc : 0.7881
     Batch 075 | Loss : 0.3571 | Acc : 0.8303
     Batch 100 | Loss : 0.4476 | Acc : 0.7774
     Batch 125 | Loss : 0.4084 | Acc : 0.8002
     Batch 150 | Loss : 0.3913 | Acc : 0.8133
     Batch 175 | Loss : 0.3526 | Acc : 0.8358
     Batch 200 | Loss : 0.3781 | Acc : 0.8217
     Batch 225 | Loss : 0.3819 | Acc : 0.8171
     Batch 250 | Loss : 0.3683 | Acc : 0.8245
     Batch 275 | Loss : 0.4312 | Acc : 0.7898
     Batch 300 | Loss : 0.3752 | Acc : 0.8235
Epoch 00338 | Train Loss : 0.3940 | Eval Loss : 0.4084 | Train acc : 0.8126 | Eval Acc : 0.8027
     Batch 000 | Loss : 0.3806 | Acc : 0.8151
     Batch 025 | Loss : 0.3783 | Acc : 0.8255
     Batch 050 | Loss : 0.4293 | Acc : 0.7804
     Batch 075 | Loss : 0.3835 | Acc : 0.8270
     Batch 100 | Loss : 0.3693 | Acc : 0.8257
     Batch 125 | Loss : 0.4386 | Acc : 0.7872
     Batch 150 | Loss : 0.4867 | Acc : 0.7645
     Batch 175 | Loss : 0.3357 | Acc : 0.8470
     Batch 200 | Loss : 0.4401 | Acc : 0.7896
     Batch 225 | Loss : 0.4243 | Acc : 0.7962
     Batch 250 | Loss : 0.3879 | Acc : 0.8097
     Batch 275 | Loss : 0.3739 | Acc : 0.8322
     Batch 300 | Loss : 0.3968 | Acc : 0.8092
Epoch 00339 | Train Loss : 0.3932 | Eval Loss : 0.4062 | Train acc : 0.8130 | Eval Acc : 0.8042
     Batch 000 | Loss : 0.3690 | Acc : 0.8312
     Batch 025 | Loss : 0.3608 | Acc : 0.8336
     Batch 050 | Loss : 0.3821 | Acc : 0.8147
     Batch 075 | Loss : 0.3864 | Acc : 0.8235
     Batch 100 | Loss : 0.3487 | Acc : 0.8357
     Batch 125 | Loss : 0.3950 | Acc : 0.8101
     Batch 150 | Loss : 0.4848 | Acc : 0.7768
     Batch 175 | Loss : 0.3582 | Acc : 0.8292
     Batch 200 | Loss : 0.3932 | Acc : 0.8168
     Batch 225 | Loss : 0.3849 | Acc : 0.8137
     Batch 250 | Loss : 0.3474 | Acc : 0.8354
     Batch 275 | Loss : 0.3919 | Acc : 0.8039
     Batch 300 | Loss : 0.4295 | Acc : 0.7832
Epoch 00340 | Train Loss : 0.3932 | Eval Loss : 0.3991 | Train acc : 0.8128 | Eval Acc : 0.8079
     Batch 000 | Loss : 0.4647 | Acc : 0.7775
     Batch 025 | Loss : 0.3495 | Acc : 0.8477
     Batch 050 | Loss : 0.3950 | Acc : 0.8077
     Batch 075 | Loss : 0.3802 | Acc : 0.8236
     Batch 100 | Loss : 0.3358 | Acc : 0.8503
     Batch 125 | Loss : 0.4032 | Acc : 0.8061
     Batch 150 | Loss : 0.3402 | Acc : 0.8457
     Batch 175 | Loss : 0.4811 | Acc : 0.7647
     Batch 200 | Loss : 0.3682 | Acc : 0.8240
     Batch 225 | Loss : 0.4246 | Acc : 0.7880
     Batch 250 | Loss : 0.4237 | Acc : 0.7918
     Batch 275 | Loss : 0.4624 | Acc : 0.7772
     Batch 300 | Loss : 0.4182 | Acc : 0.7975
Epoch 00341 | Train Loss : 0.3943 | Eval Loss : 0.4024 | Train acc : 0.8121 | Eval Acc : 0.8071
     Batch 000 | Loss : 0.3711 | Acc : 0.8230
     Batch 025 | Loss : 0.3466 | Acc : 0.8431
     Batch 050 | Loss : 0.4106 | Acc : 0.8055
     Batch 075 | Loss : 0.4436 | Acc : 0.7852
     Batch 100 | Loss : 0.3706 | Acc : 0.8253
     Batch 125 | Loss : 0.4253 | Acc : 0.7991
     Batch 150 | Loss : 0.3477 | Acc : 0.8481
     Batch 175 | Loss : 0.3615 | Acc : 0.8334
     Batch 200 | Loss : 0.4695 | Acc : 0.7652
     Batch 225 | Loss : 0.4213 | Acc : 0.7945
     Batch 250 | Loss : 0.3588 | Acc : 0.8408
     Batch 275 | Loss : 0.3440 | Acc : 0.8435
     Batch 300 | Loss : 0.3680 | Acc : 0.8299
Epoch 00342 | Train Loss : 0.3911 | Eval Loss : 0.4054 | Train acc : 0.8140 | Eval Acc : 0.8067
     Batch 000 | Loss : 0.3683 | Acc : 0.8292
     Batch 025 | Loss : 0.3655 | Acc : 0.8235
     Batch 050 | Loss : 0.3607 | Acc : 0.8303
     Batch 075 | Loss : 0.4212 | Acc : 0.7987
     Batch 100 | Loss : 0.4241 | Acc : 0.7990
     Batch 125 | Loss : 0.3947 | Acc : 0.8027
     Batch 150 | Loss : 0.4164 | Acc : 0.7948
     Batch 175 | Loss : 0.4381 | Acc : 0.7826
     Batch 200 | Loss : 0.4060 | Acc : 0.8031
     Batch 225 | Loss : 0.4574 | Acc : 0.7819
     Batch 250 | Loss : 0.3814 | Acc : 0.8221
     Batch 275 | Loss : 0.4126 | Acc : 0.7986
     Batch 300 | Loss : 0.3669 | Acc : 0.8260
Epoch 00343 | Train Loss : 0.3944 | Eval Loss : 0.4026 | Train acc : 0.8123 | Eval Acc : 0.8062
     Batch 000 | Loss : 0.3458 | Acc : 0.8418
     Batch 025 | Loss : 0.4389 | Acc : 0.7909
     Batch 050 | Loss : 0.3729 | Acc : 0.8269
     Batch 075 | Loss : 0.5824 | Acc : 0.7057
     Batch 100 | Loss : 0.3211 | Acc : 0.8535
     Batch 125 | Loss : 0.3724 | Acc : 0.8283
     Batch 150 | Loss : 0.3481 | Acc : 0.8538
     Batch 175 | Loss : 0.5068 | Acc : 0.7542
     Batch 200 | Loss : 0.3730 | Acc : 0.8200
     Batch 225 | Loss : 0.4005 | Acc : 0.8085
     Batch 250 | Loss : 0.3524 | Acc : 0.8336
     Batch 275 | Loss : 0.4088 | Acc : 0.8003
     Batch 300 | Loss : 0.3905 | Acc : 0.8247
Epoch 00344 | Train Loss : 0.3945 | Eval Loss : 0.4033 | Train acc : 0.8125 | Eval Acc : 0.8077
     Batch 000 | Loss : 0.3844 | Acc : 0.8211
     Batch 025 | Loss : 0.3556 | Acc : 0.8377
     Batch 050 | Loss : 0.5380 | Acc : 0.7390
     Batch 075 | Loss : 0.3773 | Acc : 0.8271
     Batch 100 | Loss : 0.3923 | Acc : 0.8083
     Batch 125 | Loss : 0.4277 | Acc : 0.7843
     Batch 150 | Loss : 0.3404 | Acc : 0.8468
     Batch 175 | Loss : 0.3705 | Acc : 0.8340
     Batch 200 | Loss : 0.3607 | Acc : 0.8320
     Batch 225 | Loss : 0.3442 | Acc : 0.8424
     Batch 250 | Loss : 0.4201 | Acc : 0.7994
     Batch 275 | Loss : 0.4408 | Acc : 0.7815
     Batch 300 | Loss : 0.3596 | Acc : 0.8279
Epoch 00345 | Train Loss : 0.3905 | Eval Loss : 0.3981 | Train acc : 0.8142 | Eval Acc : 0.8085
     Batch 000 | Loss : 0.3705 | Acc : 0.8233
     Batch 025 | Loss : 0.4264 | Acc : 0.7960
     Batch 050 | Loss : 0.4418 | Acc : 0.7820
     Batch 075 | Loss : 0.3602 | Acc : 0.8347
     Batch 100 | Loss : 0.3463 | Acc : 0.8448
     Batch 125 | Loss : 0.4292 | Acc : 0.7997
     Batch 150 | Loss : 0.4924 | Acc : 0.7771
     Batch 175 | Loss : 0.3580 | Acc : 0.8275
     Batch 200 | Loss : 0.4058 | Acc : 0.8077
     Batch 225 | Loss : 0.4832 | Acc : 0.7603
     Batch 250 | Loss : 0.3682 | Acc : 0.8268
     Batch 275 | Loss : 0.4344 | Acc : 0.7938
     Batch 300 | Loss : 0.3956 | Acc : 0.8058
Epoch 00346 | Train Loss : 0.3913 | Eval Loss : 0.4131 | Train acc : 0.8138 | Eval Acc : 0.8022
     Batch 000 | Loss : 0.3650 | Acc : 0.8322
     Batch 025 | Loss : 0.3692 | Acc : 0.8350
     Batch 050 | Loss : 0.3402 | Acc : 0.8435
     Batch 075 | Loss : 0.3395 | Acc : 0.8410
     Batch 100 | Loss : 0.4199 | Acc : 0.7996
     Batch 125 | Loss : 0.3604 | Acc : 0.8258
     Batch 150 | Loss : 0.4431 | Acc : 0.7763
     Batch 175 | Loss : 0.4567 | Acc : 0.7748
     Batch 200 | Loss : 0.3412 | Acc : 0.8495
     Batch 225 | Loss : 0.4620 | Acc : 0.7713
     Batch 250 | Loss : 0.3316 | Acc : 0.8472
     Batch 275 | Loss : 0.4435 | Acc : 0.8016
     Batch 300 | Loss : 0.3700 | Acc : 0.8311
Epoch 00347 | Train Loss : 0.3932 | Eval Loss : 0.4030 | Train acc : 0.8127 | Eval Acc : 0.8059
     Batch 000 | Loss : 0.4251 | Acc : 0.7999
     Batch 025 | Loss : 0.3497 | Acc : 0.8356
     Batch 050 | Loss : 0.3693 | Acc : 0.8227
     Batch 075 | Loss : 0.3544 | Acc : 0.8348
     Batch 100 | Loss : 0.4206 | Acc : 0.7953
     Batch 125 | Loss : 0.3729 | Acc : 0.8168
     Batch 150 | Loss : 0.4095 | Acc : 0.7992
     Batch 175 | Loss : 0.3450 | Acc : 0.8454
     Batch 200 | Loss : 0.3727 | Acc : 0.8276
     Batch 225 | Loss : 0.4312 | Acc : 0.7840
     Batch 250 | Loss : 0.3740 | Acc : 0.8235
     Batch 275 | Loss : 0.3935 | Acc : 0.7978
     Batch 300 | Loss : 0.3769 | Acc : 0.8276
Epoch 00348 | Train Loss : 0.3927 | Eval Loss : 0.4077 | Train acc : 0.8130 | Eval Acc : 0.8045
     Batch 000 | Loss : 0.4173 | Acc : 0.7955
     Batch 025 | Loss : 0.4017 | Acc : 0.8080
     Batch 050 | Loss : 0.3774 | Acc : 0.8195
     Batch 075 | Loss : 0.3979 | Acc : 0.8080
     Batch 100 | Loss : 0.4403 | Acc : 0.7818
     Batch 125 | Loss : 0.4669 | Acc : 0.7711
     Batch 150 | Loss : 0.3766 | Acc : 0.8223
     Batch 175 | Loss : 0.3446 | Acc : 0.8456
     Batch 200 | Loss : 0.3846 | Acc : 0.8136
     Batch 225 | Loss : 0.3400 | Acc : 0.8442
     Batch 250 | Loss : 0.4627 | Acc : 0.7650
     Batch 275 | Loss : 0.4415 | Acc : 0.7742
     Batch 300 | Loss : 0.4339 | Acc : 0.7849
Epoch 00349 | Train Loss : 0.3926 | Eval Loss : 0.4031 | Train acc : 0.8134 | Eval Acc : 0.8047
     Batch 000 | Loss : 0.3503 | Acc : 0.8409
     Batch 025 | Loss : 0.3987 | Acc : 0.8057
     Batch 050 | Loss : 0.3785 | Acc : 0.8129
     Batch 075 | Loss : 0.4199 | Acc : 0.7902
     Batch 100 | Loss : 0.3187 | Acc : 0.8512
     Batch 125 | Loss : 0.4055 | Acc : 0.8020
     Batch 150 | Loss : 0.3767 | Acc : 0.8123
     Batch 175 | Loss : 0.4477 | Acc : 0.7711
     Batch 200 | Loss : 0.3551 | Acc : 0.8373
     Batch 225 | Loss : 0.3881 | Acc : 0.8151
     Batch 250 | Loss : 0.4679 | Acc : 0.7671
     Batch 275 | Loss : 0.4057 | Acc : 0.8000
     Batch 300 | Loss : 0.3525 | Acc : 0.8310
Epoch 00350 | Train Loss : 0.3927 | Eval Loss : 0.4066 | Train acc : 0.8126 | Eval Acc : 0.8059
     Batch 000 | Loss : 0.3748 | Acc : 0.8186
     Batch 025 | Loss : 0.4577 | Acc : 0.7802
     Batch 050 | Loss : 0.4649 | Acc : 0.7759
     Batch 075 | Loss : 0.4551 | Acc : 0.7828
     Batch 100 | Loss : 0.3740 | Acc : 0.8265
     Batch 125 | Loss : 0.3633 | Acc : 0.8285
     Batch 150 | Loss : 0.4439 | Acc : 0.7774
     Batch 175 | Loss : 0.3449 | Acc : 0.8418
     Batch 200 | Loss : 0.3211 | Acc : 0.8560
     Batch 225 | Loss : 0.3284 | Acc : 0.8529
     Batch 250 | Loss : 0.3150 | Acc : 0.8609
     Batch 275 | Loss : 0.3953 | Acc : 0.8029
     Batch 300 | Loss : 0.3713 | Acc : 0.8266
Epoch 00351 | Train Loss : 0.3919 | Eval Loss : 0.4031 | Train acc : 0.8136 | Eval Acc : 0.8064
     Batch 000 | Loss : 0.3827 | Acc : 0.8152
     Batch 025 | Loss : 0.4167 | Acc : 0.8003
     Batch 050 | Loss : 0.3576 | Acc : 0.8390
     Batch 075 | Loss : 0.5268 | Acc : 0.7584
     Batch 100 | Loss : 0.3959 | Acc : 0.8076
     Batch 125 | Loss : 0.4085 | Acc : 0.8000
     Batch 150 | Loss : 0.4385 | Acc : 0.7829
     Batch 175 | Loss : 0.3990 | Acc : 0.8083
     Batch 200 | Loss : 0.3527 | Acc : 0.8354
     Batch 225 | Loss : 0.4104 | Acc : 0.8072
     Batch 250 | Loss : 0.5338 | Acc : 0.7498
     Batch 275 | Loss : 0.3598 | Acc : 0.8332
     Batch 300 | Loss : 0.3374 | Acc : 0.8420
Epoch 00352 | Train Loss : 0.3919 | Eval Loss : 0.4009 | Train acc : 0.8134 | Eval Acc : 0.8081
     Batch 000 | Loss : 0.3421 | Acc : 0.8462
     Batch 025 | Loss : 0.4552 | Acc : 0.7815
     Batch 050 | Loss : 0.3295 | Acc : 0.8530
     Batch 075 | Loss : 0.3638 | Acc : 0.8398
     Batch 100 | Loss : 0.4151 | Acc : 0.8043
     Batch 125 | Loss : 0.3963 | Acc : 0.8140
     Batch 150 | Loss : 0.4136 | Acc : 0.7986
     Batch 175 | Loss : 0.3793 | Acc : 0.8207
     Batch 200 | Loss : 0.3900 | Acc : 0.8177
     Batch 225 | Loss : 0.4651 | Acc : 0.7675
     Batch 250 | Loss : 0.4617 | Acc : 0.7590
     Batch 275 | Loss : 0.3350 | Acc : 0.8466
     Batch 300 | Loss : 0.3348 | Acc : 0.8455
Epoch 00353 | Train Loss : 0.3914 | Eval Loss : 0.4005 | Train acc : 0.8137 | Eval Acc : 0.8068
     Batch 000 | Loss : 0.3616 | Acc : 0.8304
     Batch 025 | Loss : 0.4305 | Acc : 0.7880
     Batch 050 | Loss : 0.4750 | Acc : 0.7744
     Batch 075 | Loss : 0.3976 | Acc : 0.8035
     Batch 100 | Loss : 0.3714 | Acc : 0.8269
     Batch 125 | Loss : 0.4931 | Acc : 0.7649
     Batch 150 | Loss : 0.4352 | Acc : 0.7888
     Batch 175 | Loss : 0.3655 | Acc : 0.8312
     Batch 200 | Loss : 0.4537 | Acc : 0.7889
     Batch 225 | Loss : 0.3955 | Acc : 0.8073
     Batch 250 | Loss : 0.4040 | Acc : 0.7947
     Batch 275 | Loss : 0.4128 | Acc : 0.7986
     Batch 300 | Loss : 0.3714 | Acc : 0.8223
Epoch 00354 | Train Loss : 0.3997 | Eval Loss : 0.4182 | Train acc : 0.8092 | Eval Acc : 0.8013
     Batch 000 | Loss : 0.3322 | Acc : 0.8462
     Batch 025 | Loss : 0.3561 | Acc : 0.8301
     Batch 050 | Loss : 0.3504 | Acc : 0.8349
     Batch 075 | Loss : 0.3297 | Acc : 0.8506
     Batch 100 | Loss : 0.3451 | Acc : 0.8362
     Batch 125 | Loss : 0.4219 | Acc : 0.7968
     Batch 150 | Loss : 0.4011 | Acc : 0.8021
     Batch 175 | Loss : 0.3741 | Acc : 0.8249
     Batch 200 | Loss : 0.5127 | Acc : 0.7577
     Batch 225 | Loss : 0.3918 | Acc : 0.8083
     Batch 250 | Loss : 0.3528 | Acc : 0.8419
     Batch 275 | Loss : 0.3433 | Acc : 0.8412
     Batch 300 | Loss : 0.3490 | Acc : 0.8317
Epoch 00355 | Train Loss : 0.3941 | Eval Loss : 0.4050 | Train acc : 0.8124 | Eval Acc : 0.8044
     Batch 000 | Loss : 0.3897 | Acc : 0.8088
     Batch 025 | Loss : 0.3712 | Acc : 0.8303
     Batch 050 | Loss : 0.3540 | Acc : 0.8352
     Batch 075 | Loss : 0.4272 | Acc : 0.7856
     Batch 100 | Loss : 0.3698 | Acc : 0.8331
     Batch 125 | Loss : 0.4854 | Acc : 0.7574
     Batch 150 | Loss : 0.3617 | Acc : 0.8348
     Batch 175 | Loss : 0.4141 | Acc : 0.8023
     Batch 200 | Loss : 0.3882 | Acc : 0.8208
     Batch 225 | Loss : 0.3669 | Acc : 0.8289
     Batch 250 | Loss : 0.3543 | Acc : 0.8305
     Batch 275 | Loss : 0.3711 | Acc : 0.8244
     Batch 300 | Loss : 0.4455 | Acc : 0.7820
Epoch 00356 | Train Loss : 0.3935 | Eval Loss : 0.4028 | Train acc : 0.8127 | Eval Acc : 0.8064
     Batch 000 | Loss : 0.3593 | Acc : 0.8286
     Batch 025 | Loss : 0.4208 | Acc : 0.7960
     Batch 050 | Loss : 0.3737 | Acc : 0.8284
     Batch 075 | Loss : 0.4168 | Acc : 0.7936
     Batch 100 | Loss : 0.4200 | Acc : 0.7983
     Batch 125 | Loss : 0.5139 | Acc : 0.7588
     Batch 150 | Loss : 0.4062 | Acc : 0.8018
     Batch 175 | Loss : 0.3919 | Acc : 0.8160
     Batch 200 | Loss : 0.3507 | Acc : 0.8378
     Batch 225 | Loss : 0.3511 | Acc : 0.8436
     Batch 250 | Loss : 0.3532 | Acc : 0.8435
     Batch 275 | Loss : 0.3328 | Acc : 0.8486
     Batch 300 | Loss : 0.4091 | Acc : 0.8057
Epoch 00357 | Train Loss : 0.3932 | Eval Loss : 0.4045 | Train acc : 0.8127 | Eval Acc : 0.8059
     Batch 000 | Loss : 0.5012 | Acc : 0.7548
     Batch 025 | Loss : 0.4129 | Acc : 0.7993
     Batch 050 | Loss : 0.4420 | Acc : 0.7799
     Batch 075 | Loss : 0.3125 | Acc : 0.8616
     Batch 100 | Loss : 0.3767 | Acc : 0.8216
     Batch 125 | Loss : 0.4061 | Acc : 0.8036
     Batch 150 | Loss : 0.4263 | Acc : 0.7855
     Batch 175 | Loss : 0.4307 | Acc : 0.7895
     Batch 200 | Loss : 0.3915 | Acc : 0.8159
     Batch 225 | Loss : 0.3400 | Acc : 0.8420
     Batch 250 | Loss : 0.5015 | Acc : 0.7643
     Batch 275 | Loss : 0.3536 | Acc : 0.8428
     Batch 300 | Loss : 0.3421 | Acc : 0.8414
Epoch 00358 | Train Loss : 0.3918 | Eval Loss : 0.4107 | Train acc : 0.8137 | Eval Acc : 0.8016
     Batch 000 | Loss : 0.4039 | Acc : 0.8094
     Batch 025 | Loss : 0.3430 | Acc : 0.8474
     Batch 050 | Loss : 0.3543 | Acc : 0.8356
     Batch 075 | Loss : 0.3912 | Acc : 0.8114
     Batch 100 | Loss : 0.3701 | Acc : 0.8299
     Batch 125 | Loss : 0.4571 | Acc : 0.7830
     Batch 150 | Loss : 0.4065 | Acc : 0.7996
     Batch 175 | Loss : 0.4923 | Acc : 0.7685
     Batch 200 | Loss : 0.3296 | Acc : 0.8561
     Batch 225 | Loss : 0.4300 | Acc : 0.7935
     Batch 250 | Loss : 0.4595 | Acc : 0.7668
     Batch 275 | Loss : 0.3895 | Acc : 0.8121
     Batch 300 | Loss : 0.3467 | Acc : 0.8488
Epoch 00359 | Train Loss : 0.3942 | Eval Loss : 0.4001 | Train acc : 0.8126 | Eval Acc : 0.8080
     Batch 000 | Loss : 0.4260 | Acc : 0.7941
     Batch 025 | Loss : 0.4085 | Acc : 0.8030
     Batch 050 | Loss : 0.5907 | Acc : 0.7191
     Batch 075 | Loss : 0.3663 | Acc : 0.8336
     Batch 100 | Loss : 0.4238 | Acc : 0.7924
     Batch 125 | Loss : 0.4179 | Acc : 0.7902
     Batch 150 | Loss : 0.4795 | Acc : 0.7601
     Batch 175 | Loss : 0.4356 | Acc : 0.7863
     Batch 200 | Loss : 0.3345 | Acc : 0.8553
     Batch 225 | Loss : 0.3572 | Acc : 0.8327
     Batch 250 | Loss : 0.4809 | Acc : 0.7611
     Batch 275 | Loss : 0.3278 | Acc : 0.8565
     Batch 300 | Loss : 0.3512 | Acc : 0.8335
Epoch 00360 | Train Loss : 0.3935 | Eval Loss : 0.4048 | Train acc : 0.8126 | Eval Acc : 0.8064
     Batch 000 | Loss : 0.4145 | Acc : 0.8028
     Batch 025 | Loss : 0.3877 | Acc : 0.8067
     Batch 050 | Loss : 0.3283 | Acc : 0.8548
     Batch 075 | Loss : 0.4106 | Acc : 0.7955
     Batch 100 | Loss : 0.3576 | Acc : 0.8367
     Batch 125 | Loss : 0.3761 | Acc : 0.8237
     Batch 150 | Loss : 0.3812 | Acc : 0.8269
     Batch 175 | Loss : 0.3813 | Acc : 0.8275
     Batch 200 | Loss : 0.4711 | Acc : 0.7566
     Batch 225 | Loss : 0.3890 | Acc : 0.8106
     Batch 250 | Loss : 0.3669 | Acc : 0.8273
     Batch 275 | Loss : 0.3544 | Acc : 0.8392
     Batch 300 | Loss : 0.3608 | Acc : 0.8308
Epoch 00361 | Train Loss : 0.3932 | Eval Loss : 0.4038 | Train acc : 0.8131 | Eval Acc : 0.8074
     Batch 000 | Loss : 0.4308 | Acc : 0.7999
     Batch 025 | Loss : 0.3332 | Acc : 0.8571
     Batch 050 | Loss : 0.3628 | Acc : 0.8253
     Batch 075 | Loss : 0.4849 | Acc : 0.7474
     Batch 100 | Loss : 0.4065 | Acc : 0.8026
     Batch 125 | Loss : 0.4618 | Acc : 0.7733
     Batch 150 | Loss : 0.3295 | Acc : 0.8527
     Batch 175 | Loss : 0.4460 | Acc : 0.7780
     Batch 200 | Loss : 0.3445 | Acc : 0.8375
     Batch 225 | Loss : 0.3625 | Acc : 0.8350
     Batch 250 | Loss : 0.4893 | Acc : 0.7559
     Batch 275 | Loss : 0.3653 | Acc : 0.8317
     Batch 300 | Loss : 0.4685 | Acc : 0.7693
Epoch 00362 | Train Loss : 0.3926 | Eval Loss : 0.4033 | Train acc : 0.8133 | Eval Acc : 0.8027
     Batch 000 | Loss : 0.3852 | Acc : 0.8077
     Batch 025 | Loss : 0.3685 | Acc : 0.8332
     Batch 050 | Loss : 0.3702 | Acc : 0.8259
     Batch 075 | Loss : 0.4400 | Acc : 0.7951
     Batch 100 | Loss : 0.3832 | Acc : 0.8089
     Batch 125 | Loss : 0.4544 | Acc : 0.7747
     Batch 150 | Loss : 0.3338 | Acc : 0.8498
     Batch 175 | Loss : 0.3418 | Acc : 0.8445
     Batch 200 | Loss : 0.3853 | Acc : 0.8229
     Batch 225 | Loss : 0.3523 | Acc : 0.8328
     Batch 250 | Loss : 0.3844 | Acc : 0.8215
     Batch 275 | Loss : 0.3672 | Acc : 0.8296
     Batch 300 | Loss : 0.3908 | Acc : 0.8133
Epoch 00363 | Train Loss : 0.3917 | Eval Loss : 0.4005 | Train acc : 0.8135 | Eval Acc : 0.8063
     Batch 000 | Loss : 0.3627 | Acc : 0.8288
     Batch 025 | Loss : 0.4247 | Acc : 0.7946
     Batch 050 | Loss : 0.3690 | Acc : 0.8325
     Batch 075 | Loss : 0.4310 | Acc : 0.7909
     Batch 100 | Loss : 0.3985 | Acc : 0.8099
     Batch 125 | Loss : 0.3379 | Acc : 0.8506
     Batch 150 | Loss : 0.3445 | Acc : 0.8464
     Batch 175 | Loss : 0.3053 | Acc : 0.8654
     Batch 200 | Loss : 0.3456 | Acc : 0.8381
     Batch 225 | Loss : 0.4395 | Acc : 0.7794
     Batch 250 | Loss : 0.3953 | Acc : 0.8086
     Batch 275 | Loss : 0.3670 | Acc : 0.8334
     Batch 300 | Loss : 0.3662 | Acc : 0.8319
Epoch 00364 | Train Loss : 0.3934 | Eval Loss : 0.4077 | Train acc : 0.8130 | Eval Acc : 0.8051
     Batch 000 | Loss : 0.3763 | Acc : 0.8252
     Batch 025 | Loss : 0.4350 | Acc : 0.7943
     Batch 050 | Loss : 0.4256 | Acc : 0.7961
     Batch 075 | Loss : 0.3576 | Acc : 0.8316
     Batch 100 | Loss : 0.4339 | Acc : 0.7994
     Batch 125 | Loss : 0.3917 | Acc : 0.8185
     Batch 150 | Loss : 0.4037 | Acc : 0.8086
     Batch 175 | Loss : 0.4210 | Acc : 0.7977
     Batch 200 | Loss : 0.4778 | Acc : 0.7781
     Batch 225 | Loss : 0.3808 | Acc : 0.8157
     Batch 250 | Loss : 0.3569 | Acc : 0.8317
     Batch 275 | Loss : 0.3937 | Acc : 0.8107
     Batch 300 | Loss : 0.3626 | Acc : 0.8334
Epoch 00365 | Train Loss : 0.3930 | Eval Loss : 0.4105 | Train acc : 0.8129 | Eval Acc : 0.8041
     Batch 000 | Loss : 0.4723 | Acc : 0.7763
     Batch 025 | Loss : 0.4071 | Acc : 0.8032
     Batch 050 | Loss : 0.5148 | Acc : 0.7407
     Batch 075 | Loss : 0.3733 | Acc : 0.8263
     Batch 100 | Loss : 0.3906 | Acc : 0.8159
     Batch 125 | Loss : 0.4508 | Acc : 0.7749
     Batch 150 | Loss : 0.4263 | Acc : 0.7926
     Batch 175 | Loss : 0.3484 | Acc : 0.8392
     Batch 200 | Loss : 0.4003 | Acc : 0.8104
     Batch 225 | Loss : 0.5047 | Acc : 0.7549
     Batch 250 | Loss : 0.4005 | Acc : 0.8070
     Batch 275 | Loss : 0.3879 | Acc : 0.8189
     Batch 300 | Loss : 0.3771 | Acc : 0.8191
Epoch 00366 | Train Loss : 0.3937 | Eval Loss : 0.4016 | Train acc : 0.8129 | Eval Acc : 0.8090
     Batch 000 | Loss : 0.3243 | Acc : 0.8514
     Batch 025 | Loss : 0.4068 | Acc : 0.7895
     Batch 050 | Loss : 0.3708 | Acc : 0.8364
     Batch 075 | Loss : 0.3735 | Acc : 0.8239
     Batch 100 | Loss : 0.3920 | Acc : 0.8172
     Batch 125 | Loss : 0.3810 | Acc : 0.8189
     Batch 150 | Loss : 0.5668 | Acc : 0.7206
     Batch 175 | Loss : 0.3955 | Acc : 0.8164
     Batch 200 | Loss : 0.3511 | Acc : 0.8335
     Batch 225 | Loss : 0.3386 | Acc : 0.8495
     Batch 250 | Loss : 0.4009 | Acc : 0.8030
     Batch 275 | Loss : 0.3776 | Acc : 0.8278
     Batch 300 | Loss : 0.4103 | Acc : 0.8003
Epoch 00367 | Train Loss : 0.3919 | Eval Loss : 0.4009 | Train acc : 0.8137 | Eval Acc : 0.8072
     Batch 000 | Loss : 0.4102 | Acc : 0.7982
     Batch 025 | Loss : 0.3402 | Acc : 0.8482
     Batch 050 | Loss : 0.3448 | Acc : 0.8380
     Batch 075 | Loss : 0.3818 | Acc : 0.8297
     Batch 100 | Loss : 0.3977 | Acc : 0.8086
     Batch 125 | Loss : 0.3613 | Acc : 0.8308
     Batch 150 | Loss : 0.4049 | Acc : 0.8012
     Batch 175 | Loss : 0.4304 | Acc : 0.7838
     Batch 200 | Loss : 0.3737 | Acc : 0.8284
     Batch 225 | Loss : 0.4579 | Acc : 0.7873
     Batch 250 | Loss : 0.3920 | Acc : 0.8140
     Batch 275 | Loss : 0.3800 | Acc : 0.8224
     Batch 300 | Loss : 0.4585 | Acc : 0.7777
Epoch 00368 | Train Loss : 0.3932 | Eval Loss : 0.4041 | Train acc : 0.8133 | Eval Acc : 0.8052
     Batch 000 | Loss : 0.4388 | Acc : 0.7772
     Batch 025 | Loss : 0.4460 | Acc : 0.7738
     Batch 050 | Loss : 0.3667 | Acc : 0.8309
     Batch 075 | Loss : 0.4114 | Acc : 0.7951
     Batch 100 | Loss : 0.3850 | Acc : 0.8139
     Batch 125 | Loss : 0.3796 | Acc : 0.8300
     Batch 150 | Loss : 0.3485 | Acc : 0.8389
     Batch 175 | Loss : 0.3588 | Acc : 0.8371
     Batch 200 | Loss : 0.3606 | Acc : 0.8443
     Batch 225 | Loss : 0.3568 | Acc : 0.8339
     Batch 250 | Loss : 0.3461 | Acc : 0.8445
     Batch 275 | Loss : 0.3698 | Acc : 0.8323
     Batch 300 | Loss : 0.4482 | Acc : 0.7777
Epoch 00369 | Train Loss : 0.3926 | Eval Loss : 0.4024 | Train acc : 0.8131 | Eval Acc : 0.8068
     Batch 000 | Loss : 0.3743 | Acc : 0.8267
     Batch 025 | Loss : 0.4207 | Acc : 0.7876
     Batch 050 | Loss : 0.4314 | Acc : 0.7830
     Batch 075 | Loss : 0.3456 | Acc : 0.8430
     Batch 100 | Loss : 0.4292 | Acc : 0.7911
     Batch 125 | Loss : 0.3626 | Acc : 0.8307
     Batch 150 | Loss : 0.4060 | Acc : 0.7959
     Batch 175 | Loss : 0.4215 | Acc : 0.8018
     Batch 200 | Loss : 0.3507 | Acc : 0.8347
     Batch 225 | Loss : 0.4225 | Acc : 0.8024
     Batch 250 | Loss : 0.3609 | Acc : 0.8310
     Batch 275 | Loss : 0.3653 | Acc : 0.8304
     Batch 300 | Loss : 0.4874 | Acc : 0.7548
Epoch 00370 | Train Loss : 0.3921 | Eval Loss : 0.4022 | Train acc : 0.8134 | Eval Acc : 0.8071
     Batch 000 | Loss : 0.4263 | Acc : 0.7849
     Batch 025 | Loss : 0.3433 | Acc : 0.8417
     Batch 050 | Loss : 0.3732 | Acc : 0.8279
     Batch 075 | Loss : 0.3730 | Acc : 0.8114
     Batch 100 | Loss : 0.3815 | Acc : 0.8180
     Batch 125 | Loss : 0.3708 | Acc : 0.8192
     Batch 150 | Loss : 0.4768 | Acc : 0.7635
     Batch 175 | Loss : 0.4253 | Acc : 0.7994
     Batch 200 | Loss : 0.3953 | Acc : 0.8120
     Batch 225 | Loss : 0.4405 | Acc : 0.7839
     Batch 250 | Loss : 0.4307 | Acc : 0.8002
     Batch 275 | Loss : 0.3711 | Acc : 0.8278
     Batch 300 | Loss : 0.4165 | Acc : 0.8020
Epoch 00371 | Train Loss : 0.3944 | Eval Loss : 0.4035 | Train acc : 0.8121 | Eval Acc : 0.8060
     Batch 000 | Loss : 0.3664 | Acc : 0.8290
     Batch 025 | Loss : 0.3390 | Acc : 0.8415
     Batch 050 | Loss : 0.4320 | Acc : 0.7804
     Batch 075 | Loss : 0.4861 | Acc : 0.7585
     Batch 100 | Loss : 0.3747 | Acc : 0.8271
     Batch 125 | Loss : 0.3624 | Acc : 0.8338
     Batch 150 | Loss : 0.3620 | Acc : 0.8223
     Batch 175 | Loss : 0.3775 | Acc : 0.8177
     Batch 200 | Loss : 0.3939 | Acc : 0.8093
     Batch 225 | Loss : 0.3470 | Acc : 0.8369
     Batch 250 | Loss : 0.4530 | Acc : 0.7781
     Batch 275 | Loss : 0.3595 | Acc : 0.8284
     Batch 300 | Loss : 0.3378 | Acc : 0.8485
Epoch 00372 | Train Loss : 0.3912 | Eval Loss : 0.4038 | Train acc : 0.8137 | Eval Acc : 0.8064
     Batch 000 | Loss : 0.4259 | Acc : 0.7958
     Batch 025 | Loss : 0.3611 | Acc : 0.8249
     Batch 050 | Loss : 0.3768 | Acc : 0.8170
     Batch 075 | Loss : 0.3300 | Acc : 0.8436
     Batch 100 | Loss : 0.3800 | Acc : 0.8189
     Batch 125 | Loss : 0.4367 | Acc : 0.7867
     Batch 150 | Loss : 0.4524 | Acc : 0.7811
     Batch 175 | Loss : 0.3569 | Acc : 0.8317
     Batch 200 | Loss : 0.3856 | Acc : 0.8132
     Batch 225 | Loss : 0.3963 | Acc : 0.8105
     Batch 250 | Loss : 0.3508 | Acc : 0.8317
     Batch 275 | Loss : 0.3884 | Acc : 0.8156
     Batch 300 | Loss : 0.3500 | Acc : 0.8382
Epoch 00373 | Train Loss : 0.3913 | Eval Loss : 0.4099 | Train acc : 0.8138 | Eval Acc : 0.8027
     Batch 000 | Loss : 0.4153 | Acc : 0.7910
     Batch 025 | Loss : 0.3634 | Acc : 0.8385
     Batch 050 | Loss : 0.3995 | Acc : 0.8048
     Batch 075 | Loss : 0.3936 | Acc : 0.8094
     Batch 100 | Loss : 0.3459 | Acc : 0.8364
     Batch 125 | Loss : 0.3765 | Acc : 0.8196
     Batch 150 | Loss : 0.3222 | Acc : 0.8545
     Batch 175 | Loss : 0.3618 | Acc : 0.8259
     Batch 200 | Loss : 0.4055 | Acc : 0.7981
     Batch 225 | Loss : 0.3690 | Acc : 0.8265
     Batch 250 | Loss : 0.3518 | Acc : 0.8434
     Batch 275 | Loss : 0.3811 | Acc : 0.8214
     Batch 300 | Loss : 0.3863 | Acc : 0.8192
Epoch 00374 | Train Loss : 0.3910 | Eval Loss : 0.4030 | Train acc : 0.8137 | Eval Acc : 0.8068
     Batch 000 | Loss : 0.3366 | Acc : 0.8481
     Batch 025 | Loss : 0.4048 | Acc : 0.8053
     Batch 050 | Loss : 0.4600 | Acc : 0.7769
     Batch 075 | Loss : 0.3942 | Acc : 0.8016
     Batch 100 | Loss : 0.3501 | Acc : 0.8436
     Batch 125 | Loss : 0.4260 | Acc : 0.7957
     Batch 150 | Loss : 0.3755 | Acc : 0.8237
     Batch 175 | Loss : 0.3631 | Acc : 0.8301
     Batch 200 | Loss : 0.4147 | Acc : 0.7992
     Batch 225 | Loss : 0.4534 | Acc : 0.7576
     Batch 250 | Loss : 0.3680 | Acc : 0.8305
     Batch 275 | Loss : 0.3747 | Acc : 0.8248
     Batch 300 | Loss : 0.3579 | Acc : 0.8287
Epoch 00375 | Train Loss : 0.3931 | Eval Loss : 0.4108 | Train acc : 0.8130 | Eval Acc : 0.8049
     Batch 000 | Loss : 0.4341 | Acc : 0.7962
     Batch 025 | Loss : 0.3564 | Acc : 0.8336
     Batch 050 | Loss : 0.3423 | Acc : 0.8394
     Batch 075 | Loss : 0.3575 | Acc : 0.8254
     Batch 100 | Loss : 0.3416 | Acc : 0.8478
     Batch 125 | Loss : 0.3602 | Acc : 0.8296
     Batch 150 | Loss : 0.4126 | Acc : 0.7960
     Batch 175 | Loss : 0.3358 | Acc : 0.8507
     Batch 200 | Loss : 0.4613 | Acc : 0.7721
     Batch 225 | Loss : 0.3608 | Acc : 0.8353
     Batch 250 | Loss : 0.3484 | Acc : 0.8418
     Batch 275 | Loss : 0.4029 | Acc : 0.8013
     Batch 300 | Loss : 0.4087 | Acc : 0.7894
Epoch 00376 | Train Loss : 0.3908 | Eval Loss : 0.4036 | Train acc : 0.8137 | Eval Acc : 0.8061
     Batch 000 | Loss : 0.3799 | Acc : 0.8175
     Batch 025 | Loss : 0.3625 | Acc : 0.8315
     Batch 050 | Loss : 0.3360 | Acc : 0.8508
     Batch 075 | Loss : 0.4638 | Acc : 0.7673
     Batch 100 | Loss : 0.4484 | Acc : 0.7758
     Batch 125 | Loss : 0.3777 | Acc : 0.8287
     Batch 150 | Loss : 0.3587 | Acc : 0.8316
     Batch 175 | Loss : 0.3812 | Acc : 0.8201
     Batch 200 | Loss : 0.3517 | Acc : 0.8344
     Batch 225 | Loss : 0.3508 | Acc : 0.8355
     Batch 250 | Loss : 0.3172 | Acc : 0.8602
     Batch 275 | Loss : 0.4337 | Acc : 0.7909
     Batch 300 | Loss : 0.4017 | Acc : 0.8004
Epoch 00377 | Train Loss : 0.3910 | Eval Loss : 0.4128 | Train acc : 0.8139 | Eval Acc : 0.8059
     Batch 000 | Loss : 0.3326 | Acc : 0.8489
     Batch 025 | Loss : 0.4140 | Acc : 0.8109
     Batch 050 | Loss : 0.3796 | Acc : 0.8261
     Batch 075 | Loss : 0.4329 | Acc : 0.7884
     Batch 100 | Loss : 0.3579 | Acc : 0.8316
     Batch 125 | Loss : 0.3758 | Acc : 0.8203
     Batch 150 | Loss : 0.3571 | Acc : 0.8282
     Batch 175 | Loss : 0.5247 | Acc : 0.7403
     Batch 200 | Loss : 0.3438 | Acc : 0.8466
     Batch 225 | Loss : 0.3509 | Acc : 0.8383
     Batch 250 | Loss : 0.3797 | Acc : 0.8198
     Batch 275 | Loss : 0.4681 | Acc : 0.7623
     Batch 300 | Loss : 0.3606 | Acc : 0.8348
Epoch 00378 | Train Loss : 0.3915 | Eval Loss : 0.4029 | Train acc : 0.8136 | Eval Acc : 0.8067
     Batch 000 | Loss : 0.4609 | Acc : 0.7782
     Batch 025 | Loss : 0.3519 | Acc : 0.8364
     Batch 050 | Loss : 0.3778 | Acc : 0.8214
     Batch 075 | Loss : 0.3465 | Acc : 0.8416
     Batch 100 | Loss : 0.4740 | Acc : 0.7809
     Batch 125 | Loss : 0.3846 | Acc : 0.8208
     Batch 150 | Loss : 0.4002 | Acc : 0.8099
     Batch 175 | Loss : 0.4004 | Acc : 0.8021
     Batch 200 | Loss : 0.4236 | Acc : 0.8013
     Batch 225 | Loss : 0.3432 | Acc : 0.8365
     Batch 250 | Loss : 0.3372 | Acc : 0.8386
     Batch 275 | Loss : 0.4214 | Acc : 0.7935
     Batch 300 | Loss : 0.4123 | Acc : 0.8042
Epoch 00379 | Train Loss : 0.3909 | Eval Loss : 0.4153 | Train acc : 0.8142 | Eval Acc : 0.8016
     Batch 000 | Loss : 0.3412 | Acc : 0.8500
     Batch 025 | Loss : 0.5206 | Acc : 0.7546
     Batch 050 | Loss : 0.4834 | Acc : 0.7612
     Batch 075 | Loss : 0.3714 | Acc : 0.8257
     Batch 100 | Loss : 0.3844 | Acc : 0.8124
     Batch 125 | Loss : 0.4227 | Acc : 0.7867
     Batch 150 | Loss : 0.3703 | Acc : 0.8211
     Batch 175 | Loss : 0.4202 | Acc : 0.7987
     Batch 200 | Loss : 0.4720 | Acc : 0.7719
     Batch 225 | Loss : 0.4542 | Acc : 0.7721
     Batch 250 | Loss : 0.3500 | Acc : 0.8440
     Batch 275 | Loss : 0.4549 | Acc : 0.7694
     Batch 300 | Loss : 0.3813 | Acc : 0.8298
Epoch 00380 | Train Loss : 0.3906 | Eval Loss : 0.4051 | Train acc : 0.8142 | Eval Acc : 0.8049
     Batch 000 | Loss : 0.3757 | Acc : 0.8187
     Batch 025 | Loss : 0.5307 | Acc : 0.7427
     Batch 050 | Loss : 0.4241 | Acc : 0.7932
     Batch 075 | Loss : 0.3265 | Acc : 0.8525
     Batch 100 | Loss : 0.4401 | Acc : 0.7881
     Batch 125 | Loss : 0.3994 | Acc : 0.8021
     Batch 150 | Loss : 0.3649 | Acc : 0.8268
     Batch 175 | Loss : 0.3490 | Acc : 0.8405
     Batch 200 | Loss : 0.3859 | Acc : 0.8211
     Batch 225 | Loss : 0.4186 | Acc : 0.8013
     Batch 250 | Loss : 0.3887 | Acc : 0.8263
     Batch 275 | Loss : 0.3476 | Acc : 0.8347
     Batch 300 | Loss : 0.5024 | Acc : 0.7539
Epoch 00381 | Train Loss : 0.3943 | Eval Loss : 0.3989 | Train acc : 0.8126 | Eval Acc : 0.8092
     Batch 000 | Loss : 0.3625 | Acc : 0.8326
     Batch 025 | Loss : 0.3545 | Acc : 0.8366
     Batch 050 | Loss : 0.3834 | Acc : 0.8158
     Batch 075 | Loss : 0.3863 | Acc : 0.8188
     Batch 100 | Loss : 0.3684 | Acc : 0.8307
     Batch 125 | Loss : 0.3223 | Acc : 0.8477
     Batch 150 | Loss : 0.3829 | Acc : 0.8175
     Batch 175 | Loss : 0.3516 | Acc : 0.8329
     Batch 200 | Loss : 0.3794 | Acc : 0.8211
     Batch 225 | Loss : 0.3499 | Acc : 0.8362
     Batch 250 | Loss : 0.3931 | Acc : 0.8181
     Batch 275 | Loss : 0.4687 | Acc : 0.7592
     Batch 300 | Loss : 0.4932 | Acc : 0.7636
Epoch 00382 | Train Loss : 0.3934 | Eval Loss : 0.4018 | Train acc : 0.8130 | Eval Acc : 0.8072
     Batch 000 | Loss : 0.3632 | Acc : 0.8385
     Batch 025 | Loss : 0.3657 | Acc : 0.8283
     Batch 050 | Loss : 0.3716 | Acc : 0.8234
     Batch 075 | Loss : 0.4157 | Acc : 0.8023
     Batch 100 | Loss : 0.3617 | Acc : 0.8259
     Batch 125 | Loss : 0.3628 | Acc : 0.8309
     Batch 150 | Loss : 0.4396 | Acc : 0.7870
     Batch 175 | Loss : 0.3837 | Acc : 0.8172
     Batch 200 | Loss : 0.3921 | Acc : 0.8180
     Batch 225 | Loss : 0.4225 | Acc : 0.7937
     Batch 250 | Loss : 0.4550 | Acc : 0.7820
     Batch 275 | Loss : 0.4363 | Acc : 0.7862
     Batch 300 | Loss : 0.3511 | Acc : 0.8469
Epoch 00383 | Train Loss : 0.3908 | Eval Loss : 0.4008 | Train acc : 0.8143 | Eval Acc : 0.8086
     Batch 000 | Loss : 0.3556 | Acc : 0.8337
     Batch 025 | Loss : 0.4039 | Acc : 0.8114
     Batch 050 | Loss : 0.3802 | Acc : 0.8219
     Batch 075 | Loss : 0.3489 | Acc : 0.8352
     Batch 100 | Loss : 0.5208 | Acc : 0.7414
     Batch 125 | Loss : 0.3515 | Acc : 0.8373
     Batch 150 | Loss : 0.4287 | Acc : 0.7852
     Batch 175 | Loss : 0.3681 | Acc : 0.8322
     Batch 200 | Loss : 0.4335 | Acc : 0.7940
     Batch 225 | Loss : 0.4167 | Acc : 0.7920
     Batch 250 | Loss : 0.4620 | Acc : 0.7751
     Batch 275 | Loss : 0.3364 | Acc : 0.8530
     Batch 300 | Loss : 0.4027 | Acc : 0.8047
Epoch 00384 | Train Loss : 0.3910 | Eval Loss : 0.4056 | Train acc : 0.8138 | Eval Acc : 0.8070
     Batch 000 | Loss : 0.4302 | Acc : 0.7900
     Batch 025 | Loss : 0.3532 | Acc : 0.8341
     Batch 050 | Loss : 0.4432 | Acc : 0.7835
     Batch 075 | Loss : 0.3400 | Acc : 0.8427
     Batch 100 | Loss : 0.4148 | Acc : 0.8016
     Batch 125 | Loss : 0.3697 | Acc : 0.8204
     Batch 150 | Loss : 0.4113 | Acc : 0.8018
     Batch 175 | Loss : 0.3849 | Acc : 0.8235
     Batch 200 | Loss : 0.3422 | Acc : 0.8377
     Batch 225 | Loss : 0.4602 | Acc : 0.7674
     Batch 250 | Loss : 0.4438 | Acc : 0.7798
     Batch 275 | Loss : 0.3953 | Acc : 0.8017
     Batch 300 | Loss : 0.4498 | Acc : 0.7740
Epoch 00385 | Train Loss : 0.3944 | Eval Loss : 0.4028 | Train acc : 0.8127 | Eval Acc : 0.8059
     Batch 000 | Loss : 0.4453 | Acc : 0.7842
     Batch 025 | Loss : 0.5406 | Acc : 0.7400
     Batch 050 | Loss : 0.3413 | Acc : 0.8365
     Batch 075 | Loss : 0.4992 | Acc : 0.7599
     Batch 100 | Loss : 0.3968 | Acc : 0.8219
     Batch 125 | Loss : 0.3715 | Acc : 0.8380
     Batch 150 | Loss : 0.3709 | Acc : 0.8265
     Batch 175 | Loss : 0.3603 | Acc : 0.8346
     Batch 200 | Loss : 0.4161 | Acc : 0.8017
     Batch 225 | Loss : 0.3771 | Acc : 0.8260
     Batch 250 | Loss : 0.4098 | Acc : 0.8001
     Batch 275 | Loss : 0.4145 | Acc : 0.8042
     Batch 300 | Loss : 0.4427 | Acc : 0.7725
Epoch 00386 | Train Loss : 0.3915 | Eval Loss : 0.4030 | Train acc : 0.8138 | Eval Acc : 0.8071
     Batch 000 | Loss : 0.4667 | Acc : 0.7734
     Batch 025 | Loss : 0.4387 | Acc : 0.7915
     Batch 050 | Loss : 0.3367 | Acc : 0.8417
     Batch 075 | Loss : 0.3774 | Acc : 0.8244
     Batch 100 | Loss : 0.3359 | Acc : 0.8488
     Batch 125 | Loss : 0.3994 | Acc : 0.8035
     Batch 150 | Loss : 0.3638 | Acc : 0.8279
     Batch 175 | Loss : 0.3976 | Acc : 0.8119
     Batch 200 | Loss : 0.4066 | Acc : 0.8040
     Batch 225 | Loss : 0.4006 | Acc : 0.8074
     Batch 250 | Loss : 0.3542 | Acc : 0.8398
     Batch 275 | Loss : 0.3691 | Acc : 0.8307
     Batch 300 | Loss : 0.4531 | Acc : 0.7725
Epoch 00387 | Train Loss : 0.3946 | Eval Loss : 0.3988 | Train acc : 0.8125 | Eval Acc : 0.8084
     Batch 000 | Loss : 0.3808 | Acc : 0.8181
     Batch 025 | Loss : 0.3885 | Acc : 0.8191
     Batch 050 | Loss : 0.4302 | Acc : 0.7932
     Batch 075 | Loss : 0.3461 | Acc : 0.8397
     Batch 100 | Loss : 0.3778 | Acc : 0.8136
     Batch 125 | Loss : 0.3801 | Acc : 0.8182
     Batch 150 | Loss : 0.3833 | Acc : 0.8107
     Batch 175 | Loss : 0.3667 | Acc : 0.8210
     Batch 200 | Loss : 0.4487 | Acc : 0.7779
     Batch 225 | Loss : 0.4320 | Acc : 0.7924
     Batch 250 | Loss : 0.3758 | Acc : 0.8264
     Batch 275 | Loss : 0.4330 | Acc : 0.7890
     Batch 300 | Loss : 0.3755 | Acc : 0.8292
Epoch 00388 | Train Loss : 0.3909 | Eval Loss : 0.4012 | Train acc : 0.8141 | Eval Acc : 0.8083
     Batch 000 | Loss : 0.3640 | Acc : 0.8321
     Batch 025 | Loss : 0.4090 | Acc : 0.7973
     Batch 050 | Loss : 0.4954 | Acc : 0.7453
     Batch 075 | Loss : 0.3706 | Acc : 0.8284
     Batch 100 | Loss : 0.3991 | Acc : 0.8029
     Batch 125 | Loss : 0.3939 | Acc : 0.8056
     Batch 150 | Loss : 0.3593 | Acc : 0.8271
     Batch 175 | Loss : 0.3872 | Acc : 0.8182
     Batch 200 | Loss : 0.3735 | Acc : 0.8278
     Batch 225 | Loss : 0.4336 | Acc : 0.7796
     Batch 250 | Loss : 0.3654 | Acc : 0.8299
     Batch 275 | Loss : 0.3349 | Acc : 0.8538
     Batch 300 | Loss : 0.3677 | Acc : 0.8351
Epoch 00389 | Train Loss : 0.3918 | Eval Loss : 0.4073 | Train acc : 0.8140 | Eval Acc : 0.8039
     Batch 000 | Loss : 0.3697 | Acc : 0.8273
     Batch 025 | Loss : 0.3214 | Acc : 0.8537
     Batch 050 | Loss : 0.3831 | Acc : 0.8164
     Batch 075 | Loss : 0.3862 | Acc : 0.8155
     Batch 100 | Loss : 0.3683 | Acc : 0.8277
     Batch 125 | Loss : 0.3801 | Acc : 0.8234
     Batch 150 | Loss : 0.4265 | Acc : 0.7860
     Batch 175 | Loss : 0.4795 | Acc : 0.7565
     Batch 200 | Loss : 0.3513 | Acc : 0.8383
     Batch 225 | Loss : 0.4223 | Acc : 0.7895
     Batch 250 | Loss : 0.3604 | Acc : 0.8418
     Batch 275 | Loss : 0.4174 | Acc : 0.7996
     Batch 300 | Loss : 0.4427 | Acc : 0.7771
Epoch 00390 | Train Loss : 0.3949 | Eval Loss : 0.3986 | Train acc : 0.8121 | Eval Acc : 0.8093
     Batch 000 | Loss : 0.3540 | Acc : 0.8303
     Batch 025 | Loss : 0.4281 | Acc : 0.7927
     Batch 050 | Loss : 0.3813 | Acc : 0.8187
     Batch 075 | Loss : 0.4222 | Acc : 0.7976
     Batch 100 | Loss : 0.3776 | Acc : 0.8251
     Batch 125 | Loss : 0.3739 | Acc : 0.8225
     Batch 150 | Loss : 0.3858 | Acc : 0.8214
     Batch 175 | Loss : 0.4269 | Acc : 0.7899
     Batch 200 | Loss : 0.4473 | Acc : 0.7943
     Batch 225 | Loss : 0.4278 | Acc : 0.7914
     Batch 250 | Loss : 0.3534 | Acc : 0.8400
     Batch 275 | Loss : 0.3527 | Acc : 0.8364
     Batch 300 | Loss : 0.3262 | Acc : 0.8523
Epoch 00391 | Train Loss : 0.3904 | Eval Loss : 0.4008 | Train acc : 0.8148 | Eval Acc : 0.8072
     Batch 000 | Loss : 0.3402 | Acc : 0.8507
     Batch 025 | Loss : 0.3902 | Acc : 0.8177
     Batch 050 | Loss : 0.4141 | Acc : 0.8053
     Batch 075 | Loss : 0.3872 | Acc : 0.8146
     Batch 100 | Loss : 0.3203 | Acc : 0.8548
     Batch 125 | Loss : 0.4010 | Acc : 0.8057
     Batch 150 | Loss : 0.3870 | Acc : 0.8056
     Batch 175 | Loss : 0.4017 | Acc : 0.8019
     Batch 200 | Loss : 0.3644 | Acc : 0.8346
     Batch 225 | Loss : 0.3447 | Acc : 0.8502
     Batch 250 | Loss : 0.3448 | Acc : 0.8383
     Batch 275 | Loss : 0.3646 | Acc : 0.8315
     Batch 300 | Loss : 0.4837 | Acc : 0.7769
Epoch 00392 | Train Loss : 0.3928 | Eval Loss : 0.4205 | Train acc : 0.8134 | Eval Acc : 0.8048
     Batch 000 | Loss : 0.3911 | Acc : 0.8199
     Batch 025 | Loss : 0.3540 | Acc : 0.8286
     Batch 050 | Loss : 0.3571 | Acc : 0.8280
     Batch 075 | Loss : 0.3486 | Acc : 0.8315
     Batch 100 | Loss : 0.3816 | Acc : 0.8227
     Batch 125 | Loss : 0.4756 | Acc : 0.7704
     Batch 150 | Loss : 0.3471 | Acc : 0.8434
     Batch 175 | Loss : 0.3312 | Acc : 0.8527
     Batch 200 | Loss : 0.3617 | Acc : 0.8313
     Batch 225 | Loss : 0.3312 | Acc : 0.8544
     Batch 250 | Loss : 0.3478 | Acc : 0.8424
     Batch 275 | Loss : 0.3615 | Acc : 0.8247
     Batch 300 | Loss : 0.3349 | Acc : 0.8505
Epoch 00393 | Train Loss : 0.3897 | Eval Loss : 0.3994 | Train acc : 0.8147 | Eval Acc : 0.8093
     Batch 000 | Loss : 0.3866 | Acc : 0.8117
     Batch 025 | Loss : 0.4302 | Acc : 0.7943
     Batch 050 | Loss : 0.4992 | Acc : 0.7608
     Batch 075 | Loss : 0.3980 | Acc : 0.8117
     Batch 100 | Loss : 0.3449 | Acc : 0.8357
     Batch 125 | Loss : 0.3629 | Acc : 0.8306
     Batch 150 | Loss : 0.4088 | Acc : 0.7912
     Batch 175 | Loss : 0.4333 | Acc : 0.7806
     Batch 200 | Loss : 0.3732 | Acc : 0.8240
     Batch 225 | Loss : 0.3705 | Acc : 0.8245
     Batch 250 | Loss : 0.4438 | Acc : 0.7847
     Batch 275 | Loss : 0.3355 | Acc : 0.8480
     Batch 300 | Loss : 0.3420 | Acc : 0.8446
Epoch 00394 | Train Loss : 0.3901 | Eval Loss : 0.4108 | Train acc : 0.8144 | Eval Acc : 0.8066
     Batch 000 | Loss : 0.3260 | Acc : 0.8540
     Batch 025 | Loss : 0.4590 | Acc : 0.7714
     Batch 050 | Loss : 0.4400 | Acc : 0.7764
     Batch 075 | Loss : 0.3634 | Acc : 0.8318
     Batch 100 | Loss : 0.4214 | Acc : 0.7993
     Batch 125 | Loss : 0.3653 | Acc : 0.8234
     Batch 150 | Loss : 0.4277 | Acc : 0.7912
     Batch 175 | Loss : 0.3332 | Acc : 0.8539
     Batch 200 | Loss : 0.3576 | Acc : 0.8277
     Batch 225 | Loss : 0.3716 | Acc : 0.8209
     Batch 250 | Loss : 0.3863 | Acc : 0.8148
     Batch 275 | Loss : 0.3407 | Acc : 0.8422
     Batch 300 | Loss : 0.3389 | Acc : 0.8460
Epoch 00395 | Train Loss : 0.3931 | Eval Loss : 0.4047 | Train acc : 0.8131 | Eval Acc : 0.8030
     Batch 000 | Loss : 0.4476 | Acc : 0.7734
     Batch 025 | Loss : 0.3301 | Acc : 0.8559
     Batch 050 | Loss : 0.4155 | Acc : 0.7945
     Batch 075 | Loss : 0.3841 | Acc : 0.8156
     Batch 100 | Loss : 0.4392 | Acc : 0.7837
     Batch 125 | Loss : 0.3685 | Acc : 0.8249
     Batch 150 | Loss : 0.3840 | Acc : 0.8206
     Batch 175 | Loss : 0.4094 | Acc : 0.8018
     Batch 200 | Loss : 0.4468 | Acc : 0.7803
     Batch 225 | Loss : 0.3564 | Acc : 0.8366
     Batch 250 | Loss : 0.3596 | Acc : 0.8332
     Batch 275 | Loss : 0.4671 | Acc : 0.7715
     Batch 300 | Loss : 0.3893 | Acc : 0.8085
Epoch 00396 | Train Loss : 0.3916 | Eval Loss : 0.3984 | Train acc : 0.8135 | Eval Acc : 0.8088
     Batch 000 | Loss : 0.4030 | Acc : 0.8026
     Batch 025 | Loss : 0.4063 | Acc : 0.8003
     Batch 050 | Loss : 0.3380 | Acc : 0.8424
     Batch 075 | Loss : 0.4867 | Acc : 0.7516
     Batch 100 | Loss : 0.4161 | Acc : 0.8010
     Batch 125 | Loss : 0.3565 | Acc : 0.8321
     Batch 150 | Loss : 0.3547 | Acc : 0.8308
     Batch 175 | Loss : 0.4158 | Acc : 0.7899
     Batch 200 | Loss : 0.3882 | Acc : 0.8134
     Batch 225 | Loss : 0.3492 | Acc : 0.8316
     Batch 250 | Loss : 0.4152 | Acc : 0.7968
     Batch 275 | Loss : 0.3801 | Acc : 0.8166
     Batch 300 | Loss : 0.4492 | Acc : 0.7785
Epoch 00397 | Train Loss : 0.3907 | Eval Loss : 0.4000 | Train acc : 0.8141 | Eval Acc : 0.8083
     Batch 000 | Loss : 0.4492 | Acc : 0.7825
     Batch 025 | Loss : 0.3316 | Acc : 0.8558
     Batch 050 | Loss : 0.4150 | Acc : 0.7944
     Batch 075 | Loss : 0.3781 | Acc : 0.8196
     Batch 100 | Loss : 0.4173 | Acc : 0.7950
     Batch 125 | Loss : 0.3804 | Acc : 0.8299
     Batch 150 | Loss : 0.3687 | Acc : 0.8293
     Batch 175 | Loss : 0.3755 | Acc : 0.8263
     Batch 200 | Loss : 0.4605 | Acc : 0.7728
     Batch 225 | Loss : 0.4502 | Acc : 0.7806
     Batch 250 | Loss : 0.3685 | Acc : 0.8358
     Batch 275 | Loss : 0.3775 | Acc : 0.8237
     Batch 300 | Loss : 0.3391 | Acc : 0.8477
Epoch 00398 | Train Loss : 0.3932 | Eval Loss : 0.4026 | Train acc : 0.8134 | Eval Acc : 0.8058
     Batch 000 | Loss : 0.3802 | Acc : 0.8129
     Batch 025 | Loss : 0.3677 | Acc : 0.8272
     Batch 050 | Loss : 0.3906 | Acc : 0.8146
     Batch 075 | Loss : 0.3506 | Acc : 0.8375
     Batch 100 | Loss : 0.4745 | Acc : 0.7715
     Batch 125 | Loss : 0.3426 | Acc : 0.8408
     Batch 150 | Loss : 0.4134 | Acc : 0.7946
     Batch 175 | Loss : 0.3502 | Acc : 0.8508
     Batch 200 | Loss : 0.3941 | Acc : 0.8061
     Batch 225 | Loss : 0.3592 | Acc : 0.8377
     Batch 250 | Loss : 0.4457 | Acc : 0.7819
     Batch 275 | Loss : 0.4630 | Acc : 0.7762
     Batch 300 | Loss : 0.3229 | Acc : 0.8476
Epoch 00399 | Train Loss : 0.3923 | Eval Loss : 0.3988 | Train acc : 0.8137 | Eval Acc : 0.8084
Testing...
Test Loss 0.6207 | Test Acc 0.8112
