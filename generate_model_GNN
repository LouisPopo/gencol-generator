from unicodedata import name
import dgl
import torch

import pandas as pd

import networkx as nx
import torch.nn as nn

import numpy as np

import torch.nn.functional as F

from dgl.data import DGLDataset
from dgl.nn import GraphConv

class MDEVSPDataset(DGLDataset):

    def __init__(self):
        super().__init__(name='MDEVSP')

    def process(self):
        
        nodes_data = pd.read_csv('DGL_graph/nodes4b_4_0.csv',sep=';',index_col = 0)
        edges_data = pd.read_csv('DGL_graph/edges4b_4_0.csv',sep=';',index_col = 0)
        
        edges_features = torch.tensor(edges_data[['cost', 'energy', 'travel_time', 'waiting_time', 'delta_time', 'rg_id','rg']].astype('float').values, dtype=torch.float)
        nodes_features = torch.tensor(nodes_data[[c for c in nodes_data.columns if c in ['o', 'k', 'n', 'w', 'c', 'd', 'nb_dep_10', 'nb_dep_10_id', 'nb_fin_10', 'nb_fin_10_id', 't_s', 't_e'] or 's_' in c or 'e_' in c]].astype('float').values, dtype=torch.float)

        # node_labels = torch.tensor(nodes_data['class'].astype('category').cat.codes.to_numpy())
        node_labels = torch.tensor(nodes_data['class'].astype('float').values, dtype=torch.long)

        self.graph = dgl.graph((edges_data['idx_src'], edges_data['idx_dst']))

        #self.graph = dgl.add_self_loop(self.graph)

        self.graph.ndata['feat'] = nodes_features
        self.graph.ndata['label'] = node_labels
        self.graph.edata['feat'] = edges_features

        n_nodes = nodes_data.shape[0]
        n_train = int(n_nodes*0.6)
        n_val = int(n_nodes*0.2)

        train_mask = torch.zeros(n_nodes, dtype=torch.bool)
        val_mask = torch.zeros(n_nodes, dtype=torch.bool)
        test_mask = torch.zeros(n_nodes, dtype=torch.bool)

        train_mask[:n_train] = True
        val_mask[n_train:n_train+n_val] = True
        test_mask[n_train+n_val:] = True

        df_mask = pd.DataFrame()
        df_mask['train_mask'] = train_mask
        df_mask['val_mask'] = val_mask
        df_mask['test_mask'] = test_mask

        df_mask = df_mask.sample(frac=1).reset_index(drop=True)

        self.graph.ndata['train_mask'] = torch.tensor(df_mask['train_mask'])
        self.graph.ndata['val_mask'] = torch.tensor(df_mask['val_mask'])
        self.graph.ndata['test_mask'] = torch.tensor(df_mask['test_mask'])

        self.num_classes = 2

    def __getitem__(self, idx):
        return self.graph

    def __len__(self):
        return 1

class GCN(nn.Module):

    def __init__(self, in_feats, h_feats, num_classes) -> None:
        super(GCN, self).__init__()
        self.conv1 = GraphConv(in_feats, h_feats, allow_zero_in_degree=True)
        self.conv2 = GraphConv(h_feats, num_classes, allow_zero_in_degree=True)

    def forward(self, g, in_feat):
        h = self.conv1(g, in_feat)
        h = F.relu(h)
        h = self.conv2(g, h)
        return h


def train(g, model):
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
    best_val_acc = 0
    best_test_acc = 0

    features = g.ndata['feat'].float()
    labels = g.ndata['label']
    train_mask = g.ndata['train_mask']
    val_mask = g.ndata['val_mask']
    test_mask = g.ndata['test_mask']

    for e in range(100):

        # Forward : 
        logits = model(g, features)

        # logp = F.log_softmax(logits, 1)

        # print(logp)

        # loss = F.nll_loss(logp[train_mask], labels[train_mask])

        # # Compute predictions 
        pred = logits.argmax(1)

        # # Compute loss

        # print(logits[train_mask])
        # print(labels[train_mask])

        loss = F.cross_entropy(logits[train_mask], labels[train_mask])

        # Compute accuracy on train val test
        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()
        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()
        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()

        # Save the best validation accuracy and the corresponding test accuracy.
        if best_val_acc < val_acc:
            best_val_acc = val_acc
            best_test_acc = test_acc

        # Backward
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if e % 5 == 0:
            print('In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})'.format(
                e, loss, val_acc, best_val_acc, test_acc, best_test_acc))

        # if e % 5 == 0:
        #     print("Epoch {:05d} | Loss {:.4f}".format(
        #         e, loss.item()))


dataset = MDEVSPDataset()
graph = dataset[0]

model = GCN(graph.ndata['feat'].shape[1], 16, dataset.num_classes)
train(graph, model)