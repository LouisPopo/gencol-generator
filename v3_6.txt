Done loading data from cached files.
Training ...
     Batch 000 | Loss : 0.6936 | Acc : 0.5135
     Batch 025 | Loss : 0.6929 | Acc : 0.5120
     Batch 050 | Loss : 0.6926 | Acc : 0.5169
     Batch 075 | Loss : 0.6905 | Acc : 0.5153
     Batch 100 | Loss : 0.6534 | Acc : 0.6742
     Batch 125 | Loss : 0.6049 | Acc : 0.6841
     Batch 150 | Loss : 0.5189 | Acc : 0.7259
     Batch 175 | Loss : 0.6191 | Acc : 0.6816
     Batch 200 | Loss : 0.4970 | Acc : 0.7309
     Batch 225 | Loss : 0.4777 | Acc : 0.7762
     Batch 250 | Loss : 0.5741 | Acc : 0.6751
     Batch 275 | Loss : 0.5356 | Acc : 0.6984
     Batch 300 | Loss : 0.4831 | Acc : 0.7605
Epoch 00000 | Train Loss : 0.5891 | Eval Loss : 0.5231 | Train acc : 0.6576 | Eval Acc : 0.7133 | Eval Log. Respected : 1.0000
     Batch 000 | Loss : 0.5217 | Acc : 0.7409
     Batch 025 | Loss : 0.4985 | Acc : 0.7390
     Batch 050 | Loss : 0.5121 | Acc : 0.7194
     Batch 075 | Loss : 0.5585 | Acc : 0.6896
     Batch 100 | Loss : 0.4940 | Acc : 0.7578
     Batch 125 | Loss : 0.4744 | Acc : 0.7564
     Batch 150 | Loss : 0.5008 | Acc : 0.7328
     Batch 175 | Loss : 0.5130 | Acc : 0.7166
     Batch 200 | Loss : 0.4537 | Acc : 0.7734
     Batch 225 | Loss : 0.5196 | Acc : 0.7213
     Batch 250 | Loss : 0.5703 | Acc : 0.6930
     Batch 275 | Loss : 0.4894 | Acc : 0.7453
     Batch 300 | Loss : 0.4924 | Acc : 0.7448
Epoch 00001 | Train Loss : 0.5174 | Eval Loss : 0.5194 | Train acc : 0.7255 | Eval Acc : 0.7230 | Eval Log. Respected : 1.0000
     Batch 000 | Loss : 0.5911 | Acc : 0.6941
     Batch 025 | Loss : 0.5267 | Acc : 0.7213
     Batch 050 | Loss : 0.4887 | Acc : 0.7255
     Batch 075 | Loss : 0.4752 | Acc : 0.7537
     Batch 100 | Loss : 0.5015 | Acc : 0.7459
     Batch 125 | Loss : 0.4661 | Acc : 0.7535
     Batch 150 | Loss : 0.5146 | Acc : 0.7217
     Batch 175 | Loss : 0.5954 | Acc : 0.6657
     Batch 200 | Loss : 0.4510 | Acc : 0.7716
     Batch 225 | Loss : 0.5246 | Acc : 0.7178
     Batch 250 | Loss : 0.5238 | Acc : 0.7314
     Batch 275 | Loss : 0.4817 | Acc : 0.7466
     Batch 300 | Loss : 0.4524 | Acc : 0.7783
Epoch 00002 | Train Loss : 0.5073 | Eval Loss : 0.4986 | Train acc : 0.7346 | Eval Acc : 0.7360 | Eval Log. Respected : 0.9997
     Batch 000 | Loss : 0.4883 | Acc : 0.7587
     Batch 025 | Loss : 0.5221 | Acc : 0.7229
     Batch 050 | Loss : 0.4789 | Acc : 0.7601
     Batch 075 | Loss : 0.5500 | Acc : 0.6951
     Batch 100 | Loss : 0.4859 | Acc : 0.7319
     Batch 125 | Loss : 0.5161 | Acc : 0.7212
     Batch 150 | Loss : 0.4740 | Acc : 0.7481
     Batch 175 | Loss : 0.5575 | Acc : 0.6952
     Batch 200 | Loss : 0.5134 | Acc : 0.7418
     Batch 225 | Loss : 0.5399 | Acc : 0.7098
     Batch 250 | Loss : 0.4568 | Acc : 0.7663
     Batch 275 | Loss : 0.4604 | Acc : 0.7606
     Batch 300 | Loss : 0.4156 | Acc : 0.7729
Epoch 00003 | Train Loss : 0.5035 | Eval Loss : 0.4966 | Train acc : 0.7362 | Eval Acc : 0.7312 | Eval Log. Respected : 0.9886
     Batch 000 | Loss : 0.5226 | Acc : 0.7208
     Batch 025 | Loss : 0.4968 | Acc : 0.7499
     Batch 050 | Loss : 0.5460 | Acc : 0.7004
     Batch 075 | Loss : 0.4752 | Acc : 0.7522
     Batch 100 | Loss : 0.5363 | Acc : 0.7183
     Batch 125 | Loss : 0.4789 | Acc : 0.7548
     Batch 150 | Loss : 0.4517 | Acc : 0.7789
     Batch 175 | Loss : 0.5176 | Acc : 0.7294
     Batch 200 | Loss : 0.4378 | Acc : 0.7791
     Batch 225 | Loss : 0.4938 | Acc : 0.7452
     Batch 250 | Loss : 0.5191 | Acc : 0.7331
     Batch 275 | Loss : 0.4704 | Acc : 0.7705
     Batch 300 | Loss : 0.5159 | Acc : 0.7295
Epoch 00004 | Train Loss : 0.4929 | Eval Loss : 0.4930 | Train acc : 0.7433 | Eval Acc : 0.7350 | Eval Log. Respected : 0.9927
     Batch 000 | Loss : 0.4493 | Acc : 0.7749
     Batch 025 | Loss : 0.5026 | Acc : 0.7348
     Batch 050 | Loss : 0.4467 | Acc : 0.7722
     Batch 075 | Loss : 0.4563 | Acc : 0.7848
     Batch 100 | Loss : 0.5466 | Acc : 0.7011
     Batch 125 | Loss : 0.5375 | Acc : 0.7237
     Batch 150 | Loss : 0.5136 | Acc : 0.7304
     Batch 175 | Loss : 0.4394 | Acc : 0.7655
     Batch 200 | Loss : 0.4500 | Acc : 0.7703
     Batch 225 | Loss : 0.5717 | Acc : 0.6973
     Batch 250 | Loss : 0.5260 | Acc : 0.7206
     Batch 275 | Loss : 0.4699 | Acc : 0.7581
     Batch 300 | Loss : 0.4898 | Acc : 0.7445
Epoch 00005 | Train Loss : 0.4881 | Eval Loss : 0.4803 | Train acc : 0.7483 | Eval Acc : 0.7435 | Eval Log. Respected : 1.0000
     Batch 000 | Loss : 0.3997 | Acc : 0.8150
     Batch 025 | Loss : 0.4625 | Acc : 0.7634
     Batch 050 | Loss : 0.4829 | Acc : 0.7475
     Batch 075 | Loss : 0.4519 | Acc : 0.7738
     Batch 100 | Loss : 0.5105 | Acc : 0.7274
     Batch 125 | Loss : 0.4941 | Acc : 0.7449
     Batch 150 | Loss : 0.3971 | Acc : 0.7999
     Batch 175 | Loss : 0.4953 | Acc : 0.7402
     Batch 200 | Loss : 0.4455 | Acc : 0.7801
     Batch 225 | Loss : 0.4893 | Acc : 0.7550
     Batch 250 | Loss : 0.3990 | Acc : 0.8062
     Batch 275 | Loss : 0.4050 | Acc : 0.7959
     Batch 300 | Loss : 0.4995 | Acc : 0.7464
Epoch 00006 | Train Loss : 0.4792 | Eval Loss : 0.4719 | Train acc : 0.7552 | Eval Acc : 0.7506 | Eval Log. Respected : 0.9971
     Batch 000 | Loss : 0.4669 | Acc : 0.7559
     Batch 025 | Loss : 0.5231 | Acc : 0.7422
     Batch 050 | Loss : 0.4791 | Acc : 0.7559
     Batch 075 | Loss : 0.4843 | Acc : 0.7634
     Batch 100 | Loss : 0.5405 | Acc : 0.7304
     Batch 125 | Loss : 0.4769 | Acc : 0.7528
     Batch 150 | Loss : 0.4915 | Acc : 0.7382
     Batch 175 | Loss : 0.5074 | Acc : 0.7479
     Batch 200 | Loss : 0.5226 | Acc : 0.7252
     Batch 225 | Loss : 0.4829 | Acc : 0.7490
     Batch 250 | Loss : 0.4637 | Acc : 0.7590
     Batch 275 | Loss : 0.4306 | Acc : 0.7878
     Batch 300 | Loss : 0.4604 | Acc : 0.7658
Epoch 00007 | Train Loss : 0.4739 | Eval Loss : 0.4676 | Train acc : 0.7583 | Eval Acc : 0.7526 | Eval Log. Respected : 0.9862
     Batch 000 | Loss : 0.4274 | Acc : 0.7772
     Batch 025 | Loss : 0.5729 | Acc : 0.6933
     Batch 050 | Loss : 0.4457 | Acc : 0.7847
     Batch 075 | Loss : 0.4298 | Acc : 0.7846
     Batch 100 | Loss : 0.4208 | Acc : 0.7944
     Batch 125 | Loss : 0.5564 | Acc : 0.7149
     Batch 150 | Loss : 0.6331 | Acc : 0.6729
     Batch 175 | Loss : 0.4991 | Acc : 0.7374
     Batch 200 | Loss : 0.5374 | Acc : 0.7260
     Batch 225 | Loss : 0.4103 | Acc : 0.8021
     Batch 250 | Loss : 0.3968 | Acc : 0.8100
     Batch 275 | Loss : 0.4533 | Acc : 0.7700
     Batch 300 | Loss : 0.5101 | Acc : 0.7343
Epoch 00008 | Train Loss : 0.4693 | Eval Loss : 0.4695 | Train acc : 0.7609 | Eval Acc : 0.7519 | Eval Log. Respected : 0.9907
     Batch 000 | Loss : 0.4903 | Acc : 0.7419
     Batch 025 | Loss : 0.4848 | Acc : 0.7445
     Batch 050 | Loss : 0.4505 | Acc : 0.7660
     Batch 075 | Loss : 0.5179 | Acc : 0.7154
     Batch 100 | Loss : 0.4720 | Acc : 0.7556
     Batch 125 | Loss : 0.5301 | Acc : 0.7266
     Batch 150 | Loss : 0.4908 | Acc : 0.7492
     Batch 175 | Loss : 0.4024 | Acc : 0.8127
     Batch 200 | Loss : 0.4476 | Acc : 0.7968
     Batch 225 | Loss : 0.4869 | Acc : 0.7428
     Batch 250 | Loss : 0.4396 | Acc : 0.7767
     Batch 275 | Loss : 0.5314 | Acc : 0.7301
     Batch 300 | Loss : 0.4190 | Acc : 0.8001
Epoch 00009 | Train Loss : 0.4683 | Eval Loss : 0.4642 | Train acc : 0.7627 | Eval Acc : 0.7579 | Eval Log. Respected : 0.9958
     Batch 000 | Loss : 0.6026 | Acc : 0.6849
     Batch 025 | Loss : 0.4441 | Acc : 0.7753
     Batch 050 | Loss : 0.3940 | Acc : 0.8018
     Batch 075 | Loss : 0.5157 | Acc : 0.7270
     Batch 100 | Loss : 0.4254 | Acc : 0.7814
     Batch 125 | Loss : 0.5413 | Acc : 0.7168
     Batch 150 | Loss : 0.4003 | Acc : 0.8092
     Batch 175 | Loss : 0.4130 | Acc : 0.7950
     Batch 200 | Loss : 0.5244 | Acc : 0.7298
     Batch 225 | Loss : 0.4956 | Acc : 0.7359
     Batch 250 | Loss : 0.5101 | Acc : 0.7304
     Batch 275 | Loss : 0.4231 | Acc : 0.8158
     Batch 300 | Loss : 0.3949 | Acc : 0.8091
Epoch 00010 | Train Loss : 0.4648 | Eval Loss : 0.4581 | Train acc : 0.7647 | Eval Acc : 0.7613 | Eval Log. Respected : 0.9935
     Batch 000 | Loss : 0.4528 | Acc : 0.7625
     Batch 025 | Loss : 0.5751 | Acc : 0.6829
     Batch 050 | Loss : 0.4685 | Acc : 0.7555
     Batch 075 | Loss : 0.5309 | Acc : 0.7246
     Batch 100 | Loss : 0.4598 | Acc : 0.7685
     Batch 125 | Loss : 0.4515 | Acc : 0.7699
     Batch 150 | Loss : 0.3713 | Acc : 0.8212
     Batch 175 | Loss : 0.4792 | Acc : 0.7424
     Batch 200 | Loss : 0.4511 | Acc : 0.7732
     Batch 225 | Loss : 0.4566 | Acc : 0.7706
     Batch 250 | Loss : 0.4004 | Acc : 0.8113
     Batch 275 | Loss : 0.5145 | Acc : 0.7189
     Batch 300 | Loss : 0.4527 | Acc : 0.7915
Epoch 00011 | Train Loss : 0.4609 | Eval Loss : 0.4513 | Train acc : 0.7670 | Eval Acc : 0.7664 | Eval Log. Respected : 0.9589
     Batch 000 | Loss : 0.4838 | Acc : 0.7491
     Batch 025 | Loss : 0.4792 | Acc : 0.7821
     Batch 050 | Loss : 0.4414 | Acc : 0.7841
     Batch 075 | Loss : 0.4889 | Acc : 0.7468
     Batch 100 | Loss : 0.4336 | Acc : 0.7850
     Batch 125 | Loss : 0.4425 | Acc : 0.7812
     Batch 150 | Loss : 0.3840 | Acc : 0.8167
     Batch 175 | Loss : 0.5336 | Acc : 0.7299
     Batch 200 | Loss : 0.4567 | Acc : 0.7719
     Batch 225 | Loss : 0.4176 | Acc : 0.7867
     Batch 250 | Loss : 0.4394 | Acc : 0.7833
     Batch 275 | Loss : 0.4978 | Acc : 0.7509
     Batch 300 | Loss : 0.3743 | Acc : 0.8267
Epoch 00012 | Train Loss : 0.4585 | Eval Loss : 0.4519 | Train acc : 0.7701 | Eval Acc : 0.7671 | Eval Log. Respected : 0.9586
     Batch 000 | Loss : 0.4293 | Acc : 0.7836
     Batch 025 | Loss : 0.5412 | Acc : 0.7115
     Batch 050 | Loss : 0.4390 | Acc : 0.7830
     Batch 075 | Loss : 0.4645 | Acc : 0.7630
     Batch 100 | Loss : 0.5228 | Acc : 0.7094
     Batch 125 | Loss : 0.4137 | Acc : 0.7832
     Batch 150 | Loss : 0.3910 | Acc : 0.8097
     Batch 175 | Loss : 0.4312 | Acc : 0.7792
     Batch 200 | Loss : 0.4932 | Acc : 0.7385
     Batch 225 | Loss : 0.4673 | Acc : 0.7615
     Batch 250 | Loss : 0.4836 | Acc : 0.7544
     Batch 275 | Loss : 0.6345 | Acc : 0.6693
     Batch 300 | Loss : 0.4620 | Acc : 0.7606
Epoch 00013 | Train Loss : 0.4694 | Eval Loss : 0.4687 | Train acc : 0.7600 | Eval Acc : 0.7481 | Eval Log. Respected : 0.9669
     Batch 000 | Loss : 0.5284 | Acc : 0.7196
     Batch 025 | Loss : 0.4032 | Acc : 0.7973
     Batch 050 | Loss : 0.4746 | Acc : 0.7541
     Batch 075 | Loss : 0.4965 | Acc : 0.7659
     Batch 100 | Loss : 0.4918 | Acc : 0.7405
     Batch 125 | Loss : 0.5611 | Acc : 0.6996
     Batch 150 | Loss : 0.4850 | Acc : 0.7455
     Batch 175 | Loss : 0.3969 | Acc : 0.7951
     Batch 200 | Loss : 0.4998 | Acc : 0.7298
     Batch 225 | Loss : 0.5054 | Acc : 0.7419
     Batch 250 | Loss : 0.5910 | Acc : 0.6942
     Batch 275 | Loss : 0.4356 | Acc : 0.7878
     Batch 300 | Loss : 0.4771 | Acc : 0.7658
Epoch 00014 | Train Loss : 0.4734 | Eval Loss : 0.4763 | Train acc : 0.7561 | Eval Acc : 0.7523 | Eval Log. Respected : 0.9929
     Batch 000 | Loss : 0.4517 | Acc : 0.7752
     Batch 025 | Loss : 0.4583 | Acc : 0.7679
     Batch 050 | Loss : 0.4813 | Acc : 0.7534
     Batch 075 | Loss : 0.3462 | Acc : 0.8512
     Batch 100 | Loss : 0.3685 | Acc : 0.8299
     Batch 125 | Loss : 0.4488 | Acc : 0.7798
     Batch 150 | Loss : 0.4833 | Acc : 0.7669
     Batch 175 | Loss : 0.4250 | Acc : 0.7970
     Batch 200 | Loss : 0.4159 | Acc : 0.7974
     Batch 225 | Loss : 0.3458 | Acc : 0.8526
     Batch 250 | Loss : 0.4501 | Acc : 0.7683
     Batch 275 | Loss : 0.3609 | Acc : 0.8352
     Batch 300 | Loss : 0.3424 | Acc : 0.8419
Epoch 00015 | Train Loss : 0.4072 | Eval Loss : 0.3703 | Train acc : 0.8067 | Eval Acc : 0.8258 | Eval Log. Respected : 0.9568
     Batch 000 | Loss : 0.3309 | Acc : 0.8431
     Batch 025 | Loss : 0.3293 | Acc : 0.8502
     Batch 050 | Loss : 0.3388 | Acc : 0.8473
     Batch 075 | Loss : 0.3281 | Acc : 0.8539
     Batch 100 | Loss : 0.3613 | Acc : 0.8306
     Batch 125 | Loss : 0.3365 | Acc : 0.8459
     Batch 150 | Loss : 0.3974 | Acc : 0.8100
     Batch 175 | Loss : 0.3588 | Acc : 0.8328
     Batch 200 | Loss : 0.3382 | Acc : 0.8475
     Batch 225 | Loss : 0.3566 | Acc : 0.8371
     Batch 250 | Loss : 0.3546 | Acc : 0.8334
     Batch 275 | Loss : 0.3641 | Acc : 0.8307
     Batch 300 | Loss : 0.3996 | Acc : 0.8036
Epoch 00016 | Train Loss : 0.3690 | Eval Loss : 0.3670 | Train acc : 0.8293 | Eval Acc : 0.8290 | Eval Log. Respected : 0.9562
     Batch 000 | Loss : 0.3806 | Acc : 0.8298
     Batch 025 | Loss : 0.3569 | Acc : 0.8292
     Batch 050 | Loss : 0.3768 | Acc : 0.8214
     Batch 075 | Loss : 0.3512 | Acc : 0.8453
     Batch 100 | Loss : 0.3120 | Acc : 0.8539
     Batch 125 | Loss : 0.3367 | Acc : 0.8442
     Batch 150 | Loss : 0.3435 | Acc : 0.8436
     Batch 175 | Loss : 0.3993 | Acc : 0.8057
     Batch 200 | Loss : 0.4609 | Acc : 0.7819
     Batch 225 | Loss : 0.3592 | Acc : 0.8349
     Batch 250 | Loss : 0.3522 | Acc : 0.8400
     Batch 275 | Loss : 0.3728 | Acc : 0.8183
     Batch 300 | Loss : 0.4176 | Acc : 0.8021
Epoch 00017 | Train Loss : 0.3599 | Eval Loss : 0.3544 | Train acc : 0.8343 | Eval Acc : 0.8348 | Eval Log. Respected : 0.9531
     Batch 000 | Loss : 0.3045 | Acc : 0.8694
     Batch 025 | Loss : 0.3659 | Acc : 0.8402
     Batch 050 | Loss : 0.3118 | Acc : 0.8581
     Batch 075 | Loss : 0.3816 | Acc : 0.8189
     Batch 100 | Loss : 0.4786 | Acc : 0.7749
     Batch 125 | Loss : 0.3775 | Acc : 0.8270
     Batch 150 | Loss : 0.4252 | Acc : 0.8000
     Batch 175 | Loss : 0.3676 | Acc : 0.8313
     Batch 200 | Loss : 0.3913 | Acc : 0.8140
     Batch 225 | Loss : 0.4825 | Acc : 0.7952
     Batch 250 | Loss : 0.4140 | Acc : 0.7947
     Batch 275 | Loss : 0.3230 | Acc : 0.8527
     Batch 300 | Loss : 0.3564 | Acc : 0.8330
Epoch 00018 | Train Loss : 0.3556 | Eval Loss : 0.3520 | Train acc : 0.8368 | Eval Acc : 0.8376 | Eval Log. Respected : 0.9443
     Batch 000 | Loss : 0.3760 | Acc : 0.8191
     Batch 025 | Loss : 0.4095 | Acc : 0.8055
     Batch 050 | Loss : 0.3071 | Acc : 0.8651
     Batch 075 | Loss : 0.3388 | Acc : 0.8482
     Batch 100 | Loss : 0.4457 | Acc : 0.7906
     Batch 125 | Loss : 0.3571 | Acc : 0.8344
     Batch 150 | Loss : 0.3079 | Acc : 0.8652
     Batch 175 | Loss : 0.3838 | Acc : 0.8209
     Batch 200 | Loss : 0.2996 | Acc : 0.8712
     Batch 225 | Loss : 0.3373 | Acc : 0.8466
     Batch 250 | Loss : 0.3395 | Acc : 0.8466
     Batch 275 | Loss : 0.3309 | Acc : 0.8463
     Batch 300 | Loss : 0.4462 | Acc : 0.7929
Epoch 00019 | Train Loss : 0.3519 | Eval Loss : 0.3552 | Train acc : 0.8389 | Eval Acc : 0.8355 | Eval Log. Respected : 0.9615
     Batch 000 | Loss : 0.3087 | Acc : 0.8653
     Batch 025 | Loss : 0.3584 | Acc : 0.8359
     Batch 050 | Loss : 0.3118 | Acc : 0.8573
     Batch 075 | Loss : 0.3233 | Acc : 0.8540
     Batch 100 | Loss : 0.3105 | Acc : 0.8626
     Batch 125 | Loss : 0.3758 | Acc : 0.8211
     Batch 150 | Loss : 0.2970 | Acc : 0.8695
     Batch 175 | Loss : 0.3143 | Acc : 0.8682
     Batch 200 | Loss : 0.3313 | Acc : 0.8530
     Batch 225 | Loss : 0.4051 | Acc : 0.8041
     Batch 250 | Loss : 0.3453 | Acc : 0.8450
     Batch 275 | Loss : 0.2957 | Acc : 0.8706
     Batch 300 | Loss : 0.3739 | Acc : 0.8298
Epoch 00020 | Train Loss : 0.3507 | Eval Loss : 0.3486 | Train acc : 0.8399 | Eval Acc : 0.8390 | Eval Log. Respected : 0.9573
     Batch 000 | Loss : 0.3175 | Acc : 0.8503
     Batch 025 | Loss : 0.3838 | Acc : 0.8225
     Batch 050 | Loss : 0.3331 | Acc : 0.8492
     Batch 075 | Loss : 0.3229 | Acc : 0.8525
     Batch 100 | Loss : 0.3860 | Acc : 0.8167
     Batch 125 | Loss : 0.3283 | Acc : 0.8467
     Batch 150 | Loss : 0.3874 | Acc : 0.8220
     Batch 175 | Loss : 0.3446 | Acc : 0.8385
     Batch 200 | Loss : 0.3477 | Acc : 0.8462
     Batch 225 | Loss : 0.4003 | Acc : 0.8056
     Batch 250 | Loss : 0.2919 | Acc : 0.8747
     Batch 275 | Loss : 0.3168 | Acc : 0.8556
     Batch 300 | Loss : 0.3898 | Acc : 0.8102
Epoch 00021 | Train Loss : 0.3486 | Eval Loss : 0.3483 | Train acc : 0.8409 | Eval Acc : 0.8390 | Eval Log. Respected : 0.9463
     Batch 000 | Loss : 0.3244 | Acc : 0.8536
     Batch 025 | Loss : 0.3931 | Acc : 0.8131
     Batch 050 | Loss : 0.3534 | Acc : 0.8342
     Batch 075 | Loss : 0.4098 | Acc : 0.8037
     Batch 100 | Loss : 0.3821 | Acc : 0.8271
     Batch 125 | Loss : 0.3578 | Acc : 0.8346
     Batch 150 | Loss : 0.4039 | Acc : 0.8133
     Batch 175 | Loss : 0.3119 | Acc : 0.8716
     Batch 200 | Loss : 0.2762 | Acc : 0.8802
     Batch 225 | Loss : 0.3087 | Acc : 0.8720
     Batch 250 | Loss : 0.3082 | Acc : 0.8570
     Batch 275 | Loss : 0.3098 | Acc : 0.8656
     Batch 300 | Loss : 0.3489 | Acc : 0.8400
Epoch 00022 | Train Loss : 0.3474 | Eval Loss : 0.3447 | Train acc : 0.8419 | Eval Acc : 0.8414 | Eval Log. Respected : 0.9475
     Batch 000 | Loss : 0.4067 | Acc : 0.8117
     Batch 025 | Loss : 0.3687 | Acc : 0.8187
     Batch 050 | Loss : 0.3206 | Acc : 0.8551
     Batch 075 | Loss : 0.3883 | Acc : 0.8147
     Batch 100 | Loss : 0.3192 | Acc : 0.8548
     Batch 125 | Loss : 0.2881 | Acc : 0.8729
     Batch 150 | Loss : 0.3387 | Acc : 0.8454
     Batch 175 | Loss : 0.3274 | Acc : 0.8455
     Batch 200 | Loss : 0.3643 | Acc : 0.8380
     Batch 225 | Loss : 0.2903 | Acc : 0.8720
     Batch 250 | Loss : 0.3050 | Acc : 0.8659
     Batch 275 | Loss : 0.5346 | Acc : 0.7674
     Batch 300 | Loss : 0.4362 | Acc : 0.7902
Epoch 00023 | Train Loss : 0.3468 | Eval Loss : 0.3432 | Train acc : 0.8422 | Eval Acc : 0.8431 | Eval Log. Respected : 0.9490
     Batch 000 | Loss : 0.2850 | Acc : 0.8793
     Batch 025 | Loss : 0.3037 | Acc : 0.8761
     Batch 050 | Loss : 0.3453 | Acc : 0.8353
     Batch 075 | Loss : 0.3688 | Acc : 0.8277
     Batch 100 | Loss : 0.3183 | Acc : 0.8530
     Batch 125 | Loss : 0.3133 | Acc : 0.8645
     Batch 150 | Loss : 0.3593 | Acc : 0.8314
     Batch 175 | Loss : 0.3611 | Acc : 0.8309
     Batch 200 | Loss : 0.3213 | Acc : 0.8629
     Batch 225 | Loss : 0.3421 | Acc : 0.8448
     Batch 250 | Loss : 0.3616 | Acc : 0.8374
     Batch 275 | Loss : 0.3204 | Acc : 0.8598
     Batch 300 | Loss : 0.3048 | Acc : 0.8645
Epoch 00024 | Train Loss : 0.3461 | Eval Loss : 0.3449 | Train acc : 0.8426 | Eval Acc : 0.8421 | Eval Log. Respected : 0.9553
     Batch 000 | Loss : 0.3074 | Acc : 0.8612
     Batch 025 | Loss : 0.3035 | Acc : 0.8682
     Batch 050 | Loss : 0.3777 | Acc : 0.8182
     Batch 075 | Loss : 0.3558 | Acc : 0.8341
     Batch 100 | Loss : 0.3270 | Acc : 0.8518
     Batch 125 | Loss : 0.5288 | Acc : 0.7736
     Batch 150 | Loss : 0.3536 | Acc : 0.8301
     Batch 175 | Loss : 0.3173 | Acc : 0.8599
     Batch 200 | Loss : 0.3672 | Acc : 0.8343
     Batch 225 | Loss : 0.3620 | Acc : 0.8274
     Batch 250 | Loss : 0.3308 | Acc : 0.8473
     Batch 275 | Loss : 0.3067 | Acc : 0.8626
     Batch 300 | Loss : 0.3160 | Acc : 0.8550
Epoch 00025 | Train Loss : 0.3448 | Eval Loss : 0.3419 | Train acc : 0.8432 | Eval Acc : 0.8438 | Eval Log. Respected : 0.9471
     Batch 000 | Loss : 0.3933 | Acc : 0.8156
     Batch 025 | Loss : 0.3070 | Acc : 0.8653
     Batch 050 | Loss : 0.3039 | Acc : 0.8686
     Batch 075 | Loss : 0.3387 | Acc : 0.8459
     Batch 100 | Loss : 0.3077 | Acc : 0.8625
     Batch 125 | Loss : 0.3501 | Acc : 0.8391
     Batch 150 | Loss : 0.2916 | Acc : 0.8720
     Batch 175 | Loss : 0.3119 | Acc : 0.8597
     Batch 200 | Loss : 0.3265 | Acc : 0.8542
     Batch 225 | Loss : 0.2788 | Acc : 0.8866
     Batch 250 | Loss : 0.3731 | Acc : 0.8269
     Batch 275 | Loss : 0.3576 | Acc : 0.8344
     Batch 300 | Loss : 0.3051 | Acc : 0.8615
Epoch 00026 | Train Loss : 0.3442 | Eval Loss : 0.3513 | Train acc : 0.8435 | Eval Acc : 0.8398 | Eval Log. Respected : 0.9422
     Batch 000 | Loss : 0.4303 | Acc : 0.8014
     Batch 025 | Loss : 0.3473 | Acc : 0.8391
     Batch 050 | Loss : 0.3631 | Acc : 0.8317
     Batch 075 | Loss : 0.3476 | Acc : 0.8439
     Batch 100 | Loss : 0.3463 | Acc : 0.8405
     Batch 125 | Loss : 0.3951 | Acc : 0.8172
     Batch 150 | Loss : 0.3823 | Acc : 0.8240
     Batch 175 | Loss : 0.3162 | Acc : 0.8529
     Batch 200 | Loss : 0.4235 | Acc : 0.8006
     Batch 225 | Loss : 0.3222 | Acc : 0.8543
     Batch 250 | Loss : 0.3281 | Acc : 0.8528
     Batch 275 | Loss : 0.3354 | Acc : 0.8499
     Batch 300 | Loss : 0.2612 | Acc : 0.8900
Epoch 00027 | Train Loss : 0.3433 | Eval Loss : 0.3450 | Train acc : 0.8439 | Eval Acc : 0.8421 | Eval Log. Respected : 0.9461
     Batch 000 | Loss : 0.2735 | Acc : 0.8858
     Batch 025 | Loss : 0.3962 | Acc : 0.8148
     Batch 050 | Loss : 0.3587 | Acc : 0.8332
     Batch 075 | Loss : 0.3127 | Acc : 0.8589
     Batch 100 | Loss : 0.2875 | Acc : 0.8714
     Batch 125 | Loss : 0.3227 | Acc : 0.8533
     Batch 150 | Loss : 0.3353 | Acc : 0.8419
     Batch 175 | Loss : 0.3251 | Acc : 0.8494
     Batch 200 | Loss : 0.2861 | Acc : 0.8721
     Batch 225 | Loss : 0.3338 | Acc : 0.8488
     Batch 250 | Loss : 0.2922 | Acc : 0.8710
     Batch 275 | Loss : 0.3008 | Acc : 0.8729
     Batch 300 | Loss : 0.3850 | Acc : 0.8138
Epoch 00028 | Train Loss : 0.3421 | Eval Loss : 0.3441 | Train acc : 0.8442 | Eval Acc : 0.8408 | Eval Log. Respected : 0.9515
     Batch 000 | Loss : 0.4202 | Acc : 0.8048
     Batch 025 | Loss : 0.3233 | Acc : 0.8584
     Batch 050 | Loss : 0.3666 | Acc : 0.8294
     Batch 075 | Loss : 0.3270 | Acc : 0.8484
     Batch 100 | Loss : 0.3673 | Acc : 0.8292
     Batch 125 | Loss : 0.4357 | Acc : 0.7923
     Batch 150 | Loss : 0.3182 | Acc : 0.8575
     Batch 175 | Loss : 0.4020 | Acc : 0.8246
     Batch 200 | Loss : 0.3162 | Acc : 0.8567
     Batch 225 | Loss : 0.2962 | Acc : 0.8732
     Batch 250 | Loss : 0.3292 | Acc : 0.8508
     Batch 275 | Loss : 0.3025 | Acc : 0.8663
     Batch 300 | Loss : 0.4572 | Acc : 0.8081
Epoch 00029 | Train Loss : 0.3411 | Eval Loss : 0.3391 | Train acc : 0.8443 | Eval Acc : 0.8434 | Eval Log. Respected : 0.9459
     Batch 000 | Loss : 0.3659 | Acc : 0.8303
     Batch 025 | Loss : 0.3516 | Acc : 0.8302
     Batch 050 | Loss : 0.3373 | Acc : 0.8490
     Batch 075 | Loss : 0.4083 | Acc : 0.8004
     Batch 100 | Loss : 0.2920 | Acc : 0.8758
     Batch 125 | Loss : 0.3468 | Acc : 0.8448
     Batch 150 | Loss : 0.3303 | Acc : 0.8491
     Batch 175 | Loss : 0.3534 | Acc : 0.8411
     Batch 200 | Loss : 0.3360 | Acc : 0.8433
     Batch 225 | Loss : 0.3881 | Acc : 0.8172
     Batch 250 | Loss : 0.2893 | Acc : 0.8707
     Batch 275 | Loss : 0.3145 | Acc : 0.8555
     Batch 300 | Loss : 0.3110 | Acc : 0.8618
Epoch 00030 | Train Loss : 0.3400 | Eval Loss : 0.3394 | Train acc : 0.8448 | Eval Acc : 0.8437 | Eval Log. Respected : 0.9355
     Batch 000 | Loss : 0.4604 | Acc : 0.7851
     Batch 025 | Loss : 0.2992 | Acc : 0.8711
     Batch 050 | Loss : 0.3333 | Acc : 0.8450
     Batch 075 | Loss : 0.3291 | Acc : 0.8498
     Batch 100 | Loss : 0.2996 | Acc : 0.8681
     Batch 125 | Loss : 0.3650 | Acc : 0.8295
     Batch 150 | Loss : 0.4295 | Acc : 0.7998
     Batch 175 | Loss : 0.2932 | Acc : 0.8701
     Batch 200 | Loss : 0.3654 | Acc : 0.8327
     Batch 225 | Loss : 0.3308 | Acc : 0.8473
     Batch 250 | Loss : 0.3750 | Acc : 0.8199
     Batch 275 | Loss : 0.3628 | Acc : 0.8320
     Batch 300 | Loss : 0.3633 | Acc : 0.8364
Epoch 00031 | Train Loss : 0.3387 | Eval Loss : 0.3383 | Train acc : 0.8450 | Eval Acc : 0.8422 | Eval Log. Respected : 0.9397
     Batch 000 | Loss : 0.3210 | Acc : 0.8535
     Batch 025 | Loss : 0.3973 | Acc : 0.8119
     Batch 050 | Loss : 0.4341 | Acc : 0.7966
     Batch 075 | Loss : 0.3656 | Acc : 0.8293
     Batch 100 | Loss : 0.3529 | Acc : 0.8342
     Batch 125 | Loss : 0.3345 | Acc : 0.8433
     Batch 150 | Loss : 0.2978 | Acc : 0.8681
     Batch 175 | Loss : 0.3764 | Acc : 0.8297
     Batch 200 | Loss : 0.2860 | Acc : 0.8745
     Batch 225 | Loss : 0.2829 | Acc : 0.8708
     Batch 250 | Loss : 0.3622 | Acc : 0.8265
     Batch 275 | Loss : 0.3794 | Acc : 0.8308
     Batch 300 | Loss : 0.2982 | Acc : 0.8622
Epoch 00032 | Train Loss : 0.3373 | Eval Loss : 0.3474 | Train acc : 0.8453 | Eval Acc : 0.8403 | Eval Log. Respected : 0.9464
     Batch 000 | Loss : 0.3539 | Acc : 0.8450
     Batch 025 | Loss : 0.3591 | Acc : 0.8338
     Batch 050 | Loss : 0.3376 | Acc : 0.8486
     Batch 075 | Loss : 0.3387 | Acc : 0.8477
     Batch 100 | Loss : 0.3131 | Acc : 0.8591
     Batch 125 | Loss : 0.3064 | Acc : 0.8619
     Batch 150 | Loss : 0.3483 | Acc : 0.8408
     Batch 175 | Loss : 0.3812 | Acc : 0.8204
     Batch 200 | Loss : 0.4016 | Acc : 0.8063
     Batch 225 | Loss : 0.2806 | Acc : 0.8779
     Batch 250 | Loss : 0.3007 | Acc : 0.8677
     Batch 275 | Loss : 0.3873 | Acc : 0.8228
     Batch 300 | Loss : 0.2915 | Acc : 0.8676
Epoch 00033 | Train Loss : 0.3360 | Eval Loss : 0.3365 | Train acc : 0.8458 | Eval Acc : 0.8432 | Eval Log. Respected : 0.9318
     Batch 000 | Loss : 0.3720 | Acc : 0.8253
     Batch 025 | Loss : 0.3833 | Acc : 0.8254
     Batch 050 | Loss : 0.2887 | Acc : 0.8697
     Batch 075 | Loss : 0.3470 | Acc : 0.8402
     Batch 100 | Loss : 0.4292 | Acc : 0.7904
     Batch 125 | Loss : 0.3285 | Acc : 0.8466
     Batch 150 | Loss : 0.3149 | Acc : 0.8526
     Batch 175 | Loss : 0.2991 | Acc : 0.8663
     Batch 200 | Loss : 0.3169 | Acc : 0.8597
     Batch 225 | Loss : 0.2750 | Acc : 0.8796
     Batch 250 | Loss : 0.2613 | Acc : 0.8857
     Batch 275 | Loss : 0.3470 | Acc : 0.8317
     Batch 300 | Loss : 0.2984 | Acc : 0.8658
Epoch 00034 | Train Loss : 0.3360 | Eval Loss : 0.3362 | Train acc : 0.8460 | Eval Acc : 0.8438 | Eval Log. Respected : 0.9365
     Batch 000 | Loss : 0.3414 | Acc : 0.8448
     Batch 025 | Loss : 0.2784 | Acc : 0.8777
     Batch 050 | Loss : 0.3158 | Acc : 0.8530
     Batch 075 | Loss : 0.3740 | Acc : 0.8189
     Batch 100 | Loss : 0.3007 | Acc : 0.8692
     Batch 125 | Loss : 0.3659 | Acc : 0.8308
     Batch 150 | Loss : 0.3338 | Acc : 0.8480
     Batch 175 | Loss : 0.3952 | Acc : 0.8201
     Batch 200 | Loss : 0.2706 | Acc : 0.8814
     Batch 225 | Loss : 0.3222 | Acc : 0.8503
     Batch 250 | Loss : 0.3619 | Acc : 0.8322
     Batch 275 | Loss : 0.3699 | Acc : 0.8238
     Batch 300 | Loss : 0.3817 | Acc : 0.8233
Epoch 00035 | Train Loss : 0.3348 | Eval Loss : 0.3326 | Train acc : 0.8464 | Eval Acc : 0.8448 | Eval Log. Respected : 0.9293
     Batch 000 | Loss : 0.3922 | Acc : 0.8190
     Batch 025 | Loss : 0.2876 | Acc : 0.8754
     Batch 050 | Loss : 0.3134 | Acc : 0.8536
     Batch 075 | Loss : 0.3436 | Acc : 0.8363
     Batch 100 | Loss : 0.2795 | Acc : 0.8763
     Batch 125 | Loss : 0.3745 | Acc : 0.8247
     Batch 150 | Loss : 0.3605 | Acc : 0.8323
     Batch 175 | Loss : 0.3080 | Acc : 0.8654
     Batch 200 | Loss : 0.2959 | Acc : 0.8655
     Batch 225 | Loss : 0.3020 | Acc : 0.8630
     Batch 250 | Loss : 0.3446 | Acc : 0.8374
     Batch 275 | Loss : 0.3256 | Acc : 0.8524
     Batch 300 | Loss : 0.3263 | Acc : 0.8493
Epoch 00036 | Train Loss : 0.3342 | Eval Loss : 0.3335 | Train acc : 0.8467 | Eval Acc : 0.8441 | Eval Log. Respected : 0.9314
     Batch 000 | Loss : 0.3191 | Acc : 0.8526
     Batch 025 | Loss : 0.2878 | Acc : 0.8707
     Batch 050 | Loss : 0.2904 | Acc : 0.8643
     Batch 075 | Loss : 0.3448 | Acc : 0.8361
     Batch 100 | Loss : 0.3145 | Acc : 0.8541
     Batch 125 | Loss : 0.3098 | Acc : 0.8648
     Batch 150 | Loss : 0.2855 | Acc : 0.8699
     Batch 175 | Loss : 0.3295 | Acc : 0.8442
     Batch 200 | Loss : 0.2934 | Acc : 0.8643
     Batch 225 | Loss : 0.3605 | Acc : 0.8318
     Batch 250 | Loss : 0.4066 | Acc : 0.8078
     Batch 275 | Loss : 0.3468 | Acc : 0.8340
     Batch 300 | Loss : 0.3120 | Acc : 0.8589
Epoch 00037 | Train Loss : 0.3339 | Eval Loss : 0.3388 | Train acc : 0.8468 | Eval Acc : 0.8421 | Eval Log. Respected : 0.9309
     Batch 000 | Loss : 0.3339 | Acc : 0.8493
     Batch 025 | Loss : 0.3041 | Acc : 0.8587
     Batch 050 | Loss : 0.4196 | Acc : 0.8057
     Batch 075 | Loss : 0.3281 | Acc : 0.8474
     Batch 100 | Loss : 0.2994 | Acc : 0.8681
     Batch 125 | Loss : 0.3845 | Acc : 0.8130
     Batch 150 | Loss : 0.3685 | Acc : 0.8243
     Batch 175 | Loss : 0.2895 | Acc : 0.8690
     Batch 200 | Loss : 0.2881 | Acc : 0.8693
     Batch 225 | Loss : 0.3195 | Acc : 0.8510
     Batch 250 | Loss : 0.2782 | Acc : 0.8707
     Batch 275 | Loss : 0.3286 | Acc : 0.8545
     Batch 300 | Loss : 0.2967 | Acc : 0.8652
Epoch 00038 | Train Loss : 0.3334 | Eval Loss : 0.3309 | Train acc : 0.8470 | Eval Acc : 0.8464 | Eval Log. Respected : 0.9350
     Batch 000 | Loss : 0.2767 | Acc : 0.8784
     Batch 025 | Loss : 0.4270 | Acc : 0.7971
     Batch 050 | Loss : 0.3698 | Acc : 0.8203
     Batch 075 | Loss : 0.3132 | Acc : 0.8599
     Batch 100 | Loss : 0.3530 | Acc : 0.8367
     Batch 125 | Loss : 0.3879 | Acc : 0.8195
     Batch 150 | Loss : 0.3070 | Acc : 0.8620
     Batch 175 | Loss : 0.3043 | Acc : 0.8611
     Batch 200 | Loss : 0.3445 | Acc : 0.8359
     Batch 225 | Loss : 0.3864 | Acc : 0.8233
     Batch 250 | Loss : 0.3116 | Acc : 0.8558
     Batch 275 | Loss : 0.3389 | Acc : 0.8417
     Batch 300 | Loss : 0.2862 | Acc : 0.8657
Epoch 00039 | Train Loss : 0.3337 | Eval Loss : 0.3334 | Train acc : 0.8469 | Eval Acc : 0.8441 | Eval Log. Respected : 0.9342
     Batch 000 | Loss : 0.2951 | Acc : 0.8713
     Batch 025 | Loss : 0.2920 | Acc : 0.8715
     Batch 050 | Loss : 0.3132 | Acc : 0.8529
     Batch 075 | Loss : 0.3192 | Acc : 0.8505
     Batch 100 | Loss : 0.3419 | Acc : 0.8441
     Batch 125 | Loss : 0.3067 | Acc : 0.8662
     Batch 150 | Loss : 0.3577 | Acc : 0.8289
     Batch 175 | Loss : 0.3317 | Acc : 0.8437
     Batch 200 | Loss : 0.4525 | Acc : 0.7912
     Batch 225 | Loss : 0.2785 | Acc : 0.8720
     Batch 250 | Loss : 0.3180 | Acc : 0.8519
     Batch 275 | Loss : 0.3564 | Acc : 0.8287
     Batch 300 | Loss : 0.4090 | Acc : 0.8015
Epoch 00040 | Train Loss : 0.3320 | Eval Loss : 0.3416 | Train acc : 0.8476 | Eval Acc : 0.8398 | Eval Log. Respected : 0.9309
     Batch 000 | Loss : 0.3204 | Acc : 0.8594
     Batch 025 | Loss : 0.2727 | Acc : 0.8814
     Batch 050 | Loss : 0.3236 | Acc : 0.8553
     Batch 075 | Loss : 0.3829 | Acc : 0.8263
     Batch 100 | Loss : 0.3092 | Acc : 0.8581
     Batch 125 | Loss : 0.2956 | Acc : 0.8640
     Batch 150 | Loss : 0.3723 | Acc : 0.8293
     Batch 175 | Loss : 0.2732 | Acc : 0.8793
     Batch 200 | Loss : 0.2910 | Acc : 0.8722
     Batch 225 | Loss : 0.3626 | Acc : 0.8288
     Batch 250 | Loss : 0.3705 | Acc : 0.8223
     Batch 275 | Loss : 0.4436 | Acc : 0.7990
     Batch 300 | Loss : 0.3562 | Acc : 0.8347
Epoch 00041 | Train Loss : 0.3327 | Eval Loss : 0.3339 | Train acc : 0.8470 | Eval Acc : 0.8437 | Eval Log. Respected : 0.9338
     Batch 000 | Loss : 0.3721 | Acc : 0.8269
     Batch 025 | Loss : 0.5083 | Acc : 0.7787
     Batch 050 | Loss : 0.3133 | Acc : 0.8533
     Batch 075 | Loss : 0.2463 | Acc : 0.8919
     Batch 100 | Loss : 0.2969 | Acc : 0.8693
     Batch 125 | Loss : 0.2839 | Acc : 0.8708
     Batch 150 | Loss : 0.3487 | Acc : 0.8400
     Batch 175 | Loss : 0.3518 | Acc : 0.8320
     Batch 200 | Loss : 0.3282 | Acc : 0.8527
     Batch 225 | Loss : 0.3170 | Acc : 0.8521
     Batch 250 | Loss : 0.3226 | Acc : 0.8532
     Batch 275 | Loss : 0.2583 | Acc : 0.8866
     Batch 300 | Loss : 0.3041 | Acc : 0.8616
Epoch 00042 | Train Loss : 0.3310 | Eval Loss : 0.3366 | Train acc : 0.8479 | Eval Acc : 0.8455 | Eval Log. Respected : 0.9363
     Batch 000 | Loss : 0.2968 | Acc : 0.8667
     Batch 025 | Loss : 0.3018 | Acc : 0.8584
     Batch 050 | Loss : 0.2642 | Acc : 0.8797
     Batch 075 | Loss : 0.2801 | Acc : 0.8744
     Batch 100 | Loss : 0.3193 | Acc : 0.8552
     Batch 125 | Loss : 0.3245 | Acc : 0.8519
     Batch 150 | Loss : 0.2871 | Acc : 0.8652
     Batch 175 | Loss : 0.3215 | Acc : 0.8562
     Batch 200 | Loss : 0.3203 | Acc : 0.8488
     Batch 225 | Loss : 0.3241 | Acc : 0.8477
     Batch 250 | Loss : 0.2740 | Acc : 0.8749
     Batch 275 | Loss : 0.3300 | Acc : 0.8499
     Batch 300 | Loss : 0.3827 | Acc : 0.8206
Epoch 00043 | Train Loss : 0.3305 | Eval Loss : 0.3300 | Train acc : 0.8479 | Eval Acc : 0.8458 | Eval Log. Respected : 0.9325
     Batch 000 | Loss : 0.3255 | Acc : 0.8488
     Batch 025 | Loss : 0.2860 | Acc : 0.8740
     Batch 050 | Loss : 0.3518 | Acc : 0.8381
     Batch 075 | Loss : 0.3724 | Acc : 0.8227
     Batch 100 | Loss : 0.3024 | Acc : 0.8555
     Batch 125 | Loss : 0.3228 | Acc : 0.8521
     Batch 150 | Loss : 0.3471 | Acc : 0.8385
     Batch 175 | Loss : 0.3682 | Acc : 0.8259
     Batch 200 | Loss : 0.3678 | Acc : 0.8225
     Batch 225 | Loss : 0.3298 | Acc : 0.8485
     Batch 250 | Loss : 0.3704 | Acc : 0.8261
     Batch 275 | Loss : 0.3524 | Acc : 0.8348
     Batch 300 | Loss : 0.3478 | Acc : 0.8384
Epoch 00044 | Train Loss : 0.3297 | Eval Loss : 0.3499 | Train acc : 0.8483 | Eval Acc : 0.8343 | Eval Log. Respected : 0.9422
     Batch 000 | Loss : 0.2951 | Acc : 0.8646
     Batch 025 | Loss : 0.3738 | Acc : 0.8189
     Batch 050 | Loss : 0.3037 | Acc : 0.8599
     Batch 075 | Loss : 0.2797 | Acc : 0.8787
     Batch 100 | Loss : 0.3186 | Acc : 0.8560
     Batch 125 | Loss : 0.3527 | Acc : 0.8369
     Batch 150 | Loss : 0.3024 | Acc : 0.8560
     Batch 175 | Loss : 0.3022 | Acc : 0.8657
     Batch 200 | Loss : 0.3063 | Acc : 0.8626
     Batch 225 | Loss : 0.3082 | Acc : 0.8590
     Batch 250 | Loss : 0.4728 | Acc : 0.7790
     Batch 275 | Loss : 0.4300 | Acc : 0.8000
     Batch 300 | Loss : 0.3098 | Acc : 0.8559
Epoch 00045 | Train Loss : 0.3309 | Eval Loss : 0.3320 | Train acc : 0.8475 | Eval Acc : 0.8439 | Eval Log. Respected : 0.9338
     Batch 000 | Loss : 0.3099 | Acc : 0.8604
     Batch 025 | Loss : 0.3031 | Acc : 0.8569
     Batch 050 | Loss : 0.3388 | Acc : 0.8416
     Batch 075 | Loss : 0.3325 | Acc : 0.8424
     Batch 100 | Loss : 0.3195 | Acc : 0.8526
     Batch 125 | Loss : 0.3937 | Acc : 0.8172
     Batch 150 | Loss : 0.2771 | Acc : 0.8744
     Batch 175 | Loss : 0.3132 | Acc : 0.8561
     Batch 200 | Loss : 0.3121 | Acc : 0.8674
     Batch 225 | Loss : 0.3020 | Acc : 0.8637
     Batch 250 | Loss : 0.5449 | Acc : 0.7548
     Batch 275 | Loss : 0.3021 | Acc : 0.8617
     Batch 300 | Loss : 0.3085 | Acc : 0.8596
Epoch 00046 | Train Loss : 0.3302 | Eval Loss : 0.3291 | Train acc : 0.8480 | Eval Acc : 0.8464 | Eval Log. Respected : 0.9289
     Batch 000 | Loss : 0.3356 | Acc : 0.8418
     Batch 025 | Loss : 0.3504 | Acc : 0.8382
     Batch 050 | Loss : 0.2627 | Acc : 0.8841
     Batch 075 | Loss : 0.3762 | Acc : 0.8282
     Batch 100 | Loss : 0.2814 | Acc : 0.8717
     Batch 125 | Loss : 0.3083 | Acc : 0.8583
     Batch 150 | Loss : 0.3729 | Acc : 0.8235
     Batch 175 | Loss : 0.3092 | Acc : 0.8629
     Batch 200 | Loss : 0.3197 | Acc : 0.8517
     Batch 225 | Loss : 0.3671 | Acc : 0.8313
     Batch 250 | Loss : 0.3411 | Acc : 0.8370
     Batch 275 | Loss : 0.3592 | Acc : 0.8294
     Batch 300 | Loss : 0.3093 | Acc : 0.8593
Epoch 00047 | Train Loss : 0.3296 | Eval Loss : 0.3288 | Train acc : 0.8483 | Eval Acc : 0.8462 | Eval Log. Respected : 0.9315
     Batch 000 | Loss : 0.2750 | Acc : 0.8795
     Batch 025 | Loss : 0.2887 | Acc : 0.8666
     Batch 050 | Loss : 0.3895 | Acc : 0.8214
     Batch 075 | Loss : 0.2966 | Acc : 0.8637
     Batch 100 | Loss : 0.3525 | Acc : 0.8360
     Batch 125 | Loss : 0.2811 | Acc : 0.8753
     Batch 150 | Loss : 0.2967 | Acc : 0.8683
     Batch 175 | Loss : 0.2760 | Acc : 0.8791
     Batch 200 | Loss : 0.3201 | Acc : 0.8497
     Batch 225 | Loss : 0.3092 | Acc : 0.8560
     Batch 250 | Loss : 0.2829 | Acc : 0.8724
     Batch 275 | Loss : 0.2567 | Acc : 0.8825
     Batch 300 | Loss : 0.2904 | Acc : 0.8680
Epoch 00048 | Train Loss : 0.3296 | Eval Loss : 0.3301 | Train acc : 0.8484 | Eval Acc : 0.8459 | Eval Log. Respected : 0.9340
     Batch 000 | Loss : 0.4499 | Acc : 0.7862
     Batch 025 | Loss : 0.3208 | Acc : 0.8538
     Batch 050 | Loss : 0.3349 | Acc : 0.8445
     Batch 075 | Loss : 0.2739 | Acc : 0.8751
     Batch 100 | Loss : 0.3213 | Acc : 0.8474
     Batch 125 | Loss : 0.2744 | Acc : 0.8758
     Batch 150 | Loss : 0.2909 | Acc : 0.8643
     Batch 175 | Loss : 0.3391 | Acc : 0.8343
     Batch 200 | Loss : 0.3499 | Acc : 0.8412
     Batch 225 | Loss : 0.3235 | Acc : 0.8531
     Batch 250 | Loss : 0.4198 | Acc : 0.8042
     Batch 275 | Loss : 0.3593 | Acc : 0.8363
     Batch 300 | Loss : 0.3129 | Acc : 0.8547
Epoch 00049 | Train Loss : 0.3284 | Eval Loss : 0.3331 | Train acc : 0.8487 | Eval Acc : 0.8464 | Eval Log. Respected : 0.9348
     Batch 000 | Loss : 0.2608 | Acc : 0.8846
     Batch 025 | Loss : 0.3004 | Acc : 0.8580
     Batch 050 | Loss : 0.2679 | Acc : 0.8800
     Batch 075 | Loss : 0.2820 | Acc : 0.8734
     Batch 100 | Loss : 0.3739 | Acc : 0.8162
     Batch 125 | Loss : 0.2777 | Acc : 0.8764
     Batch 150 | Loss : 0.2672 | Acc : 0.8834
     Batch 175 | Loss : 0.2941 | Acc : 0.8709
     Batch 200 | Loss : 0.3629 | Acc : 0.8294
     Batch 225 | Loss : 0.2745 | Acc : 0.8789
     Batch 250 | Loss : 0.3510 | Acc : 0.8324
     Batch 275 | Loss : 0.3736 | Acc : 0.8303
     Batch 300 | Loss : 0.2723 | Acc : 0.8760
Epoch 00050 | Train Loss : 0.3277 | Eval Loss : 0.3269 | Train acc : 0.8491 | Eval Acc : 0.8479 | Eval Log. Respected : 0.9339
     Batch 000 | Loss : 0.3466 | Acc : 0.8345
     Batch 025 | Loss : 0.3948 | Acc : 0.8193
     Batch 050 | Loss : 0.3461 | Acc : 0.8395
     Batch 075 | Loss : 0.3917 | Acc : 0.8216
     Batch 100 | Loss : 0.3040 | Acc : 0.8633
     Batch 125 | Loss : 0.3048 | Acc : 0.8678
     Batch 150 | Loss : 0.2924 | Acc : 0.8694
     Batch 175 | Loss : 0.3309 | Acc : 0.8486
     Batch 200 | Loss : 0.2720 | Acc : 0.8805
     Batch 225 | Loss : 0.3696 | Acc : 0.8235
     Batch 250 | Loss : 0.3603 | Acc : 0.8353
     Batch 275 | Loss : 0.3240 | Acc : 0.8648
     Batch 300 | Loss : 0.3325 | Acc : 0.8463
Epoch 00051 | Train Loss : 0.3282 | Eval Loss : 0.3257 | Train acc : 0.8488 | Eval Acc : 0.8477 | Eval Log. Respected : 0.9336
     Batch 000 | Loss : 0.3605 | Acc : 0.8284
     Batch 025 | Loss : 0.2749 | Acc : 0.8810
     Batch 050 | Loss : 0.2816 | Acc : 0.8723
     Batch 075 | Loss : 0.3128 | Acc : 0.8582
     Batch 100 | Loss : 0.3754 | Acc : 0.8321
     Batch 125 | Loss : 0.3346 | Acc : 0.8458
     Batch 150 | Loss : 0.3290 | Acc : 0.8511
     Batch 175 | Loss : 0.3061 | Acc : 0.8613
     Batch 200 | Loss : 0.2817 | Acc : 0.8694
     Batch 225 | Loss : 0.3117 | Acc : 0.8545
     Batch 250 | Loss : 0.2874 | Acc : 0.8740
     Batch 275 | Loss : 0.3199 | Acc : 0.8556
     Batch 300 | Loss : 0.2618 | Acc : 0.8818
Epoch 00052 | Train Loss : 0.3281 | Eval Loss : 0.3286 | Train acc : 0.8490 | Eval Acc : 0.8455 | Eval Log. Respected : 0.9403
     Batch 000 | Loss : 0.2858 | Acc : 0.8706
     Batch 025 | Loss : 0.3152 | Acc : 0.8532
     Batch 050 | Loss : 0.2826 | Acc : 0.8797
     Batch 075 | Loss : 0.3469 | Acc : 0.8339
     Batch 100 | Loss : 0.4006 | Acc : 0.8059
     Batch 125 | Loss : 0.2624 | Acc : 0.8841
     Batch 150 | Loss : 0.3893 | Acc : 0.8246
     Batch 175 | Loss : 0.3705 | Acc : 0.8287
     Batch 200 | Loss : 0.2943 | Acc : 0.8665
     Batch 225 | Loss : 0.5272 | Acc : 0.7748
     Batch 250 | Loss : 0.3076 | Acc : 0.8584
     Batch 275 | Loss : 0.2729 | Acc : 0.8824
     Batch 300 | Loss : 0.3056 | Acc : 0.8637
Epoch 00053 | Train Loss : 0.3278 | Eval Loss : 0.3283 | Train acc : 0.8491 | Eval Acc : 0.8464 | Eval Log. Respected : 0.9349
     Batch 000 | Loss : 0.3498 | Acc : 0.8318
     Batch 025 | Loss : 0.3554 | Acc : 0.8313
     Batch 050 | Loss : 0.3019 | Acc : 0.8600
     Batch 075 | Loss : 0.3405 | Acc : 0.8435
     Batch 100 | Loss : 0.2899 | Acc : 0.8760
     Batch 125 | Loss : 0.3004 | Acc : 0.8671
     Batch 150 | Loss : 0.2821 | Acc : 0.8772
     Batch 175 | Loss : 0.4398 | Acc : 0.7890
     Batch 200 | Loss : 0.3180 | Acc : 0.8525
     Batch 225 | Loss : 0.3416 | Acc : 0.8398
     Batch 250 | Loss : 0.2521 | Acc : 0.8900
     Batch 275 | Loss : 0.3439 | Acc : 0.8408
     Batch 300 | Loss : 0.3259 | Acc : 0.8514
Epoch 00054 | Train Loss : 0.3272 | Eval Loss : 0.3320 | Train acc : 0.8492 | Eval Acc : 0.8458 | Eval Log. Respected : 0.9397
     Batch 000 | Loss : 0.3432 | Acc : 0.8439
     Batch 025 | Loss : 0.2682 | Acc : 0.8801
     Batch 050 | Loss : 0.3146 | Acc : 0.8531
     Batch 075 | Loss : 0.3139 | Acc : 0.8536
     Batch 100 | Loss : 0.3253 | Acc : 0.8472
     Batch 125 | Loss : 0.3442 | Acc : 0.8367
     Batch 150 | Loss : 0.3126 | Acc : 0.8554
     Batch 175 | Loss : 0.3461 | Acc : 0.8396
     Batch 200 | Loss : 0.3423 | Acc : 0.8408
     Batch 225 | Loss : 0.3014 | Acc : 0.8721
     Batch 250 | Loss : 0.2993 | Acc : 0.8604
     Batch 275 | Loss : 0.3156 | Acc : 0.8536
     Batch 300 | Loss : 0.3516 | Acc : 0.8271
Epoch 00055 | Train Loss : 0.3271 | Eval Loss : 0.3259 | Train acc : 0.8494 | Eval Acc : 0.8479 | Eval Log. Respected : 0.9341
     Batch 000 | Loss : 0.2714 | Acc : 0.8771
     Batch 025 | Loss : 0.3898 | Acc : 0.8138
     Batch 050 | Loss : 0.2672 | Acc : 0.8775
     Batch 075 | Loss : 0.3059 | Acc : 0.8621
     Batch 100 | Loss : 0.3803 | Acc : 0.8117
     Batch 125 | Loss : 0.2348 | Acc : 0.8956
     Batch 150 | Loss : 0.3420 | Acc : 0.8374
     Batch 175 | Loss : 0.3083 | Acc : 0.8528
     Batch 200 | Loss : 0.3009 | Acc : 0.8626
     Batch 225 | Loss : 0.2799 | Acc : 0.8754
     Batch 250 | Loss : 0.3776 | Acc : 0.8187
     Batch 275 | Loss : 0.3580 | Acc : 0.8279
     Batch 300 | Loss : 0.4420 | Acc : 0.8130
Epoch 00056 | Train Loss : 0.3268 | Eval Loss : 0.3264 | Train acc : 0.8492 | Eval Acc : 0.8474 | Eval Log. Respected : 0.9367
     Batch 000 | Loss : 0.3739 | Acc : 0.8238
     Batch 025 | Loss : 0.3091 | Acc : 0.8590
     Batch 050 | Loss : 0.3544 | Acc : 0.8318
     Batch 075 | Loss : 0.2756 | Acc : 0.8776
     Batch 100 | Loss : 0.3160 | Acc : 0.8589
     Batch 125 | Loss : 0.3006 | Acc : 0.8618
     Batch 150 | Loss : 0.2813 | Acc : 0.8701
     Batch 175 | Loss : 0.3611 | Acc : 0.8328
     Batch 200 | Loss : 0.2893 | Acc : 0.8700
     Batch 225 | Loss : 0.3641 | Acc : 0.8213
     Batch 250 | Loss : 0.2400 | Acc : 0.8983
     Batch 275 | Loss : 0.3256 | Acc : 0.8483
     Batch 300 | Loss : 0.2773 | Acc : 0.8753
Epoch 00057 | Train Loss : 0.3264 | Eval Loss : 0.3268 | Train acc : 0.8495 | Eval Acc : 0.8465 | Eval Log. Respected : 0.9362
     Batch 000 | Loss : 0.2750 | Acc : 0.8779
     Batch 025 | Loss : 0.3174 | Acc : 0.8562
     Batch 050 | Loss : 0.3891 | Acc : 0.8129
     Batch 075 | Loss : 0.2466 | Acc : 0.8946
     Batch 100 | Loss : 0.3005 | Acc : 0.8616
     Batch 125 | Loss : 0.3358 | Acc : 0.8474
     Batch 150 | Loss : 0.3034 | Acc : 0.8641
     Batch 175 | Loss : 0.3166 | Acc : 0.8573
     Batch 200 | Loss : 0.3215 | Acc : 0.8538
     Batch 225 | Loss : 0.3495 | Acc : 0.8356
     Batch 250 | Loss : 0.2654 | Acc : 0.8831
     Batch 275 | Loss : 0.3033 | Acc : 0.8633
     Batch 300 | Loss : 0.3162 | Acc : 0.8537
Epoch 00058 | Train Loss : 0.3267 | Eval Loss : 0.3277 | Train acc : 0.8494 | Eval Acc : 0.8460 | Eval Log. Respected : 0.9365
     Batch 000 | Loss : 0.3953 | Acc : 0.8121
     Batch 025 | Loss : 0.2733 | Acc : 0.8800
     Batch 050 | Loss : 0.2958 | Acc : 0.8656
     Batch 075 | Loss : 0.2775 | Acc : 0.8720
     Batch 100 | Loss : 0.2938 | Acc : 0.8679
     Batch 125 | Loss : 0.3170 | Acc : 0.8516
     Batch 150 | Loss : 0.2739 | Acc : 0.8748
     Batch 175 | Loss : 0.2555 | Acc : 0.8851
     Batch 200 | Loss : 0.3380 | Acc : 0.8411
     Batch 225 | Loss : 0.3429 | Acc : 0.8368
     Batch 250 | Loss : 0.2958 | Acc : 0.8650
     Batch 275 | Loss : 0.2591 | Acc : 0.8860
     Batch 300 | Loss : 0.2828 | Acc : 0.8735
Epoch 00059 | Train Loss : 0.3263 | Eval Loss : 0.3260 | Train acc : 0.8497 | Eval Acc : 0.8474 | Eval Log. Respected : 0.9361
     Batch 000 | Loss : 0.3127 | Acc : 0.8494
     Batch 025 | Loss : 0.2487 | Acc : 0.8899
     Batch 050 | Loss : 0.4617 | Acc : 0.7970
     Batch 075 | Loss : 0.2825 | Acc : 0.8806
     Batch 100 | Loss : 0.3456 | Acc : 0.8358
     Batch 125 | Loss : 0.3241 | Acc : 0.8535
     Batch 150 | Loss : 0.3213 | Acc : 0.8563
     Batch 175 | Loss : 0.2973 | Acc : 0.8611
     Batch 200 | Loss : 0.2764 | Acc : 0.8730
     Batch 225 | Loss : 0.3063 | Acc : 0.8572
     Batch 250 | Loss : 0.3012 | Acc : 0.8631
     Batch 275 | Loss : 0.2777 | Acc : 0.8717
     Batch 300 | Loss : 0.2893 | Acc : 0.8654
Epoch 00060 | Train Loss : 0.3254 | Eval Loss : 0.3271 | Train acc : 0.8500 | Eval Acc : 0.8469 | Eval Log. Respected : 0.9393
     Batch 000 | Loss : 0.3618 | Acc : 0.8304
     Batch 025 | Loss : 0.3404 | Acc : 0.8361
     Batch 050 | Loss : 0.3083 | Acc : 0.8551
     Batch 075 | Loss : 0.3126 | Acc : 0.8559
     Batch 100 | Loss : 0.2537 | Acc : 0.8916
     Batch 125 | Loss : 0.3638 | Acc : 0.8287
     Batch 150 | Loss : 0.2983 | Acc : 0.8625
     Batch 175 | Loss : 0.3482 | Acc : 0.8415
     Batch 200 | Loss : 0.3451 | Acc : 0.8389
     Batch 225 | Loss : 0.3888 | Acc : 0.8200
     Batch 250 | Loss : 0.2996 | Acc : 0.8615
     Batch 275 | Loss : 0.2935 | Acc : 0.8689
     Batch 300 | Loss : 0.3323 | Acc : 0.8465
Epoch 00061 | Train Loss : 0.3253 | Eval Loss : 0.3316 | Train acc : 0.8500 | Eval Acc : 0.8448 | Eval Log. Respected : 0.9295
Early Stopping
Testing...
Test Loss 0.5949 | Test Acc 0.8340 | Test Log. Res. 0.9332
