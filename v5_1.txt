cuda is available
USING : cuda
Done loading data from cached files.
Training ...
     Batch 000 | Loss : 0.6969 | Acc : 0.5172
     Batch 025 | Loss : 0.6922 | Acc : 0.5141
     Batch 050 | Loss : 0.5915 | Acc : 0.7258
     Batch 075 | Loss : 0.5119 | Acc : 0.7846
     Batch 100 | Loss : 0.3499 | Acc : 0.8406
     Batch 125 | Loss : 0.4592 | Acc : 0.7686
     Batch 150 | Loss : 0.4978 | Acc : 0.7588
     Batch 175 | Loss : 0.4698 | Acc : 0.7649
     Batch 200 | Loss : 0.3438 | Acc : 0.8434
     Batch 225 | Loss : 0.3997 | Acc : 0.8211
     Batch 250 | Loss : 0.4044 | Acc : 0.8101
     Batch 275 | Loss : 0.3880 | Acc : 0.8164
     Batch 300 | Loss : 0.4011 | Acc : 0.8023
Epoch 00000 | Train Loss : 0.4655 | Eval Loss : 0.3819 | Train acc : 0.7677 | Eval Acc : 0.8189 | Eval Log. Respected : 0.9187
     Batch 000 | Loss : 0.4392 | Acc : 0.7904
     Batch 025 | Loss : 0.4095 | Acc : 0.8069
     Batch 050 | Loss : 0.3574 | Acc : 0.8351
     Batch 075 | Loss : 0.3985 | Acc : 0.8072
     Batch 100 | Loss : 0.3676 | Acc : 0.8347
     Batch 125 | Loss : 0.4407 | Acc : 0.7898
     Batch 150 | Loss : 0.3906 | Acc : 0.8104
     Batch 175 | Loss : 0.3357 | Acc : 0.8486
     Batch 200 | Loss : 0.3331 | Acc : 0.8479
     Batch 225 | Loss : 0.3784 | Acc : 0.8231
     Batch 250 | Loss : 0.3896 | Acc : 0.8124
     Batch 275 | Loss : 0.3551 | Acc : 0.8391
     Batch 300 | Loss : 0.4013 | Acc : 0.8111
Epoch 00001 | Train Loss : 0.3826 | Eval Loss : 0.3686 | Train acc : 0.8221 | Eval Acc : 0.8252 | Eval Log. Respected : 0.9732
     Batch 000 | Loss : 0.3253 | Acc : 0.8533
     Batch 025 | Loss : 0.3561 | Acc : 0.8283
     Batch 050 | Loss : 0.4259 | Acc : 0.7938
     Batch 075 | Loss : 0.3234 | Acc : 0.8606
     Batch 100 | Loss : 0.3337 | Acc : 0.8463
     Batch 125 | Loss : 0.3804 | Acc : 0.8239
     Batch 150 | Loss : 0.3496 | Acc : 0.8454
     Batch 175 | Loss : 0.4564 | Acc : 0.7942
     Batch 200 | Loss : 0.3867 | Acc : 0.8180
     Batch 225 | Loss : 0.3681 | Acc : 0.8317
     Batch 250 | Loss : 0.3825 | Acc : 0.8255
     Batch 275 | Loss : 0.4951 | Acc : 0.7892
     Batch 300 | Loss : 0.3655 | Acc : 0.8406
Epoch 00002 | Train Loss : 0.3701 | Eval Loss : 0.3684 | Train acc : 0.8289 | Eval Acc : 0.8297 | Eval Log. Respected : 0.9062
     Batch 000 | Loss : 0.3733 | Acc : 0.8276
     Batch 025 | Loss : 0.3910 | Acc : 0.8198
     Batch 050 | Loss : 0.4197 | Acc : 0.8051
     Batch 075 | Loss : 0.3265 | Acc : 0.8487
     Batch 100 | Loss : 0.3285 | Acc : 0.8543
     Batch 125 | Loss : 0.4325 | Acc : 0.7876
     Batch 150 | Loss : 0.3558 | Acc : 0.8341
     Batch 175 | Loss : 0.4284 | Acc : 0.7961
     Batch 200 | Loss : 0.4999 | Acc : 0.7868
     Batch 225 | Loss : 0.3135 | Acc : 0.8604
     Batch 250 | Loss : 0.4200 | Acc : 0.7910
     Batch 275 | Loss : 0.3203 | Acc : 0.8490
     Batch 300 | Loss : 0.2969 | Acc : 0.8711
Epoch 00003 | Train Loss : 0.3593 | Eval Loss : 0.3469 | Train acc : 0.8348 | Eval Acc : 0.8380 | Eval Log. Respected : 0.9305
     Batch 000 | Loss : 0.3106 | Acc : 0.8632
     Batch 025 | Loss : 0.3757 | Acc : 0.8194
     Batch 050 | Loss : 0.3299 | Acc : 0.8501
     Batch 075 | Loss : 0.3008 | Acc : 0.8651
     Batch 100 | Loss : 0.3226 | Acc : 0.8518
     Batch 125 | Loss : 0.3478 | Acc : 0.8437
     Batch 150 | Loss : 0.4169 | Acc : 0.8110
     Batch 175 | Loss : 0.2915 | Acc : 0.8713
     Batch 200 | Loss : 0.2751 | Acc : 0.8747
     Batch 225 | Loss : 0.3079 | Acc : 0.8662
     Batch 250 | Loss : 0.3976 | Acc : 0.8103
     Batch 275 | Loss : 0.3118 | Acc : 0.8548
     Batch 300 | Loss : 0.3123 | Acc : 0.8555
Epoch 00004 | Train Loss : 0.3491 | Eval Loss : 0.3349 | Train acc : 0.8392 | Eval Acc : 0.8432 | Eval Log. Respected : 0.9382
     Batch 000 | Loss : 0.4407 | Acc : 0.7909
     Batch 025 | Loss : 0.3387 | Acc : 0.8438
     Batch 050 | Loss : 0.2693 | Acc : 0.8798
     Batch 075 | Loss : 0.3629 | Acc : 0.8261
     Batch 100 | Loss : 0.4226 | Acc : 0.7944
     Batch 125 | Loss : 0.3671 | Acc : 0.8274
     Batch 150 | Loss : 0.3727 | Acc : 0.8184
     Batch 175 | Loss : 0.3270 | Acc : 0.8431
     Batch 200 | Loss : 0.3374 | Acc : 0.8497
     Batch 225 | Loss : 0.4365 | Acc : 0.7921
     Batch 250 | Loss : 0.2986 | Acc : 0.8610
     Batch 275 | Loss : 0.3669 | Acc : 0.8331
     Batch 300 | Loss : 0.4298 | Acc : 0.8049
Epoch 00005 | Train Loss : 0.3436 | Eval Loss : 0.3352 | Train acc : 0.8414 | Eval Acc : 0.8416 | Eval Log. Respected : 0.9128
     Batch 000 | Loss : 0.3683 | Acc : 0.8256
     Batch 025 | Loss : 0.3377 | Acc : 0.8496
     Batch 050 | Loss : 0.3688 | Acc : 0.8189
     Batch 075 | Loss : 0.3696 | Acc : 0.8255
     Batch 100 | Loss : 0.3401 | Acc : 0.8463
     Batch 125 | Loss : 0.2618 | Acc : 0.8841
     Batch 150 | Loss : 0.3717 | Acc : 0.8144
     Batch 175 | Loss : 0.3134 | Acc : 0.8517
     Batch 200 | Loss : 0.3073 | Acc : 0.8607
     Batch 225 | Loss : 0.3587 | Acc : 0.8296
     Batch 250 | Loss : 0.4198 | Acc : 0.7945
     Batch 275 | Loss : 0.3965 | Acc : 0.8095
     Batch 300 | Loss : 0.3302 | Acc : 0.8503
Epoch 00006 | Train Loss : 0.3419 | Eval Loss : 0.3394 | Train acc : 0.8424 | Eval Acc : 0.8426 | Eval Log. Respected : 0.9112
     Batch 000 | Loss : 0.2907 | Acc : 0.8758
     Batch 025 | Loss : 0.4051 | Acc : 0.8230
     Batch 050 | Loss : 0.3806 | Acc : 0.8195
     Batch 075 | Loss : 0.3025 | Acc : 0.8694
     Batch 100 | Loss : 0.4054 | Acc : 0.8070
     Batch 125 | Loss : 0.4234 | Acc : 0.8042
     Batch 150 | Loss : 0.3107 | Acc : 0.8645
     Batch 175 | Loss : 0.4051 | Acc : 0.8139
     Batch 200 | Loss : 0.3836 | Acc : 0.8241
     Batch 225 | Loss : 0.2986 | Acc : 0.8620
     Batch 250 | Loss : 0.3325 | Acc : 0.8520
     Batch 275 | Loss : 0.3061 | Acc : 0.8555
     Batch 300 | Loss : 0.3918 | Acc : 0.8228
Epoch 00007 | Train Loss : 0.3431 | Eval Loss : 0.3319 | Train acc : 0.8421 | Eval Acc : 0.8450 | Eval Log. Respected : 0.9219
     Batch 000 | Loss : 0.2979 | Acc : 0.8668
     Batch 025 | Loss : 0.3396 | Acc : 0.8411
     Batch 050 | Loss : 0.3262 | Acc : 0.8546
     Batch 075 | Loss : 0.3149 | Acc : 0.8572
     Batch 100 | Loss : 0.3328 | Acc : 0.8433
     Batch 125 | Loss : 0.3840 | Acc : 0.8122
     Batch 150 | Loss : 0.3172 | Acc : 0.8504
     Batch 175 | Loss : 0.3018 | Acc : 0.8605
     Batch 200 | Loss : 0.3668 | Acc : 0.8277
     Batch 225 | Loss : 0.3484 | Acc : 0.8462
     Batch 250 | Loss : 0.3536 | Acc : 0.8309
     Batch 275 | Loss : 0.3090 | Acc : 0.8588
     Batch 300 | Loss : 0.2968 | Acc : 0.8649
Epoch 00008 | Train Loss : 0.3414 | Eval Loss : 0.3360 | Train acc : 0.8426 | Eval Acc : 0.8423 | Eval Log. Respected : 0.9342
     Batch 000 | Loss : 0.4360 | Acc : 0.7869
     Batch 025 | Loss : 0.3951 | Acc : 0.8197
     Batch 050 | Loss : 0.3555 | Acc : 0.8293
     Batch 075 | Loss : 0.3324 | Acc : 0.8458
     Batch 100 | Loss : 0.4037 | Acc : 0.8031
     Batch 125 | Loss : 0.3053 | Acc : 0.8624
     Batch 150 | Loss : 0.3353 | Acc : 0.8473
     Batch 175 | Loss : 0.2805 | Acc : 0.8737
     Batch 200 | Loss : 0.3400 | Acc : 0.8416
     Batch 225 | Loss : 0.2914 | Acc : 0.8686
     Batch 250 | Loss : 0.3622 | Acc : 0.8329
     Batch 275 | Loss : 0.2539 | Acc : 0.8923
     Batch 300 | Loss : 0.3223 | Acc : 0.8506
Epoch 00009 | Train Loss : 0.3376 | Eval Loss : 0.3327 | Train acc : 0.8440 | Eval Acc : 0.8436 | Eval Log. Respected : 0.9318
     Batch 000 | Loss : 0.4669 | Acc : 0.7867
     Batch 025 | Loss : 0.3166 | Acc : 0.8551
     Batch 050 | Loss : 0.2661 | Acc : 0.8824
     Batch 075 | Loss : 0.3405 | Acc : 0.8439
     Batch 100 | Loss : 0.3629 | Acc : 0.8251
     Batch 125 | Loss : 0.2992 | Acc : 0.8731
     Batch 150 | Loss : 0.2993 | Acc : 0.8657
     Batch 175 | Loss : 0.3995 | Acc : 0.8110
     Batch 200 | Loss : 0.3064 | Acc : 0.8596
     Batch 225 | Loss : 0.3396 | Acc : 0.8349
     Batch 250 | Loss : 0.4419 | Acc : 0.8009
     Batch 275 | Loss : 0.5454 | Acc : 0.7684
     Batch 300 | Loss : 0.3534 | Acc : 0.8358
Epoch 00010 | Train Loss : 0.3362 | Eval Loss : 0.3326 | Train acc : 0.8447 | Eval Acc : 0.8446 | Eval Log. Respected : 0.9165
     Batch 000 | Loss : 0.3182 | Acc : 0.8536
     Batch 025 | Loss : 0.4262 | Acc : 0.8025
     Batch 050 | Loss : 0.3316 | Acc : 0.8434
     Batch 075 | Loss : 0.3294 | Acc : 0.8437
     Batch 100 | Loss : 0.3805 | Acc : 0.8197
     Batch 125 | Loss : 0.3880 | Acc : 0.8127
     Batch 150 | Loss : 0.2689 | Acc : 0.8796
     Batch 175 | Loss : 0.3619 | Acc : 0.8330
     Batch 200 | Loss : 0.2830 | Acc : 0.8698
     Batch 225 | Loss : 0.3156 | Acc : 0.8506
     Batch 250 | Loss : 0.3475 | Acc : 0.8365
     Batch 275 | Loss : 0.4322 | Acc : 0.8028
     Batch 300 | Loss : 0.3051 | Acc : 0.8646
Epoch 00011 | Train Loss : 0.3317 | Eval Loss : 0.3296 | Train acc : 0.8463 | Eval Acc : 0.8460 | Eval Log. Respected : 0.9178
     Batch 000 | Loss : 0.3417 | Acc : 0.8365
     Batch 025 | Loss : 0.3133 | Acc : 0.8549
     Batch 050 | Loss : 0.4721 | Acc : 0.7815
     Batch 075 | Loss : 0.2826 | Acc : 0.8709
     Batch 100 | Loss : 0.2927 | Acc : 0.8690
     Batch 125 | Loss : 0.2832 | Acc : 0.8746
     Batch 150 | Loss : 0.3816 | Acc : 0.8158
     Batch 175 | Loss : 0.3530 | Acc : 0.8331
     Batch 200 | Loss : 0.3756 | Acc : 0.8248
     Batch 225 | Loss : 0.2618 | Acc : 0.8831
     Batch 250 | Loss : 0.3075 | Acc : 0.8588
     Batch 275 | Loss : 0.3166 | Acc : 0.8543
     Batch 300 | Loss : 0.2748 | Acc : 0.8771
Epoch 00012 | Train Loss : 0.3323 | Eval Loss : 0.3250 | Train acc : 0.8461 | Eval Acc : 0.8473 | Eval Log. Respected : 0.9322
     Batch 000 | Loss : 0.3266 | Acc : 0.8473
     Batch 025 | Loss : 0.2687 | Acc : 0.8772
     Batch 050 | Loss : 0.3609 | Acc : 0.8372
     Batch 075 | Loss : 0.3072 | Acc : 0.8576
     Batch 100 | Loss : 0.3702 | Acc : 0.8298
     Batch 125 | Loss : 0.2775 | Acc : 0.8743
     Batch 150 | Loss : 0.3051 | Acc : 0.8620
     Batch 175 | Loss : 0.4211 | Acc : 0.8094
     Batch 200 | Loss : 0.3116 | Acc : 0.8584
     Batch 225 | Loss : 0.3344 | Acc : 0.8441
     Batch 250 | Loss : 0.3799 | Acc : 0.8205
     Batch 275 | Loss : 0.3202 | Acc : 0.8518
     Batch 300 | Loss : 0.2857 | Acc : 0.8701
Epoch 00013 | Train Loss : 0.3309 | Eval Loss : 0.3242 | Train acc : 0.8468 | Eval Acc : 0.8475 | Eval Log. Respected : 0.9335
     Batch 000 | Loss : 0.3079 | Acc : 0.8601
     Batch 025 | Loss : 0.3169 | Acc : 0.8517
     Batch 050 | Loss : 0.3812 | Acc : 0.8276
     Batch 075 | Loss : 0.3098 | Acc : 0.8569
     Batch 100 | Loss : 0.3407 | Acc : 0.8430
     Batch 125 | Loss : 0.2663 | Acc : 0.8852
     Batch 150 | Loss : 0.3306 | Acc : 0.8447
     Batch 175 | Loss : 0.3542 | Acc : 0.8361
     Batch 200 | Loss : 0.3026 | Acc : 0.8590
     Batch 225 | Loss : 0.2865 | Acc : 0.8628
     Batch 250 | Loss : 0.4688 | Acc : 0.7869
     Batch 275 | Loss : 0.3617 | Acc : 0.8299
     Batch 300 | Loss : 0.3154 | Acc : 0.8464
Epoch 00014 | Train Loss : 0.3318 | Eval Loss : 0.3302 | Train acc : 0.8469 | Eval Acc : 0.8446 | Eval Log. Respected : 0.9430
     Batch 000 | Loss : 0.3867 | Acc : 0.8219
     Batch 025 | Loss : 0.2994 | Acc : 0.8697
     Batch 050 | Loss : 0.3180 | Acc : 0.8556
     Batch 075 | Loss : 0.3768 | Acc : 0.8205
     Batch 100 | Loss : 0.3075 | Acc : 0.8606
     Batch 125 | Loss : 0.3753 | Acc : 0.8269
     Batch 150 | Loss : 0.2797 | Acc : 0.8789
     Batch 175 | Loss : 0.3160 | Acc : 0.8557
     Batch 200 | Loss : 0.3449 | Acc : 0.8378
     Batch 225 | Loss : 0.3432 | Acc : 0.8323
     Batch 250 | Loss : 0.3649 | Acc : 0.8321
     Batch 275 | Loss : 0.3063 | Acc : 0.8605
     Batch 300 | Loss : 0.3139 | Acc : 0.8550
Epoch 00015 | Train Loss : 0.3308 | Eval Loss : 0.3303 | Train acc : 0.8471 | Eval Acc : 0.8457 | Eval Log. Respected : 0.9271
     Batch 000 | Loss : 0.3163 | Acc : 0.8525
     Batch 025 | Loss : 0.3221 | Acc : 0.8480
     Batch 050 | Loss : 0.3048 | Acc : 0.8601
     Batch 075 | Loss : 0.4258 | Acc : 0.7976
     Batch 100 | Loss : 0.3746 | Acc : 0.8178
     Batch 125 | Loss : 0.3225 | Acc : 0.8483
     Batch 150 | Loss : 0.3018 | Acc : 0.8674
     Batch 175 | Loss : 0.3221 | Acc : 0.8517
     Batch 200 | Loss : 0.2793 | Acc : 0.8741
     Batch 225 | Loss : 0.3629 | Acc : 0.8306
     Batch 250 | Loss : 0.3731 | Acc : 0.8225
     Batch 275 | Loss : 0.3386 | Acc : 0.8367
     Batch 300 | Loss : 0.2748 | Acc : 0.8728
Epoch 00016 | Train Loss : 0.3287 | Eval Loss : 0.3236 | Train acc : 0.8481 | Eval Acc : 0.8481 | Eval Log. Respected : 0.9348
     Batch 000 | Loss : 0.3695 | Acc : 0.8282
     Batch 025 | Loss : 0.3139 | Acc : 0.8562
     Batch 050 | Loss : 0.3596 | Acc : 0.8318
     Batch 075 | Loss : 0.3029 | Acc : 0.8638
     Batch 100 | Loss : 0.3271 | Acc : 0.8493
     Batch 125 | Loss : 0.2739 | Acc : 0.8797
     Batch 150 | Loss : 0.3631 | Acc : 0.8227
     Batch 175 | Loss : 0.3385 | Acc : 0.8399
     Batch 200 | Loss : 0.3430 | Acc : 0.8394
     Batch 225 | Loss : 0.2999 | Acc : 0.8650
     Batch 250 | Loss : 0.3624 | Acc : 0.8307
     Batch 275 | Loss : 0.3493 | Acc : 0.8351
     Batch 300 | Loss : 0.3229 | Acc : 0.8520
Epoch 00017 | Train Loss : 0.3296 | Eval Loss : 0.3238 | Train acc : 0.8475 | Eval Acc : 0.8491 | Eval Log. Respected : 0.9249
     Batch 000 | Loss : 0.3224 | Acc : 0.8539
     Batch 025 | Loss : 0.3616 | Acc : 0.8350
     Batch 050 | Loss : 0.2963 | Acc : 0.8624
     Batch 075 | Loss : 0.3449 | Acc : 0.8372
     Batch 100 | Loss : 0.2932 | Acc : 0.8641
     Batch 125 | Loss : 0.3468 | Acc : 0.8325
     Batch 150 | Loss : 0.3332 | Acc : 0.8389
     Batch 175 | Loss : 0.2866 | Acc : 0.8765
     Batch 200 | Loss : 0.3010 | Acc : 0.8658
     Batch 225 | Loss : 0.3675 | Acc : 0.8244
     Batch 250 | Loss : 0.3874 | Acc : 0.8076
     Batch 275 | Loss : 0.2996 | Acc : 0.8661
     Batch 300 | Loss : 0.3592 | Acc : 0.8290
Epoch 00018 | Train Loss : 0.3276 | Eval Loss : 0.3202 | Train acc : 0.8485 | Eval Acc : 0.8510 | Eval Log. Respected : 0.9164
     Batch 000 | Loss : 0.3359 | Acc : 0.8442
     Batch 025 | Loss : 0.3277 | Acc : 0.8428
     Batch 050 | Loss : 0.2892 | Acc : 0.8661
     Batch 075 | Loss : 0.3511 | Acc : 0.8361
     Batch 100 | Loss : 0.4535 | Acc : 0.7881
     Batch 125 | Loss : 0.3363 | Acc : 0.8437
     Batch 150 | Loss : 0.3266 | Acc : 0.8512
     Batch 175 | Loss : 0.3891 | Acc : 0.8039
     Batch 200 | Loss : 0.3565 | Acc : 0.8306
     Batch 225 | Loss : 0.3082 | Acc : 0.8580
     Batch 250 | Loss : 0.3571 | Acc : 0.8294
     Batch 275 | Loss : 0.3219 | Acc : 0.8508
     Batch 300 | Loss : 0.2615 | Acc : 0.8839
Epoch 00019 | Train Loss : 0.3265 | Eval Loss : 0.3145 | Train acc : 0.8488 | Eval Acc : 0.8527 | Eval Log. Respected : 0.9393
     Batch 000 | Loss : 0.3164 | Acc : 0.8509
     Batch 025 | Loss : 0.2470 | Acc : 0.8909
     Batch 050 | Loss : 0.3000 | Acc : 0.8605
     Batch 075 | Loss : 0.2674 | Acc : 0.8765
     Batch 100 | Loss : 0.3700 | Acc : 0.8256
     Batch 125 | Loss : 0.2847 | Acc : 0.8692
     Batch 150 | Loss : 0.2771 | Acc : 0.8731
     Batch 175 | Loss : 0.2617 | Acc : 0.8833
     Batch 200 | Loss : 0.2896 | Acc : 0.8727
     Batch 225 | Loss : 0.2933 | Acc : 0.8745
     Batch 250 | Loss : 0.2704 | Acc : 0.8772
     Batch 275 | Loss : 0.2828 | Acc : 0.8679
     Batch 300 | Loss : 0.2593 | Acc : 0.8838
Epoch 00020 | Train Loss : 0.3253 | Eval Loss : 0.3292 | Train acc : 0.8494 | Eval Acc : 0.8459 | Eval Log. Respected : 0.9445
     Batch 000 | Loss : 0.2864 | Acc : 0.8732
     Batch 025 | Loss : 0.3352 | Acc : 0.8422
     Batch 050 | Loss : 0.3991 | Acc : 0.8055
     Batch 075 | Loss : 0.3756 | Acc : 0.8193
     Batch 100 | Loss : 0.3072 | Acc : 0.8629
     Batch 125 | Loss : 0.2579 | Acc : 0.8878
     Batch 150 | Loss : 0.3460 | Acc : 0.8385
     Batch 175 | Loss : 0.3953 | Acc : 0.8105
     Batch 200 | Loss : 0.3331 | Acc : 0.8394
     Batch 225 | Loss : 0.3318 | Acc : 0.8403
     Batch 250 | Loss : 0.3236 | Acc : 0.8501
     Batch 275 | Loss : 0.3798 | Acc : 0.8286
     Batch 300 | Loss : 0.2993 | Acc : 0.8568
Epoch 00021 | Train Loss : 0.3262 | Eval Loss : 0.3202 | Train acc : 0.8495 | Eval Acc : 0.8515 | Eval Log. Respected : 0.9308
     Batch 000 | Loss : 0.3477 | Acc : 0.8312
     Batch 025 | Loss : 0.3258 | Acc : 0.8471
     Batch 050 | Loss : 0.3409 | Acc : 0.8444
     Batch 075 | Loss : 0.3538 | Acc : 0.8255
     Batch 100 | Loss : 0.3461 | Acc : 0.8384
     Batch 125 | Loss : 0.2902 | Acc : 0.8688
     Batch 150 | Loss : 0.3416 | Acc : 0.8411
     Batch 175 | Loss : 0.3388 | Acc : 0.8435
     Batch 200 | Loss : 0.5477 | Acc : 0.7542
     Batch 225 | Loss : 0.3755 | Acc : 0.8219
     Batch 250 | Loss : 0.2371 | Acc : 0.8919
     Batch 275 | Loss : 0.3549 | Acc : 0.8275
     Batch 300 | Loss : 0.3365 | Acc : 0.8452
Epoch 00022 | Train Loss : 0.3237 | Eval Loss : 0.3254 | Train acc : 0.8502 | Eval Acc : 0.8474 | Eval Log. Respected : 0.9250
     Batch 000 | Loss : 0.2780 | Acc : 0.8758
     Batch 025 | Loss : 0.2925 | Acc : 0.8678
     Batch 050 | Loss : 0.3346 | Acc : 0.8500
     Batch 075 | Loss : 0.3414 | Acc : 0.8428
     Batch 100 | Loss : 0.3973 | Acc : 0.8085
     Batch 125 | Loss : 0.4117 | Acc : 0.8089
     Batch 150 | Loss : 0.3472 | Acc : 0.8316
     Batch 175 | Loss : 0.3110 | Acc : 0.8682
     Batch 200 | Loss : 0.4115 | Acc : 0.7992
     Batch 225 | Loss : 0.2651 | Acc : 0.8817
     Batch 250 | Loss : 0.2695 | Acc : 0.8885
     Batch 275 | Loss : 0.3275 | Acc : 0.8468
     Batch 300 | Loss : 0.3876 | Acc : 0.8240
Epoch 00023 | Train Loss : 0.3243 | Eval Loss : 0.3196 | Train acc : 0.8500 | Eval Acc : 0.8497 | Eval Log. Respected : 0.9360
     Batch 000 | Loss : 0.3495 | Acc : 0.8284
     Batch 025 | Loss : 0.3056 | Acc : 0.8593
     Batch 050 | Loss : 0.3640 | Acc : 0.8294
     Batch 075 | Loss : 0.3696 | Acc : 0.8188
     Batch 100 | Loss : 0.3721 | Acc : 0.8245
     Batch 125 | Loss : 0.2917 | Acc : 0.8665
     Batch 150 | Loss : 0.3274 | Acc : 0.8432
     Batch 175 | Loss : 0.4004 | Acc : 0.8117
     Batch 200 | Loss : 0.4094 | Acc : 0.8218
     Batch 225 | Loss : 0.3451 | Acc : 0.8458
     Batch 250 | Loss : 0.3312 | Acc : 0.8513
     Batch 275 | Loss : 0.3096 | Acc : 0.8652
     Batch 300 | Loss : 0.3397 | Acc : 0.8435
Epoch 00024 | Train Loss : 0.3246 | Eval Loss : 0.3201 | Train acc : 0.8501 | Eval Acc : 0.8499 | Eval Log. Respected : 0.9315
     Batch 000 | Loss : 0.3104 | Acc : 0.8533
     Batch 025 | Loss : 0.2699 | Acc : 0.8833
     Batch 050 | Loss : 0.3092 | Acc : 0.8559
     Batch 075 | Loss : 0.2759 | Acc : 0.8751
     Batch 100 | Loss : 0.4217 | Acc : 0.7947
     Batch 125 | Loss : 0.2904 | Acc : 0.8673
     Batch 150 | Loss : 0.2645 | Acc : 0.8846
     Batch 175 | Loss : 0.3671 | Acc : 0.8276
     Batch 200 | Loss : 0.3528 | Acc : 0.8314
     Batch 225 | Loss : 0.3252 | Acc : 0.8421
     Batch 250 | Loss : 0.3266 | Acc : 0.8460
     Batch 275 | Loss : 0.3127 | Acc : 0.8498
     Batch 300 | Loss : 0.3072 | Acc : 0.8530
Epoch 00025 | Train Loss : 0.3215 | Eval Loss : 0.3154 | Train acc : 0.8511 | Eval Acc : 0.8515 | Eval Log. Respected : 0.9395
     Batch 000 | Loss : 0.3298 | Acc : 0.8521
     Batch 025 | Loss : 0.3135 | Acc : 0.8561
     Batch 050 | Loss : 0.2952 | Acc : 0.8676
     Batch 075 | Loss : 0.2769 | Acc : 0.8790
     Batch 100 | Loss : 0.2964 | Acc : 0.8673
     Batch 125 | Loss : 0.3486 | Acc : 0.8394
     Batch 150 | Loss : 0.2811 | Acc : 0.8781
     Batch 175 | Loss : 0.3018 | Acc : 0.8701
     Batch 200 | Loss : 0.2839 | Acc : 0.8685
     Batch 225 | Loss : 0.2637 | Acc : 0.8826
     Batch 250 | Loss : 0.2650 | Acc : 0.8807
     Batch 275 | Loss : 0.3205 | Acc : 0.8536
     Batch 300 | Loss : 0.3121 | Acc : 0.8557
Epoch 00026 | Train Loss : 0.3221 | Eval Loss : 0.3185 | Train acc : 0.8511 | Eval Acc : 0.8502 | Eval Log. Respected : 0.9516
     Batch 000 | Loss : 0.3034 | Acc : 0.8598
     Batch 025 | Loss : 0.3237 | Acc : 0.8539
     Batch 050 | Loss : 0.3493 | Acc : 0.8415
     Batch 075 | Loss : 0.3084 | Acc : 0.8577
     Batch 100 | Loss : 0.3224 | Acc : 0.8516
     Batch 125 | Loss : 0.3335 | Acc : 0.8498
     Batch 150 | Loss : 0.2948 | Acc : 0.8670
     Batch 175 | Loss : 0.4176 | Acc : 0.7981
     Batch 200 | Loss : 0.2643 | Acc : 0.8848
     Batch 225 | Loss : 0.3624 | Acc : 0.8254
     Batch 250 | Loss : 0.2962 | Acc : 0.8615
     Batch 275 | Loss : 0.3014 | Acc : 0.8679
     Batch 300 | Loss : 0.3426 | Acc : 0.8376
Epoch 00027 | Train Loss : 0.3232 | Eval Loss : 0.3245 | Train acc : 0.8505 | Eval Acc : 0.8475 | Eval Log. Respected : 0.9374
     Batch 000 | Loss : 0.2852 | Acc : 0.8667
     Batch 025 | Loss : 0.2654 | Acc : 0.8833
     Batch 050 | Loss : 0.3108 | Acc : 0.8556
     Batch 075 | Loss : 0.2633 | Acc : 0.8819
     Batch 100 | Loss : 0.4556 | Acc : 0.7930
     Batch 125 | Loss : 0.2630 | Acc : 0.8831
     Batch 150 | Loss : 0.3093 | Acc : 0.8596
     Batch 175 | Loss : 0.3004 | Acc : 0.8669
     Batch 200 | Loss : 0.2629 | Acc : 0.8800
     Batch 225 | Loss : 0.2872 | Acc : 0.8694
     Batch 250 | Loss : 0.2611 | Acc : 0.8806
     Batch 275 | Loss : 0.3542 | Acc : 0.8349
     Batch 300 | Loss : 0.4059 | Acc : 0.8048
Epoch 00028 | Train Loss : 0.3227 | Eval Loss : 0.3204 | Train acc : 0.8508 | Eval Acc : 0.8507 | Eval Log. Respected : 0.9421
     Batch 000 | Loss : 0.2716 | Acc : 0.8839
     Batch 025 | Loss : 0.3446 | Acc : 0.8353
     Batch 050 | Loss : 0.2819 | Acc : 0.8751
     Batch 075 | Loss : 0.3318 | Acc : 0.8380
     Batch 100 | Loss : 0.3344 | Acc : 0.8461
     Batch 125 | Loss : 0.2840 | Acc : 0.8711
     Batch 150 | Loss : 0.2971 | Acc : 0.8659
     Batch 175 | Loss : 0.3208 | Acc : 0.8513
     Batch 200 | Loss : 0.2977 | Acc : 0.8631
     Batch 225 | Loss : 0.3182 | Acc : 0.8567
     Batch 250 | Loss : 0.3183 | Acc : 0.8549
     Batch 275 | Loss : 0.3166 | Acc : 0.8562
     Batch 300 | Loss : 0.3400 | Acc : 0.8414
Epoch 00029 | Train Loss : 0.3204 | Eval Loss : 0.3203 | Train acc : 0.8518 | Eval Acc : 0.8504 | Eval Log. Respected : 0.9191
Early Stopping
Testing...
Test Loss 0.5833 | Test Acc 0.8468 | Test Log. Res. 0.9188
