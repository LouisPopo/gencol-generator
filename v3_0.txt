Done loading data from cached files.
Training ...
     Batch 000 | Loss : 0.6981 | Acc : 0.4890
     Batch 025 | Loss : 0.6889 | Acc : 0.5337
     Batch 050 | Loss : 0.6757 | Acc : 0.5806
     Batch 075 | Loss : 0.6639 | Acc : 0.5748
     Batch 100 | Loss : 0.6625 | Acc : 0.5652
     Batch 125 | Loss : 0.6657 | Acc : 0.5597
     Batch 150 | Loss : 0.6231 | Acc : 0.6094
     Batch 175 | Loss : 0.6629 | Acc : 0.5835
     Batch 200 | Loss : 0.6390 | Acc : 0.6169
     Batch 225 | Loss : 0.6124 | Acc : 0.6205
     Batch 250 | Loss : 0.6330 | Acc : 0.6153
     Batch 275 | Loss : 0.6292 | Acc : 0.5892
     Batch 300 | Loss : 0.5972 | Acc : 0.6742
Epoch 00000 | Train Loss : 0.6484 | Eval Loss : 0.6072 | Train acc : 0.5945 | Eval Acc : 0.6639 | Eval Log. Respected : 0.6992
     Batch 000 | Loss : 0.6107 | Acc : 0.6648
     Batch 025 | Loss : 0.6088 | Acc : 0.6250
     Batch 050 | Loss : 0.5996 | Acc : 0.6559
     Batch 075 | Loss : 0.6037 | Acc : 0.6835
     Batch 100 | Loss : 0.5701 | Acc : 0.7002
     Batch 125 | Loss : 0.6566 | Acc : 0.5984
     Batch 150 | Loss : 0.5681 | Acc : 0.6732
     Batch 175 | Loss : 0.5533 | Acc : 0.7035
     Batch 200 | Loss : 0.6169 | Acc : 0.6258
     Batch 225 | Loss : 0.6020 | Acc : 0.6696
     Batch 250 | Loss : 0.5887 | Acc : 0.6743
     Batch 275 | Loss : 0.5081 | Acc : 0.7518
     Batch 300 | Loss : 0.6099 | Acc : 0.6593
Epoch 00001 | Train Loss : 0.5930 | Eval Loss : 0.5495 | Train acc : 0.6692 | Eval Acc : 0.7124 | Eval Log. Respected : 0.6419
     Batch 000 | Loss : 0.5557 | Acc : 0.7055
     Batch 025 | Loss : 0.5835 | Acc : 0.6742
     Batch 050 | Loss : 0.5197 | Acc : 0.7565
     Batch 075 | Loss : 0.5325 | Acc : 0.7177
     Batch 100 | Loss : 0.5303 | Acc : 0.7202
     Batch 125 | Loss : 0.5640 | Acc : 0.6769
     Batch 150 | Loss : 0.5093 | Acc : 0.7464
     Batch 175 | Loss : 0.5792 | Acc : 0.6809
     Batch 200 | Loss : 0.5412 | Acc : 0.7207
     Batch 225 | Loss : 0.5232 | Acc : 0.7422
     Batch 250 | Loss : 0.4549 | Acc : 0.7752
     Batch 275 | Loss : 0.4992 | Acc : 0.7569
     Batch 300 | Loss : 0.5613 | Acc : 0.6762
Epoch 00002 | Train Loss : 0.5441 | Eval Loss : 0.5200 | Train acc : 0.7124 | Eval Acc : 0.7316 | Eval Log. Respected : 0.6393
     Batch 000 | Loss : 0.5646 | Acc : 0.7092
     Batch 025 | Loss : 0.5013 | Acc : 0.7486
     Batch 050 | Loss : 0.4611 | Acc : 0.7913
     Batch 075 | Loss : 0.4876 | Acc : 0.7464
     Batch 100 | Loss : 0.5182 | Acc : 0.7360
     Batch 125 | Loss : 0.5245 | Acc : 0.7302
     Batch 150 | Loss : 0.5207 | Acc : 0.7398
     Batch 175 | Loss : 0.5268 | Acc : 0.7176
     Batch 200 | Loss : 0.5430 | Acc : 0.7082
     Batch 225 | Loss : 0.4897 | Acc : 0.7594
     Batch 250 | Loss : 0.5032 | Acc : 0.7546
     Batch 275 | Loss : 0.4768 | Acc : 0.7800
     Batch 300 | Loss : 0.4917 | Acc : 0.7572
Epoch 00003 | Train Loss : 0.5235 | Eval Loss : 0.4961 | Train acc : 0.7316 | Eval Acc : 0.7492 | Eval Log. Respected : 0.6223
     Batch 000 | Loss : 0.4995 | Acc : 0.7467
     Batch 025 | Loss : 0.4995 | Acc : 0.7387
     Batch 050 | Loss : 0.5665 | Acc : 0.6987
     Batch 075 | Loss : 0.5036 | Acc : 0.7300
     Batch 100 | Loss : 0.5002 | Acc : 0.7535
     Batch 125 | Loss : 0.5966 | Acc : 0.6763
     Batch 150 | Loss : 0.5095 | Acc : 0.7549
     Batch 175 | Loss : 0.4487 | Acc : 0.7904
     Batch 200 | Loss : 0.4709 | Acc : 0.7703
     Batch 225 | Loss : 0.4629 | Acc : 0.7740
     Batch 250 | Loss : 0.5376 | Acc : 0.7229
     Batch 275 | Loss : 0.5049 | Acc : 0.7372
     Batch 300 | Loss : 0.4985 | Acc : 0.7415
Epoch 00004 | Train Loss : 0.5158 | Eval Loss : 0.6025 | Train acc : 0.7356 | Eval Acc : 0.6752 | Eval Log. Respected : 0.6986
     Batch 000 | Loss : 0.5721 | Acc : 0.7095
     Batch 025 | Loss : 0.4404 | Acc : 0.7896
     Batch 050 | Loss : 0.5644 | Acc : 0.6988
     Batch 075 | Loss : 0.5694 | Acc : 0.7097
     Batch 100 | Loss : 0.5095 | Acc : 0.7717
     Batch 125 | Loss : 0.4698 | Acc : 0.7638
     Batch 150 | Loss : 0.5101 | Acc : 0.7407
     Batch 175 | Loss : 0.4649 | Acc : 0.7651
     Batch 200 | Loss : 0.4853 | Acc : 0.7517
     Batch 225 | Loss : 0.4747 | Acc : 0.7979
     Batch 250 | Loss : 0.4761 | Acc : 0.7654
     Batch 275 | Loss : 0.5212 | Acc : 0.7379
     Batch 300 | Loss : 0.5115 | Acc : 0.7481
Epoch 00005 | Train Loss : 0.4966 | Eval Loss : 0.4669 | Train acc : 0.7506 | Eval Acc : 0.7651 | Eval Log. Respected : 0.6498
     Batch 000 | Loss : 0.4625 | Acc : 0.7869
     Batch 025 | Loss : 0.4718 | Acc : 0.7685
     Batch 050 | Loss : 0.5542 | Acc : 0.7259
     Batch 075 | Loss : 0.4951 | Acc : 0.7358
     Batch 100 | Loss : 0.4930 | Acc : 0.7431
     Batch 125 | Loss : 0.6106 | Acc : 0.6683
     Batch 150 | Loss : 0.4553 | Acc : 0.7755
     Batch 175 | Loss : 0.5281 | Acc : 0.7162
     Batch 200 | Loss : 0.4763 | Acc : 0.7641
     Batch 225 | Loss : 0.5274 | Acc : 0.7309
     Batch 250 | Loss : 0.4453 | Acc : 0.7888
     Batch 275 | Loss : 0.4734 | Acc : 0.7654
     Batch 300 | Loss : 0.4585 | Acc : 0.7764
Epoch 00006 | Train Loss : 0.4942 | Eval Loss : 0.4883 | Train acc : 0.7518 | Eval Acc : 0.7521 | Eval Log. Respected : 0.6387
     Batch 000 | Loss : 0.4430 | Acc : 0.7850
     Batch 025 | Loss : 0.4361 | Acc : 0.7970
     Batch 050 | Loss : 0.4624 | Acc : 0.7720
     Batch 075 | Loss : 0.4580 | Acc : 0.7703
     Batch 100 | Loss : 0.4948 | Acc : 0.7527
     Batch 125 | Loss : 0.4339 | Acc : 0.7897
     Batch 150 | Loss : 0.4949 | Acc : 0.7494
     Batch 175 | Loss : 0.4540 | Acc : 0.7788
     Batch 200 | Loss : 0.5005 | Acc : 0.7523
     Batch 225 | Loss : 0.6266 | Acc : 0.6580
     Batch 250 | Loss : 0.5152 | Acc : 0.7271
     Batch 275 | Loss : 0.4993 | Acc : 0.7437
     Batch 300 | Loss : 0.4690 | Acc : 0.7666
Epoch 00007 | Train Loss : 0.4742 | Eval Loss : 0.4562 | Train acc : 0.7648 | Eval Acc : 0.7728 | Eval Log. Respected : 0.6537
     Batch 000 | Loss : 0.4116 | Acc : 0.8136
     Batch 025 | Loss : 0.4676 | Acc : 0.7659
     Batch 050 | Loss : 0.4260 | Acc : 0.7920
     Batch 075 | Loss : 0.4564 | Acc : 0.7666
     Batch 100 | Loss : 0.5438 | Acc : 0.7150
     Batch 125 | Loss : 0.5659 | Acc : 0.7098
     Batch 150 | Loss : 0.4627 | Acc : 0.7692
     Batch 175 | Loss : 0.4735 | Acc : 0.7631
     Batch 200 | Loss : 0.4189 | Acc : 0.8025
     Batch 225 | Loss : 0.5239 | Acc : 0.7175
     Batch 250 | Loss : 0.3990 | Acc : 0.8212
     Batch 275 | Loss : 0.4318 | Acc : 0.7931
     Batch 300 | Loss : 0.4557 | Acc : 0.7734
Epoch 00008 | Train Loss : 0.4710 | Eval Loss : 0.4519 | Train acc : 0.7668 | Eval Acc : 0.7756 | Eval Log. Respected : 0.6579
     Batch 000 | Loss : 0.4656 | Acc : 0.7690
     Batch 025 | Loss : 0.4505 | Acc : 0.7777
     Batch 050 | Loss : 0.5332 | Acc : 0.7144
     Batch 075 | Loss : 0.4343 | Acc : 0.7911
     Batch 100 | Loss : 0.3838 | Acc : 0.8274
     Batch 125 | Loss : 0.4056 | Acc : 0.8123
     Batch 150 | Loss : 0.4816 | Acc : 0.7569
     Batch 175 | Loss : 0.4373 | Acc : 0.7867
     Batch 200 | Loss : 0.4193 | Acc : 0.7952
     Batch 225 | Loss : 0.4477 | Acc : 0.7859
     Batch 250 | Loss : 0.4559 | Acc : 0.7737
     Batch 275 | Loss : 0.4317 | Acc : 0.7860
     Batch 300 | Loss : 0.4584 | Acc : 0.7629
Epoch 00009 | Train Loss : 0.4628 | Eval Loss : 0.4421 | Train acc : 0.7713 | Eval Acc : 0.7796 | Eval Log. Respected : 0.6451
     Batch 000 | Loss : 0.4492 | Acc : 0.7720
     Batch 025 | Loss : 0.4600 | Acc : 0.7662
     Batch 050 | Loss : 0.4802 | Acc : 0.7618
     Batch 075 | Loss : 0.4622 | Acc : 0.7685
     Batch 100 | Loss : 0.4046 | Acc : 0.8205
     Batch 125 | Loss : 0.4586 | Acc : 0.7688
     Batch 150 | Loss : 0.4196 | Acc : 0.8141
     Batch 175 | Loss : 0.4230 | Acc : 0.7912
     Batch 200 | Loss : 0.4062 | Acc : 0.8150
     Batch 225 | Loss : 0.4543 | Acc : 0.7729
     Batch 250 | Loss : 0.5008 | Acc : 0.7486
     Batch 275 | Loss : 0.3929 | Acc : 0.8138
     Batch 300 | Loss : 0.4555 | Acc : 0.7660
Epoch 00010 | Train Loss : 0.4559 | Eval Loss : 0.4479 | Train acc : 0.7752 | Eval Acc : 0.7764 | Eval Log. Respected : 0.6495
     Batch 000 | Loss : 0.4293 | Acc : 0.7928
     Batch 025 | Loss : 0.6190 | Acc : 0.6689
     Batch 050 | Loss : 0.4793 | Acc : 0.7581
     Batch 075 | Loss : 0.4796 | Acc : 0.7609
     Batch 100 | Loss : 0.5102 | Acc : 0.7466
     Batch 125 | Loss : 0.5406 | Acc : 0.7305
     Batch 150 | Loss : 0.4362 | Acc : 0.7825
     Batch 175 | Loss : 0.4236 | Acc : 0.7939
     Batch 200 | Loss : 0.4840 | Acc : 0.7481
     Batch 225 | Loss : 0.4053 | Acc : 0.8178
     Batch 250 | Loss : 0.5556 | Acc : 0.7175
     Batch 275 | Loss : 0.3777 | Acc : 0.8376
     Batch 300 | Loss : 0.4623 | Acc : 0.7817
Epoch 00011 | Train Loss : 0.4525 | Eval Loss : 0.4570 | Train acc : 0.7781 | Eval Acc : 0.7759 | Eval Log. Respected : 0.6447
     Batch 000 | Loss : 0.4836 | Acc : 0.7515
     Batch 025 | Loss : 0.4017 | Acc : 0.8229
     Batch 050 | Loss : 0.3874 | Acc : 0.8227
     Batch 075 | Loss : 0.3704 | Acc : 0.8340
     Batch 100 | Loss : 0.4784 | Acc : 0.7610
     Batch 125 | Loss : 0.5391 | Acc : 0.7343
     Batch 150 | Loss : 0.4669 | Acc : 0.7798
     Batch 175 | Loss : 0.4096 | Acc : 0.7950
     Batch 200 | Loss : 0.5082 | Acc : 0.7345
     Batch 225 | Loss : 0.4523 | Acc : 0.7835
     Batch 250 | Loss : 0.4772 | Acc : 0.7640
     Batch 275 | Loss : 0.5336 | Acc : 0.7414
     Batch 300 | Loss : 0.4513 | Acc : 0.7809
Epoch 00012 | Train Loss : 0.4518 | Eval Loss : 0.4446 | Train acc : 0.7784 | Eval Acc : 0.7812 | Eval Log. Respected : 0.6423
     Batch 000 | Loss : 0.4533 | Acc : 0.7718
     Batch 025 | Loss : 0.4492 | Acc : 0.7815
     Batch 050 | Loss : 0.4456 | Acc : 0.7749
     Batch 075 | Loss : 0.4916 | Acc : 0.7350
     Batch 100 | Loss : 0.4342 | Acc : 0.7826
     Batch 125 | Loss : 0.4698 | Acc : 0.7521
     Batch 150 | Loss : 0.4639 | Acc : 0.7681
     Batch 175 | Loss : 0.4941 | Acc : 0.7442
     Batch 200 | Loss : 0.4197 | Acc : 0.8100
     Batch 225 | Loss : 0.4922 | Acc : 0.7437
     Batch 250 | Loss : 0.5164 | Acc : 0.7396
     Batch 275 | Loss : 0.5136 | Acc : 0.7405
     Batch 300 | Loss : 0.4205 | Acc : 0.7949
Epoch 00013 | Train Loss : 0.4461 | Eval Loss : 0.4439 | Train acc : 0.7813 | Eval Acc : 0.7810 | Eval Log. Respected : 0.6444
     Batch 000 | Loss : 0.3984 | Acc : 0.8261
     Batch 025 | Loss : 0.4681 | Acc : 0.7627
     Batch 050 | Loss : 0.4479 | Acc : 0.7732
     Batch 075 | Loss : 0.4688 | Acc : 0.7649
     Batch 100 | Loss : 0.4899 | Acc : 0.7458
     Batch 125 | Loss : 0.4456 | Acc : 0.7768
     Batch 150 | Loss : 0.4273 | Acc : 0.7913
     Batch 175 | Loss : 0.5183 | Acc : 0.7352
     Batch 200 | Loss : 0.4611 | Acc : 0.7808
     Batch 225 | Loss : 0.4744 | Acc : 0.7586
     Batch 250 | Loss : 0.4391 | Acc : 0.7815
     Batch 275 | Loss : 0.4029 | Acc : 0.8150
     Batch 300 | Loss : 0.5063 | Acc : 0.7525
Epoch 00014 | Train Loss : 0.4472 | Eval Loss : 0.4460 | Train acc : 0.7808 | Eval Acc : 0.7797 | Eval Log. Respected : 0.6632
     Batch 000 | Loss : 0.4924 | Acc : 0.7423
     Batch 025 | Loss : 0.4529 | Acc : 0.7829
     Batch 050 | Loss : 0.4316 | Acc : 0.7966
     Batch 075 | Loss : 0.4410 | Acc : 0.7758
     Batch 100 | Loss : 0.3950 | Acc : 0.8187
     Batch 125 | Loss : 0.4289 | Acc : 0.7962
     Batch 150 | Loss : 0.3856 | Acc : 0.8171
     Batch 175 | Loss : 0.4143 | Acc : 0.7982
     Batch 200 | Loss : 0.4033 | Acc : 0.8132
     Batch 225 | Loss : 0.5097 | Acc : 0.7268
     Batch 250 | Loss : 0.3934 | Acc : 0.8144
     Batch 275 | Loss : 0.5152 | Acc : 0.7346
     Batch 300 | Loss : 0.4034 | Acc : 0.8106
Epoch 00015 | Train Loss : 0.4455 | Eval Loss : 0.4348 | Train acc : 0.7817 | Eval Acc : 0.7843 | Eval Log. Respected : 0.6618
     Batch 000 | Loss : 0.3892 | Acc : 0.8175
     Batch 025 | Loss : 0.4311 | Acc : 0.7842
     Batch 050 | Loss : 0.4238 | Acc : 0.8061
     Batch 075 | Loss : 0.4499 | Acc : 0.7970
     Batch 100 | Loss : 0.5580 | Acc : 0.7249
     Batch 125 | Loss : 0.3742 | Acc : 0.8283
     Batch 150 | Loss : 0.4721 | Acc : 0.7515
     Batch 175 | Loss : 0.4162 | Acc : 0.8055
     Batch 200 | Loss : 0.4122 | Acc : 0.8100
     Batch 225 | Loss : 0.4311 | Acc : 0.7831
     Batch 250 | Loss : 0.3727 | Acc : 0.8304
     Batch 275 | Loss : 0.4019 | Acc : 0.8110
     Batch 300 | Loss : 0.4247 | Acc : 0.7979
Epoch 00016 | Train Loss : 0.4425 | Eval Loss : 0.4405 | Train acc : 0.7838 | Eval Acc : 0.7805 | Eval Log. Respected : 0.6506
     Batch 000 | Loss : 0.4297 | Acc : 0.7932
     Batch 025 | Loss : 0.4068 | Acc : 0.8082
     Batch 050 | Loss : 0.3843 | Acc : 0.8269
     Batch 075 | Loss : 0.3901 | Acc : 0.8201
     Batch 100 | Loss : 0.4804 | Acc : 0.7515
     Batch 125 | Loss : 0.4219 | Acc : 0.7996
     Batch 150 | Loss : 0.4743 | Acc : 0.7652
     Batch 175 | Loss : 0.4363 | Acc : 0.7901
     Batch 200 | Loss : 0.3880 | Acc : 0.8215
     Batch 225 | Loss : 0.4200 | Acc : 0.7978
     Batch 250 | Loss : 0.3806 | Acc : 0.8276
     Batch 275 | Loss : 0.5015 | Acc : 0.7461
     Batch 300 | Loss : 0.4735 | Acc : 0.7785
Epoch 00017 | Train Loss : 0.4416 | Eval Loss : 0.4421 | Train acc : 0.7845 | Eval Acc : 0.7808 | Eval Log. Respected : 0.6556
     Batch 000 | Loss : 0.5398 | Acc : 0.7297
     Batch 025 | Loss : 0.4495 | Acc : 0.7757
     Batch 050 | Loss : 0.4554 | Acc : 0.7657
     Batch 075 | Loss : 0.4760 | Acc : 0.7560
     Batch 100 | Loss : 0.4829 | Acc : 0.7544
     Batch 125 | Loss : 0.4365 | Acc : 0.7883
     Batch 150 | Loss : 0.4628 | Acc : 0.7639
     Batch 175 | Loss : 0.4341 | Acc : 0.7901
     Batch 200 | Loss : 0.3821 | Acc : 0.8209
     Batch 225 | Loss : 0.4014 | Acc : 0.8211
     Batch 250 | Loss : 0.3848 | Acc : 0.8215
     Batch 275 | Loss : 0.4158 | Acc : 0.8038
     Batch 300 | Loss : 0.4528 | Acc : 0.7754
Epoch 00018 | Train Loss : 0.4374 | Eval Loss : 0.4337 | Train acc : 0.7865 | Eval Acc : 0.7862 | Eval Log. Respected : 0.6492
     Batch 000 | Loss : 0.4281 | Acc : 0.7860
     Batch 025 | Loss : 0.4869 | Acc : 0.7395
     Batch 050 | Loss : 0.3847 | Acc : 0.8250
     Batch 075 | Loss : 0.4621 | Acc : 0.7625
     Batch 100 | Loss : 0.4699 | Acc : 0.7525
     Batch 125 | Loss : 0.3834 | Acc : 0.8206
     Batch 150 | Loss : 0.4752 | Acc : 0.7473
     Batch 175 | Loss : 0.4969 | Acc : 0.7385
     Batch 200 | Loss : 0.4290 | Acc : 0.7879
     Batch 225 | Loss : 0.3929 | Acc : 0.8265
     Batch 250 | Loss : 0.4102 | Acc : 0.8032
     Batch 275 | Loss : 0.4725 | Acc : 0.7609
     Batch 300 | Loss : 0.3503 | Acc : 0.8366
Epoch 00019 | Train Loss : 0.4401 | Eval Loss : 0.5236 | Train acc : 0.7850 | Eval Acc : 0.7215 | Eval Log. Respected : 0.6661
     Batch 000 | Loss : 0.5217 | Acc : 0.7317
     Batch 025 | Loss : 0.4001 | Acc : 0.8162
     Batch 050 | Loss : 0.4388 | Acc : 0.7778
     Batch 075 | Loss : 0.3668 | Acc : 0.8365
     Batch 100 | Loss : 0.4616 | Acc : 0.7575
     Batch 125 | Loss : 0.4324 | Acc : 0.7868
     Batch 150 | Loss : 0.5148 | Acc : 0.7430
     Batch 175 | Loss : 0.4494 | Acc : 0.7726
     Batch 200 | Loss : 0.3570 | Acc : 0.8396
     Batch 225 | Loss : 0.4620 | Acc : 0.7606
     Batch 250 | Loss : 0.4014 | Acc : 0.8039
     Batch 275 | Loss : 0.4696 | Acc : 0.7627
     Batch 300 | Loss : 0.4201 | Acc : 0.7875
Epoch 00020 | Train Loss : 0.4347 | Eval Loss : 0.4275 | Train acc : 0.7879 | Eval Acc : 0.7890 | Eval Log. Respected : 0.6623
     Batch 000 | Loss : 0.4688 | Acc : 0.7641
     Batch 025 | Loss : 0.4709 | Acc : 0.7695
     Batch 050 | Loss : 0.3689 | Acc : 0.8241
     Batch 075 | Loss : 0.3730 | Acc : 0.8285
     Batch 100 | Loss : 0.4629 | Acc : 0.7630
     Batch 125 | Loss : 0.3886 | Acc : 0.8201
     Batch 150 | Loss : 0.3948 | Acc : 0.8249
     Batch 175 | Loss : 0.3881 | Acc : 0.8136
     Batch 200 | Loss : 0.4426 | Acc : 0.7934
     Batch 225 | Loss : 0.3777 | Acc : 0.8248
     Batch 250 | Loss : 0.4127 | Acc : 0.8006
     Batch 275 | Loss : 0.4157 | Acc : 0.8057
     Batch 300 | Loss : 0.4364 | Acc : 0.7951
Epoch 00021 | Train Loss : 0.4347 | Eval Loss : 0.4233 | Train acc : 0.7884 | Eval Acc : 0.7932 | Eval Log. Respected : 0.6596
     Batch 000 | Loss : 0.3927 | Acc : 0.8200
     Batch 025 | Loss : 0.4322 | Acc : 0.7985
     Batch 050 | Loss : 0.3912 | Acc : 0.8131
     Batch 075 | Loss : 0.4233 | Acc : 0.7815
     Batch 100 | Loss : 0.4454 | Acc : 0.7814
     Batch 125 | Loss : 0.4786 | Acc : 0.7580
     Batch 150 | Loss : 0.4029 | Acc : 0.8129
     Batch 175 | Loss : 0.4735 | Acc : 0.7634
     Batch 200 | Loss : 0.4257 | Acc : 0.7812
     Batch 225 | Loss : 0.4190 | Acc : 0.8038
     Batch 250 | Loss : 0.4801 | Acc : 0.7518
     Batch 275 | Loss : 0.3758 | Acc : 0.8239
     Batch 300 | Loss : 0.4427 | Acc : 0.7879
Epoch 00022 | Train Loss : 0.4336 | Eval Loss : 0.4439 | Train acc : 0.7889 | Eval Acc : 0.7800 | Eval Log. Respected : 0.6505
     Batch 000 | Loss : 0.5068 | Acc : 0.7390
     Batch 025 | Loss : 0.3940 | Acc : 0.8117
     Batch 050 | Loss : 0.4213 | Acc : 0.7931
     Batch 075 | Loss : 0.3940 | Acc : 0.8198
     Batch 100 | Loss : 0.4065 | Acc : 0.8099
     Batch 125 | Loss : 0.5160 | Acc : 0.7401
     Batch 150 | Loss : 0.3857 | Acc : 0.8190
     Batch 175 | Loss : 0.4142 | Acc : 0.8087
     Batch 200 | Loss : 0.4444 | Acc : 0.7733
     Batch 225 | Loss : 0.3845 | Acc : 0.8249
     Batch 250 | Loss : 0.4240 | Acc : 0.7931
     Batch 275 | Loss : 0.4338 | Acc : 0.7794
     Batch 300 | Loss : 0.5248 | Acc : 0.7376
Epoch 00023 | Train Loss : 0.4336 | Eval Loss : 0.4402 | Train acc : 0.7889 | Eval Acc : 0.7821 | Eval Log. Respected : 0.6423
     Batch 000 | Loss : 0.4192 | Acc : 0.7977
     Batch 025 | Loss : 0.4328 | Acc : 0.7891
     Batch 050 | Loss : 0.5053 | Acc : 0.7689
     Batch 075 | Loss : 0.4632 | Acc : 0.7691
     Batch 100 | Loss : 0.4763 | Acc : 0.7565
     Batch 125 | Loss : 0.4278 | Acc : 0.7900
     Batch 150 | Loss : 0.4067 | Acc : 0.8044
     Batch 175 | Loss : 0.4108 | Acc : 0.8058
     Batch 200 | Loss : 0.4479 | Acc : 0.7697
     Batch 225 | Loss : 0.4575 | Acc : 0.7599
     Batch 250 | Loss : 0.5293 | Acc : 0.7385
     Batch 275 | Loss : 0.3880 | Acc : 0.8170
     Batch 300 | Loss : 0.3872 | Acc : 0.8209
Epoch 00024 | Train Loss : 0.4306 | Eval Loss : 0.4378 | Train acc : 0.7909 | Eval Acc : 0.7845 | Eval Log. Respected : 0.6578
     Batch 000 | Loss : 0.4771 | Acc : 0.7559
     Batch 025 | Loss : 0.4152 | Acc : 0.8095
     Batch 050 | Loss : 0.4071 | Acc : 0.8024
     Batch 075 | Loss : 0.4417 | Acc : 0.7841
     Batch 100 | Loss : 0.3987 | Acc : 0.8148
     Batch 125 | Loss : 0.3750 | Acc : 0.8233
     Batch 150 | Loss : 0.5279 | Acc : 0.7314
     Batch 175 | Loss : 0.3734 | Acc : 0.8321
     Batch 200 | Loss : 0.4864 | Acc : 0.7469
     Batch 225 | Loss : 0.3753 | Acc : 0.8308
     Batch 250 | Loss : 0.4414 | Acc : 0.7828
     Batch 275 | Loss : 0.3974 | Acc : 0.8164
     Batch 300 | Loss : 0.3928 | Acc : 0.8114
Epoch 00025 | Train Loss : 0.4304 | Eval Loss : 0.4270 | Train acc : 0.7908 | Eval Acc : 0.7899 | Eval Log. Respected : 0.6453
     Batch 000 | Loss : 0.3936 | Acc : 0.8138
     Batch 025 | Loss : 0.3635 | Acc : 0.8298
     Batch 050 | Loss : 0.3976 | Acc : 0.8145
     Batch 075 | Loss : 0.3841 | Acc : 0.8270
     Batch 100 | Loss : 0.4493 | Acc : 0.7743
     Batch 125 | Loss : 0.3307 | Acc : 0.8556
     Batch 150 | Loss : 0.4110 | Acc : 0.8091
     Batch 175 | Loss : 0.3658 | Acc : 0.8374
     Batch 200 | Loss : 0.4936 | Acc : 0.7540
     Batch 225 | Loss : 0.4576 | Acc : 0.7772
     Batch 250 | Loss : 0.4018 | Acc : 0.8151
     Batch 275 | Loss : 0.4225 | Acc : 0.7805
     Batch 300 | Loss : 0.4036 | Acc : 0.8078
Epoch 00026 | Train Loss : 0.4277 | Eval Loss : 0.4363 | Train acc : 0.7925 | Eval Acc : 0.7846 | Eval Log. Respected : 0.6635
     Batch 000 | Loss : 0.4136 | Acc : 0.8116
     Batch 025 | Loss : 0.4342 | Acc : 0.7853
     Batch 050 | Loss : 0.4802 | Acc : 0.7413
     Batch 075 | Loss : 0.4306 | Acc : 0.7870
     Batch 100 | Loss : 0.4101 | Acc : 0.7972
     Batch 125 | Loss : 0.4482 | Acc : 0.7716
     Batch 150 | Loss : 0.3976 | Acc : 0.8105
     Batch 175 | Loss : 0.4411 | Acc : 0.7883
     Batch 200 | Loss : 0.3815 | Acc : 0.8272
     Batch 225 | Loss : 0.5645 | Acc : 0.7173
     Batch 250 | Loss : 0.4260 | Acc : 0.7952
     Batch 275 | Loss : 0.3773 | Acc : 0.8235
     Batch 300 | Loss : 0.3613 | Acc : 0.8386
Epoch 00027 | Train Loss : 0.4284 | Eval Loss : 0.4199 | Train acc : 0.7921 | Eval Acc : 0.7928 | Eval Log. Respected : 0.6484
     Batch 000 | Loss : 0.4126 | Acc : 0.7979
     Batch 025 | Loss : 0.5208 | Acc : 0.7245
     Batch 050 | Loss : 0.4076 | Acc : 0.8099
     Batch 075 | Loss : 0.4287 | Acc : 0.7863
     Batch 100 | Loss : 0.4026 | Acc : 0.8076
     Batch 125 | Loss : 0.3965 | Acc : 0.8011
     Batch 150 | Loss : 0.3628 | Acc : 0.8390
     Batch 175 | Loss : 0.3854 | Acc : 0.8227
     Batch 200 | Loss : 0.3727 | Acc : 0.8303
     Batch 225 | Loss : 0.4039 | Acc : 0.8142
     Batch 250 | Loss : 0.3964 | Acc : 0.8133
     Batch 275 | Loss : 0.4015 | Acc : 0.8163
     Batch 300 | Loss : 0.3794 | Acc : 0.8271
Epoch 00028 | Train Loss : 0.4279 | Eval Loss : 0.4243 | Train acc : 0.7924 | Eval Acc : 0.7910 | Eval Log. Respected : 0.6595
     Batch 000 | Loss : 0.4461 | Acc : 0.7807
     Batch 025 | Loss : 0.4080 | Acc : 0.8107
     Batch 050 | Loss : 0.4205 | Acc : 0.8002
     Batch 075 | Loss : 0.4219 | Acc : 0.7938
     Batch 100 | Loss : 0.5046 | Acc : 0.7438
     Batch 125 | Loss : 0.4034 | Acc : 0.8064
     Batch 150 | Loss : 0.4262 | Acc : 0.7913
     Batch 175 | Loss : 0.3561 | Acc : 0.8363
     Batch 200 | Loss : 0.4198 | Acc : 0.7985
     Batch 225 | Loss : 0.5149 | Acc : 0.7377
     Batch 250 | Loss : 0.4493 | Acc : 0.7683
     Batch 275 | Loss : 0.3905 | Acc : 0.8303
     Batch 300 | Loss : 0.4961 | Acc : 0.7522
Epoch 00029 | Train Loss : 0.4307 | Eval Loss : 0.4247 | Train acc : 0.7904 | Eval Acc : 0.7922 | Eval Log. Respected : 0.6607
     Batch 000 | Loss : 0.4416 | Acc : 0.7812
     Batch 025 | Loss : 0.4192 | Acc : 0.7983
     Batch 050 | Loss : 0.4827 | Acc : 0.7485
     Batch 075 | Loss : 0.4425 | Acc : 0.7764
     Batch 100 | Loss : 0.4660 | Acc : 0.7763
     Batch 125 | Loss : 0.4289 | Acc : 0.7952
     Batch 150 | Loss : 0.4633 | Acc : 0.7666
     Batch 175 | Loss : 0.4244 | Acc : 0.7857
     Batch 200 | Loss : 0.3919 | Acc : 0.8171
     Batch 225 | Loss : 0.4787 | Acc : 0.7484
     Batch 250 | Loss : 0.4622 | Acc : 0.7683
     Batch 275 | Loss : 0.4226 | Acc : 0.7937
     Batch 300 | Loss : 0.4131 | Acc : 0.8027
Epoch 00030 | Train Loss : 0.4273 | Eval Loss : 0.4361 | Train acc : 0.7929 | Eval Acc : 0.7855 | Eval Log. Respected : 0.6433
     Batch 000 | Loss : 0.3953 | Acc : 0.8114
     Batch 025 | Loss : 0.4887 | Acc : 0.7473
     Batch 050 | Loss : 0.5286 | Acc : 0.7322
     Batch 075 | Loss : 0.3471 | Acc : 0.8376
     Batch 100 | Loss : 0.3811 | Acc : 0.8235
     Batch 125 | Loss : 0.4852 | Acc : 0.7541
     Batch 150 | Loss : 0.4381 | Acc : 0.7812
     Batch 175 | Loss : 0.4143 | Acc : 0.7937
     Batch 200 | Loss : 0.4230 | Acc : 0.8047
     Batch 225 | Loss : 0.4291 | Acc : 0.7855
     Batch 250 | Loss : 0.3683 | Acc : 0.8251
     Batch 275 | Loss : 0.4425 | Acc : 0.7812
     Batch 300 | Loss : 0.4908 | Acc : 0.7629
Epoch 00031 | Train Loss : 0.4282 | Eval Loss : 0.4242 | Train acc : 0.7931 | Eval Acc : 0.7945 | Eval Log. Respected : 0.6592
     Batch 000 | Loss : 0.4425 | Acc : 0.7796
     Batch 025 | Loss : 0.3743 | Acc : 0.8249
     Batch 050 | Loss : 0.3835 | Acc : 0.8244
     Batch 075 | Loss : 0.3545 | Acc : 0.8430
     Batch 100 | Loss : 0.4188 | Acc : 0.7951
     Batch 125 | Loss : 0.3890 | Acc : 0.8195
     Batch 150 | Loss : 0.4247 | Acc : 0.7937
     Batch 175 | Loss : 0.3938 | Acc : 0.8177
     Batch 200 | Loss : 0.4688 | Acc : 0.7644
     Batch 225 | Loss : 0.4639 | Acc : 0.7728
     Batch 250 | Loss : 0.4244 | Acc : 0.7975
     Batch 275 | Loss : 0.5091 | Acc : 0.7279
     Batch 300 | Loss : 0.4734 | Acc : 0.7722
Epoch 00032 | Train Loss : 0.4266 | Eval Loss : 0.4214 | Train acc : 0.7935 | Eval Acc : 0.7903 | Eval Log. Respected : 0.6602
     Batch 000 | Loss : 0.3784 | Acc : 0.8246
     Batch 025 | Loss : 0.4474 | Acc : 0.7750
     Batch 050 | Loss : 0.4120 | Acc : 0.7977
     Batch 075 | Loss : 0.4245 | Acc : 0.7909
     Batch 100 | Loss : 0.4159 | Acc : 0.7989
     Batch 125 | Loss : 0.4063 | Acc : 0.8083
     Batch 150 | Loss : 0.3594 | Acc : 0.8357
     Batch 175 | Loss : 0.4741 | Acc : 0.7589
     Batch 200 | Loss : 0.3867 | Acc : 0.8149
     Batch 225 | Loss : 0.3923 | Acc : 0.8140
     Batch 250 | Loss : 0.4666 | Acc : 0.7588
     Batch 275 | Loss : 0.4395 | Acc : 0.7838
     Batch 300 | Loss : 0.4219 | Acc : 0.7799
Epoch 00033 | Train Loss : 0.4263 | Eval Loss : 0.4312 | Train acc : 0.7932 | Eval Acc : 0.7878 | Eval Log. Respected : 0.6507
     Batch 000 | Loss : 0.4908 | Acc : 0.7489
     Batch 025 | Loss : 0.3950 | Acc : 0.8136
     Batch 050 | Loss : 0.5188 | Acc : 0.7272
     Batch 075 | Loss : 0.4136 | Acc : 0.8032
     Batch 100 | Loss : 0.4516 | Acc : 0.7783
     Batch 125 | Loss : 0.4371 | Acc : 0.7787
     Batch 150 | Loss : 0.4712 | Acc : 0.7666
     Batch 175 | Loss : 0.4066 | Acc : 0.8064
     Batch 200 | Loss : 0.4618 | Acc : 0.7752
     Batch 225 | Loss : 0.3672 | Acc : 0.8299
     Batch 250 | Loss : 0.3786 | Acc : 0.8251
     Batch 275 | Loss : 0.3660 | Acc : 0.8293
     Batch 300 | Loss : 0.3916 | Acc : 0.8252
Epoch 00034 | Train Loss : 0.4233 | Eval Loss : 0.4164 | Train acc : 0.7949 | Eval Acc : 0.7946 | Eval Log. Respected : 0.6585
     Batch 000 | Loss : 0.3916 | Acc : 0.8073
     Batch 025 | Loss : 0.4868 | Acc : 0.7608
     Batch 050 | Loss : 0.3631 | Acc : 0.8404
     Batch 075 | Loss : 0.4376 | Acc : 0.7864
     Batch 100 | Loss : 0.5408 | Acc : 0.7336
     Batch 125 | Loss : 0.4160 | Acc : 0.8030
     Batch 150 | Loss : 0.4156 | Acc : 0.8045
     Batch 175 | Loss : 0.3639 | Acc : 0.8268
     Batch 200 | Loss : 0.3904 | Acc : 0.8186
     Batch 225 | Loss : 0.4472 | Acc : 0.7762
     Batch 250 | Loss : 0.4254 | Acc : 0.7904
     Batch 275 | Loss : 0.3785 | Acc : 0.8327
     Batch 300 | Loss : 0.4004 | Acc : 0.8018
Epoch 00035 | Train Loss : 0.4275 | Eval Loss : 0.4209 | Train acc : 0.7931 | Eval Acc : 0.7929 | Eval Log. Respected : 0.6583
     Batch 000 | Loss : 0.4459 | Acc : 0.7832
     Batch 025 | Loss : 0.4202 | Acc : 0.8083
     Batch 050 | Loss : 0.4878 | Acc : 0.7474
     Batch 075 | Loss : 0.5102 | Acc : 0.7351
     Batch 100 | Loss : 0.3969 | Acc : 0.8155
     Batch 125 | Loss : 0.4405 | Acc : 0.7814
     Batch 150 | Loss : 0.4332 | Acc : 0.7878
     Batch 175 | Loss : 0.4648 | Acc : 0.7664
     Batch 200 | Loss : 0.4069 | Acc : 0.8086
     Batch 225 | Loss : 0.3625 | Acc : 0.8296
     Batch 250 | Loss : 0.4126 | Acc : 0.8076
     Batch 275 | Loss : 0.4600 | Acc : 0.7837
     Batch 300 | Loss : 0.3569 | Acc : 0.8311
Epoch 00036 | Train Loss : 0.4239 | Eval Loss : 0.4292 | Train acc : 0.7945 | Eval Acc : 0.7870 | Eval Log. Respected : 0.6423
     Batch 000 | Loss : 0.3888 | Acc : 0.8146
     Batch 025 | Loss : 0.4333 | Acc : 0.7891
     Batch 050 | Loss : 0.3895 | Acc : 0.8222
     Batch 075 | Loss : 0.3727 | Acc : 0.8388
     Batch 100 | Loss : 0.4237 | Acc : 0.7965
     Batch 125 | Loss : 0.4321 | Acc : 0.7886
     Batch 150 | Loss : 0.3974 | Acc : 0.8155
     Batch 175 | Loss : 0.4759 | Acc : 0.7517
     Batch 200 | Loss : 0.4750 | Acc : 0.7634
     Batch 225 | Loss : 0.4527 | Acc : 0.7751
     Batch 250 | Loss : 0.4700 | Acc : 0.7790
     Batch 275 | Loss : 0.5118 | Acc : 0.7365
     Batch 300 | Loss : 0.3969 | Acc : 0.8065
Epoch 00037 | Train Loss : 0.4241 | Eval Loss : 0.4160 | Train acc : 0.7947 | Eval Acc : 0.7979 | Eval Log. Respected : 0.6637
     Batch 000 | Loss : 0.3921 | Acc : 0.8112
     Batch 025 | Loss : 0.4392 | Acc : 0.7851
     Batch 050 | Loss : 0.3677 | Acc : 0.8318
     Batch 075 | Loss : 0.4925 | Acc : 0.7635
     Batch 100 | Loss : 0.4209 | Acc : 0.7859
     Batch 125 | Loss : 0.4096 | Acc : 0.8096
     Batch 150 | Loss : 0.4369 | Acc : 0.7915
     Batch 175 | Loss : 0.4431 | Acc : 0.7878
     Batch 200 | Loss : 0.4642 | Acc : 0.7745
     Batch 225 | Loss : 0.4534 | Acc : 0.7729
     Batch 250 | Loss : 0.4380 | Acc : 0.7731
     Batch 275 | Loss : 0.4987 | Acc : 0.7343
     Batch 300 | Loss : 0.4775 | Acc : 0.7589
Epoch 00038 | Train Loss : 0.4252 | Eval Loss : 0.4241 | Train acc : 0.7941 | Eval Acc : 0.7937 | Eval Log. Respected : 0.6628
     Batch 000 | Loss : 0.5165 | Acc : 0.7639
     Batch 025 | Loss : 0.3979 | Acc : 0.8094
     Batch 050 | Loss : 0.3990 | Acc : 0.8079
     Batch 075 | Loss : 0.4795 | Acc : 0.7580
     Batch 100 | Loss : 0.4347 | Acc : 0.7937
     Batch 125 | Loss : 0.4224 | Acc : 0.7873
     Batch 150 | Loss : 0.3541 | Acc : 0.8348
     Batch 175 | Loss : 0.4316 | Acc : 0.7916
     Batch 200 | Loss : 0.3932 | Acc : 0.8186
     Batch 225 | Loss : 0.3663 | Acc : 0.8306
     Batch 250 | Loss : 0.4832 | Acc : 0.7502
     Batch 275 | Loss : 0.3781 | Acc : 0.8217
     Batch 300 | Loss : 0.3959 | Acc : 0.8150
Epoch 00039 | Train Loss : 0.4199 | Eval Loss : 0.4247 | Train acc : 0.7974 | Eval Acc : 0.7897 | Eval Log. Respected : 0.6592
     Batch 000 | Loss : 0.3552 | Acc : 0.8361
     Batch 025 | Loss : 0.5066 | Acc : 0.7644
     Batch 050 | Loss : 0.4086 | Acc : 0.7986
     Batch 075 | Loss : 0.4250 | Acc : 0.7835
     Batch 100 | Loss : 0.3718 | Acc : 0.8307
     Batch 125 | Loss : 0.3844 | Acc : 0.8216
     Batch 150 | Loss : 0.4941 | Acc : 0.7631
     Batch 175 | Loss : 0.3749 | Acc : 0.8291
     Batch 200 | Loss : 0.4267 | Acc : 0.7881
     Batch 225 | Loss : 0.3355 | Acc : 0.8536
     Batch 250 | Loss : 0.4571 | Acc : 0.7755
     Batch 275 | Loss : 0.4240 | Acc : 0.7893
     Batch 300 | Loss : 0.4082 | Acc : 0.8038
Epoch 00040 | Train Loss : 0.4199 | Eval Loss : 0.4184 | Train acc : 0.7970 | Eval Acc : 0.7966 | Eval Log. Respected : 0.6548
     Batch 000 | Loss : 0.3613 | Acc : 0.8333
     Batch 025 | Loss : 0.3721 | Acc : 0.8361
     Batch 050 | Loss : 0.4911 | Acc : 0.7614
     Batch 075 | Loss : 0.3687 | Acc : 0.8272
     Batch 100 | Loss : 0.4055 | Acc : 0.8060
     Batch 125 | Loss : 0.3874 | Acc : 0.8222
     Batch 150 | Loss : 0.4072 | Acc : 0.8006
     Batch 175 | Loss : 0.4299 | Acc : 0.7920
     Batch 200 | Loss : 0.4472 | Acc : 0.7733
     Batch 225 | Loss : 0.3700 | Acc : 0.8342
     Batch 250 | Loss : 0.4219 | Acc : 0.7974
     Batch 275 | Loss : 0.3700 | Acc : 0.8334
     Batch 300 | Loss : 0.4143 | Acc : 0.8057
Epoch 00041 | Train Loss : 0.4205 | Eval Loss : 0.4134 | Train acc : 0.7969 | Eval Acc : 0.7970 | Eval Log. Respected : 0.6604
     Batch 000 | Loss : 0.3664 | Acc : 0.8306
     Batch 025 | Loss : 0.4320 | Acc : 0.7901
     Batch 050 | Loss : 0.4012 | Acc : 0.8089
     Batch 075 | Loss : 0.5077 | Acc : 0.7333
     Batch 100 | Loss : 0.4077 | Acc : 0.8094
     Batch 125 | Loss : 0.3913 | Acc : 0.8187
     Batch 150 | Loss : 0.3522 | Acc : 0.8423
     Batch 175 | Loss : 0.4408 | Acc : 0.7842
     Batch 200 | Loss : 0.3753 | Acc : 0.8240
     Batch 225 | Loss : 0.3512 | Acc : 0.8430
     Batch 250 | Loss : 0.3430 | Acc : 0.8409
     Batch 275 | Loss : 0.3989 | Acc : 0.8054
     Batch 300 | Loss : 0.5765 | Acc : 0.6978
Epoch 00042 | Train Loss : 0.4195 | Eval Loss : 0.4533 | Train acc : 0.7977 | Eval Acc : 0.7748 | Eval Log. Respected : 0.6614
     Batch 000 | Loss : 0.4120 | Acc : 0.8032
     Batch 025 | Loss : 0.4621 | Acc : 0.7640
     Batch 050 | Loss : 0.4853 | Acc : 0.7657
     Batch 075 | Loss : 0.3462 | Acc : 0.8458
     Batch 100 | Loss : 0.3987 | Acc : 0.8064
     Batch 125 | Loss : 0.4433 | Acc : 0.7816
     Batch 150 | Loss : 0.4280 | Acc : 0.7919
     Batch 175 | Loss : 0.3739 | Acc : 0.8331
     Batch 200 | Loss : 0.3465 | Acc : 0.8406
     Batch 225 | Loss : 0.3745 | Acc : 0.8235
     Batch 250 | Loss : 0.4249 | Acc : 0.7942
     Batch 275 | Loss : 0.3750 | Acc : 0.8277
     Batch 300 | Loss : 0.3943 | Acc : 0.8080
Epoch 00043 | Train Loss : 0.4185 | Eval Loss : 0.4138 | Train acc : 0.7982 | Eval Acc : 0.7981 | Eval Log. Respected : 0.6633
     Batch 000 | Loss : 0.4369 | Acc : 0.7839
     Batch 025 | Loss : 0.4592 | Acc : 0.7700
     Batch 050 | Loss : 0.4068 | Acc : 0.8120
     Batch 075 | Loss : 0.4224 | Acc : 0.7947
     Batch 100 | Loss : 0.5672 | Acc : 0.7109
     Batch 125 | Loss : 0.3558 | Acc : 0.8311
     Batch 150 | Loss : 0.4123 | Acc : 0.7982
     Batch 175 | Loss : 0.4971 | Acc : 0.7584
     Batch 200 | Loss : 0.3942 | Acc : 0.8133
     Batch 225 | Loss : 0.3855 | Acc : 0.8236
     Batch 250 | Loss : 0.4075 | Acc : 0.8080
     Batch 275 | Loss : 0.4784 | Acc : 0.7616
     Batch 300 | Loss : 0.3962 | Acc : 0.8138
Epoch 00044 | Train Loss : 0.4194 | Eval Loss : 0.4140 | Train acc : 0.7977 | Eval Acc : 0.7975 | Eval Log. Respected : 0.6578
     Batch 000 | Loss : 0.3818 | Acc : 0.8257
     Batch 025 | Loss : 0.3862 | Acc : 0.8152
     Batch 050 | Loss : 0.4077 | Acc : 0.8014
     Batch 075 | Loss : 0.4276 | Acc : 0.7912
     Batch 100 | Loss : 0.3871 | Acc : 0.8209
     Batch 125 | Loss : 0.4274 | Acc : 0.7847
     Batch 150 | Loss : 0.3544 | Acc : 0.8428
     Batch 175 | Loss : 0.4693 | Acc : 0.7635
     Batch 200 | Loss : 0.3969 | Acc : 0.8180
     Batch 225 | Loss : 0.3663 | Acc : 0.8317
     Batch 250 | Loss : 0.3953 | Acc : 0.8097
     Batch 275 | Loss : 0.4016 | Acc : 0.8136
     Batch 300 | Loss : 0.4311 | Acc : 0.7861
Epoch 00045 | Train Loss : 0.4156 | Eval Loss : 0.4195 | Train acc : 0.7996 | Eval Acc : 0.7944 | Eval Log. Respected : 0.6747
     Batch 000 | Loss : 0.3531 | Acc : 0.8420
     Batch 025 | Loss : 0.4449 | Acc : 0.7915
     Batch 050 | Loss : 0.4519 | Acc : 0.7678
     Batch 075 | Loss : 0.3852 | Acc : 0.8190
     Batch 100 | Loss : 0.4519 | Acc : 0.7743
     Batch 125 | Loss : 0.4307 | Acc : 0.7858
     Batch 150 | Loss : 0.3767 | Acc : 0.8204
     Batch 175 | Loss : 0.4709 | Acc : 0.7666
     Batch 200 | Loss : 0.4781 | Acc : 0.7504
     Batch 225 | Loss : 0.3802 | Acc : 0.8210
     Batch 250 | Loss : 0.3748 | Acc : 0.8162
     Batch 275 | Loss : 0.3850 | Acc : 0.8209
     Batch 300 | Loss : 0.3834 | Acc : 0.8218
Epoch 00046 | Train Loss : 0.4192 | Eval Loss : 0.4049 | Train acc : 0.7975 | Eval Acc : 0.8034 | Eval Log. Respected : 0.6773
     Batch 000 | Loss : 0.4385 | Acc : 0.7883
     Batch 025 | Loss : 0.3913 | Acc : 0.8165
     Batch 050 | Loss : 0.3808 | Acc : 0.8241
     Batch 075 | Loss : 0.4209 | Acc : 0.7994
     Batch 100 | Loss : 0.5185 | Acc : 0.7364
     Batch 125 | Loss : 0.4595 | Acc : 0.7744
     Batch 150 | Loss : 0.4344 | Acc : 0.7873
     Batch 175 | Loss : 0.3999 | Acc : 0.8077
     Batch 200 | Loss : 0.4597 | Acc : 0.7669
     Batch 225 | Loss : 0.4925 | Acc : 0.7567
     Batch 250 | Loss : 0.3776 | Acc : 0.8323
     Batch 275 | Loss : 0.3920 | Acc : 0.8115
     Batch 300 | Loss : 0.4618 | Acc : 0.7762
Epoch 00047 | Train Loss : 0.4174 | Eval Loss : 0.4169 | Train acc : 0.7990 | Eval Acc : 0.7965 | Eval Log. Respected : 0.6721
     Batch 000 | Loss : 0.5701 | Acc : 0.7234
     Batch 025 | Loss : 0.4628 | Acc : 0.7633
     Batch 050 | Loss : 0.4674 | Acc : 0.7617
     Batch 075 | Loss : 0.4254 | Acc : 0.7867
     Batch 100 | Loss : 0.4626 | Acc : 0.7667
     Batch 125 | Loss : 0.4144 | Acc : 0.8020
     Batch 150 | Loss : 0.3574 | Acc : 0.8358
     Batch 175 | Loss : 0.4670 | Acc : 0.7691
     Batch 200 | Loss : 0.4103 | Acc : 0.7992
     Batch 225 | Loss : 0.4095 | Acc : 0.8075
     Batch 250 | Loss : 0.3631 | Acc : 0.8368
     Batch 275 | Loss : 0.4018 | Acc : 0.8127
     Batch 300 | Loss : 0.3683 | Acc : 0.8281
Epoch 00048 | Train Loss : 0.4148 | Eval Loss : 0.4094 | Train acc : 0.8003 | Eval Acc : 0.8009 | Eval Log. Respected : 0.6621
     Batch 000 | Loss : 0.4181 | Acc : 0.8024
     Batch 025 | Loss : 0.4113 | Acc : 0.8039
     Batch 050 | Loss : 0.4869 | Acc : 0.7577
     Batch 075 | Loss : 0.3653 | Acc : 0.8313
     Batch 100 | Loss : 0.4185 | Acc : 0.7957
     Batch 125 | Loss : 0.3421 | Acc : 0.8451
     Batch 150 | Loss : 0.4321 | Acc : 0.7951
     Batch 175 | Loss : 0.3879 | Acc : 0.8211
     Batch 200 | Loss : 0.3579 | Acc : 0.8277
     Batch 225 | Loss : 0.3831 | Acc : 0.8154
     Batch 250 | Loss : 0.3821 | Acc : 0.8301
     Batch 275 | Loss : 0.4189 | Acc : 0.8078
     Batch 300 | Loss : 0.4544 | Acc : 0.7755
Epoch 00049 | Train Loss : 0.4180 | Eval Loss : 0.4203 | Train acc : 0.7981 | Eval Acc : 0.7954 | Eval Log. Respected : 0.6511
     Batch 000 | Loss : 0.3672 | Acc : 0.8331
     Batch 025 | Loss : 0.3662 | Acc : 0.8237
     Batch 050 | Loss : 0.4462 | Acc : 0.7797
     Batch 075 | Loss : 0.3831 | Acc : 0.8214
     Batch 100 | Loss : 0.3864 | Acc : 0.8160
     Batch 125 | Loss : 0.4046 | Acc : 0.8111
     Batch 150 | Loss : 0.3791 | Acc : 0.8197
     Batch 175 | Loss : 0.3723 | Acc : 0.8263
     Batch 200 | Loss : 0.4444 | Acc : 0.7827
     Batch 225 | Loss : 0.4258 | Acc : 0.7829
     Batch 250 | Loss : 0.3699 | Acc : 0.8270
     Batch 275 | Loss : 0.4134 | Acc : 0.8005
     Batch 300 | Loss : 0.4641 | Acc : 0.7709
Epoch 00050 | Train Loss : 0.4176 | Eval Loss : 0.4164 | Train acc : 0.7983 | Eval Acc : 0.7966 | Eval Log. Respected : 0.6690
     Batch 000 | Loss : 0.5282 | Acc : 0.7444
     Batch 025 | Loss : 0.4436 | Acc : 0.7892
     Batch 050 | Loss : 0.3874 | Acc : 0.8134
     Batch 075 | Loss : 0.4952 | Acc : 0.7520
     Batch 100 | Loss : 0.4580 | Acc : 0.7706
     Batch 125 | Loss : 0.3755 | Acc : 0.8258
     Batch 150 | Loss : 0.4142 | Acc : 0.7921
     Batch 175 | Loss : 0.3792 | Acc : 0.8111
     Batch 200 | Loss : 0.5495 | Acc : 0.7389
     Batch 225 | Loss : 0.4139 | Acc : 0.7973
     Batch 250 | Loss : 0.3460 | Acc : 0.8452
     Batch 275 | Loss : 0.3743 | Acc : 0.8249
     Batch 300 | Loss : 0.5220 | Acc : 0.7437
Epoch 00051 | Train Loss : 0.4142 | Eval Loss : 0.4079 | Train acc : 0.8009 | Eval Acc : 0.8017 | Eval Log. Respected : 0.6711
     Batch 000 | Loss : 0.3830 | Acc : 0.8175
     Batch 025 | Loss : 0.4364 | Acc : 0.7874
     Batch 050 | Loss : 0.3954 | Acc : 0.8233
     Batch 075 | Loss : 0.4195 | Acc : 0.7934
     Batch 100 | Loss : 0.4914 | Acc : 0.7530
     Batch 125 | Loss : 0.4004 | Acc : 0.8076
     Batch 150 | Loss : 0.4030 | Acc : 0.8050
     Batch 175 | Loss : 0.3874 | Acc : 0.8084
     Batch 200 | Loss : 0.4027 | Acc : 0.8027
     Batch 225 | Loss : 0.3926 | Acc : 0.8085
     Batch 250 | Loss : 0.3528 | Acc : 0.8319
     Batch 275 | Loss : 0.4415 | Acc : 0.7964
     Batch 300 | Loss : 0.3632 | Acc : 0.8341
Epoch 00052 | Train Loss : 0.4138 | Eval Loss : 0.4120 | Train acc : 0.8011 | Eval Acc : 0.7993 | Eval Log. Respected : 0.6501
     Batch 000 | Loss : 0.3633 | Acc : 0.8256
     Batch 025 | Loss : 0.5539 | Acc : 0.7267
     Batch 050 | Loss : 0.4961 | Acc : 0.7503
     Batch 075 | Loss : 0.3540 | Acc : 0.8392
     Batch 100 | Loss : 0.4100 | Acc : 0.8026
     Batch 125 | Loss : 0.6747 | Acc : 0.5694
     Batch 150 | Loss : 0.6282 | Acc : 0.5965
     Batch 175 | Loss : 0.6300 | Acc : 0.6109
     Batch 200 | Loss : 0.6268 | Acc : 0.6130
     Batch 225 | Loss : 0.6034 | Acc : 0.6219
     Batch 250 | Loss : 0.6059 | Acc : 0.6426
     Batch 275 | Loss : 0.6145 | Acc : 0.6196
     Batch 300 | Loss : 0.6506 | Acc : 0.6001
Epoch 00053 | Train Loss : 0.5630 | Eval Loss : 0.6314 | Train acc : 0.6722 | Eval Acc : 0.6200 | Eval Log. Respected : 0.7026
     Batch 000 | Loss : 0.6363 | Acc : 0.6140
     Batch 025 | Loss : 0.5930 | Acc : 0.6456
     Batch 050 | Loss : 0.6303 | Acc : 0.6139
     Batch 075 | Loss : 0.6133 | Acc : 0.6226
     Batch 100 | Loss : 0.6369 | Acc : 0.6269
     Batch 125 | Loss : 0.6185 | Acc : 0.6387
     Batch 150 | Loss : 0.5955 | Acc : 0.6531
     Batch 175 | Loss : 0.5875 | Acc : 0.6480
     Batch 200 | Loss : 0.6464 | Acc : 0.6218
     Batch 225 | Loss : 0.6088 | Acc : 0.6131
     Batch 250 | Loss : 0.6161 | Acc : 0.6143
     Batch 275 | Loss : 0.5895 | Acc : 0.6598
     Batch 300 | Loss : 0.6016 | Acc : 0.6758
Epoch 00054 | Train Loss : 0.6062 | Eval Loss : 0.6025 | Train acc : 0.6391 | Eval Acc : 0.6185 | Eval Log. Respected : 0.3896
     Batch 000 | Loss : 0.5782 | Acc : 0.6485
     Batch 025 | Loss : 0.5846 | Acc : 0.6606
     Batch 050 | Loss : 0.6147 | Acc : 0.6533
     Batch 075 | Loss : 0.5821 | Acc : 0.6557
     Batch 100 | Loss : 0.5782 | Acc : 0.6468
     Batch 125 | Loss : 0.5758 | Acc : 0.6536
     Batch 150 | Loss : 0.5738 | Acc : 0.6830
     Batch 175 | Loss : 0.5888 | Acc : 0.6677
     Batch 200 | Loss : 0.6129 | Acc : 0.6401
     Batch 225 | Loss : 0.6070 | Acc : 0.6663
     Batch 250 | Loss : 0.5824 | Acc : 0.6703
     Batch 275 | Loss : 0.6177 | Acc : 0.6487
     Batch 300 | Loss : 0.5727 | Acc : 0.6839
Epoch 00055 | Train Loss : 0.5903 | Eval Loss : 0.5804 | Train acc : 0.6636 | Eval Acc : 0.6786 | Eval Log. Respected : 0.6818
     Batch 000 | Loss : 0.5554 | Acc : 0.6826
     Batch 025 | Loss : 0.5494 | Acc : 0.7128
     Batch 050 | Loss : 0.5697 | Acc : 0.6776
     Batch 075 | Loss : 0.6276 | Acc : 0.5940
     Batch 100 | Loss : 0.6433 | Acc : 0.6402
     Batch 125 | Loss : 0.6032 | Acc : 0.6710
     Batch 150 | Loss : 0.5770 | Acc : 0.6822
     Batch 175 | Loss : 0.5717 | Acc : 0.6873
     Batch 200 | Loss : 0.5694 | Acc : 0.6851
     Batch 225 | Loss : 0.5710 | Acc : 0.6956
     Batch 250 | Loss : 0.5909 | Acc : 0.7109
     Batch 275 | Loss : 0.5849 | Acc : 0.6840
     Batch 300 | Loss : 0.5602 | Acc : 0.6985
Epoch 00056 | Train Loss : 0.5780 | Eval Loss : 0.5838 | Train acc : 0.6825 | Eval Acc : 0.6599 | Eval Log. Respected : 0.6990
Early Stopping
Testing...
Test Loss 0.6672 | Test Acc 0.6610 | Test Log. Res. 0.6947
