Done loading data from cached files.
Training ...
     Batch 000 | Loss : 1.2903 | Acc : 0.5144
     Batch 025 | Loss : 0.6870 | Acc : 0.5509
     Batch 050 | Loss : 0.6865 | Acc : 0.5525
     Batch 075 | Loss : 0.6854 | Acc : 0.5479
     Batch 100 | Loss : 0.6864 | Acc : 0.5486
     Batch 125 | Loss : 0.6849 | Acc : 0.5539
     Batch 150 | Loss : 0.6853 | Acc : 0.5527
     Batch 175 | Loss : 0.6806 | Acc : 0.5553
     Batch 200 | Loss : 0.6736 | Acc : 0.5817
     Batch 225 | Loss : 0.6454 | Acc : 0.6221
     Batch 250 | Loss : 0.6515 | Acc : 0.6133
     Batch 275 | Loss : 0.6260 | Acc : 0.6375
     Batch 300 | Loss : 0.6336 | Acc : 0.6282
Epoch 00000 | Train Loss : 0.6721 | Eval Loss : 0.6051 | Train acc : 0.5772 | Eval Acc : 0.6729 | Eval Log. Respected : 0.2803
     Batch 000 | Loss : 0.6383 | Acc : 0.6339
     Batch 025 | Loss : 0.6111 | Acc : 0.6758
     Batch 050 | Loss : 0.5366 | Acc : 0.7478
     Batch 075 | Loss : 0.6357 | Acc : 0.6542
     Batch 100 | Loss : 0.5628 | Acc : 0.7197
     Batch 125 | Loss : 0.5468 | Acc : 0.7343
     Batch 150 | Loss : 0.5421 | Acc : 0.7475
     Batch 175 | Loss : 0.5524 | Acc : 0.7341
     Batch 200 | Loss : 0.5636 | Acc : 0.7369
     Batch 225 | Loss : 0.4969 | Acc : 0.7690
     Batch 250 | Loss : 0.5837 | Acc : 0.6971
     Batch 275 | Loss : 0.5902 | Acc : 0.6726
     Batch 300 | Loss : 0.6163 | Acc : 0.6681
Epoch 00001 | Train Loss : 0.5788 | Eval Loss : 0.5323 | Train acc : 0.6945 | Eval Acc : 0.7294 | Eval Log. Respected : 0.5157
     Batch 000 | Loss : 0.5041 | Acc : 0.7543
     Batch 025 | Loss : 0.5733 | Acc : 0.7138
     Batch 050 | Loss : 0.5244 | Acc : 0.7356
     Batch 075 | Loss : 0.4818 | Acc : 0.7646
     Batch 100 | Loss : 0.4622 | Acc : 0.7848
     Batch 125 | Loss : 0.4613 | Acc : 0.7753
     Batch 150 | Loss : 0.4636 | Acc : 0.7793
     Batch 175 | Loss : 0.5392 | Acc : 0.7287
     Batch 200 | Loss : 0.4490 | Acc : 0.7890
     Batch 225 | Loss : 0.4481 | Acc : 0.7875
     Batch 250 | Loss : 0.4869 | Acc : 0.7658
     Batch 275 | Loss : 0.4763 | Acc : 0.7720
     Batch 300 | Loss : 0.4638 | Acc : 0.7838
Epoch 00002 | Train Loss : 0.5010 | Eval Loss : 0.5151 | Train acc : 0.7541 | Eval Acc : 0.7472 | Eval Log. Respected : 0.5476
     Batch 000 | Loss : 0.6314 | Acc : 0.6774
     Batch 025 | Loss : 0.4668 | Acc : 0.7761
     Batch 050 | Loss : 0.4397 | Acc : 0.7996
     Batch 075 | Loss : 0.4792 | Acc : 0.7693
     Batch 100 | Loss : 0.4735 | Acc : 0.7701
     Batch 125 | Loss : 0.4519 | Acc : 0.7800
     Batch 150 | Loss : 0.4397 | Acc : 0.7951
     Batch 175 | Loss : 0.5049 | Acc : 0.7503
     Batch 200 | Loss : 0.4149 | Acc : 0.8047
     Batch 225 | Loss : 0.5064 | Acc : 0.7459
     Batch 250 | Loss : 0.6013 | Acc : 0.7034
     Batch 275 | Loss : 0.4193 | Acc : 0.8100
     Batch 300 | Loss : 0.4852 | Acc : 0.7635
Epoch 00003 | Train Loss : 0.4681 | Eval Loss : 0.4689 | Train acc : 0.7737 | Eval Acc : 0.7743 | Eval Log. Respected : 0.4850
     Batch 000 | Loss : 0.4150 | Acc : 0.8042
     Batch 025 | Loss : 0.5344 | Acc : 0.7309
     Batch 050 | Loss : 0.4606 | Acc : 0.7822
     Batch 075 | Loss : 0.3989 | Acc : 0.8181
     Batch 100 | Loss : 0.4936 | Acc : 0.7525
     Batch 125 | Loss : 0.5047 | Acc : 0.7418
     Batch 150 | Loss : 0.4673 | Acc : 0.7678
     Batch 175 | Loss : 0.6034 | Acc : 0.6997
     Batch 200 | Loss : 0.4180 | Acc : 0.8067
     Batch 225 | Loss : 0.4485 | Acc : 0.7959
     Batch 250 | Loss : 0.4420 | Acc : 0.7987
     Batch 275 | Loss : 0.4809 | Acc : 0.7651
     Batch 300 | Loss : 0.4296 | Acc : 0.8004
Epoch 00004 | Train Loss : 0.4580 | Eval Loss : 0.4755 | Train acc : 0.7796 | Eval Acc : 0.7708 | Eval Log. Respected : 0.6454
     Batch 000 | Loss : 0.5124 | Acc : 0.7420
     Batch 025 | Loss : 0.4718 | Acc : 0.7653
     Batch 050 | Loss : 0.4458 | Acc : 0.7851
     Batch 075 | Loss : 0.5135 | Acc : 0.7408
     Batch 100 | Loss : 0.4403 | Acc : 0.7858
     Batch 125 | Loss : 0.4694 | Acc : 0.7648
     Batch 150 | Loss : 0.4463 | Acc : 0.7991
     Batch 175 | Loss : 0.5004 | Acc : 0.7543
     Batch 200 | Loss : 0.5556 | Acc : 0.7265
     Batch 225 | Loss : 0.4304 | Acc : 0.7952
     Batch 250 | Loss : 0.4196 | Acc : 0.8107
     Batch 275 | Loss : 0.4711 | Acc : 0.7638
     Batch 300 | Loss : 0.4722 | Acc : 0.7708
Epoch 00005 | Train Loss : 0.4516 | Eval Loss : 0.4720 | Train acc : 0.7838 | Eval Acc : 0.7700 | Eval Log. Respected : 0.5334
     Batch 000 | Loss : 0.5185 | Acc : 0.7410
     Batch 025 | Loss : 0.4040 | Acc : 0.8167
     Batch 050 | Loss : 0.4739 | Acc : 0.7661
     Batch 075 | Loss : 0.5907 | Acc : 0.7170
     Batch 100 | Loss : 0.4066 | Acc : 0.8077
     Batch 125 | Loss : 0.4061 | Acc : 0.8145
     Batch 150 | Loss : 0.4409 | Acc : 0.7855
     Batch 175 | Loss : 0.4387 | Acc : 0.7867
     Batch 200 | Loss : 0.4607 | Acc : 0.7810
     Batch 225 | Loss : 0.5432 | Acc : 0.7283
     Batch 250 | Loss : 0.4569 | Acc : 0.7729
     Batch 275 | Loss : 0.4161 | Acc : 0.8024
     Batch 300 | Loss : 0.4136 | Acc : 0.8044
Epoch 00006 | Train Loss : 0.4411 | Eval Loss : 0.4659 | Train acc : 0.7895 | Eval Acc : 0.7734 | Eval Log. Respected : 0.5046
     Batch 000 | Loss : 0.5136 | Acc : 0.7483
     Batch 025 | Loss : 0.4420 | Acc : 0.7865
     Batch 050 | Loss : 0.3704 | Acc : 0.8374
     Batch 075 | Loss : 0.4163 | Acc : 0.8047
     Batch 100 | Loss : 0.3914 | Acc : 0.8251
     Batch 125 | Loss : 0.4366 | Acc : 0.7912
     Batch 150 | Loss : 0.4594 | Acc : 0.7737
     Batch 175 | Loss : 0.4621 | Acc : 0.7773
     Batch 200 | Loss : 0.3579 | Acc : 0.8381
     Batch 225 | Loss : 0.4254 | Acc : 0.7963
     Batch 250 | Loss : 0.4197 | Acc : 0.7936
     Batch 275 | Loss : 0.4006 | Acc : 0.8086
     Batch 300 | Loss : 0.4779 | Acc : 0.7657
Epoch 00007 | Train Loss : 0.4350 | Eval Loss : 0.4674 | Train acc : 0.7922 | Eval Acc : 0.7748 | Eval Log. Respected : 0.5337
     Batch 000 | Loss : 0.4238 | Acc : 0.7982
     Batch 025 | Loss : 0.4043 | Acc : 0.8125
     Batch 050 | Loss : 0.5063 | Acc : 0.7558
     Batch 075 | Loss : 0.5060 | Acc : 0.7466
     Batch 100 | Loss : 0.5481 | Acc : 0.7356
     Batch 125 | Loss : 0.4846 | Acc : 0.7590
     Batch 150 | Loss : 0.3696 | Acc : 0.8346
     Batch 175 | Loss : 0.3434 | Acc : 0.8457
     Batch 200 | Loss : 0.4329 | Acc : 0.7923
     Batch 225 | Loss : 0.3869 | Acc : 0.8214
     Batch 250 | Loss : 0.4304 | Acc : 0.7938
     Batch 275 | Loss : 0.3756 | Acc : 0.8239
     Batch 300 | Loss : 0.4603 | Acc : 0.7767
Epoch 00008 | Train Loss : 0.4298 | Eval Loss : 0.4604 | Train acc : 0.7949 | Eval Acc : 0.7793 | Eval Log. Respected : 0.6291
     Batch 000 | Loss : 0.5067 | Acc : 0.7497
     Batch 025 | Loss : 0.4044 | Acc : 0.8143
     Batch 050 | Loss : 0.4545 | Acc : 0.7800
     Batch 075 | Loss : 0.4030 | Acc : 0.8082
     Batch 100 | Loss : 0.4339 | Acc : 0.7846
     Batch 125 | Loss : 0.4120 | Acc : 0.8054
     Batch 150 | Loss : 0.3822 | Acc : 0.8248
     Batch 175 | Loss : 0.4254 | Acc : 0.7933
     Batch 200 | Loss : 0.4367 | Acc : 0.7906
     Batch 225 | Loss : 0.3529 | Acc : 0.8387
     Batch 250 | Loss : 0.4191 | Acc : 0.7962
     Batch 275 | Loss : 0.3536 | Acc : 0.8401
     Batch 300 | Loss : 0.4275 | Acc : 0.7937
Epoch 00009 | Train Loss : 0.4287 | Eval Loss : 0.4470 | Train acc : 0.7950 | Eval Acc : 0.7842 | Eval Log. Respected : 0.5612
     Batch 000 | Loss : 0.4717 | Acc : 0.7615
     Batch 025 | Loss : 0.4783 | Acc : 0.7672
     Batch 050 | Loss : 0.4935 | Acc : 0.7521
     Batch 075 | Loss : 0.3808 | Acc : 0.8195
     Batch 100 | Loss : 0.4320 | Acc : 0.7919
     Batch 125 | Loss : 0.5700 | Acc : 0.7162
     Batch 150 | Loss : 0.4587 | Acc : 0.7747
     Batch 175 | Loss : 0.6325 | Acc : 0.7045
     Batch 200 | Loss : 0.4130 | Acc : 0.7982
     Batch 225 | Loss : 0.4490 | Acc : 0.7800
     Batch 250 | Loss : 0.3689 | Acc : 0.8297
     Batch 275 | Loss : 0.3983 | Acc : 0.8093
     Batch 300 | Loss : 0.5398 | Acc : 0.7477
Epoch 00010 | Train Loss : 0.4295 | Eval Loss : 0.4229 | Train acc : 0.7945 | Eval Acc : 0.7961 | Eval Log. Respected : 0.6317
     Batch 000 | Loss : 0.4598 | Acc : 0.7677
     Batch 025 | Loss : 0.4107 | Acc : 0.8072
     Batch 050 | Loss : 0.3327 | Acc : 0.8484
     Batch 075 | Loss : 0.4353 | Acc : 0.7925
     Batch 100 | Loss : 0.4657 | Acc : 0.7666
     Batch 125 | Loss : 0.4126 | Acc : 0.7992
     Batch 150 | Loss : 0.4983 | Acc : 0.7571
     Batch 175 | Loss : 0.3633 | Acc : 0.8333
     Batch 200 | Loss : 0.4186 | Acc : 0.7993
     Batch 225 | Loss : 0.3875 | Acc : 0.8176
     Batch 250 | Loss : 0.4638 | Acc : 0.7691
     Batch 275 | Loss : 0.4365 | Acc : 0.7817
     Batch 300 | Loss : 0.4024 | Acc : 0.8118
Epoch 00011 | Train Loss : 0.4254 | Eval Loss : 0.4551 | Train acc : 0.7970 | Eval Acc : 0.7825 | Eval Log. Respected : 0.5251
     Batch 000 | Loss : 0.4510 | Acc : 0.7776
     Batch 025 | Loss : 0.3836 | Acc : 0.8223
     Batch 050 | Loss : 0.5421 | Acc : 0.7223
     Batch 075 | Loss : 0.4885 | Acc : 0.7475
     Batch 100 | Loss : 0.4244 | Acc : 0.8075
     Batch 125 | Loss : 0.4553 | Acc : 0.7700
     Batch 150 | Loss : 0.4391 | Acc : 0.7911
     Batch 175 | Loss : 0.3942 | Acc : 0.8173
     Batch 200 | Loss : 0.3609 | Acc : 0.8334
     Batch 225 | Loss : 0.3701 | Acc : 0.8248
     Batch 250 | Loss : 0.3910 | Acc : 0.8136
     Batch 275 | Loss : 0.4789 | Acc : 0.7633
     Batch 300 | Loss : 0.5065 | Acc : 0.7416
Epoch 00012 | Train Loss : 0.4216 | Eval Loss : 0.4354 | Train acc : 0.7985 | Eval Acc : 0.7895 | Eval Log. Respected : 0.6250
     Batch 000 | Loss : 0.3439 | Acc : 0.8548
     Batch 025 | Loss : 0.3820 | Acc : 0.8159
     Batch 050 | Loss : 0.4680 | Acc : 0.7669
     Batch 075 | Loss : 0.3312 | Acc : 0.8516
     Batch 100 | Loss : 0.4031 | Acc : 0.8055
     Batch 125 | Loss : 0.4214 | Acc : 0.8025
     Batch 150 | Loss : 0.4379 | Acc : 0.7840
     Batch 175 | Loss : 0.4206 | Acc : 0.7981
     Batch 200 | Loss : 0.3519 | Acc : 0.8440
     Batch 225 | Loss : 0.4158 | Acc : 0.8014
     Batch 250 | Loss : 0.3799 | Acc : 0.8234
     Batch 275 | Loss : 0.4623 | Acc : 0.7665
     Batch 300 | Loss : 0.4550 | Acc : 0.7704
Epoch 00013 | Train Loss : 0.4170 | Eval Loss : 0.4306 | Train acc : 0.8004 | Eval Acc : 0.7916 | Eval Log. Respected : 0.6321
     Batch 000 | Loss : 0.4311 | Acc : 0.7905
     Batch 025 | Loss : 0.4870 | Acc : 0.7652
     Batch 050 | Loss : 0.4641 | Acc : 0.7709
     Batch 075 | Loss : 0.3887 | Acc : 0.8275
     Batch 100 | Loss : 0.3691 | Acc : 0.8244
     Batch 125 | Loss : 0.3647 | Acc : 0.8281
     Batch 150 | Loss : 0.3689 | Acc : 0.8387
     Batch 175 | Loss : 0.4737 | Acc : 0.7609
     Batch 200 | Loss : 0.4387 | Acc : 0.7898
     Batch 225 | Loss : 0.3687 | Acc : 0.8369
     Batch 250 | Loss : 0.3963 | Acc : 0.8043
     Batch 275 | Loss : 0.4224 | Acc : 0.7987
     Batch 300 | Loss : 0.4519 | Acc : 0.7763
Epoch 00014 | Train Loss : 0.4177 | Eval Loss : 0.4749 | Train acc : 0.8000 | Eval Acc : 0.7719 | Eval Log. Respected : 0.5832
     Batch 000 | Loss : 0.5316 | Acc : 0.7495
     Batch 025 | Loss : 0.4012 | Acc : 0.8058
     Batch 050 | Loss : 0.3984 | Acc : 0.8100
     Batch 075 | Loss : 0.4377 | Acc : 0.7818
     Batch 100 | Loss : 0.3695 | Acc : 0.8320
     Batch 125 | Loss : 0.4077 | Acc : 0.8119
     Batch 150 | Loss : 0.3456 | Acc : 0.8490
     Batch 175 | Loss : 0.5141 | Acc : 0.7362
     Batch 200 | Loss : 0.4086 | Acc : 0.8056
     Batch 225 | Loss : 0.5034 | Acc : 0.7537
     Batch 250 | Loss : 0.3731 | Acc : 0.8191
     Batch 275 | Loss : 0.4538 | Acc : 0.7771
     Batch 300 | Loss : 0.4574 | Acc : 0.7688
Epoch 00015 | Train Loss : 0.4203 | Eval Loss : 0.4749 | Train acc : 0.7986 | Eval Acc : 0.7747 | Eval Log. Respected : 0.6546
     Batch 000 | Loss : 0.5313 | Acc : 0.7505
     Batch 025 | Loss : 0.4712 | Acc : 0.7553
     Batch 050 | Loss : 0.4141 | Acc : 0.7954
     Batch 075 | Loss : 0.4106 | Acc : 0.8118
     Batch 100 | Loss : 0.3615 | Acc : 0.8390
     Batch 125 | Loss : 0.3980 | Acc : 0.8118
     Batch 150 | Loss : 0.4226 | Acc : 0.7902
     Batch 175 | Loss : 0.4507 | Acc : 0.7719
     Batch 200 | Loss : 0.4361 | Acc : 0.7832
     Batch 225 | Loss : 0.3936 | Acc : 0.8123
     Batch 250 | Loss : 0.4005 | Acc : 0.8128
     Batch 275 | Loss : 0.4466 | Acc : 0.7861
     Batch 300 | Loss : 0.4430 | Acc : 0.7857
Epoch 00016 | Train Loss : 0.4177 | Eval Loss : 0.4317 | Train acc : 0.7998 | Eval Acc : 0.7883 | Eval Log. Respected : 0.6292
     Batch 000 | Loss : 0.4198 | Acc : 0.7958
     Batch 025 | Loss : 0.4666 | Acc : 0.7662
     Batch 050 | Loss : 0.5670 | Acc : 0.7245
     Batch 075 | Loss : 0.4444 | Acc : 0.7841
     Batch 100 | Loss : 0.4018 | Acc : 0.8034
     Batch 125 | Loss : 0.3559 | Acc : 0.8347
     Batch 150 | Loss : 0.5172 | Acc : 0.7570
     Batch 175 | Loss : 0.4522 | Acc : 0.7863
     Batch 200 | Loss : 0.4174 | Acc : 0.7984
     Batch 225 | Loss : 0.4657 | Acc : 0.7589
     Batch 250 | Loss : 0.3693 | Acc : 0.8335
     Batch 275 | Loss : 0.4860 | Acc : 0.7515
     Batch 300 | Loss : 0.5600 | Acc : 0.7320
Epoch 00017 | Train Loss : 0.4202 | Eval Loss : 0.4224 | Train acc : 0.7987 | Eval Acc : 0.7944 | Eval Log. Respected : 0.5897
     Batch 000 | Loss : 0.3221 | Acc : 0.8570
     Batch 025 | Loss : 0.3787 | Acc : 0.8272
     Batch 050 | Loss : 0.5750 | Acc : 0.7260
     Batch 075 | Loss : 0.4194 | Acc : 0.7985
     Batch 100 | Loss : 0.3549 | Acc : 0.8409
     Batch 125 | Loss : 0.4243 | Acc : 0.7971
     Batch 150 | Loss : 0.3943 | Acc : 0.8078
     Batch 175 | Loss : 0.4065 | Acc : 0.8073
     Batch 200 | Loss : 0.3818 | Acc : 0.8195
     Batch 225 | Loss : 0.4267 | Acc : 0.7842
     Batch 250 | Loss : 0.4025 | Acc : 0.8159
     Batch 275 | Loss : 0.4169 | Acc : 0.7981
     Batch 300 | Loss : 0.3892 | Acc : 0.8180
Epoch 00018 | Train Loss : 0.4167 | Eval Loss : 0.4372 | Train acc : 0.8004 | Eval Acc : 0.7866 | Eval Log. Respected : 0.6142
     Batch 000 | Loss : 0.4523 | Acc : 0.7771
     Batch 025 | Loss : 0.3568 | Acc : 0.8371
     Batch 050 | Loss : 0.3473 | Acc : 0.8415
     Batch 075 | Loss : 0.4871 | Acc : 0.7519
     Batch 100 | Loss : 0.3955 | Acc : 0.8165
     Batch 125 | Loss : 0.4984 | Acc : 0.7554
     Batch 150 | Loss : 0.3522 | Acc : 0.8477
     Batch 175 | Loss : 0.3831 | Acc : 0.8219
     Batch 200 | Loss : 0.4772 | Acc : 0.7742
     Batch 225 | Loss : 0.3997 | Acc : 0.8117
     Batch 250 | Loss : 0.4559 | Acc : 0.7734
     Batch 275 | Loss : 0.4261 | Acc : 0.7895
     Batch 300 | Loss : 0.5268 | Acc : 0.7446
Epoch 00019 | Train Loss : 0.4180 | Eval Loss : 0.4189 | Train acc : 0.7998 | Eval Acc : 0.7980 | Eval Log. Respected : 0.6413
     Batch 000 | Loss : 0.4368 | Acc : 0.7845
     Batch 025 | Loss : 0.3684 | Acc : 0.8352
     Batch 050 | Loss : 0.3989 | Acc : 0.8099
     Batch 075 | Loss : 0.3915 | Acc : 0.8158
     Batch 100 | Loss : 0.4270 | Acc : 0.7940
     Batch 125 | Loss : 0.5736 | Acc : 0.7240
     Batch 150 | Loss : 0.5368 | Acc : 0.7297
     Batch 175 | Loss : 0.3902 | Acc : 0.8124
     Batch 200 | Loss : 0.3654 | Acc : 0.8304
     Batch 225 | Loss : 0.4195 | Acc : 0.7990
     Batch 250 | Loss : 0.4833 | Acc : 0.7631
     Batch 275 | Loss : 0.3883 | Acc : 0.8128
     Batch 300 | Loss : 0.3694 | Acc : 0.8233
Epoch 00020 | Train Loss : 0.4145 | Eval Loss : 0.4249 | Train acc : 0.8015 | Eval Acc : 0.7962 | Eval Log. Respected : 0.6695
     Batch 000 | Loss : 0.3731 | Acc : 0.8275
     Batch 025 | Loss : 0.4027 | Acc : 0.8043
     Batch 050 | Loss : 0.4414 | Acc : 0.7811
     Batch 075 | Loss : 0.5016 | Acc : 0.7538
     Batch 100 | Loss : 0.5098 | Acc : 0.7500
     Batch 125 | Loss : 0.4400 | Acc : 0.7837
     Batch 150 | Loss : 0.4457 | Acc : 0.7761
     Batch 175 | Loss : 0.4876 | Acc : 0.7649
     Batch 200 | Loss : 0.3687 | Acc : 0.8250
     Batch 225 | Loss : 0.3619 | Acc : 0.8330
     Batch 250 | Loss : 0.3445 | Acc : 0.8475
     Batch 275 | Loss : 0.4624 | Acc : 0.7660
     Batch 300 | Loss : 0.5217 | Acc : 0.7474
Epoch 00021 | Train Loss : 0.4135 | Eval Loss : 0.4526 | Train acc : 0.8018 | Eval Acc : 0.7774 | Eval Log. Respected : 0.5820
     Batch 000 | Loss : 0.4259 | Acc : 0.7885
     Batch 025 | Loss : 0.3435 | Acc : 0.8540
     Batch 050 | Loss : 0.4855 | Acc : 0.7644
     Batch 075 | Loss : 0.3936 | Acc : 0.8101
     Batch 100 | Loss : 0.4877 | Acc : 0.7571
     Batch 125 | Loss : 0.4121 | Acc : 0.7976
     Batch 150 | Loss : 0.3914 | Acc : 0.8154
     Batch 175 | Loss : 0.4274 | Acc : 0.8021
     Batch 200 | Loss : 0.3803 | Acc : 0.8257
     Batch 225 | Loss : 0.3936 | Acc : 0.8083
     Batch 250 | Loss : 0.3577 | Acc : 0.8355
     Batch 275 | Loss : 0.4367 | Acc : 0.7925
     Batch 300 | Loss : 0.3609 | Acc : 0.8344
Epoch 00022 | Train Loss : 0.4217 | Eval Loss : 0.4297 | Train acc : 0.7980 | Eval Acc : 0.7905 | Eval Log. Respected : 0.6151
     Batch 000 | Loss : 0.3990 | Acc : 0.8078
     Batch 025 | Loss : 0.4887 | Acc : 0.7497
     Batch 050 | Loss : 0.4340 | Acc : 0.7941
     Batch 075 | Loss : 0.4653 | Acc : 0.7596
     Batch 100 | Loss : 0.4042 | Acc : 0.8053
     Batch 125 | Loss : 0.3901 | Acc : 0.8140
     Batch 150 | Loss : 0.4234 | Acc : 0.7966
     Batch 175 | Loss : 0.4619 | Acc : 0.7689
     Batch 200 | Loss : 0.3982 | Acc : 0.8137
     Batch 225 | Loss : 0.3840 | Acc : 0.8160
     Batch 250 | Loss : 0.3481 | Acc : 0.8463
     Batch 275 | Loss : 0.4131 | Acc : 0.7987
     Batch 300 | Loss : 0.3889 | Acc : 0.8166
Epoch 00023 | Train Loss : 0.4145 | Eval Loss : 0.4274 | Train acc : 0.8023 | Eval Acc : 0.7932 | Eval Log. Respected : 0.6479
     Batch 000 | Loss : 0.3769 | Acc : 0.8196
     Batch 025 | Loss : 0.3767 | Acc : 0.8238
     Batch 050 | Loss : 0.3923 | Acc : 0.8144
     Batch 075 | Loss : 0.4515 | Acc : 0.7841
     Batch 100 | Loss : 0.3816 | Acc : 0.8158
     Batch 125 | Loss : 0.4647 | Acc : 0.7655
     Batch 150 | Loss : 0.4644 | Acc : 0.7735
     Batch 175 | Loss : 0.3988 | Acc : 0.8019
     Batch 200 | Loss : 0.4090 | Acc : 0.8075
     Batch 225 | Loss : 0.3789 | Acc : 0.8188
     Batch 250 | Loss : 0.4051 | Acc : 0.8071
     Batch 275 | Loss : 0.3918 | Acc : 0.8136
     Batch 300 | Loss : 0.5158 | Acc : 0.7476
Epoch 00024 | Train Loss : 0.4169 | Eval Loss : 0.4250 | Train acc : 0.8001 | Eval Acc : 0.7915 | Eval Log. Respected : 0.6329
     Batch 000 | Loss : 0.3759 | Acc : 0.8238
     Batch 025 | Loss : 0.4741 | Acc : 0.7579
     Batch 050 | Loss : 0.3655 | Acc : 0.8334
     Batch 075 | Loss : 0.3761 | Acc : 0.8271
     Batch 100 | Loss : 0.4901 | Acc : 0.7534
     Batch 125 | Loss : 0.3782 | Acc : 0.8303
     Batch 150 | Loss : 0.3311 | Acc : 0.8535
     Batch 175 | Loss : 0.3369 | Acc : 0.8543
     Batch 200 | Loss : 0.3387 | Acc : 0.8450
     Batch 225 | Loss : 0.4967 | Acc : 0.7515
     Batch 250 | Loss : 0.4213 | Acc : 0.7949
     Batch 275 | Loss : 0.3841 | Acc : 0.8155
     Batch 300 | Loss : 0.3696 | Acc : 0.8327
Epoch 00025 | Train Loss : 0.4142 | Eval Loss : 0.4486 | Train acc : 0.8018 | Eval Acc : 0.7817 | Eval Log. Respected : 0.6476
     Batch 000 | Loss : 0.4308 | Acc : 0.7918
     Batch 025 | Loss : 0.4363 | Acc : 0.7892
     Batch 050 | Loss : 0.4458 | Acc : 0.7785
     Batch 075 | Loss : 0.4311 | Acc : 0.7943
     Batch 100 | Loss : 0.4060 | Acc : 0.8057
     Batch 125 | Loss : 0.4166 | Acc : 0.7933
     Batch 150 | Loss : 0.3903 | Acc : 0.8111
     Batch 175 | Loss : 0.4508 | Acc : 0.7780
     Batch 200 | Loss : 0.4483 | Acc : 0.7794
     Batch 225 | Loss : 0.5139 | Acc : 0.7370
     Batch 250 | Loss : 0.4650 | Acc : 0.7733
     Batch 275 | Loss : 0.3940 | Acc : 0.8059
     Batch 300 | Loss : 0.3792 | Acc : 0.8221
Epoch 00026 | Train Loss : 0.4131 | Eval Loss : 0.4134 | Train acc : 0.8024 | Eval Acc : 0.8003 | Eval Log. Respected : 0.6554
     Batch 000 | Loss : 0.3377 | Acc : 0.8530
     Batch 025 | Loss : 0.4063 | Acc : 0.8084
     Batch 050 | Loss : 0.3822 | Acc : 0.8224
     Batch 075 | Loss : 0.4515 | Acc : 0.7804
     Batch 100 | Loss : 0.4779 | Acc : 0.7648
     Batch 125 | Loss : 0.3542 | Acc : 0.8368
     Batch 150 | Loss : 0.3533 | Acc : 0.8339
     Batch 175 | Loss : 0.4543 | Acc : 0.7775
     Batch 200 | Loss : 0.3993 | Acc : 0.8071
     Batch 225 | Loss : 0.4098 | Acc : 0.8005
     Batch 250 | Loss : 0.4715 | Acc : 0.7705
     Batch 275 | Loss : 0.3761 | Acc : 0.8294
     Batch 300 | Loss : 0.3587 | Acc : 0.8325
Epoch 00027 | Train Loss : 0.4143 | Eval Loss : 0.4790 | Train acc : 0.8018 | Eval Acc : 0.7792 | Eval Log. Respected : 0.6566
     Batch 000 | Loss : 0.4187 | Acc : 0.8043
     Batch 025 | Loss : 0.3963 | Acc : 0.8076
     Batch 050 | Loss : 0.3413 | Acc : 0.8444
     Batch 075 | Loss : 0.4016 | Acc : 0.8084
     Batch 100 | Loss : 0.4074 | Acc : 0.8020
     Batch 125 | Loss : 0.4535 | Acc : 0.7858
     Batch 150 | Loss : 0.3296 | Acc : 0.8589
     Batch 175 | Loss : 0.6315 | Acc : 0.7047
     Batch 200 | Loss : 0.4080 | Acc : 0.8044
     Batch 225 | Loss : 0.4195 | Acc : 0.7889
     Batch 250 | Loss : 0.3923 | Acc : 0.8089
     Batch 275 | Loss : 0.3593 | Acc : 0.8373
     Batch 300 | Loss : 0.4814 | Acc : 0.7640
Epoch 00028 | Train Loss : 0.4147 | Eval Loss : 0.4289 | Train acc : 0.8019 | Eval Acc : 0.7915 | Eval Log. Respected : 0.6024
     Batch 000 | Loss : 0.4104 | Acc : 0.7991
     Batch 025 | Loss : 0.3601 | Acc : 0.8308
     Batch 050 | Loss : 0.3561 | Acc : 0.8344
     Batch 075 | Loss : 0.3968 | Acc : 0.8098
     Batch 100 | Loss : 0.4401 | Acc : 0.7911
     Batch 125 | Loss : 0.4341 | Acc : 0.7926
     Batch 150 | Loss : 0.4607 | Acc : 0.7735
     Batch 175 | Loss : 0.4445 | Acc : 0.7831
     Batch 200 | Loss : 0.4861 | Acc : 0.7662
     Batch 225 | Loss : 0.4833 | Acc : 0.7560
     Batch 250 | Loss : 0.4195 | Acc : 0.7926
     Batch 275 | Loss : 0.5198 | Acc : 0.7513
     Batch 300 | Loss : 0.4538 | Acc : 0.7713
Epoch 00029 | Train Loss : 0.4130 | Eval Loss : 0.4378 | Train acc : 0.8023 | Eval Acc : 0.7892 | Eval Log. Respected : 0.6657
     Batch 000 | Loss : 0.4884 | Acc : 0.7512
     Batch 025 | Loss : 0.3428 | Acc : 0.8442
     Batch 050 | Loss : 0.3371 | Acc : 0.8454
     Batch 075 | Loss : 0.5036 | Acc : 0.7570
     Batch 100 | Loss : 0.4803 | Acc : 0.7623
     Batch 125 | Loss : 0.4525 | Acc : 0.7713
     Batch 150 | Loss : 0.4546 | Acc : 0.7745
     Batch 175 | Loss : 0.3766 | Acc : 0.8278
     Batch 200 | Loss : 0.4060 | Acc : 0.8166
     Batch 225 | Loss : 0.4036 | Acc : 0.8077
     Batch 250 | Loss : 0.4435 | Acc : 0.7807
     Batch 275 | Loss : 0.4169 | Acc : 0.8034
     Batch 300 | Loss : 0.4659 | Acc : 0.7754
Epoch 00030 | Train Loss : 0.4128 | Eval Loss : 0.4225 | Train acc : 0.8025 | Eval Acc : 0.7947 | Eval Log. Respected : 0.6695
     Batch 000 | Loss : 0.3553 | Acc : 0.8341
     Batch 025 | Loss : 0.5325 | Acc : 0.7500
     Batch 050 | Loss : 0.4093 | Acc : 0.7997
     Batch 075 | Loss : 0.4498 | Acc : 0.7736
     Batch 100 | Loss : 0.4430 | Acc : 0.7806
     Batch 125 | Loss : 0.4035 | Acc : 0.8096
     Batch 150 | Loss : 0.4515 | Acc : 0.7814
     Batch 175 | Loss : 0.4804 | Acc : 0.7656
     Batch 200 | Loss : 0.3852 | Acc : 0.8141
     Batch 225 | Loss : 0.3759 | Acc : 0.8222
     Batch 250 | Loss : 0.4569 | Acc : 0.7824
     Batch 275 | Loss : 0.3493 | Acc : 0.8351
     Batch 300 | Loss : 0.4563 | Acc : 0.7728
Epoch 00031 | Train Loss : 0.4115 | Eval Loss : 0.4150 | Train acc : 0.8024 | Eval Acc : 0.7968 | Eval Log. Respected : 0.6028
     Batch 000 | Loss : 0.3930 | Acc : 0.8112
     Batch 025 | Loss : 0.4698 | Acc : 0.7587
     Batch 050 | Loss : 0.4377 | Acc : 0.7809
     Batch 075 | Loss : 0.4718 | Acc : 0.7649
     Batch 100 | Loss : 0.4489 | Acc : 0.7890
     Batch 125 | Loss : 0.4629 | Acc : 0.7653
     Batch 150 | Loss : 0.3860 | Acc : 0.8211
     Batch 175 | Loss : 0.4595 | Acc : 0.7846
     Batch 200 | Loss : 0.3565 | Acc : 0.8384
     Batch 225 | Loss : 0.3748 | Acc : 0.8272
     Batch 250 | Loss : 0.3706 | Acc : 0.8292
     Batch 275 | Loss : 0.4207 | Acc : 0.8061
     Batch 300 | Loss : 0.3597 | Acc : 0.8318
Epoch 00032 | Train Loss : 0.4127 | Eval Loss : 0.4222 | Train acc : 0.8026 | Eval Acc : 0.7949 | Eval Log. Respected : 0.6499
     Batch 000 | Loss : 0.4308 | Acc : 0.7945
     Batch 025 | Loss : 0.4355 | Acc : 0.7860
     Batch 050 | Loss : 0.4906 | Acc : 0.7537
     Batch 075 | Loss : 0.5299 | Acc : 0.7378
     Batch 100 | Loss : 0.4037 | Acc : 0.8074
     Batch 125 | Loss : 0.3445 | Acc : 0.8488
     Batch 150 | Loss : 0.4046 | Acc : 0.8054
     Batch 175 | Loss : 0.4466 | Acc : 0.7741
     Batch 200 | Loss : 0.4799 | Acc : 0.7547
     Batch 225 | Loss : 0.3722 | Acc : 0.8289
     Batch 250 | Loss : 0.5195 | Acc : 0.7395
     Batch 275 | Loss : 0.3817 | Acc : 0.8178
     Batch 300 | Loss : 0.4665 | Acc : 0.7701
Epoch 00033 | Train Loss : 0.4132 | Eval Loss : 0.4176 | Train acc : 0.8018 | Eval Acc : 0.7952 | Eval Log. Respected : 0.6158
     Batch 000 | Loss : 0.3417 | Acc : 0.8545
     Batch 025 | Loss : 0.3995 | Acc : 0.8075
     Batch 050 | Loss : 0.4501 | Acc : 0.7714
     Batch 075 | Loss : 0.3430 | Acc : 0.8450
     Batch 100 | Loss : 0.3828 | Acc : 0.8203
     Batch 125 | Loss : 0.3678 | Acc : 0.8301
     Batch 150 | Loss : 0.3779 | Acc : 0.8334
     Batch 175 | Loss : 0.4902 | Acc : 0.7523
     Batch 200 | Loss : 0.3888 | Acc : 0.8129
     Batch 225 | Loss : 0.3754 | Acc : 0.8293
     Batch 250 | Loss : 0.3893 | Acc : 0.8093
     Batch 275 | Loss : 0.3248 | Acc : 0.8574
     Batch 300 | Loss : 0.3914 | Acc : 0.8125
Epoch 00034 | Train Loss : 0.4140 | Eval Loss : 0.4313 | Train acc : 0.8020 | Eval Acc : 0.7919 | Eval Log. Respected : 0.6417
     Batch 000 | Loss : 0.4312 | Acc : 0.7901
     Batch 025 | Loss : 0.4081 | Acc : 0.7971
     Batch 050 | Loss : 0.3954 | Acc : 0.8107
     Batch 075 | Loss : 0.4287 | Acc : 0.7841
     Batch 100 | Loss : 0.3681 | Acc : 0.8252
     Batch 125 | Loss : 0.4172 | Acc : 0.7954
     Batch 150 | Loss : 0.3726 | Acc : 0.8228
     Batch 175 | Loss : 0.4356 | Acc : 0.7870
     Batch 200 | Loss : 0.4111 | Acc : 0.8083
     Batch 225 | Loss : 0.4019 | Acc : 0.8099
     Batch 250 | Loss : 0.3608 | Acc : 0.8358
     Batch 275 | Loss : 0.3903 | Acc : 0.8135
     Batch 300 | Loss : 0.4166 | Acc : 0.7990
Epoch 00035 | Train Loss : 0.4128 | Eval Loss : 0.4541 | Train acc : 0.8024 | Eval Acc : 0.7828 | Eval Log. Respected : 0.6774
     Batch 000 | Loss : 0.4915 | Acc : 0.7596
     Batch 025 | Loss : 0.4276 | Acc : 0.7883
     Batch 050 | Loss : 0.4399 | Acc : 0.7779
     Batch 075 | Loss : 0.4594 | Acc : 0.7703
     Batch 100 | Loss : 0.4017 | Acc : 0.8045
     Batch 125 | Loss : 0.4355 | Acc : 0.7913
     Batch 150 | Loss : 0.3462 | Acc : 0.8407
     Batch 175 | Loss : 0.3583 | Acc : 0.8345
     Batch 200 | Loss : 0.3747 | Acc : 0.8247
     Batch 225 | Loss : 0.5203 | Acc : 0.7532
     Batch 250 | Loss : 0.3853 | Acc : 0.8185
     Batch 275 | Loss : 0.4040 | Acc : 0.8070
     Batch 300 | Loss : 0.5031 | Acc : 0.7496
Epoch 00036 | Train Loss : 0.4176 | Eval Loss : 0.4273 | Train acc : 0.8000 | Eval Acc : 0.7941 | Eval Log. Respected : 0.6568
Early Stopping
Testing...
Test Loss 0.6110 | Test Acc 0.8031 | Test Log. Res. 0.6586
