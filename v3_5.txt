Done saving data into cached files.
Training ...
     Batch 000 | Loss : 0.6926 | Acc : 0.5166
     Batch 025 | Loss : 0.6910 | Acc : 0.5121
     Batch 050 | Loss : 0.6803 | Acc : 0.5732
     Batch 075 | Loss : 0.6206 | Acc : 0.7081
     Batch 100 | Loss : 0.4771 | Acc : 0.7654
     Batch 125 | Loss : 0.3604 | Acc : 0.8417
     Batch 150 | Loss : 0.4334 | Acc : 0.7929
     Batch 175 | Loss : 0.4766 | Acc : 0.7651
     Batch 200 | Loss : 0.4616 | Acc : 0.7805
     Batch 225 | Loss : 0.4156 | Acc : 0.7998
     Batch 250 | Loss : 0.4262 | Acc : 0.7934
     Batch 275 | Loss : 0.4909 | Acc : 0.7545
     Batch 300 | Loss : 0.3710 | Acc : 0.8291
Epoch 00000 | Train Loss : 0.4925 | Eval Loss : 0.3814 | Train acc : 0.7413 | Eval Acc : 0.8200 | Eval Log. Respected : 0.9942
     Batch 000 | Loss : 0.3479 | Acc : 0.8433
     Batch 025 | Loss : 0.5714 | Acc : 0.7195
     Batch 050 | Loss : 0.4003 | Acc : 0.8080
     Batch 075 | Loss : 0.3827 | Acc : 0.8197
     Batch 100 | Loss : 0.3155 | Acc : 0.8664
     Batch 125 | Loss : 0.4029 | Acc : 0.8096
     Batch 150 | Loss : 0.3598 | Acc : 0.8362
     Batch 175 | Loss : 0.4148 | Acc : 0.7983
     Batch 200 | Loss : 0.3864 | Acc : 0.8271
     Batch 225 | Loss : 0.3560 | Acc : 0.8397
     Batch 250 | Loss : 0.3846 | Acc : 0.8140
     Batch 275 | Loss : 0.4027 | Acc : 0.8069
     Batch 300 | Loss : 0.3867 | Acc : 0.8188
Epoch 00001 | Train Loss : 0.3875 | Eval Loss : 0.3580 | Train acc : 0.8197 | Eval Acc : 0.8344 | Eval Log. Respected : 0.9687
     Batch 000 | Loss : 0.3752 | Acc : 0.8203
     Batch 025 | Loss : 0.3449 | Acc : 0.8436
     Batch 050 | Loss : 0.3835 | Acc : 0.8131
     Batch 075 | Loss : 0.3145 | Acc : 0.8566
     Batch 100 | Loss : 0.3249 | Acc : 0.8497
     Batch 125 | Loss : 0.3305 | Acc : 0.8509
     Batch 150 | Loss : 0.3771 | Acc : 0.8232
     Batch 175 | Loss : 0.3630 | Acc : 0.8305
     Batch 200 | Loss : 0.3664 | Acc : 0.8259
     Batch 225 | Loss : 0.3238 | Acc : 0.8573
     Batch 250 | Loss : 0.3318 | Acc : 0.8501
     Batch 275 | Loss : 0.3195 | Acc : 0.8584
     Batch 300 | Loss : 0.4703 | Acc : 0.7838
Epoch 00002 | Train Loss : 0.3750 | Eval Loss : 0.3636 | Train acc : 0.8265 | Eval Acc : 0.8306 | Eval Log. Respected : 0.9569
     Batch 000 | Loss : 0.4195 | Acc : 0.8037
     Batch 025 | Loss : 0.3517 | Acc : 0.8399
     Batch 050 | Loss : 0.5131 | Acc : 0.7526
     Batch 075 | Loss : 0.4067 | Acc : 0.8059
     Batch 100 | Loss : 0.4246 | Acc : 0.8024
     Batch 125 | Loss : 0.3704 | Acc : 0.8309
     Batch 150 | Loss : 0.4303 | Acc : 0.7955
     Batch 175 | Loss : 0.4416 | Acc : 0.7931
     Batch 200 | Loss : 0.3339 | Acc : 0.8508
     Batch 225 | Loss : 0.3515 | Acc : 0.8438
     Batch 250 | Loss : 0.5653 | Acc : 0.7538
     Batch 275 | Loss : 0.4309 | Acc : 0.7914
     Batch 300 | Loss : 0.3454 | Acc : 0.8445
Epoch 00003 | Train Loss : 0.3685 | Eval Loss : 0.3520 | Train acc : 0.8307 | Eval Acc : 0.8378 | Eval Log. Respected : 0.9450
     Batch 000 | Loss : 0.3144 | Acc : 0.8620
     Batch 025 | Loss : 0.3490 | Acc : 0.8403
     Batch 050 | Loss : 0.5056 | Acc : 0.7681
     Batch 075 | Loss : 0.3245 | Acc : 0.8580
     Batch 100 | Loss : 0.3406 | Acc : 0.8558
     Batch 125 | Loss : 0.3551 | Acc : 0.8372
     Batch 150 | Loss : 0.3848 | Acc : 0.8216
     Batch 175 | Loss : 0.3532 | Acc : 0.8340
     Batch 200 | Loss : 0.3185 | Acc : 0.8602
     Batch 225 | Loss : 0.3007 | Acc : 0.8680
     Batch 250 | Loss : 0.3702 | Acc : 0.8292
     Batch 275 | Loss : 0.3561 | Acc : 0.8411
     Batch 300 | Loss : 0.3951 | Acc : 0.8162
Epoch 00004 | Train Loss : 0.3664 | Eval Loss : 0.3512 | Train acc : 0.8318 | Eval Acc : 0.8395 | Eval Log. Respected : 0.9443
     Batch 000 | Loss : 0.3364 | Acc : 0.8477
     Batch 025 | Loss : 0.3495 | Acc : 0.8332
     Batch 050 | Loss : 0.3357 | Acc : 0.8475
     Batch 075 | Loss : 0.3352 | Acc : 0.8499
     Batch 100 | Loss : 0.4726 | Acc : 0.7700
     Batch 125 | Loss : 0.3332 | Acc : 0.8532
     Batch 150 | Loss : 0.3283 | Acc : 0.8540
     Batch 175 | Loss : 0.3953 | Acc : 0.8093
     Batch 200 | Loss : 0.5483 | Acc : 0.7494
     Batch 225 | Loss : 0.4415 | Acc : 0.7994
     Batch 250 | Loss : 0.2860 | Acc : 0.8807
     Batch 275 | Loss : 0.3480 | Acc : 0.8400
     Batch 300 | Loss : 0.4909 | Acc : 0.7680
Epoch 00005 | Train Loss : 0.3599 | Eval Loss : 0.3421 | Train acc : 0.8353 | Eval Acc : 0.8445 | Eval Log. Respected : 0.9433
     Batch 000 | Loss : 0.4332 | Acc : 0.7975
     Batch 025 | Loss : 0.3826 | Acc : 0.8118
     Batch 050 | Loss : 0.3407 | Acc : 0.8456
     Batch 075 | Loss : 0.3016 | Acc : 0.8611
     Batch 100 | Loss : 0.3227 | Acc : 0.8550
     Batch 125 | Loss : 0.3838 | Acc : 0.8211
     Batch 150 | Loss : 0.3533 | Acc : 0.8359
     Batch 175 | Loss : 0.3485 | Acc : 0.8424
     Batch 200 | Loss : 0.3566 | Acc : 0.8470
     Batch 225 | Loss : 0.4100 | Acc : 0.8123
     Batch 250 | Loss : 0.3623 | Acc : 0.8317
     Batch 275 | Loss : 0.3225 | Acc : 0.8522
     Batch 300 | Loss : 0.2991 | Acc : 0.8717
Epoch 00006 | Train Loss : 0.3584 | Eval Loss : 0.3486 | Train acc : 0.8364 | Eval Acc : 0.8383 | Eval Log. Respected : 0.9724
     Batch 000 | Loss : 0.3463 | Acc : 0.8423
     Batch 025 | Loss : 0.3250 | Acc : 0.8554
     Batch 050 | Loss : 0.3815 | Acc : 0.8233
     Batch 075 | Loss : 0.3763 | Acc : 0.8147
     Batch 100 | Loss : 0.3070 | Acc : 0.8640
     Batch 125 | Loss : 0.3207 | Acc : 0.8638
     Batch 150 | Loss : 0.4001 | Acc : 0.8138
     Batch 175 | Loss : 0.4328 | Acc : 0.7863
     Batch 200 | Loss : 0.3923 | Acc : 0.8160
     Batch 225 | Loss : 0.3528 | Acc : 0.8357
     Batch 250 | Loss : 0.3527 | Acc : 0.8345
     Batch 275 | Loss : 0.4669 | Acc : 0.7821
     Batch 300 | Loss : 0.3061 | Acc : 0.8609
Epoch 00007 | Train Loss : 0.3571 | Eval Loss : 0.3435 | Train acc : 0.8368 | Eval Acc : 0.8427 | Eval Log. Respected : 0.9533
     Batch 000 | Loss : 0.3654 | Acc : 0.8285
     Batch 025 | Loss : 0.3229 | Acc : 0.8599
     Batch 050 | Loss : 0.3195 | Acc : 0.8613
     Batch 075 | Loss : 0.3239 | Acc : 0.8591
     Batch 100 | Loss : 0.2886 | Acc : 0.8719
     Batch 125 | Loss : 0.4572 | Acc : 0.7811
     Batch 150 | Loss : 0.3609 | Acc : 0.8442
     Batch 175 | Loss : 0.3704 | Acc : 0.8251
     Batch 200 | Loss : 0.4371 | Acc : 0.8022
     Batch 225 | Loss : 0.3162 | Acc : 0.8559
     Batch 250 | Loss : 0.3833 | Acc : 0.8235
     Batch 275 | Loss : 0.3393 | Acc : 0.8415
     Batch 300 | Loss : 0.3280 | Acc : 0.8517
Epoch 00008 | Train Loss : 0.3575 | Eval Loss : 0.3390 | Train acc : 0.8371 | Eval Acc : 0.8444 | Eval Log. Respected : 0.9526
     Batch 000 | Loss : 0.3314 | Acc : 0.8523
     Batch 025 | Loss : 0.3232 | Acc : 0.8594
     Batch 050 | Loss : 0.3761 | Acc : 0.8268
     Batch 075 | Loss : 0.4287 | Acc : 0.8073
     Batch 100 | Loss : 0.3542 | Acc : 0.8356
     Batch 125 | Loss : 0.4239 | Acc : 0.8036
     Batch 150 | Loss : 0.3728 | Acc : 0.8245
     Batch 175 | Loss : 0.4487 | Acc : 0.7823
     Batch 200 | Loss : 0.3284 | Acc : 0.8497
     Batch 225 | Loss : 0.3669 | Acc : 0.8303
     Batch 250 | Loss : 0.3440 | Acc : 0.8425
     Batch 275 | Loss : 0.3062 | Acc : 0.8709
     Batch 300 | Loss : 0.3270 | Acc : 0.8518
Epoch 00009 | Train Loss : 0.3575 | Eval Loss : 0.3430 | Train acc : 0.8376 | Eval Acc : 0.8427 | Eval Log. Respected : 0.9615
     Batch 000 | Loss : 0.3282 | Acc : 0.8510
     Batch 025 | Loss : 0.3936 | Acc : 0.8187
     Batch 050 | Loss : 0.3048 | Acc : 0.8600
     Batch 075 | Loss : 0.3048 | Acc : 0.8638
     Batch 100 | Loss : 0.3003 | Acc : 0.8737
     Batch 125 | Loss : 0.3459 | Acc : 0.8439
     Batch 150 | Loss : 0.3218 | Acc : 0.8602
     Batch 175 | Loss : 0.3367 | Acc : 0.8534
     Batch 200 | Loss : 0.3626 | Acc : 0.8387
     Batch 225 | Loss : 0.4411 | Acc : 0.7907
     Batch 250 | Loss : 0.3976 | Acc : 0.8092
     Batch 275 | Loss : 0.3226 | Acc : 0.8563
     Batch 300 | Loss : 0.3335 | Acc : 0.8517
Epoch 00010 | Train Loss : 0.3531 | Eval Loss : 0.3396 | Train acc : 0.8393 | Eval Acc : 0.8454 | Eval Log. Respected : 0.9424
     Batch 000 | Loss : 0.4299 | Acc : 0.8053
     Batch 025 | Loss : 0.3563 | Acc : 0.8359
     Batch 050 | Loss : 0.3889 | Acc : 0.8114
     Batch 075 | Loss : 0.3115 | Acc : 0.8606
     Batch 100 | Loss : 0.3289 | Acc : 0.8571
     Batch 125 | Loss : 0.3837 | Acc : 0.8309
     Batch 150 | Loss : 0.3040 | Acc : 0.8703
     Batch 175 | Loss : 0.3947 | Acc : 0.8071
     Batch 200 | Loss : 0.4224 | Acc : 0.7989
     Batch 225 | Loss : 0.3472 | Acc : 0.8399
     Batch 250 | Loss : 0.3335 | Acc : 0.8488
     Batch 275 | Loss : 0.3431 | Acc : 0.8431
     Batch 300 | Loss : 0.3033 | Acc : 0.8639
Epoch 00011 | Train Loss : 0.3532 | Eval Loss : 0.3367 | Train acc : 0.8396 | Eval Acc : 0.8450 | Eval Log. Respected : 0.9528
     Batch 000 | Loss : 0.2991 | Acc : 0.8643
     Batch 025 | Loss : 0.4509 | Acc : 0.7933
     Batch 050 | Loss : 0.3365 | Acc : 0.8500
     Batch 075 | Loss : 0.3220 | Acc : 0.8533
     Batch 100 | Loss : 0.3256 | Acc : 0.8515
     Batch 125 | Loss : 0.3595 | Acc : 0.8346
     Batch 150 | Loss : 0.3783 | Acc : 0.8220
     Batch 175 | Loss : 0.3106 | Acc : 0.8655
     Batch 200 | Loss : 0.3319 | Acc : 0.8480
     Batch 225 | Loss : 0.4076 | Acc : 0.8077
     Batch 250 | Loss : 0.3414 | Acc : 0.8551
     Batch 275 | Loss : 0.3534 | Acc : 0.8349
     Batch 300 | Loss : 0.3591 | Acc : 0.8320
Epoch 00012 | Train Loss : 0.3514 | Eval Loss : 0.3470 | Train acc : 0.8402 | Eval Acc : 0.8406 | Eval Log. Respected : 0.9498
     Batch 000 | Loss : 0.3589 | Acc : 0.8328
     Batch 025 | Loss : 0.3920 | Acc : 0.8237
     Batch 050 | Loss : 0.2930 | Acc : 0.8757
     Batch 075 | Loss : 0.3144 | Acc : 0.8641
     Batch 100 | Loss : 0.3053 | Acc : 0.8637
     Batch 125 | Loss : 0.3516 | Acc : 0.8357
     Batch 150 | Loss : 0.4027 | Acc : 0.7968
     Batch 175 | Loss : 0.3179 | Acc : 0.8577
     Batch 200 | Loss : 0.3279 | Acc : 0.8545
     Batch 225 | Loss : 0.3172 | Acc : 0.8663
     Batch 250 | Loss : 0.3744 | Acc : 0.8208
     Batch 275 | Loss : 0.4600 | Acc : 0.7835
     Batch 300 | Loss : 0.3497 | Acc : 0.8395
Epoch 00013 | Train Loss : 0.3510 | Eval Loss : 0.3426 | Train acc : 0.8406 | Eval Acc : 0.8424 | Eval Log. Respected : 0.9577
     Batch 000 | Loss : 0.3067 | Acc : 0.8698
     Batch 025 | Loss : 0.3114 | Acc : 0.8657
     Batch 050 | Loss : 0.3230 | Acc : 0.8525
     Batch 075 | Loss : 0.3549 | Acc : 0.8389
     Batch 100 | Loss : 0.3543 | Acc : 0.8408
     Batch 125 | Loss : 0.3457 | Acc : 0.8379
     Batch 150 | Loss : 0.3447 | Acc : 0.8440
     Batch 175 | Loss : 0.2835 | Acc : 0.8788
     Batch 200 | Loss : 0.3039 | Acc : 0.8784
     Batch 225 | Loss : 0.3299 | Acc : 0.8502
     Batch 250 | Loss : 0.3109 | Acc : 0.8613
     Batch 275 | Loss : 0.3026 | Acc : 0.8654
     Batch 300 | Loss : 0.2858 | Acc : 0.8760
Epoch 00014 | Train Loss : 0.3493 | Eval Loss : 0.3392 | Train acc : 0.8412 | Eval Acc : 0.8458 | Eval Log. Respected : 0.9486
     Batch 000 | Loss : 0.3435 | Acc : 0.8431
     Batch 025 | Loss : 0.3415 | Acc : 0.8455
     Batch 050 | Loss : 0.2945 | Acc : 0.8704
     Batch 075 | Loss : 0.3141 | Acc : 0.8636
     Batch 100 | Loss : 0.3485 | Acc : 0.8522
     Batch 125 | Loss : 0.4362 | Acc : 0.7993
     Batch 150 | Loss : 0.3300 | Acc : 0.8512
     Batch 175 | Loss : 0.2899 | Acc : 0.8744
     Batch 200 | Loss : 0.3259 | Acc : 0.8553
     Batch 225 | Loss : 0.3763 | Acc : 0.8240
     Batch 250 | Loss : 0.3204 | Acc : 0.8531
     Batch 275 | Loss : 0.3877 | Acc : 0.8163
     Batch 300 | Loss : 0.3124 | Acc : 0.8598
Epoch 00015 | Train Loss : 0.3492 | Eval Loss : 0.3361 | Train acc : 0.8415 | Eval Acc : 0.8450 | Eval Log. Respected : 0.9469
     Batch 000 | Loss : 0.3680 | Acc : 0.8309
     Batch 025 | Loss : 0.3772 | Acc : 0.8281
     Batch 050 | Loss : 0.4072 | Acc : 0.8075
     Batch 075 | Loss : 0.3260 | Acc : 0.8486
     Batch 100 | Loss : 0.3089 | Acc : 0.8605
     Batch 125 | Loss : 0.3536 | Acc : 0.8378
     Batch 150 | Loss : 0.2901 | Acc : 0.8786
     Batch 175 | Loss : 0.3102 | Acc : 0.8606
     Batch 200 | Loss : 0.3108 | Acc : 0.8634
     Batch 225 | Loss : 0.2994 | Acc : 0.8686
     Batch 250 | Loss : 0.3376 | Acc : 0.8475
     Batch 275 | Loss : 0.2950 | Acc : 0.8728
     Batch 300 | Loss : 0.3357 | Acc : 0.8498
Epoch 00016 | Train Loss : 0.3483 | Eval Loss : 0.3373 | Train acc : 0.8418 | Eval Acc : 0.8482 | Eval Log. Respected : 0.9410
     Batch 000 | Loss : 0.3735 | Acc : 0.8245
     Batch 025 | Loss : 0.3091 | Acc : 0.8611
     Batch 050 | Loss : 0.3080 | Acc : 0.8651
     Batch 075 | Loss : 0.3174 | Acc : 0.8647
     Batch 100 | Loss : 0.3484 | Acc : 0.8471
     Batch 125 | Loss : 0.3613 | Acc : 0.8330
     Batch 150 | Loss : 0.3383 | Acc : 0.8480
     Batch 175 | Loss : 0.4173 | Acc : 0.8101
     Batch 200 | Loss : 0.3456 | Acc : 0.8404
     Batch 225 | Loss : 0.3180 | Acc : 0.8566
     Batch 250 | Loss : 0.3020 | Acc : 0.8652
     Batch 275 | Loss : 0.3488 | Acc : 0.8417
     Batch 300 | Loss : 0.3417 | Acc : 0.8483
Epoch 00017 | Train Loss : 0.3477 | Eval Loss : 0.3334 | Train acc : 0.8422 | Eval Acc : 0.8473 | Eval Log. Respected : 0.9539
     Batch 000 | Loss : 0.3083 | Acc : 0.8650
     Batch 025 | Loss : 0.3678 | Acc : 0.8313
     Batch 050 | Loss : 0.3307 | Acc : 0.8484
     Batch 075 | Loss : 0.3282 | Acc : 0.8559
     Batch 100 | Loss : 0.3282 | Acc : 0.8514
     Batch 125 | Loss : 0.3635 | Acc : 0.8391
     Batch 150 | Loss : 0.3636 | Acc : 0.8322
     Batch 175 | Loss : 0.3415 | Acc : 0.8496
     Batch 200 | Loss : 0.3202 | Acc : 0.8543
     Batch 225 | Loss : 0.3643 | Acc : 0.8273
     Batch 250 | Loss : 0.3577 | Acc : 0.8356
     Batch 275 | Loss : 0.3519 | Acc : 0.8422
     Batch 300 | Loss : 0.3343 | Acc : 0.8476
Epoch 00018 | Train Loss : 0.3477 | Eval Loss : 0.3339 | Train acc : 0.8420 | Eval Acc : 0.8472 | Eval Log. Respected : 0.9355
     Batch 000 | Loss : 0.2874 | Acc : 0.8800
     Batch 025 | Loss : 0.4298 | Acc : 0.7979
     Batch 050 | Loss : 0.3322 | Acc : 0.8458
     Batch 075 | Loss : 0.3702 | Acc : 0.8253
     Batch 100 | Loss : 0.4367 | Acc : 0.7858
     Batch 125 | Loss : 0.3797 | Acc : 0.8258
     Batch 150 | Loss : 0.3473 | Acc : 0.8351
     Batch 175 | Loss : 0.3516 | Acc : 0.8350
     Batch 200 | Loss : 0.4429 | Acc : 0.7979
     Batch 225 | Loss : 0.3706 | Acc : 0.8272
     Batch 250 | Loss : 0.3278 | Acc : 0.8579
     Batch 275 | Loss : 0.3015 | Acc : 0.8724
     Batch 300 | Loss : 0.3663 | Acc : 0.8292
Epoch 00019 | Train Loss : 0.3460 | Eval Loss : 0.3408 | Train acc : 0.8425 | Eval Acc : 0.8434 | Eval Log. Respected : 0.9388
     Batch 000 | Loss : 0.3845 | Acc : 0.8152
     Batch 025 | Loss : 0.3323 | Acc : 0.8461
     Batch 050 | Loss : 0.2867 | Acc : 0.8752
     Batch 075 | Loss : 0.3315 | Acc : 0.8511
     Batch 100 | Loss : 0.4074 | Acc : 0.8169
     Batch 125 | Loss : 0.3227 | Acc : 0.8590
     Batch 150 | Loss : 0.3706 | Acc : 0.8274
     Batch 175 | Loss : 0.3890 | Acc : 0.8203
     Batch 200 | Loss : 0.3260 | Acc : 0.8498
     Batch 225 | Loss : 0.2893 | Acc : 0.8697
     Batch 250 | Loss : 0.3494 | Acc : 0.8367
     Batch 275 | Loss : 0.3739 | Acc : 0.8248
     Batch 300 | Loss : 0.2693 | Acc : 0.8812
Epoch 00020 | Train Loss : 0.3442 | Eval Loss : 0.3331 | Train acc : 0.8430 | Eval Acc : 0.8462 | Eval Log. Respected : 0.9556
     Batch 000 | Loss : 0.3524 | Acc : 0.8358
     Batch 025 | Loss : 0.3023 | Acc : 0.8674
     Batch 050 | Loss : 0.3787 | Acc : 0.8229
     Batch 075 | Loss : 0.3263 | Acc : 0.8470
     Batch 100 | Loss : 0.3045 | Acc : 0.8621
     Batch 125 | Loss : 0.3359 | Acc : 0.8411
     Batch 150 | Loss : 0.3250 | Acc : 0.8503
     Batch 175 | Loss : 0.3787 | Acc : 0.8291
     Batch 200 | Loss : 0.2759 | Acc : 0.8817
     Batch 225 | Loss : 0.3269 | Acc : 0.8545
     Batch 250 | Loss : 0.3564 | Acc : 0.8348
     Batch 275 | Loss : 0.3139 | Acc : 0.8588
     Batch 300 | Loss : 0.3742 | Acc : 0.8259
Epoch 00021 | Train Loss : 0.3423 | Eval Loss : 0.3534 | Train acc : 0.8436 | Eval Acc : 0.8334 | Eval Log. Respected : 0.9482
     Batch 000 | Loss : 0.3332 | Acc : 0.8510
     Batch 025 | Loss : 0.3147 | Acc : 0.8582
     Batch 050 | Loss : 0.3554 | Acc : 0.8273
     Batch 075 | Loss : 0.3653 | Acc : 0.8313
     Batch 100 | Loss : 0.3577 | Acc : 0.8337
     Batch 125 | Loss : 0.3354 | Acc : 0.8495
     Batch 150 | Loss : 0.4095 | Acc : 0.8055
     Batch 175 | Loss : 0.3138 | Acc : 0.8624
     Batch 200 | Loss : 0.3610 | Acc : 0.8290
     Batch 225 | Loss : 0.4025 | Acc : 0.8106
     Batch 250 | Loss : 0.3356 | Acc : 0.8428
     Batch 275 | Loss : 0.2956 | Acc : 0.8667
     Batch 300 | Loss : 0.3357 | Acc : 0.8472
Epoch 00022 | Train Loss : 0.3400 | Eval Loss : 0.3303 | Train acc : 0.8439 | Eval Acc : 0.8468 | Eval Log. Respected : 0.9279
     Batch 000 | Loss : 0.3180 | Acc : 0.8548
     Batch 025 | Loss : 0.3688 | Acc : 0.8273
     Batch 050 | Loss : 0.3231 | Acc : 0.8448
     Batch 075 | Loss : 0.2761 | Acc : 0.8795
     Batch 100 | Loss : 0.2758 | Acc : 0.8794
     Batch 125 | Loss : 0.3524 | Acc : 0.8379
     Batch 150 | Loss : 0.4693 | Acc : 0.7786
     Batch 175 | Loss : 0.3434 | Acc : 0.8425
     Batch 200 | Loss : 0.2915 | Acc : 0.8713
     Batch 225 | Loss : 0.2814 | Acc : 0.8771
     Batch 250 | Loss : 0.3793 | Acc : 0.8290
     Batch 275 | Loss : 0.3447 | Acc : 0.8399
     Batch 300 | Loss : 0.3037 | Acc : 0.8686
Epoch 00023 | Train Loss : 0.3399 | Eval Loss : 0.3239 | Train acc : 0.8438 | Eval Acc : 0.8487 | Eval Log. Respected : 0.9275
     Batch 000 | Loss : 0.3333 | Acc : 0.8470
     Batch 025 | Loss : 0.3524 | Acc : 0.8324
     Batch 050 | Loss : 0.2728 | Acc : 0.8813
     Batch 075 | Loss : 0.2771 | Acc : 0.8774
     Batch 100 | Loss : 0.3197 | Acc : 0.8570
     Batch 125 | Loss : 0.3237 | Acc : 0.8508
     Batch 150 | Loss : 0.3081 | Acc : 0.8603
     Batch 175 | Loss : 0.4104 | Acc : 0.8102
     Batch 200 | Loss : 0.3169 | Acc : 0.8511
     Batch 225 | Loss : 0.3737 | Acc : 0.8215
     Batch 250 | Loss : 0.3304 | Acc : 0.8460
     Batch 275 | Loss : 0.2896 | Acc : 0.8680
     Batch 300 | Loss : 0.2800 | Acc : 0.8758
Epoch 00024 | Train Loss : 0.3374 | Eval Loss : 0.3245 | Train acc : 0.8448 | Eval Acc : 0.8491 | Eval Log. Respected : 0.9344
     Batch 000 | Loss : 0.4196 | Acc : 0.8033
     Batch 025 | Loss : 0.3360 | Acc : 0.8528
     Batch 050 | Loss : 0.3182 | Acc : 0.8505
     Batch 075 | Loss : 0.3230 | Acc : 0.8542
     Batch 100 | Loss : 0.3292 | Acc : 0.8502
     Batch 125 | Loss : 0.2925 | Acc : 0.8680
     Batch 150 | Loss : 0.3544 | Acc : 0.8359
     Batch 175 | Loss : 0.3579 | Acc : 0.8335
     Batch 200 | Loss : 0.2987 | Acc : 0.8681
     Batch 225 | Loss : 0.2917 | Acc : 0.8711
     Batch 250 | Loss : 0.3493 | Acc : 0.8361
     Batch 275 | Loss : 0.3506 | Acc : 0.8360
     Batch 300 | Loss : 0.3915 | Acc : 0.8021
Epoch 00025 | Train Loss : 0.3384 | Eval Loss : 0.3262 | Train acc : 0.8444 | Eval Acc : 0.8475 | Eval Log. Respected : 0.9374
     Batch 000 | Loss : 0.2764 | Acc : 0.8773
     Batch 025 | Loss : 0.3703 | Acc : 0.8250
     Batch 050 | Loss : 0.3509 | Acc : 0.8356
     Batch 075 | Loss : 0.3362 | Acc : 0.8507
     Batch 100 | Loss : 0.3111 | Acc : 0.8561
     Batch 125 | Loss : 0.3731 | Acc : 0.8296
     Batch 150 | Loss : 0.3288 | Acc : 0.8506
     Batch 175 | Loss : 0.3423 | Acc : 0.8441
     Batch 200 | Loss : 0.3592 | Acc : 0.8311
     Batch 225 | Loss : 0.2994 | Acc : 0.8678
     Batch 250 | Loss : 0.2789 | Acc : 0.8753
     Batch 275 | Loss : 0.3159 | Acc : 0.8565
     Batch 300 | Loss : 0.3044 | Acc : 0.8585
Epoch 00026 | Train Loss : 0.3360 | Eval Loss : 0.3341 | Train acc : 0.8453 | Eval Acc : 0.8442 | Eval Log. Respected : 0.9346
     Batch 000 | Loss : 0.3281 | Acc : 0.8529
     Batch 025 | Loss : 0.4027 | Acc : 0.8087
     Batch 050 | Loss : 0.3816 | Acc : 0.8143
     Batch 075 | Loss : 0.3844 | Acc : 0.8229
     Batch 100 | Loss : 0.3710 | Acc : 0.8318
     Batch 125 | Loss : 0.3223 | Acc : 0.8565
     Batch 150 | Loss : 0.3903 | Acc : 0.8148
     Batch 175 | Loss : 0.4128 | Acc : 0.7997
     Batch 200 | Loss : 0.3239 | Acc : 0.8505
     Batch 225 | Loss : 0.3218 | Acc : 0.8541
     Batch 250 | Loss : 0.3389 | Acc : 0.8389
     Batch 275 | Loss : 0.3158 | Acc : 0.8560
     Batch 300 | Loss : 0.4787 | Acc : 0.7851
Epoch 00027 | Train Loss : 0.3364 | Eval Loss : 0.3249 | Train acc : 0.8450 | Eval Acc : 0.8483 | Eval Log. Respected : 0.9228
     Batch 000 | Loss : 0.3550 | Acc : 0.8326
     Batch 025 | Loss : 0.2886 | Acc : 0.8742
     Batch 050 | Loss : 0.3425 | Acc : 0.8444
     Batch 075 | Loss : 0.3679 | Acc : 0.8320
     Batch 100 | Loss : 0.3072 | Acc : 0.8583
     Batch 125 | Loss : 0.3060 | Acc : 0.8606
     Batch 150 | Loss : 0.3013 | Acc : 0.8624
     Batch 175 | Loss : 0.3543 | Acc : 0.8380
     Batch 200 | Loss : 0.3420 | Acc : 0.8415
     Batch 225 | Loss : 0.4177 | Acc : 0.8069
     Batch 250 | Loss : 0.2699 | Acc : 0.8792
     Batch 275 | Loss : 0.3882 | Acc : 0.8262
     Batch 300 | Loss : 0.3740 | Acc : 0.8224
Epoch 00028 | Train Loss : 0.3339 | Eval Loss : 0.3220 | Train acc : 0.8463 | Eval Acc : 0.8496 | Eval Log. Respected : 0.9270
     Batch 000 | Loss : 0.2903 | Acc : 0.8693
     Batch 025 | Loss : 0.2935 | Acc : 0.8693
     Batch 050 | Loss : 0.3531 | Acc : 0.8364
     Batch 075 | Loss : 0.3407 | Acc : 0.8301
     Batch 100 | Loss : 0.2861 | Acc : 0.8713
     Batch 125 | Loss : 0.3514 | Acc : 0.8371
     Batch 150 | Loss : 0.2863 | Acc : 0.8720
     Batch 175 | Loss : 0.3286 | Acc : 0.8524
     Batch 200 | Loss : 0.3093 | Acc : 0.8594
     Batch 225 | Loss : 0.3408 | Acc : 0.8386
     Batch 250 | Loss : 0.3570 | Acc : 0.8327
     Batch 275 | Loss : 0.3786 | Acc : 0.8266
     Batch 300 | Loss : 0.3092 | Acc : 0.8588
Epoch 00029 | Train Loss : 0.3343 | Eval Loss : 0.3177 | Train acc : 0.8460 | Eval Acc : 0.8521 | Eval Log. Respected : 0.9257
     Batch 000 | Loss : 0.3544 | Acc : 0.8338
     Batch 025 | Loss : 0.2871 | Acc : 0.8698
     Batch 050 | Loss : 0.4052 | Acc : 0.8094
     Batch 075 | Loss : 0.2916 | Acc : 0.8672
     Batch 100 | Loss : 0.3029 | Acc : 0.8563
     Batch 125 | Loss : 0.4465 | Acc : 0.7831
     Batch 150 | Loss : 0.2792 | Acc : 0.8765
     Batch 175 | Loss : 0.2650 | Acc : 0.8871
     Batch 200 | Loss : 0.3508 | Acc : 0.8378
     Batch 225 | Loss : 0.3120 | Acc : 0.8575
     Batch 250 | Loss : 0.3493 | Acc : 0.8362
     Batch 275 | Loss : 0.3895 | Acc : 0.8154
     Batch 300 | Loss : 0.3171 | Acc : 0.8602
Epoch 00030 | Train Loss : 0.3337 | Eval Loss : 0.3209 | Train acc : 0.8462 | Eval Acc : 0.8499 | Eval Log. Respected : 0.9211
     Batch 000 | Loss : 0.3258 | Acc : 0.8474
     Batch 025 | Loss : 0.3125 | Acc : 0.8600
     Batch 050 | Loss : 0.3000 | Acc : 0.8707
     Batch 075 | Loss : 0.4169 | Acc : 0.8062
     Batch 100 | Loss : 0.4823 | Acc : 0.7789
     Batch 125 | Loss : 0.4349 | Acc : 0.8044
     Batch 150 | Loss : 0.4622 | Acc : 0.7876
     Batch 175 | Loss : 0.3178 | Acc : 0.8543
     Batch 200 | Loss : 0.3564 | Acc : 0.8338
     Batch 225 | Loss : 0.2702 | Acc : 0.8768
     Batch 250 | Loss : 0.3128 | Acc : 0.8567
     Batch 275 | Loss : 0.3004 | Acc : 0.8655
     Batch 300 | Loss : 0.3342 | Acc : 0.8491
Epoch 00031 | Train Loss : 0.3331 | Eval Loss : 0.3180 | Train acc : 0.8464 | Eval Acc : 0.8516 | Eval Log. Respected : 0.9243
     Batch 000 | Loss : 0.2918 | Acc : 0.8652
     Batch 025 | Loss : 0.3373 | Acc : 0.8400
     Batch 050 | Loss : 0.3525 | Acc : 0.8299
     Batch 075 | Loss : 0.2995 | Acc : 0.8667
     Batch 100 | Loss : 0.3224 | Acc : 0.8563
     Batch 125 | Loss : 0.3309 | Acc : 0.8414
     Batch 150 | Loss : 0.3470 | Acc : 0.8371
     Batch 175 | Loss : 0.2888 | Acc : 0.8735
     Batch 200 | Loss : 0.3182 | Acc : 0.8570
     Batch 225 | Loss : 0.2668 | Acc : 0.8857
     Batch 250 | Loss : 0.3591 | Acc : 0.8329
     Batch 275 | Loss : 0.3119 | Acc : 0.8563
     Batch 300 | Loss : 0.3371 | Acc : 0.8409
Epoch 00032 | Train Loss : 0.3329 | Eval Loss : 0.3269 | Train acc : 0.8466 | Eval Acc : 0.8474 | Eval Log. Respected : 0.9252
     Batch 000 | Loss : 0.3195 | Acc : 0.8518
     Batch 025 | Loss : 0.2974 | Acc : 0.8676
     Batch 050 | Loss : 0.2681 | Acc : 0.8788
     Batch 075 | Loss : 0.3350 | Acc : 0.8410
     Batch 100 | Loss : 0.3467 | Acc : 0.8399
     Batch 125 | Loss : 0.2828 | Acc : 0.8836
     Batch 150 | Loss : 0.3384 | Acc : 0.8458
     Batch 175 | Loss : 0.3147 | Acc : 0.8538
     Batch 200 | Loss : 0.3036 | Acc : 0.8627
     Batch 225 | Loss : 0.3796 | Acc : 0.8269
     Batch 250 | Loss : 0.3557 | Acc : 0.8353
     Batch 275 | Loss : 0.3222 | Acc : 0.8524
     Batch 300 | Loss : 0.2960 | Acc : 0.8666
Epoch 00033 | Train Loss : 0.3316 | Eval Loss : 0.3279 | Train acc : 0.8471 | Eval Acc : 0.8458 | Eval Log. Respected : 0.9218
     Batch 000 | Loss : 0.3120 | Acc : 0.8545
     Batch 025 | Loss : 0.3096 | Acc : 0.8629
     Batch 050 | Loss : 0.3647 | Acc : 0.8299
     Batch 075 | Loss : 0.3139 | Acc : 0.8559
     Batch 100 | Loss : 0.4393 | Acc : 0.8069
     Batch 125 | Loss : 0.2888 | Acc : 0.8690
     Batch 150 | Loss : 0.3269 | Acc : 0.8513
     Batch 175 | Loss : 0.3934 | Acc : 0.8166
     Batch 200 | Loss : 0.2689 | Acc : 0.8793
     Batch 225 | Loss : 0.4036 | Acc : 0.8026
     Batch 250 | Loss : 0.3293 | Acc : 0.8472
     Batch 275 | Loss : 0.3010 | Acc : 0.8634
     Batch 300 | Loss : 0.4486 | Acc : 0.7988
Epoch 00034 | Train Loss : 0.3314 | Eval Loss : 0.3296 | Train acc : 0.8472 | Eval Acc : 0.8455 | Eval Log. Respected : 0.9306
     Batch 000 | Loss : 0.3791 | Acc : 0.8185
     Batch 025 | Loss : 0.2885 | Acc : 0.8714
     Batch 050 | Loss : 0.2748 | Acc : 0.8786
     Batch 075 | Loss : 0.4205 | Acc : 0.7985
     Batch 100 | Loss : 0.3280 | Acc : 0.8443
     Batch 125 | Loss : 0.3101 | Acc : 0.8617
     Batch 150 | Loss : 0.2905 | Acc : 0.8679
     Batch 175 | Loss : 0.2829 | Acc : 0.8734
     Batch 200 | Loss : 0.4131 | Acc : 0.8028
     Batch 225 | Loss : 0.3023 | Acc : 0.8642
     Batch 250 | Loss : 0.3991 | Acc : 0.8088
     Batch 275 | Loss : 0.2886 | Acc : 0.8708
     Batch 300 | Loss : 0.4028 | Acc : 0.8054
Epoch 00035 | Train Loss : 0.3312 | Eval Loss : 0.3244 | Train acc : 0.8474 | Eval Acc : 0.8482 | Eval Log. Respected : 0.9276
     Batch 000 | Loss : 0.3150 | Acc : 0.8505
     Batch 025 | Loss : 0.3122 | Acc : 0.8571
     Batch 050 | Loss : 0.2928 | Acc : 0.8661
     Batch 075 | Loss : 0.2720 | Acc : 0.8834
     Batch 100 | Loss : 0.3276 | Acc : 0.8522
     Batch 125 | Loss : 0.3631 | Acc : 0.8292
     Batch 150 | Loss : 0.2956 | Acc : 0.8665
     Batch 175 | Loss : 0.3745 | Acc : 0.8263
     Batch 200 | Loss : 0.2974 | Acc : 0.8629
     Batch 225 | Loss : 0.3232 | Acc : 0.8492
     Batch 250 | Loss : 0.3542 | Acc : 0.8306
     Batch 275 | Loss : 0.3705 | Acc : 0.8288
     Batch 300 | Loss : 0.3480 | Acc : 0.8356
Epoch 00036 | Train Loss : 0.3318 | Eval Loss : 0.3159 | Train acc : 0.8470 | Eval Acc : 0.8528 | Eval Log. Respected : 0.9310
     Batch 000 | Loss : 0.3439 | Acc : 0.8342
     Batch 025 | Loss : 0.3368 | Acc : 0.8432
     Batch 050 | Loss : 0.3203 | Acc : 0.8519
     Batch 075 | Loss : 0.3767 | Acc : 0.8238
     Batch 100 | Loss : 0.3621 | Acc : 0.8303
     Batch 125 | Loss : 0.3427 | Acc : 0.8425
     Batch 150 | Loss : 0.3713 | Acc : 0.8263
     Batch 175 | Loss : 0.5097 | Acc : 0.7650
     Batch 200 | Loss : 0.2731 | Acc : 0.8790
     Batch 225 | Loss : 0.3057 | Acc : 0.8632
     Batch 250 | Loss : 0.3362 | Acc : 0.8375
     Batch 275 | Loss : 0.3166 | Acc : 0.8539
     Batch 300 | Loss : 0.3100 | Acc : 0.8597
Epoch 00037 | Train Loss : 0.3303 | Eval Loss : 0.3177 | Train acc : 0.8477 | Eval Acc : 0.8511 | Eval Log. Respected : 0.9270
     Batch 000 | Loss : 0.2640 | Acc : 0.8840
     Batch 025 | Loss : 0.2710 | Acc : 0.8831
     Batch 050 | Loss : 0.3629 | Acc : 0.8320
     Batch 075 | Loss : 0.2775 | Acc : 0.8794
     Batch 100 | Loss : 0.4134 | Acc : 0.8051
     Batch 125 | Loss : 0.2977 | Acc : 0.8672
     Batch 150 | Loss : 0.3565 | Acc : 0.8404
     Batch 175 | Loss : 0.3143 | Acc : 0.8569
     Batch 200 | Loss : 0.3451 | Acc : 0.8417
     Batch 225 | Loss : 0.3850 | Acc : 0.8255
     Batch 250 | Loss : 0.3797 | Acc : 0.8227
     Batch 275 | Loss : 0.3635 | Acc : 0.8253
     Batch 300 | Loss : 0.3000 | Acc : 0.8627
Epoch 00038 | Train Loss : 0.3300 | Eval Loss : 0.3147 | Train acc : 0.8478 | Eval Acc : 0.8530 | Eval Log. Respected : 0.9301
     Batch 000 | Loss : 0.2806 | Acc : 0.8778
     Batch 025 | Loss : 0.3302 | Acc : 0.8438
     Batch 050 | Loss : 0.3654 | Acc : 0.8266
     Batch 075 | Loss : 0.3064 | Acc : 0.8600
     Batch 100 | Loss : 0.3016 | Acc : 0.8713
     Batch 125 | Loss : 0.3674 | Acc : 0.8332
     Batch 150 | Loss : 0.3068 | Acc : 0.8577
     Batch 175 | Loss : 0.3509 | Acc : 0.8344
     Batch 200 | Loss : 0.3373 | Acc : 0.8333
     Batch 225 | Loss : 0.3266 | Acc : 0.8465
     Batch 250 | Loss : 0.3635 | Acc : 0.8285
     Batch 275 | Loss : 0.2987 | Acc : 0.8591
     Batch 300 | Loss : 0.2919 | Acc : 0.8703
Epoch 00039 | Train Loss : 0.3310 | Eval Loss : 0.3186 | Train acc : 0.8476 | Eval Acc : 0.8510 | Eval Log. Respected : 0.9231
     Batch 000 | Loss : 0.2874 | Acc : 0.8676
     Batch 025 | Loss : 0.3288 | Acc : 0.8487
     Batch 050 | Loss : 0.3107 | Acc : 0.8542
     Batch 075 | Loss : 0.3318 | Acc : 0.8423
     Batch 100 | Loss : 0.3299 | Acc : 0.8492
     Batch 125 | Loss : 0.3266 | Acc : 0.8497
     Batch 150 | Loss : 0.2957 | Acc : 0.8633
     Batch 175 | Loss : 0.3069 | Acc : 0.8608
     Batch 200 | Loss : 0.3007 | Acc : 0.8638
     Batch 225 | Loss : 0.3391 | Acc : 0.8391
     Batch 250 | Loss : 0.3093 | Acc : 0.8571
     Batch 275 | Loss : 0.5567 | Acc : 0.7538
     Batch 300 | Loss : 0.3030 | Acc : 0.8651
Epoch 00040 | Train Loss : 0.3297 | Eval Loss : 0.3165 | Train acc : 0.8478 | Eval Acc : 0.8522 | Eval Log. Respected : 0.9392
     Batch 000 | Loss : 0.2660 | Acc : 0.8802
     Batch 025 | Loss : 0.3111 | Acc : 0.8676
     Batch 050 | Loss : 0.3465 | Acc : 0.8420
     Batch 075 | Loss : 0.3215 | Acc : 0.8540
     Batch 100 | Loss : 0.3690 | Acc : 0.8366
     Batch 125 | Loss : 0.4352 | Acc : 0.7981
     Batch 150 | Loss : 0.3025 | Acc : 0.8656
     Batch 175 | Loss : 0.3104 | Acc : 0.8553
     Batch 200 | Loss : 0.2503 | Acc : 0.8914
     Batch 225 | Loss : 0.2928 | Acc : 0.8707
     Batch 250 | Loss : 0.2915 | Acc : 0.8718
     Batch 275 | Loss : 0.2787 | Acc : 0.8766
     Batch 300 | Loss : 0.4517 | Acc : 0.7994
Epoch 00041 | Train Loss : 0.3284 | Eval Loss : 0.3219 | Train acc : 0.8487 | Eval Acc : 0.8498 | Eval Log. Respected : 0.9296
     Batch 000 | Loss : 0.2990 | Acc : 0.8664
     Batch 025 | Loss : 0.3325 | Acc : 0.8471
     Batch 050 | Loss : 0.2781 | Acc : 0.8723
     Batch 075 | Loss : 0.3232 | Acc : 0.8505
     Batch 100 | Loss : 0.2923 | Acc : 0.8708
     Batch 125 | Loss : 0.3786 | Acc : 0.8179
     Batch 150 | Loss : 0.2984 | Acc : 0.8648
     Batch 175 | Loss : 0.4110 | Acc : 0.8043
     Batch 200 | Loss : 0.2763 | Acc : 0.8769
     Batch 225 | Loss : 0.2963 | Acc : 0.8665
     Batch 250 | Loss : 0.2615 | Acc : 0.8838
     Batch 275 | Loss : 0.3090 | Acc : 0.8557
     Batch 300 | Loss : 0.3545 | Acc : 0.8278
Epoch 00042 | Train Loss : 0.3298 | Eval Loss : 0.3170 | Train acc : 0.8481 | Eval Acc : 0.8515 | Eval Log. Respected : 0.9253
     Batch 000 | Loss : 0.3579 | Acc : 0.8254
     Batch 025 | Loss : 0.4047 | Acc : 0.8022
     Batch 050 | Loss : 0.2722 | Acc : 0.8826
     Batch 075 | Loss : 0.3506 | Acc : 0.8324
     Batch 100 | Loss : 0.2795 | Acc : 0.8781
     Batch 125 | Loss : 0.3376 | Acc : 0.8435
     Batch 150 | Loss : 0.3393 | Acc : 0.8434
     Batch 175 | Loss : 0.3425 | Acc : 0.8385
     Batch 200 | Loss : 0.2588 | Acc : 0.8876
     Batch 225 | Loss : 0.3461 | Acc : 0.8387
     Batch 250 | Loss : 0.4264 | Acc : 0.8046
     Batch 275 | Loss : 0.3427 | Acc : 0.8343
     Batch 300 | Loss : 0.2993 | Acc : 0.8632
Epoch 00043 | Train Loss : 0.3288 | Eval Loss : 0.3212 | Train acc : 0.8485 | Eval Acc : 0.8486 | Eval Log. Respected : 0.9321
     Batch 000 | Loss : 0.3298 | Acc : 0.8444
     Batch 025 | Loss : 0.2941 | Acc : 0.8680
     Batch 050 | Loss : 0.3491 | Acc : 0.8381
     Batch 075 | Loss : 0.3089 | Acc : 0.8607
     Batch 100 | Loss : 0.3071 | Acc : 0.8597
     Batch 125 | Loss : 0.2975 | Acc : 0.8666
     Batch 150 | Loss : 0.4252 | Acc : 0.8011
     Batch 175 | Loss : 0.2916 | Acc : 0.8672
     Batch 200 | Loss : 0.3097 | Acc : 0.8583
     Batch 225 | Loss : 0.2924 | Acc : 0.8660
     Batch 250 | Loss : 0.3469 | Acc : 0.8353
     Batch 275 | Loss : 0.3000 | Acc : 0.8649
     Batch 300 | Loss : 0.3300 | Acc : 0.8437
Epoch 00044 | Train Loss : 0.3279 | Eval Loss : 0.3175 | Train acc : 0.8487 | Eval Acc : 0.8508 | Eval Log. Respected : 0.9142
     Batch 000 | Loss : 0.3906 | Acc : 0.8182
     Batch 025 | Loss : 0.3153 | Acc : 0.8562
     Batch 050 | Loss : 0.3156 | Acc : 0.8581
     Batch 075 | Loss : 0.2672 | Acc : 0.8808
     Batch 100 | Loss : 0.3092 | Acc : 0.8572
     Batch 125 | Loss : 0.3118 | Acc : 0.8596
     Batch 150 | Loss : 0.3480 | Acc : 0.8331
     Batch 175 | Loss : 0.4016 | Acc : 0.8051
     Batch 200 | Loss : 0.2796 | Acc : 0.8728
     Batch 225 | Loss : 0.3535 | Acc : 0.8284
     Batch 250 | Loss : 0.3386 | Acc : 0.8397
     Batch 275 | Loss : 0.3835 | Acc : 0.8204
     Batch 300 | Loss : 0.3208 | Acc : 0.8500
Epoch 00045 | Train Loss : 0.3281 | Eval Loss : 0.3145 | Train acc : 0.8487 | Eval Acc : 0.8526 | Eval Log. Respected : 0.9282
     Batch 000 | Loss : 0.2853 | Acc : 0.8719
     Batch 025 | Loss : 0.2697 | Acc : 0.8776
     Batch 050 | Loss : 0.3363 | Acc : 0.8401
     Batch 075 | Loss : 0.2977 | Acc : 0.8610
     Batch 100 | Loss : 0.3211 | Acc : 0.8506
     Batch 125 | Loss : 0.3030 | Acc : 0.8639
     Batch 150 | Loss : 0.3068 | Acc : 0.8602
     Batch 175 | Loss : 0.2897 | Acc : 0.8672
     Batch 200 | Loss : 0.3251 | Acc : 0.8519
     Batch 225 | Loss : 0.3241 | Acc : 0.8492
     Batch 250 | Loss : 0.3169 | Acc : 0.8552
     Batch 275 | Loss : 0.2861 | Acc : 0.8711
     Batch 300 | Loss : 0.2938 | Acc : 0.8659
Epoch 00046 | Train Loss : 0.3267 | Eval Loss : 0.3129 | Train acc : 0.8494 | Eval Acc : 0.8536 | Eval Log. Respected : 0.9298
     Batch 000 | Loss : 0.2932 | Acc : 0.8681
     Batch 025 | Loss : 0.3635 | Acc : 0.8294
     Batch 050 | Loss : 0.3808 | Acc : 0.8145
     Batch 075 | Loss : 0.3359 | Acc : 0.8429
     Batch 100 | Loss : 0.3425 | Acc : 0.8342
     Batch 125 | Loss : 0.3276 | Acc : 0.8502
     Batch 150 | Loss : 0.3201 | Acc : 0.8495
     Batch 175 | Loss : 0.3541 | Acc : 0.8348
     Batch 200 | Loss : 0.2890 | Acc : 0.8639
     Batch 225 | Loss : 0.2709 | Acc : 0.8798
     Batch 250 | Loss : 0.3040 | Acc : 0.8640
     Batch 275 | Loss : 0.3370 | Acc : 0.8432
     Batch 300 | Loss : 0.3562 | Acc : 0.8336
Epoch 00047 | Train Loss : 0.3280 | Eval Loss : 0.3139 | Train acc : 0.8487 | Eval Acc : 0.8531 | Eval Log. Respected : 0.9283
     Batch 000 | Loss : 0.3514 | Acc : 0.8329
     Batch 025 | Loss : 0.3392 | Acc : 0.8428
     Batch 050 | Loss : 0.3599 | Acc : 0.8313
     Batch 075 | Loss : 0.3391 | Acc : 0.8437
     Batch 100 | Loss : 0.2774 | Acc : 0.8777
     Batch 125 | Loss : 0.2780 | Acc : 0.8726
     Batch 150 | Loss : 0.2886 | Acc : 0.8704
     Batch 175 | Loss : 0.3238 | Acc : 0.8490
     Batch 200 | Loss : 0.2832 | Acc : 0.8688
     Batch 225 | Loss : 0.3182 | Acc : 0.8567
     Batch 250 | Loss : 0.3689 | Acc : 0.8252
     Batch 275 | Loss : 0.2598 | Acc : 0.8858
     Batch 300 | Loss : 0.3492 | Acc : 0.8373
Epoch 00048 | Train Loss : 0.3270 | Eval Loss : 0.3210 | Train acc : 0.8491 | Eval Acc : 0.8499 | Eval Log. Respected : 0.9346
     Batch 000 | Loss : 0.3503 | Acc : 0.8377
     Batch 025 | Loss : 0.3481 | Acc : 0.8435
     Batch 050 | Loss : 0.3304 | Acc : 0.8489
     Batch 075 | Loss : 0.3357 | Acc : 0.8445
     Batch 100 | Loss : 0.3540 | Acc : 0.8333
     Batch 125 | Loss : 0.4260 | Acc : 0.8010
     Batch 150 | Loss : 0.3768 | Acc : 0.8113
     Batch 175 | Loss : 0.4160 | Acc : 0.8041
     Batch 200 | Loss : 0.2733 | Acc : 0.8794
     Batch 225 | Loss : 0.3011 | Acc : 0.8619
     Batch 250 | Loss : 0.3087 | Acc : 0.8557
     Batch 275 | Loss : 0.3148 | Acc : 0.8624
     Batch 300 | Loss : 0.2737 | Acc : 0.8795
Epoch 00049 | Train Loss : 0.3270 | Eval Loss : 0.3163 | Train acc : 0.8493 | Eval Acc : 0.8523 | Eval Log. Respected : 0.9321
     Batch 000 | Loss : 0.2865 | Acc : 0.8697
     Batch 025 | Loss : 0.5603 | Acc : 0.7577
     Batch 050 | Loss : 0.2917 | Acc : 0.8685
     Batch 075 | Loss : 0.4021 | Acc : 0.8080
     Batch 100 | Loss : 0.2713 | Acc : 0.8819
     Batch 125 | Loss : 0.2764 | Acc : 0.8853
     Batch 150 | Loss : 0.2973 | Acc : 0.8635
     Batch 175 | Loss : 0.2996 | Acc : 0.8636
     Batch 200 | Loss : 0.2892 | Acc : 0.8698
     Batch 225 | Loss : 0.2788 | Acc : 0.8754
     Batch 250 | Loss : 0.4378 | Acc : 0.7974
     Batch 275 | Loss : 0.3247 | Acc : 0.8518
     Batch 300 | Loss : 0.4038 | Acc : 0.8139
Epoch 00050 | Train Loss : 0.3267 | Eval Loss : 0.3142 | Train acc : 0.8494 | Eval Acc : 0.8524 | Eval Log. Respected : 0.9188
     Batch 000 | Loss : 0.3792 | Acc : 0.8146
     Batch 025 | Loss : 0.3028 | Acc : 0.8584
     Batch 050 | Loss : 0.2866 | Acc : 0.8705
     Batch 075 | Loss : 0.2865 | Acc : 0.8718
     Batch 100 | Loss : 0.3384 | Acc : 0.8447
     Batch 125 | Loss : 0.4242 | Acc : 0.8000
     Batch 150 | Loss : 0.2673 | Acc : 0.8804
     Batch 175 | Loss : 0.3550 | Acc : 0.8370
     Batch 200 | Loss : 0.3504 | Acc : 0.8287
     Batch 225 | Loss : 0.2958 | Acc : 0.8636
     Batch 250 | Loss : 0.2852 | Acc : 0.8701
     Batch 275 | Loss : 0.3410 | Acc : 0.8389
     Batch 300 | Loss : 0.3539 | Acc : 0.8403
Epoch 00051 | Train Loss : 0.3261 | Eval Loss : 0.3147 | Train acc : 0.8495 | Eval Acc : 0.8529 | Eval Log. Respected : 0.9353
     Batch 000 | Loss : 0.3039 | Acc : 0.8622
     Batch 025 | Loss : 0.3480 | Acc : 0.8402
     Batch 050 | Loss : 0.4078 | Acc : 0.8152
     Batch 075 | Loss : 0.2659 | Acc : 0.8760
     Batch 100 | Loss : 0.2804 | Acc : 0.8767
     Batch 125 | Loss : 0.3187 | Acc : 0.8506
     Batch 150 | Loss : 0.2846 | Acc : 0.8751
     Batch 175 | Loss : 0.2876 | Acc : 0.8646
     Batch 200 | Loss : 0.3458 | Acc : 0.8373
     Batch 225 | Loss : 0.2992 | Acc : 0.8634
     Batch 250 | Loss : 0.3408 | Acc : 0.8424
     Batch 275 | Loss : 0.3458 | Acc : 0.8416
     Batch 300 | Loss : 0.3523 | Acc : 0.8401
Epoch 00052 | Train Loss : 0.3261 | Eval Loss : 0.3149 | Train acc : 0.8499 | Eval Acc : 0.8519 | Eval Log. Respected : 0.9212
     Batch 000 | Loss : 0.3120 | Acc : 0.8557
     Batch 025 | Loss : 0.3913 | Acc : 0.8123
     Batch 050 | Loss : 0.3426 | Acc : 0.8357
     Batch 075 | Loss : 0.3181 | Acc : 0.8569
     Batch 100 | Loss : 0.3282 | Acc : 0.8474
     Batch 125 | Loss : 0.2829 | Acc : 0.8703
     Batch 150 | Loss : 0.3552 | Acc : 0.8345
     Batch 175 | Loss : 0.2725 | Acc : 0.8778
     Batch 200 | Loss : 0.2834 | Acc : 0.8766
     Batch 225 | Loss : 0.2805 | Acc : 0.8749
     Batch 250 | Loss : 0.3623 | Acc : 0.8286
     Batch 275 | Loss : 0.3032 | Acc : 0.8598
     Batch 300 | Loss : 0.3218 | Acc : 0.8524
Epoch 00053 | Train Loss : 0.3251 | Eval Loss : 0.3245 | Train acc : 0.8497 | Eval Acc : 0.8470 | Eval Log. Respected : 0.9184
     Batch 000 | Loss : 0.3811 | Acc : 0.8225
     Batch 025 | Loss : 0.3799 | Acc : 0.8105
     Batch 050 | Loss : 0.3384 | Acc : 0.8432
     Batch 075 | Loss : 0.2799 | Acc : 0.8751
     Batch 100 | Loss : 0.4585 | Acc : 0.7863
     Batch 125 | Loss : 0.3071 | Acc : 0.8648
     Batch 150 | Loss : 0.3318 | Acc : 0.8466
     Batch 175 | Loss : 0.3066 | Acc : 0.8584
     Batch 200 | Loss : 0.3420 | Acc : 0.8423
     Batch 225 | Loss : 0.3911 | Acc : 0.8139
     Batch 250 | Loss : 0.2833 | Acc : 0.8705
     Batch 275 | Loss : 0.2849 | Acc : 0.8710
     Batch 300 | Loss : 0.3722 | Acc : 0.8236
Epoch 00054 | Train Loss : 0.3267 | Eval Loss : 0.3169 | Train acc : 0.8494 | Eval Acc : 0.8520 | Eval Log. Respected : 0.9331
     Batch 000 | Loss : 0.2721 | Acc : 0.8806
     Batch 025 | Loss : 0.3061 | Acc : 0.8617
     Batch 050 | Loss : 0.2715 | Acc : 0.8763
     Batch 075 | Loss : 0.3467 | Acc : 0.8238
     Batch 100 | Loss : 0.3599 | Acc : 0.8259
     Batch 125 | Loss : 0.3975 | Acc : 0.8080
     Batch 150 | Loss : 0.3100 | Acc : 0.8591
     Batch 175 | Loss : 0.2944 | Acc : 0.8669
     Batch 200 | Loss : 0.2740 | Acc : 0.8726
     Batch 225 | Loss : 0.3041 | Acc : 0.8569
     Batch 250 | Loss : 0.3033 | Acc : 0.8669
     Batch 275 | Loss : 0.4790 | Acc : 0.7827
     Batch 300 | Loss : 0.3241 | Acc : 0.8521
Epoch 00055 | Train Loss : 0.3247 | Eval Loss : 0.3181 | Train acc : 0.8501 | Eval Acc : 0.8522 | Eval Log. Respected : 0.9281
     Batch 000 | Loss : 0.3951 | Acc : 0.8138
     Batch 025 | Loss : 0.2982 | Acc : 0.8657
     Batch 050 | Loss : 0.3256 | Acc : 0.8504
     Batch 075 | Loss : 0.2829 | Acc : 0.8715
     Batch 100 | Loss : 0.3511 | Acc : 0.8362
     Batch 125 | Loss : 0.3362 | Acc : 0.8400
     Batch 150 | Loss : 0.3256 | Acc : 0.8507
     Batch 175 | Loss : 0.3809 | Acc : 0.8211
     Batch 200 | Loss : 0.2811 | Acc : 0.8755
     Batch 225 | Loss : 0.3370 | Acc : 0.8470
     Batch 250 | Loss : 0.2877 | Acc : 0.8706
     Batch 275 | Loss : 0.3126 | Acc : 0.8517
     Batch 300 | Loss : 0.3605 | Acc : 0.8319
Epoch 00056 | Train Loss : 0.3249 | Eval Loss : 0.3145 | Train acc : 0.8501 | Eval Acc : 0.8520 | Eval Log. Respected : 0.9238
Early Stopping
Testing...
Test Loss 0.5864 | Test Acc 0.8488 | Test Log. Res. 0.9243
