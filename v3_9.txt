Done loading data from cached files.
Training ...
     Batch 000 | Loss : 0.6944 | Acc : 0.4869
     Batch 025 | Loss : 0.6791 | Acc : 0.5512
     Batch 050 | Loss : 0.5817 | Acc : 0.7402
     Batch 075 | Loss : 0.5781 | Acc : 0.7268
     Batch 100 | Loss : 0.4573 | Acc : 0.7788
     Batch 125 | Loss : 0.3796 | Acc : 0.8260
     Batch 150 | Loss : 0.3548 | Acc : 0.8404
     Batch 175 | Loss : 0.4657 | Acc : 0.7733
     Batch 200 | Loss : 0.5139 | Acc : 0.7568
     Batch 225 | Loss : 0.3681 | Acc : 0.8255
     Batch 250 | Loss : 0.3980 | Acc : 0.8133
     Batch 275 | Loss : 0.4478 | Acc : 0.7886
     Batch 300 | Loss : 0.3147 | Acc : 0.8611
Epoch 00000 | Train Loss : 0.4713 | Eval Loss : 0.4351 | Train acc : 0.7635 | Eval Acc : 0.7932 | Eval Log. Respected : 0.9697
     Batch 000 | Loss : 0.4198 | Acc : 0.8089
     Batch 025 | Loss : 0.3824 | Acc : 0.8118
     Batch 050 | Loss : 0.4180 | Acc : 0.8029
     Batch 075 | Loss : 0.3161 | Acc : 0.8601
     Batch 100 | Loss : 0.3744 | Acc : 0.8335
     Batch 125 | Loss : 0.3607 | Acc : 0.8340
     Batch 150 | Loss : 0.3877 | Acc : 0.8201
     Batch 175 | Loss : 0.3348 | Acc : 0.8503
     Batch 200 | Loss : 0.3677 | Acc : 0.8277
     Batch 225 | Loss : 0.3886 | Acc : 0.8160
     Batch 250 | Loss : 0.4128 | Acc : 0.8024
     Batch 275 | Loss : 0.3982 | Acc : 0.8048
     Batch 300 | Loss : 0.3603 | Acc : 0.8390
Epoch 00001 | Train Loss : 0.3814 | Eval Loss : 0.3780 | Train acc : 0.8230 | Eval Acc : 0.8224 | Eval Log. Respected : 0.9713
     Batch 000 | Loss : 0.3489 | Acc : 0.8475
     Batch 025 | Loss : 0.3280 | Acc : 0.8611
     Batch 050 | Loss : 0.3981 | Acc : 0.8124
     Batch 075 | Loss : 0.3541 | Acc : 0.8323
     Batch 100 | Loss : 0.3287 | Acc : 0.8512
     Batch 125 | Loss : 0.3589 | Acc : 0.8296
     Batch 150 | Loss : 0.4220 | Acc : 0.7999
     Batch 175 | Loss : 0.3312 | Acc : 0.8447
     Batch 200 | Loss : 0.3600 | Acc : 0.8320
     Batch 225 | Loss : 0.3053 | Acc : 0.8675
     Batch 250 | Loss : 0.3981 | Acc : 0.8096
     Batch 275 | Loss : 0.3294 | Acc : 0.8514
     Batch 300 | Loss : 0.3653 | Acc : 0.8300
Epoch 00002 | Train Loss : 0.3709 | Eval Loss : 0.3820 | Train acc : 0.8297 | Eval Acc : 0.8202 | Eval Log. Respected : 0.9374
     Batch 000 | Loss : 0.2883 | Acc : 0.8749
     Batch 025 | Loss : 0.3261 | Acc : 0.8579
     Batch 050 | Loss : 0.3332 | Acc : 0.8508
     Batch 075 | Loss : 0.3548 | Acc : 0.8384
     Batch 100 | Loss : 0.3839 | Acc : 0.8181
     Batch 125 | Loss : 0.3710 | Acc : 0.8209
     Batch 150 | Loss : 0.3234 | Acc : 0.8606
     Batch 175 | Loss : 0.3521 | Acc : 0.8334
     Batch 200 | Loss : 0.4171 | Acc : 0.8060
     Batch 225 | Loss : 0.4095 | Acc : 0.8040
     Batch 250 | Loss : 0.3883 | Acc : 0.8169
     Batch 275 | Loss : 0.3702 | Acc : 0.8239
     Batch 300 | Loss : 0.4194 | Acc : 0.8074
Epoch 00003 | Train Loss : 0.3636 | Eval Loss : 0.3963 | Train acc : 0.8332 | Eval Acc : 0.8140 | Eval Log. Respected : 0.9701
     Batch 000 | Loss : 0.3580 | Acc : 0.8380
     Batch 025 | Loss : 0.3513 | Acc : 0.8393
     Batch 050 | Loss : 0.3796 | Acc : 0.8167
     Batch 075 | Loss : 0.3397 | Acc : 0.8452
     Batch 100 | Loss : 0.2996 | Acc : 0.8719
     Batch 125 | Loss : 0.3951 | Acc : 0.8126
     Batch 150 | Loss : 0.3688 | Acc : 0.8292
     Batch 175 | Loss : 0.3169 | Acc : 0.8537
     Batch 200 | Loss : 0.3714 | Acc : 0.8223
     Batch 225 | Loss : 0.3341 | Acc : 0.8540
     Batch 250 | Loss : 0.5634 | Acc : 0.7497
     Batch 275 | Loss : 0.3246 | Acc : 0.8533
     Batch 300 | Loss : 0.3026 | Acc : 0.8703
Epoch 00004 | Train Loss : 0.3627 | Eval Loss : 0.3827 | Train acc : 0.8344 | Eval Acc : 0.8261 | Eval Log. Respected : 0.9390
     Batch 000 | Loss : 0.2725 | Acc : 0.8819
     Batch 025 | Loss : 0.3247 | Acc : 0.8524
     Batch 050 | Loss : 0.3109 | Acc : 0.8627
     Batch 075 | Loss : 0.3810 | Acc : 0.8113
     Batch 100 | Loss : 0.3929 | Acc : 0.8158
     Batch 125 | Loss : 0.3938 | Acc : 0.8167
     Batch 150 | Loss : 0.3676 | Acc : 0.8295
     Batch 175 | Loss : 0.3497 | Acc : 0.8376
     Batch 200 | Loss : 0.3388 | Acc : 0.8446
     Batch 225 | Loss : 0.3171 | Acc : 0.8560
     Batch 250 | Loss : 0.3244 | Acc : 0.8512
     Batch 275 | Loss : 0.3064 | Acc : 0.8670
     Batch 300 | Loss : 0.3743 | Acc : 0.8262
Epoch 00005 | Train Loss : 0.3567 | Eval Loss : 0.3707 | Train acc : 0.8369 | Eval Acc : 0.8291 | Eval Log. Respected : 0.9384
     Batch 000 | Loss : 0.3545 | Acc : 0.8348
     Batch 025 | Loss : 0.3369 | Acc : 0.8470
     Batch 050 | Loss : 0.4098 | Acc : 0.8052
     Batch 075 | Loss : 0.3035 | Acc : 0.8622
     Batch 100 | Loss : 0.3172 | Acc : 0.8546
     Batch 125 | Loss : 0.3568 | Acc : 0.8334
     Batch 150 | Loss : 0.3380 | Acc : 0.8442
     Batch 175 | Loss : 0.3739 | Acc : 0.8271
     Batch 200 | Loss : 0.3317 | Acc : 0.8469
     Batch 225 | Loss : 0.4056 | Acc : 0.8025
     Batch 250 | Loss : 0.2989 | Acc : 0.8712
     Batch 275 | Loss : 0.4131 | Acc : 0.8061
     Batch 300 | Loss : 0.2935 | Acc : 0.8692
Epoch 00006 | Train Loss : 0.3541 | Eval Loss : 0.3668 | Train acc : 0.8377 | Eval Acc : 0.8319 | Eval Log. Respected : 0.9337
     Batch 000 | Loss : 0.3544 | Acc : 0.8380
     Batch 025 | Loss : 0.4542 | Acc : 0.7964
     Batch 050 | Loss : 0.3803 | Acc : 0.8166
     Batch 075 | Loss : 0.2956 | Acc : 0.8668
     Batch 100 | Loss : 0.3106 | Acc : 0.8628
     Batch 125 | Loss : 0.3758 | Acc : 0.8225
     Batch 150 | Loss : 0.4541 | Acc : 0.7791
     Batch 175 | Loss : 0.3584 | Acc : 0.8365
     Batch 200 | Loss : 0.3332 | Acc : 0.8469
     Batch 225 | Loss : 0.3365 | Acc : 0.8412
     Batch 250 | Loss : 0.3202 | Acc : 0.8526
     Batch 275 | Loss : 0.3245 | Acc : 0.8514
     Batch 300 | Loss : 0.3152 | Acc : 0.8553
Epoch 00007 | Train Loss : 0.3495 | Eval Loss : 0.3609 | Train acc : 0.8396 | Eval Acc : 0.8299 | Eval Log. Respected : 0.9350
     Batch 000 | Loss : 0.2954 | Acc : 0.8670
     Batch 025 | Loss : 0.2874 | Acc : 0.8697
     Batch 050 | Loss : 0.3508 | Acc : 0.8361
     Batch 075 | Loss : 0.3291 | Acc : 0.8463
     Batch 100 | Loss : 0.3355 | Acc : 0.8441
     Batch 125 | Loss : 0.3954 | Acc : 0.8191
     Batch 150 | Loss : 0.3621 | Acc : 0.8272
     Batch 175 | Loss : 0.2949 | Acc : 0.8685
     Batch 200 | Loss : 0.3622 | Acc : 0.8307
     Batch 225 | Loss : 0.3526 | Acc : 0.8381
     Batch 250 | Loss : 0.3550 | Acc : 0.8405
     Batch 275 | Loss : 0.3375 | Acc : 0.8400
     Batch 300 | Loss : 0.3072 | Acc : 0.8635
Epoch 00008 | Train Loss : 0.3451 | Eval Loss : 0.3687 | Train acc : 0.8414 | Eval Acc : 0.8259 | Eval Log. Respected : 0.9337
     Batch 000 | Loss : 0.4394 | Acc : 0.7820
     Batch 025 | Loss : 0.2848 | Acc : 0.8740
     Batch 050 | Loss : 0.3258 | Acc : 0.8508
     Batch 075 | Loss : 0.3733 | Acc : 0.8319
     Batch 100 | Loss : 0.2908 | Acc : 0.8687
     Batch 125 | Loss : 0.3282 | Acc : 0.8495
     Batch 150 | Loss : 0.3173 | Acc : 0.8536
     Batch 175 | Loss : 0.3023 | Acc : 0.8645
     Batch 200 | Loss : 0.3525 | Acc : 0.8372
     Batch 225 | Loss : 0.3280 | Acc : 0.8489
     Batch 250 | Loss : 0.3830 | Acc : 0.8165
     Batch 275 | Loss : 0.3236 | Acc : 0.8585
     Batch 300 | Loss : 0.2994 | Acc : 0.8708
Epoch 00009 | Train Loss : 0.3438 | Eval Loss : 0.3519 | Train acc : 0.8417 | Eval Acc : 0.8339 | Eval Log. Respected : 0.9349
     Batch 000 | Loss : 0.3697 | Acc : 0.8228
     Batch 025 | Loss : 0.3216 | Acc : 0.8518
     Batch 050 | Loss : 0.3045 | Acc : 0.8679
     Batch 075 | Loss : 0.2776 | Acc : 0.8836
     Batch 100 | Loss : 0.3387 | Acc : 0.8450
     Batch 125 | Loss : 0.3099 | Acc : 0.8610
     Batch 150 | Loss : 0.3283 | Acc : 0.8536
     Batch 175 | Loss : 0.4236 | Acc : 0.7914
     Batch 200 | Loss : 0.3034 | Acc : 0.8695
     Batch 225 | Loss : 0.3600 | Acc : 0.8305
     Batch 250 | Loss : 0.4032 | Acc : 0.8144
     Batch 275 | Loss : 0.3092 | Acc : 0.8586
     Batch 300 | Loss : 0.3624 | Acc : 0.8352
Epoch 00010 | Train Loss : 0.3423 | Eval Loss : 0.3488 | Train acc : 0.8429 | Eval Acc : 0.8359 | Eval Log. Respected : 0.9272
     Batch 000 | Loss : 0.3998 | Acc : 0.8041
     Batch 025 | Loss : 0.3936 | Acc : 0.8132
     Batch 050 | Loss : 0.3181 | Acc : 0.8547
     Batch 075 | Loss : 0.2975 | Acc : 0.8699
     Batch 100 | Loss : 0.3240 | Acc : 0.8560
     Batch 125 | Loss : 0.4207 | Acc : 0.8018
     Batch 150 | Loss : 0.3946 | Acc : 0.8143
     Batch 175 | Loss : 0.3501 | Acc : 0.8280
     Batch 200 | Loss : 0.3191 | Acc : 0.8561
     Batch 225 | Loss : 0.3521 | Acc : 0.8363
     Batch 250 | Loss : 0.3401 | Acc : 0.8423
     Batch 275 | Loss : 0.2882 | Acc : 0.8764
     Batch 300 | Loss : 0.2654 | Acc : 0.8829
Epoch 00011 | Train Loss : 0.3399 | Eval Loss : 0.3557 | Train acc : 0.8439 | Eval Acc : 0.8313 | Eval Log. Respected : 0.9566
     Batch 000 | Loss : 0.3683 | Acc : 0.8130
     Batch 025 | Loss : 0.3815 | Acc : 0.8217
     Batch 050 | Loss : 0.2866 | Acc : 0.8723
     Batch 075 | Loss : 0.4046 | Acc : 0.8128
     Batch 100 | Loss : 0.3899 | Acc : 0.8096
     Batch 125 | Loss : 0.4100 | Acc : 0.8057
     Batch 150 | Loss : 0.2782 | Acc : 0.8749
     Batch 175 | Loss : 0.4529 | Acc : 0.7826
     Batch 200 | Loss : 0.4127 | Acc : 0.8130
     Batch 225 | Loss : 0.2952 | Acc : 0.8684
     Batch 250 | Loss : 0.3239 | Acc : 0.8493
     Batch 275 | Loss : 0.4126 | Acc : 0.8005
     Batch 300 | Loss : 0.3844 | Acc : 0.8229
Epoch 00012 | Train Loss : 0.3386 | Eval Loss : 0.3492 | Train acc : 0.8442 | Eval Acc : 0.8354 | Eval Log. Respected : 0.9370
     Batch 000 | Loss : 0.3170 | Acc : 0.8558
     Batch 025 | Loss : 0.2770 | Acc : 0.8800
     Batch 050 | Loss : 0.3731 | Acc : 0.8286
     Batch 075 | Loss : 0.2479 | Acc : 0.8904
     Batch 100 | Loss : 0.3218 | Acc : 0.8554
     Batch 125 | Loss : 0.3551 | Acc : 0.8331
     Batch 150 | Loss : 0.3462 | Acc : 0.8368
     Batch 175 | Loss : 0.3566 | Acc : 0.8324
     Batch 200 | Loss : 0.3173 | Acc : 0.8548
     Batch 225 | Loss : 0.3059 | Acc : 0.8600
     Batch 250 | Loss : 0.3253 | Acc : 0.8539
     Batch 275 | Loss : 0.3003 | Acc : 0.8659
     Batch 300 | Loss : 0.4636 | Acc : 0.7800
Epoch 00013 | Train Loss : 0.3361 | Eval Loss : 0.3486 | Train acc : 0.8454 | Eval Acc : 0.8360 | Eval Log. Respected : 0.9370
     Batch 000 | Loss : 0.2893 | Acc : 0.8789
     Batch 025 | Loss : 0.3906 | Acc : 0.8052
     Batch 050 | Loss : 0.3218 | Acc : 0.8504
     Batch 075 | Loss : 0.3947 | Acc : 0.8176
     Batch 100 | Loss : 0.3128 | Acc : 0.8564
     Batch 125 | Loss : 0.4965 | Acc : 0.7780
     Batch 150 | Loss : 0.3061 | Acc : 0.8602
     Batch 175 | Loss : 0.3000 | Acc : 0.8668
     Batch 200 | Loss : 0.2874 | Acc : 0.8813
     Batch 225 | Loss : 0.3362 | Acc : 0.8440
     Batch 250 | Loss : 0.3327 | Acc : 0.8462
     Batch 275 | Loss : 0.3760 | Acc : 0.8272
     Batch 300 | Loss : 0.3050 | Acc : 0.8609
Epoch 00014 | Train Loss : 0.3354 | Eval Loss : 0.3492 | Train acc : 0.8458 | Eval Acc : 0.8373 | Eval Log. Respected : 0.9318
     Batch 000 | Loss : 0.3251 | Acc : 0.8462
     Batch 025 | Loss : 0.3996 | Acc : 0.8100
     Batch 050 | Loss : 0.3035 | Acc : 0.8675
     Batch 075 | Loss : 0.3364 | Acc : 0.8470
     Batch 100 | Loss : 0.3318 | Acc : 0.8402
     Batch 125 | Loss : 0.3275 | Acc : 0.8539
     Batch 150 | Loss : 0.3746 | Acc : 0.8198
     Batch 175 | Loss : 0.4944 | Acc : 0.7809
     Batch 200 | Loss : 0.3654 | Acc : 0.8315
     Batch 225 | Loss : 0.2765 | Acc : 0.8793
     Batch 250 | Loss : 0.3048 | Acc : 0.8652
     Batch 275 | Loss : 0.3545 | Acc : 0.8349
     Batch 300 | Loss : 0.3684 | Acc : 0.8346
Epoch 00015 | Train Loss : 0.3366 | Eval Loss : 0.3512 | Train acc : 0.8452 | Eval Acc : 0.8346 | Eval Log. Respected : 0.9304
     Batch 000 | Loss : 0.3221 | Acc : 0.8516
     Batch 025 | Loss : 0.3519 | Acc : 0.8381
     Batch 050 | Loss : 0.2986 | Acc : 0.8640
     Batch 075 | Loss : 0.3006 | Acc : 0.8626
     Batch 100 | Loss : 0.3112 | Acc : 0.8533
     Batch 125 | Loss : 0.2678 | Acc : 0.8806
     Batch 150 | Loss : 0.2704 | Acc : 0.8812
     Batch 175 | Loss : 0.4258 | Acc : 0.8015
     Batch 200 | Loss : 0.3682 | Acc : 0.8303
     Batch 225 | Loss : 0.3144 | Acc : 0.8566
     Batch 250 | Loss : 0.3572 | Acc : 0.8407
     Batch 275 | Loss : 0.3846 | Acc : 0.8141
     Batch 300 | Loss : 0.3672 | Acc : 0.8306
Epoch 00016 | Train Loss : 0.3350 | Eval Loss : 0.3482 | Train acc : 0.8459 | Eval Acc : 0.8347 | Eval Log. Respected : 0.9301
     Batch 000 | Loss : 0.3211 | Acc : 0.8521
     Batch 025 | Loss : 0.3393 | Acc : 0.8407
     Batch 050 | Loss : 0.2753 | Acc : 0.8770
     Batch 075 | Loss : 0.3735 | Acc : 0.8211
     Batch 100 | Loss : 0.3588 | Acc : 0.8312
     Batch 125 | Loss : 0.2923 | Acc : 0.8739
     Batch 150 | Loss : 0.2695 | Acc : 0.8848
     Batch 175 | Loss : 0.3288 | Acc : 0.8442
     Batch 200 | Loss : 0.3366 | Acc : 0.8410
     Batch 225 | Loss : 0.3129 | Acc : 0.8624
     Batch 250 | Loss : 0.3463 | Acc : 0.8368
     Batch 275 | Loss : 0.3995 | Acc : 0.8117
     Batch 300 | Loss : 0.3774 | Acc : 0.8217
Epoch 00017 | Train Loss : 0.3342 | Eval Loss : 0.3576 | Train acc : 0.8461 | Eval Acc : 0.8327 | Eval Log. Respected : 0.9273
     Batch 000 | Loss : 0.2911 | Acc : 0.8693
     Batch 025 | Loss : 0.3806 | Acc : 0.8175
     Batch 050 | Loss : 0.2811 | Acc : 0.8805
     Batch 075 | Loss : 0.2626 | Acc : 0.8861
     Batch 100 | Loss : 0.4452 | Acc : 0.7851
     Batch 125 | Loss : 0.2648 | Acc : 0.8828
     Batch 150 | Loss : 0.2886 | Acc : 0.8717
     Batch 175 | Loss : 0.3808 | Acc : 0.8218
     Batch 200 | Loss : 0.3904 | Acc : 0.8202
     Batch 225 | Loss : 0.2996 | Acc : 0.8639
     Batch 250 | Loss : 0.2622 | Acc : 0.8839
     Batch 275 | Loss : 0.2989 | Acc : 0.8677
     Batch 300 | Loss : 0.3887 | Acc : 0.8172
Epoch 00018 | Train Loss : 0.3334 | Eval Loss : 0.3455 | Train acc : 0.8462 | Eval Acc : 0.8361 | Eval Log. Respected : 0.9336
     Batch 000 | Loss : 0.2979 | Acc : 0.8681
     Batch 025 | Loss : 0.4871 | Acc : 0.7742
     Batch 050 | Loss : 0.4862 | Acc : 0.7889
     Batch 075 | Loss : 0.2922 | Acc : 0.8664
     Batch 100 | Loss : 0.4543 | Acc : 0.7837
     Batch 125 | Loss : 0.3404 | Acc : 0.8517
     Batch 150 | Loss : 0.3049 | Acc : 0.8578
     Batch 175 | Loss : 0.3947 | Acc : 0.8137
     Batch 200 | Loss : 0.3562 | Acc : 0.8326
     Batch 225 | Loss : 0.2742 | Acc : 0.8750
     Batch 250 | Loss : 0.3254 | Acc : 0.8525
     Batch 275 | Loss : 0.2668 | Acc : 0.8873
     Batch 300 | Loss : 0.3446 | Acc : 0.8461
Epoch 00019 | Train Loss : 0.3343 | Eval Loss : 0.3448 | Train acc : 0.8460 | Eval Acc : 0.8370 | Eval Log. Respected : 0.9286
     Batch 000 | Loss : 0.2799 | Acc : 0.8764
     Batch 025 | Loss : 0.4324 | Acc : 0.7853
     Batch 050 | Loss : 0.2880 | Acc : 0.8738
     Batch 075 | Loss : 0.2596 | Acc : 0.8884
     Batch 100 | Loss : 0.3281 | Acc : 0.8516
     Batch 125 | Loss : 0.2820 | Acc : 0.8754
     Batch 150 | Loss : 0.3571 | Acc : 0.8322
     Batch 175 | Loss : 0.3686 | Acc : 0.8265
     Batch 200 | Loss : 0.3149 | Acc : 0.8526
     Batch 225 | Loss : 0.3540 | Acc : 0.8318
     Batch 250 | Loss : 0.3518 | Acc : 0.8400
     Batch 275 | Loss : 0.3687 | Acc : 0.8270
     Batch 300 | Loss : 0.3635 | Acc : 0.8219
Epoch 00020 | Train Loss : 0.3324 | Eval Loss : 0.3634 | Train acc : 0.8468 | Eval Acc : 0.8334 | Eval Log. Respected : 0.9183
     Batch 000 | Loss : 0.3708 | Acc : 0.8318
     Batch 025 | Loss : 0.2780 | Acc : 0.8730
     Batch 050 | Loss : 0.4033 | Acc : 0.8062
     Batch 075 | Loss : 0.3194 | Acc : 0.8564
     Batch 100 | Loss : 0.3181 | Acc : 0.8513
     Batch 125 | Loss : 0.2842 | Acc : 0.8719
     Batch 150 | Loss : 0.3194 | Acc : 0.8513
     Batch 175 | Loss : 0.3243 | Acc : 0.8500
     Batch 200 | Loss : 0.2949 | Acc : 0.8698
     Batch 225 | Loss : 0.3558 | Acc : 0.8323
     Batch 250 | Loss : 0.3755 | Acc : 0.8188
     Batch 275 | Loss : 0.3154 | Acc : 0.8575
     Batch 300 | Loss : 0.3169 | Acc : 0.8552
Epoch 00021 | Train Loss : 0.3319 | Eval Loss : 0.3445 | Train acc : 0.8470 | Eval Acc : 0.8370 | Eval Log. Respected : 0.9184
     Batch 000 | Loss : 0.3198 | Acc : 0.8531
     Batch 025 | Loss : 0.2906 | Acc : 0.8660
     Batch 050 | Loss : 0.2971 | Acc : 0.8706
     Batch 075 | Loss : 0.3286 | Acc : 0.8449
     Batch 100 | Loss : 0.3281 | Acc : 0.8441
     Batch 125 | Loss : 0.3882 | Acc : 0.8182
     Batch 150 | Loss : 0.3881 | Acc : 0.8153
     Batch 175 | Loss : 0.2977 | Acc : 0.8640
     Batch 200 | Loss : 0.3457 | Acc : 0.8352
     Batch 225 | Loss : 0.3927 | Acc : 0.8186
     Batch 250 | Loss : 0.5710 | Acc : 0.7481
     Batch 275 | Loss : 0.2842 | Acc : 0.8729
     Batch 300 | Loss : 0.2983 | Acc : 0.8666
Epoch 00022 | Train Loss : 0.3301 | Eval Loss : 0.3422 | Train acc : 0.8477 | Eval Acc : 0.8390 | Eval Log. Respected : 0.9380
     Batch 000 | Loss : 0.3847 | Acc : 0.8214
     Batch 025 | Loss : 0.3318 | Acc : 0.8493
     Batch 050 | Loss : 0.3402 | Acc : 0.8405
     Batch 075 | Loss : 0.4818 | Acc : 0.7780
     Batch 100 | Loss : 0.3600 | Acc : 0.8286
     Batch 125 | Loss : 0.2861 | Acc : 0.8746
     Batch 150 | Loss : 0.3203 | Acc : 0.8499
     Batch 175 | Loss : 0.3040 | Acc : 0.8591
     Batch 200 | Loss : 0.3079 | Acc : 0.8559
     Batch 225 | Loss : 0.3329 | Acc : 0.8468
     Batch 250 | Loss : 0.3084 | Acc : 0.8585
     Batch 275 | Loss : 0.3055 | Acc : 0.8605
     Batch 300 | Loss : 0.2908 | Acc : 0.8702
Epoch 00023 | Train Loss : 0.3293 | Eval Loss : 0.3404 | Train acc : 0.8481 | Eval Acc : 0.8386 | Eval Log. Respected : 0.9260
     Batch 000 | Loss : 0.3343 | Acc : 0.8461
     Batch 025 | Loss : 0.3060 | Acc : 0.8641
     Batch 050 | Loss : 0.3001 | Acc : 0.8602
     Batch 075 | Loss : 0.3608 | Acc : 0.8328
     Batch 100 | Loss : 0.3139 | Acc : 0.8626
     Batch 125 | Loss : 0.3510 | Acc : 0.8325
     Batch 150 | Loss : 0.4036 | Acc : 0.8113
     Batch 175 | Loss : 0.3722 | Acc : 0.8307
     Batch 200 | Loss : 0.3984 | Acc : 0.8110
     Batch 225 | Loss : 0.2787 | Acc : 0.8748
     Batch 250 | Loss : 0.3545 | Acc : 0.8306
     Batch 275 | Loss : 0.3647 | Acc : 0.8361
     Batch 300 | Loss : 0.2767 | Acc : 0.8757
Epoch 00024 | Train Loss : 0.3296 | Eval Loss : 0.3434 | Train acc : 0.8483 | Eval Acc : 0.8375 | Eval Log. Respected : 0.9301
     Batch 000 | Loss : 0.2807 | Acc : 0.8737
     Batch 025 | Loss : 0.3089 | Acc : 0.8518
     Batch 050 | Loss : 0.2810 | Acc : 0.8715
     Batch 075 | Loss : 0.3031 | Acc : 0.8655
     Batch 100 | Loss : 0.3676 | Acc : 0.8203
     Batch 125 | Loss : 0.3206 | Acc : 0.8516
     Batch 150 | Loss : 0.4008 | Acc : 0.8086
     Batch 175 | Loss : 0.3326 | Acc : 0.8406
     Batch 200 | Loss : 0.3086 | Acc : 0.8576
     Batch 225 | Loss : 0.2679 | Acc : 0.8792
     Batch 250 | Loss : 0.3740 | Acc : 0.8235
     Batch 275 | Loss : 0.3006 | Acc : 0.8636
     Batch 300 | Loss : 0.3131 | Acc : 0.8571
Epoch 00025 | Train Loss : 0.3283 | Eval Loss : 0.3472 | Train acc : 0.8488 | Eval Acc : 0.8355 | Eval Log. Respected : 0.9113
     Batch 000 | Loss : 0.3229 | Acc : 0.8493
     Batch 025 | Loss : 0.2846 | Acc : 0.8744
     Batch 050 | Loss : 0.3528 | Acc : 0.8330
     Batch 075 | Loss : 0.3004 | Acc : 0.8579
     Batch 100 | Loss : 0.2937 | Acc : 0.8655
     Batch 125 | Loss : 0.2964 | Acc : 0.8695
     Batch 150 | Loss : 0.2871 | Acc : 0.8731
     Batch 175 | Loss : 0.2857 | Acc : 0.8695
     Batch 200 | Loss : 0.3702 | Acc : 0.8239
     Batch 225 | Loss : 0.2845 | Acc : 0.8711
     Batch 250 | Loss : 0.3306 | Acc : 0.8475
     Batch 275 | Loss : 0.2791 | Acc : 0.8762
     Batch 300 | Loss : 0.3212 | Acc : 0.8546
Epoch 00026 | Train Loss : 0.3292 | Eval Loss : 0.3406 | Train acc : 0.8481 | Eval Acc : 0.8384 | Eval Log. Respected : 0.9319
     Batch 000 | Loss : 0.3514 | Acc : 0.8316
     Batch 025 | Loss : 0.2984 | Acc : 0.8651
     Batch 050 | Loss : 0.2917 | Acc : 0.8672
     Batch 075 | Loss : 0.3080 | Acc : 0.8629
     Batch 100 | Loss : 0.3294 | Acc : 0.8465
     Batch 125 | Loss : 0.3538 | Acc : 0.8369
     Batch 150 | Loss : 0.3018 | Acc : 0.8605
     Batch 175 | Loss : 0.3344 | Acc : 0.8395
     Batch 200 | Loss : 0.2724 | Acc : 0.8784
     Batch 225 | Loss : 0.3192 | Acc : 0.8533
     Batch 250 | Loss : 0.3395 | Acc : 0.8383
     Batch 275 | Loss : 0.3343 | Acc : 0.8403
     Batch 300 | Loss : 0.3134 | Acc : 0.8539
Epoch 00027 | Train Loss : 0.3259 | Eval Loss : 0.3467 | Train acc : 0.8496 | Eval Acc : 0.8361 | Eval Log. Respected : 0.9414
     Batch 000 | Loss : 0.2778 | Acc : 0.8792
     Batch 025 | Loss : 0.3476 | Acc : 0.8435
     Batch 050 | Loss : 0.3285 | Acc : 0.8468
     Batch 075 | Loss : 0.3118 | Acc : 0.8588
     Batch 100 | Loss : 0.3812 | Acc : 0.8281
     Batch 125 | Loss : 0.3305 | Acc : 0.8478
     Batch 150 | Loss : 0.2500 | Acc : 0.8903
     Batch 175 | Loss : 0.3355 | Acc : 0.8431
     Batch 200 | Loss : 0.3120 | Acc : 0.8601
     Batch 225 | Loss : 0.3554 | Acc : 0.8260
     Batch 250 | Loss : 0.3787 | Acc : 0.8205
     Batch 275 | Loss : 0.2660 | Acc : 0.8809
     Batch 300 | Loss : 0.3268 | Acc : 0.8483
Epoch 00028 | Train Loss : 0.3273 | Eval Loss : 0.3417 | Train acc : 0.8492 | Eval Acc : 0.8383 | Eval Log. Respected : 0.9282
     Batch 000 | Loss : 0.3325 | Acc : 0.8499
     Batch 025 | Loss : 0.3501 | Acc : 0.8345
     Batch 050 | Loss : 0.2978 | Acc : 0.8638
     Batch 075 | Loss : 0.2985 | Acc : 0.8690
     Batch 100 | Loss : 0.3470 | Acc : 0.8342
     Batch 125 | Loss : 0.3080 | Acc : 0.8582
     Batch 150 | Loss : 0.3012 | Acc : 0.8644
     Batch 175 | Loss : 0.2714 | Acc : 0.8799
     Batch 200 | Loss : 0.3443 | Acc : 0.8396
     Batch 225 | Loss : 0.3619 | Acc : 0.8338
     Batch 250 | Loss : 0.3468 | Acc : 0.8410
     Batch 275 | Loss : 0.3646 | Acc : 0.8333
     Batch 300 | Loss : 0.4218 | Acc : 0.8039
Epoch 00029 | Train Loss : 0.3258 | Eval Loss : 0.3369 | Train acc : 0.8498 | Eval Acc : 0.8399 | Eval Log. Respected : 0.9325
     Batch 000 | Loss : 0.3512 | Acc : 0.8408
     Batch 025 | Loss : 0.3133 | Acc : 0.8528
     Batch 050 | Loss : 0.2840 | Acc : 0.8757
     Batch 075 | Loss : 0.2574 | Acc : 0.8866
     Batch 100 | Loss : 0.3285 | Acc : 0.8463
     Batch 125 | Loss : 0.3236 | Acc : 0.8518
     Batch 150 | Loss : 0.3060 | Acc : 0.8578
     Batch 175 | Loss : 0.3695 | Acc : 0.8242
     Batch 200 | Loss : 0.3386 | Acc : 0.8459
     Batch 225 | Loss : 0.2600 | Acc : 0.8822
     Batch 250 | Loss : 0.3157 | Acc : 0.8553
     Batch 275 | Loss : 0.4072 | Acc : 0.8121
     Batch 300 | Loss : 0.3332 | Acc : 0.8474
Epoch 00030 | Train Loss : 0.3265 | Eval Loss : 0.3438 | Train acc : 0.8498 | Eval Acc : 0.8365 | Eval Log. Respected : 0.9218
     Batch 000 | Loss : 0.2989 | Acc : 0.8643
     Batch 025 | Loss : 0.3044 | Acc : 0.8590
     Batch 050 | Loss : 0.3148 | Acc : 0.8618
     Batch 075 | Loss : 0.3397 | Acc : 0.8377
     Batch 100 | Loss : 0.3331 | Acc : 0.8399
     Batch 125 | Loss : 0.4752 | Acc : 0.7835
     Batch 150 | Loss : 0.2635 | Acc : 0.8820
     Batch 175 | Loss : 0.3471 | Acc : 0.8425
     Batch 200 | Loss : 0.4644 | Acc : 0.7763
     Batch 225 | Loss : 0.2830 | Acc : 0.8740
     Batch 250 | Loss : 0.3648 | Acc : 0.8230
     Batch 275 | Loss : 0.3556 | Acc : 0.8374
     Batch 300 | Loss : 0.2472 | Acc : 0.8942
Epoch 00031 | Train Loss : 0.3259 | Eval Loss : 0.3455 | Train acc : 0.8496 | Eval Acc : 0.8369 | Eval Log. Respected : 0.9274
     Batch 000 | Loss : 0.2900 | Acc : 0.8721
     Batch 025 | Loss : 0.3235 | Acc : 0.8579
     Batch 050 | Loss : 0.3626 | Acc : 0.8267
     Batch 075 | Loss : 0.3014 | Acc : 0.8624
     Batch 100 | Loss : 0.2836 | Acc : 0.8774
     Batch 125 | Loss : 0.3135 | Acc : 0.8603
     Batch 150 | Loss : 0.2883 | Acc : 0.8704
     Batch 175 | Loss : 0.2554 | Acc : 0.8859
     Batch 200 | Loss : 0.3715 | Acc : 0.8142
     Batch 225 | Loss : 0.4269 | Acc : 0.7991
     Batch 250 | Loss : 0.2882 | Acc : 0.8685
     Batch 275 | Loss : 0.2837 | Acc : 0.8783
     Batch 300 | Loss : 0.2538 | Acc : 0.8891
Epoch 00032 | Train Loss : 0.3238 | Eval Loss : 0.3449 | Train acc : 0.8506 | Eval Acc : 0.8397 | Eval Log. Respected : 0.9341
     Batch 000 | Loss : 0.3540 | Acc : 0.8347
     Batch 025 | Loss : 0.2742 | Acc : 0.8775
     Batch 050 | Loss : 0.3758 | Acc : 0.8202
     Batch 075 | Loss : 0.3085 | Acc : 0.8578
     Batch 100 | Loss : 0.3160 | Acc : 0.8503
     Batch 125 | Loss : 0.2761 | Acc : 0.8741
     Batch 150 | Loss : 0.2738 | Acc : 0.8778
     Batch 175 | Loss : 0.3273 | Acc : 0.8447
     Batch 200 | Loss : 0.3566 | Acc : 0.8292
     Batch 225 | Loss : 0.3318 | Acc : 0.8449
     Batch 250 | Loss : 0.3728 | Acc : 0.8215
     Batch 275 | Loss : 0.2799 | Acc : 0.8741
     Batch 300 | Loss : 0.3078 | Acc : 0.8583
Epoch 00033 | Train Loss : 0.3242 | Eval Loss : 0.3374 | Train acc : 0.8505 | Eval Acc : 0.8396 | Eval Log. Respected : 0.9298
     Batch 000 | Loss : 0.3065 | Acc : 0.8564
     Batch 025 | Loss : 0.3698 | Acc : 0.8181
     Batch 050 | Loss : 0.2967 | Acc : 0.8631
     Batch 075 | Loss : 0.3146 | Acc : 0.8504
     Batch 100 | Loss : 0.3102 | Acc : 0.8587
     Batch 125 | Loss : 0.2767 | Acc : 0.8757
     Batch 150 | Loss : 0.2904 | Acc : 0.8720
     Batch 175 | Loss : 0.2915 | Acc : 0.8718
     Batch 200 | Loss : 0.3363 | Acc : 0.8388
     Batch 225 | Loss : 0.3550 | Acc : 0.8361
     Batch 250 | Loss : 0.2662 | Acc : 0.8790
     Batch 275 | Loss : 0.3315 | Acc : 0.8416
     Batch 300 | Loss : 0.3611 | Acc : 0.8201
Epoch 00034 | Train Loss : 0.3227 | Eval Loss : 0.3378 | Train acc : 0.8510 | Eval Acc : 0.8403 | Eval Log. Respected : 0.9258
     Batch 000 | Loss : 0.3918 | Acc : 0.8134
     Batch 025 | Loss : 0.3912 | Acc : 0.8173
     Batch 050 | Loss : 0.2667 | Acc : 0.8804
     Batch 075 | Loss : 0.3193 | Acc : 0.8529
     Batch 100 | Loss : 0.3271 | Acc : 0.8506
     Batch 125 | Loss : 0.2588 | Acc : 0.8825
     Batch 150 | Loss : 0.2630 | Acc : 0.8827
     Batch 175 | Loss : 0.2918 | Acc : 0.8649
     Batch 200 | Loss : 0.2636 | Acc : 0.8835
     Batch 225 | Loss : 0.3989 | Acc : 0.8135
     Batch 250 | Loss : 0.2801 | Acc : 0.8738
     Batch 275 | Loss : 0.3367 | Acc : 0.8461
     Batch 300 | Loss : 0.3476 | Acc : 0.8395
Epoch 00035 | Train Loss : 0.3212 | Eval Loss : 0.3436 | Train acc : 0.8517 | Eval Acc : 0.8360 | Eval Log. Respected : 0.9341
     Batch 000 | Loss : 0.3469 | Acc : 0.8408
     Batch 025 | Loss : 0.3388 | Acc : 0.8427
     Batch 050 | Loss : 0.2871 | Acc : 0.8746
     Batch 075 | Loss : 0.3047 | Acc : 0.8644
     Batch 100 | Loss : 0.2813 | Acc : 0.8692
     Batch 125 | Loss : 0.3271 | Acc : 0.8485
     Batch 150 | Loss : 0.2466 | Acc : 0.8981
     Batch 175 | Loss : 0.2958 | Acc : 0.8624
     Batch 200 | Loss : 0.3681 | Acc : 0.8233
     Batch 225 | Loss : 0.3075 | Acc : 0.8565
     Batch 250 | Loss : 0.3155 | Acc : 0.8536
     Batch 275 | Loss : 0.3454 | Acc : 0.8421
     Batch 300 | Loss : 0.2774 | Acc : 0.8708
Epoch 00036 | Train Loss : 0.3223 | Eval Loss : 0.3402 | Train acc : 0.8512 | Eval Acc : 0.8395 | Eval Log. Respected : 0.9281
     Batch 000 | Loss : 0.2905 | Acc : 0.8648
     Batch 025 | Loss : 0.3429 | Acc : 0.8371
     Batch 050 | Loss : 0.2676 | Acc : 0.8758
     Batch 075 | Loss : 0.3720 | Acc : 0.8218
     Batch 100 | Loss : 0.2572 | Acc : 0.8853
     Batch 125 | Loss : 0.2632 | Acc : 0.8856
     Batch 150 | Loss : 0.2366 | Acc : 0.8966
     Batch 175 | Loss : 0.3326 | Acc : 0.8443
     Batch 200 | Loss : 0.2860 | Acc : 0.8707
     Batch 225 | Loss : 0.3831 | Acc : 0.8195
     Batch 250 | Loss : 0.3391 | Acc : 0.8424
     Batch 275 | Loss : 0.2965 | Acc : 0.8649
     Batch 300 | Loss : 0.3731 | Acc : 0.8228
Epoch 00037 | Train Loss : 0.3212 | Eval Loss : 0.3444 | Train acc : 0.8519 | Eval Acc : 0.8364 | Eval Log. Respected : 0.9211
     Batch 000 | Loss : 0.3084 | Acc : 0.8598
     Batch 025 | Loss : 0.3591 | Acc : 0.8363
     Batch 050 | Loss : 0.3046 | Acc : 0.8627
     Batch 075 | Loss : 0.2828 | Acc : 0.8752
     Batch 100 | Loss : 0.2788 | Acc : 0.8700
     Batch 125 | Loss : 0.3885 | Acc : 0.8219
     Batch 150 | Loss : 0.2881 | Acc : 0.8716
     Batch 175 | Loss : 0.2646 | Acc : 0.8848
     Batch 200 | Loss : 0.2635 | Acc : 0.8816
     Batch 225 | Loss : 0.2961 | Acc : 0.8599
     Batch 250 | Loss : 0.3261 | Acc : 0.8424
     Batch 275 | Loss : 0.3226 | Acc : 0.8486
     Batch 300 | Loss : 0.3162 | Acc : 0.8519
Epoch 00038 | Train Loss : 0.3221 | Eval Loss : 0.3384 | Train acc : 0.8515 | Eval Acc : 0.8390 | Eval Log. Respected : 0.9200
     Batch 000 | Loss : 0.3385 | Acc : 0.8405
     Batch 025 | Loss : 0.2651 | Acc : 0.8807
     Batch 050 | Loss : 0.2699 | Acc : 0.8808
     Batch 075 | Loss : 0.3066 | Acc : 0.8610
     Batch 100 | Loss : 0.2722 | Acc : 0.8764
     Batch 125 | Loss : 0.2875 | Acc : 0.8695
     Batch 150 | Loss : 0.3159 | Acc : 0.8597
     Batch 175 | Loss : 0.3504 | Acc : 0.8329
     Batch 200 | Loss : 0.2852 | Acc : 0.8733
     Batch 225 | Loss : 0.3345 | Acc : 0.8427
     Batch 250 | Loss : 0.3256 | Acc : 0.8549
     Batch 275 | Loss : 0.2732 | Acc : 0.8782
     Batch 300 | Loss : 0.3488 | Acc : 0.8369
Epoch 00039 | Train Loss : 0.3211 | Eval Loss : 0.3396 | Train acc : 0.8518 | Eval Acc : 0.8386 | Eval Log. Respected : 0.9289
Early Stopping
Testing...
Test Loss 0.5867 | Test Acc 0.8420 | Test Log. Res. 0.9272
