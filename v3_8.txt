Done loading data from cached files.
Training ...
     Batch 000 | Loss : 0.6963 | Acc : 0.5115
     Batch 025 | Loss : 0.6921 | Acc : 0.5127
     Batch 050 | Loss : 0.6642 | Acc : 0.6562
     Batch 075 | Loss : 0.6147 | Acc : 0.6758
     Batch 100 | Loss : 0.5569 | Acc : 0.7201
     Batch 125 | Loss : 0.4238 | Acc : 0.8018
     Batch 150 | Loss : 0.5376 | Acc : 0.7510
     Batch 175 | Loss : 0.5067 | Acc : 0.7547
     Batch 200 | Loss : 0.4725 | Acc : 0.7624
     Batch 225 | Loss : 0.3773 | Acc : 0.8264
     Batch 250 | Loss : 0.3947 | Acc : 0.8144
     Batch 275 | Loss : 0.4527 | Acc : 0.7798
     Batch 300 | Loss : 0.3396 | Acc : 0.8473
Epoch 00000 | Train Loss : 0.4998 | Eval Loss : 0.4056 | Train acc : 0.7413 | Eval Acc : 0.8047 | Eval Log. Respected : 0.9887
     Batch 000 | Loss : 0.3625 | Acc : 0.8278
     Batch 025 | Loss : 0.3993 | Acc : 0.8208
     Batch 050 | Loss : 0.4975 | Acc : 0.7724
     Batch 075 | Loss : 0.3899 | Acc : 0.8145
     Batch 100 | Loss : 0.3459 | Acc : 0.8357
     Batch 125 | Loss : 0.3707 | Acc : 0.8257
     Batch 150 | Loss : 0.4936 | Acc : 0.7606
     Batch 175 | Loss : 0.4742 | Acc : 0.7733
     Batch 200 | Loss : 0.4119 | Acc : 0.8014
     Batch 225 | Loss : 0.3499 | Acc : 0.8433
     Batch 250 | Loss : 0.3428 | Acc : 0.8435
     Batch 275 | Loss : 0.3235 | Acc : 0.8513
     Batch 300 | Loss : 0.4177 | Acc : 0.7968
Epoch 00001 | Train Loss : 0.3936 | Eval Loss : 0.3954 | Train acc : 0.8146 | Eval Acc : 0.8113 | Eval Log. Respected : 0.9936
     Batch 000 | Loss : 0.3867 | Acc : 0.8120
     Batch 025 | Loss : 0.3889 | Acc : 0.8146
     Batch 050 | Loss : 0.3598 | Acc : 0.8293
     Batch 075 | Loss : 0.3671 | Acc : 0.8233
     Batch 100 | Loss : 0.3893 | Acc : 0.8170
     Batch 125 | Loss : 0.3132 | Acc : 0.8573
     Batch 150 | Loss : 0.3486 | Acc : 0.8387
     Batch 175 | Loss : 0.3489 | Acc : 0.8362
     Batch 200 | Loss : 0.4589 | Acc : 0.7696
     Batch 225 | Loss : 0.3334 | Acc : 0.8467
     Batch 250 | Loss : 0.3271 | Acc : 0.8514
     Batch 275 | Loss : 0.3666 | Acc : 0.8303
     Batch 300 | Loss : 0.3498 | Acc : 0.8374
Epoch 00002 | Train Loss : 0.3809 | Eval Loss : 0.3814 | Train acc : 0.8211 | Eval Acc : 0.8182 | Eval Log. Respected : 0.9969
     Batch 000 | Loss : 0.3180 | Acc : 0.8603
     Batch 025 | Loss : 0.3237 | Acc : 0.8547
     Batch 050 | Loss : 0.4262 | Acc : 0.7927
     Batch 075 | Loss : 0.3556 | Acc : 0.8299
     Batch 100 | Loss : 0.3279 | Acc : 0.8523
     Batch 125 | Loss : 0.3466 | Acc : 0.8414
     Batch 150 | Loss : 0.4033 | Acc : 0.8003
     Batch 175 | Loss : 0.4361 | Acc : 0.7835
     Batch 200 | Loss : 0.4732 | Acc : 0.7693
     Batch 225 | Loss : 0.3208 | Acc : 0.8610
     Batch 250 | Loss : 0.4848 | Acc : 0.7733
     Batch 275 | Loss : 0.3680 | Acc : 0.8292
     Batch 300 | Loss : 0.3162 | Acc : 0.8567
Epoch 00003 | Train Loss : 0.3741 | Eval Loss : 0.3739 | Train acc : 0.8247 | Eval Acc : 0.8240 | Eval Log. Respected : 0.9798
     Batch 000 | Loss : 0.4332 | Acc : 0.7947
     Batch 025 | Loss : 0.3939 | Acc : 0.8109
     Batch 050 | Loss : 0.3363 | Acc : 0.8452
     Batch 075 | Loss : 0.4125 | Acc : 0.8191
     Batch 100 | Loss : 0.3986 | Acc : 0.8058
     Batch 125 | Loss : 0.4588 | Acc : 0.7810
     Batch 150 | Loss : 0.3099 | Acc : 0.8611
     Batch 175 | Loss : 0.4249 | Acc : 0.7920
     Batch 200 | Loss : 0.3349 | Acc : 0.8487
     Batch 225 | Loss : 0.3651 | Acc : 0.8276
     Batch 250 | Loss : 0.3281 | Acc : 0.8505
     Batch 275 | Loss : 0.3326 | Acc : 0.8496
     Batch 300 | Loss : 0.4094 | Acc : 0.8071
Epoch 00004 | Train Loss : 0.3671 | Eval Loss : 0.3745 | Train acc : 0.8286 | Eval Acc : 0.8235 | Eval Log. Respected : 0.9856
     Batch 000 | Loss : 0.3573 | Acc : 0.8349
     Batch 025 | Loss : 0.3339 | Acc : 0.8397
     Batch 050 | Loss : 0.3157 | Acc : 0.8565
     Batch 075 | Loss : 0.4328 | Acc : 0.7862
     Batch 100 | Loss : 0.3940 | Acc : 0.8143
     Batch 125 | Loss : 0.3586 | Acc : 0.8365
     Batch 150 | Loss : 0.3414 | Acc : 0.8448
     Batch 175 | Loss : 0.3237 | Acc : 0.8548
     Batch 200 | Loss : 0.3784 | Acc : 0.8176
     Batch 225 | Loss : 0.4028 | Acc : 0.8055
     Batch 250 | Loss : 0.3950 | Acc : 0.8037
     Batch 275 | Loss : 0.4136 | Acc : 0.8110
     Batch 300 | Loss : 0.3981 | Acc : 0.8181
Epoch 00005 | Train Loss : 0.3647 | Eval Loss : 0.3805 | Train acc : 0.8301 | Eval Acc : 0.8208 | Eval Log. Respected : 0.9760
     Batch 000 | Loss : 0.3908 | Acc : 0.8126
     Batch 025 | Loss : 0.3697 | Acc : 0.8250
     Batch 050 | Loss : 0.3646 | Acc : 0.8325
     Batch 075 | Loss : 0.3218 | Acc : 0.8526
     Batch 100 | Loss : 0.3353 | Acc : 0.8471
     Batch 125 | Loss : 0.4009 | Acc : 0.8147
     Batch 150 | Loss : 0.3170 | Acc : 0.8568
     Batch 175 | Loss : 0.3228 | Acc : 0.8513
     Batch 200 | Loss : 0.3188 | Acc : 0.8522
     Batch 225 | Loss : 0.3967 | Acc : 0.8134
     Batch 250 | Loss : 0.3462 | Acc : 0.8374
     Batch 275 | Loss : 0.3059 | Acc : 0.8637
     Batch 300 | Loss : 0.5108 | Acc : 0.7639
Epoch 00006 | Train Loss : 0.3604 | Eval Loss : 0.3670 | Train acc : 0.8328 | Eval Acc : 0.8292 | Eval Log. Respected : 0.9558
     Batch 000 | Loss : 0.3239 | Acc : 0.8600
     Batch 025 | Loss : 0.3723 | Acc : 0.8207
     Batch 050 | Loss : 0.3373 | Acc : 0.8448
     Batch 075 | Loss : 0.3373 | Acc : 0.8444
     Batch 100 | Loss : 0.3389 | Acc : 0.8468
     Batch 125 | Loss : 0.3973 | Acc : 0.8179
     Batch 150 | Loss : 0.3526 | Acc : 0.8378
     Batch 175 | Loss : 0.3566 | Acc : 0.8351
     Batch 200 | Loss : 0.3065 | Acc : 0.8628
     Batch 225 | Loss : 0.3119 | Acc : 0.8612
     Batch 250 | Loss : 0.3080 | Acc : 0.8578
     Batch 275 | Loss : 0.3221 | Acc : 0.8501
     Batch 300 | Loss : 0.3374 | Acc : 0.8384
Epoch 00007 | Train Loss : 0.3565 | Eval Loss : 0.3661 | Train acc : 0.8347 | Eval Acc : 0.8285 | Eval Log. Respected : 0.9539
     Batch 000 | Loss : 0.4023 | Acc : 0.8016
     Batch 025 | Loss : 0.4032 | Acc : 0.8049
     Batch 050 | Loss : 0.3631 | Acc : 0.8277
     Batch 075 | Loss : 0.3071 | Acc : 0.8663
     Batch 100 | Loss : 0.4532 | Acc : 0.7834
     Batch 125 | Loss : 0.3329 | Acc : 0.8505
     Batch 150 | Loss : 0.2939 | Acc : 0.8671
     Batch 175 | Loss : 0.3896 | Acc : 0.8187
     Batch 200 | Loss : 0.3330 | Acc : 0.8482
     Batch 225 | Loss : 0.3318 | Acc : 0.8477
     Batch 250 | Loss : 0.3316 | Acc : 0.8476
     Batch 275 | Loss : 0.3478 | Acc : 0.8447
     Batch 300 | Loss : 0.3654 | Acc : 0.8273
Epoch 00008 | Train Loss : 0.3551 | Eval Loss : 0.3635 | Train acc : 0.8353 | Eval Acc : 0.8296 | Eval Log. Respected : 0.9379
     Batch 000 | Loss : 0.4043 | Acc : 0.8156
     Batch 025 | Loss : 0.3010 | Acc : 0.8632
     Batch 050 | Loss : 0.3201 | Acc : 0.8507
     Batch 075 | Loss : 0.3420 | Acc : 0.8493
     Batch 100 | Loss : 0.3485 | Acc : 0.8336
     Batch 125 | Loss : 0.4552 | Acc : 0.7889
     Batch 150 | Loss : 0.3275 | Acc : 0.8527
     Batch 175 | Loss : 0.3372 | Acc : 0.8468
     Batch 200 | Loss : 0.3737 | Acc : 0.8324
     Batch 225 | Loss : 0.3121 | Acc : 0.8622
     Batch 250 | Loss : 0.3268 | Acc : 0.8495
     Batch 275 | Loss : 0.2997 | Acc : 0.8647
     Batch 300 | Loss : 0.4191 | Acc : 0.7974
Epoch 00009 | Train Loss : 0.3520 | Eval Loss : 0.3614 | Train acc : 0.8373 | Eval Acc : 0.8330 | Eval Log. Respected : 0.9379
     Batch 000 | Loss : 0.3186 | Acc : 0.8639
     Batch 025 | Loss : 0.3073 | Acc : 0.8627
     Batch 050 | Loss : 0.3769 | Acc : 0.8163
     Batch 075 | Loss : 0.3289 | Acc : 0.8485
     Batch 100 | Loss : 0.2938 | Acc : 0.8655
     Batch 125 | Loss : 0.3001 | Acc : 0.8617
     Batch 150 | Loss : 0.3308 | Acc : 0.8448
     Batch 175 | Loss : 0.3624 | Acc : 0.8274
     Batch 200 | Loss : 0.4341 | Acc : 0.8072
     Batch 225 | Loss : 0.3415 | Acc : 0.8452
     Batch 250 | Loss : 0.3096 | Acc : 0.8641
     Batch 275 | Loss : 0.3496 | Acc : 0.8394
     Batch 300 | Loss : 0.3353 | Acc : 0.8468
Epoch 00010 | Train Loss : 0.3516 | Eval Loss : 0.3740 | Train acc : 0.8379 | Eval Acc : 0.8308 | Eval Log. Respected : 0.9376
     Batch 000 | Loss : 0.3355 | Acc : 0.8567
     Batch 025 | Loss : 0.3871 | Acc : 0.8172
     Batch 050 | Loss : 0.4008 | Acc : 0.8200
     Batch 075 | Loss : 0.3840 | Acc : 0.8166
     Batch 100 | Loss : 0.3629 | Acc : 0.8350
     Batch 125 | Loss : 0.3899 | Acc : 0.8136
     Batch 150 | Loss : 0.3147 | Acc : 0.8583
     Batch 175 | Loss : 0.3568 | Acc : 0.8449
     Batch 200 | Loss : 0.3215 | Acc : 0.8527
     Batch 225 | Loss : 0.3886 | Acc : 0.8198
     Batch 250 | Loss : 0.4824 | Acc : 0.7818
     Batch 275 | Loss : 0.3503 | Acc : 0.8317
     Batch 300 | Loss : 0.3503 | Acc : 0.8399
Epoch 00011 | Train Loss : 0.3491 | Eval Loss : 0.3624 | Train acc : 0.8389 | Eval Acc : 0.8352 | Eval Log. Respected : 0.9563
     Batch 000 | Loss : 0.3283 | Acc : 0.8568
     Batch 025 | Loss : 0.3117 | Acc : 0.8580
     Batch 050 | Loss : 0.3232 | Acc : 0.8514
     Batch 075 | Loss : 0.4131 | Acc : 0.7994
     Batch 100 | Loss : 0.3436 | Acc : 0.8464
     Batch 125 | Loss : 0.3517 | Acc : 0.8383
     Batch 150 | Loss : 0.3460 | Acc : 0.8423
     Batch 175 | Loss : 0.3538 | Acc : 0.8323
     Batch 200 | Loss : 0.3569 | Acc : 0.8407
     Batch 225 | Loss : 0.2983 | Acc : 0.8690
     Batch 250 | Loss : 0.3934 | Acc : 0.8170
     Batch 275 | Loss : 0.3821 | Acc : 0.8134
     Batch 300 | Loss : 0.2772 | Acc : 0.8750
Epoch 00012 | Train Loss : 0.3468 | Eval Loss : 0.3533 | Train acc : 0.8402 | Eval Acc : 0.8366 | Eval Log. Respected : 0.9346
     Batch 000 | Loss : 0.3223 | Acc : 0.8507
     Batch 025 | Loss : 0.4214 | Acc : 0.7962
     Batch 050 | Loss : 0.3824 | Acc : 0.8287
     Batch 075 | Loss : 0.3222 | Acc : 0.8600
     Batch 100 | Loss : 0.4432 | Acc : 0.7999
     Batch 125 | Loss : 0.3540 | Acc : 0.8351
     Batch 150 | Loss : 0.3465 | Acc : 0.8433
     Batch 175 | Loss : 0.2895 | Acc : 0.8684
     Batch 200 | Loss : 0.3335 | Acc : 0.8420
     Batch 225 | Loss : 0.2871 | Acc : 0.8741
     Batch 250 | Loss : 0.2955 | Acc : 0.8676
     Batch 275 | Loss : 0.3586 | Acc : 0.8271
     Batch 300 | Loss : 0.3291 | Acc : 0.8514
Epoch 00013 | Train Loss : 0.3453 | Eval Loss : 0.3578 | Train acc : 0.8408 | Eval Acc : 0.8342 | Eval Log. Respected : 0.9612
     Batch 000 | Loss : 0.4575 | Acc : 0.7941
     Batch 025 | Loss : 0.4011 | Acc : 0.8059
     Batch 050 | Loss : 0.4390 | Acc : 0.7948
     Batch 075 | Loss : 0.3253 | Acc : 0.8514
     Batch 100 | Loss : 0.3425 | Acc : 0.8428
     Batch 125 | Loss : 0.2943 | Acc : 0.8665
     Batch 150 | Loss : 0.3398 | Acc : 0.8382
     Batch 175 | Loss : 0.3395 | Acc : 0.8449
     Batch 200 | Loss : 0.3381 | Acc : 0.8421
     Batch 225 | Loss : 0.3239 | Acc : 0.8513
     Batch 250 | Loss : 0.2972 | Acc : 0.8601
     Batch 275 | Loss : 0.3811 | Acc : 0.8194
     Batch 300 | Loss : 0.2705 | Acc : 0.8808
Epoch 00014 | Train Loss : 0.3423 | Eval Loss : 0.3537 | Train acc : 0.8418 | Eval Acc : 0.8366 | Eval Log. Respected : 0.9408
     Batch 000 | Loss : 0.3066 | Acc : 0.8593
     Batch 025 | Loss : 0.3596 | Acc : 0.8363
     Batch 050 | Loss : 0.3286 | Acc : 0.8501
     Batch 075 | Loss : 0.3454 | Acc : 0.8360
     Batch 100 | Loss : 0.3342 | Acc : 0.8470
     Batch 125 | Loss : 0.3538 | Acc : 0.8354
     Batch 150 | Loss : 0.3587 | Acc : 0.8258
     Batch 175 | Loss : 0.4692 | Acc : 0.7757
     Batch 200 | Loss : 0.2612 | Acc : 0.8853
     Batch 225 | Loss : 0.3974 | Acc : 0.8185
     Batch 250 | Loss : 0.3123 | Acc : 0.8580
     Batch 275 | Loss : 0.3875 | Acc : 0.8100
     Batch 300 | Loss : 0.2891 | Acc : 0.8705
Epoch 00015 | Train Loss : 0.3420 | Eval Loss : 0.3498 | Train acc : 0.8421 | Eval Acc : 0.8372 | Eval Log. Respected : 0.9491
     Batch 000 | Loss : 0.3304 | Acc : 0.8520
     Batch 025 | Loss : 0.3512 | Acc : 0.8366
     Batch 050 | Loss : 0.3506 | Acc : 0.8408
     Batch 075 | Loss : 0.2900 | Acc : 0.8689
     Batch 100 | Loss : 0.3762 | Acc : 0.8306
     Batch 125 | Loss : 0.3205 | Acc : 0.8548
     Batch 150 | Loss : 0.3602 | Acc : 0.8257
     Batch 175 | Loss : 0.3412 | Acc : 0.8454
     Batch 200 | Loss : 0.2936 | Acc : 0.8731
     Batch 225 | Loss : 0.3313 | Acc : 0.8437
     Batch 250 | Loss : 0.3580 | Acc : 0.8362
     Batch 275 | Loss : 0.3027 | Acc : 0.8683
     Batch 300 | Loss : 0.3268 | Acc : 0.8571
Epoch 00016 | Train Loss : 0.3417 | Eval Loss : 0.3536 | Train acc : 0.8424 | Eval Acc : 0.8349 | Eval Log. Respected : 0.9458
     Batch 000 | Loss : 0.3729 | Acc : 0.8240
     Batch 025 | Loss : 0.2964 | Acc : 0.8597
     Batch 050 | Loss : 0.2877 | Acc : 0.8655
     Batch 075 | Loss : 0.2797 | Acc : 0.8710
     Batch 100 | Loss : 0.3516 | Acc : 0.8280
     Batch 125 | Loss : 0.3585 | Acc : 0.8332
     Batch 150 | Loss : 0.3771 | Acc : 0.8190
     Batch 175 | Loss : 0.2975 | Acc : 0.8742
     Batch 200 | Loss : 0.4113 | Acc : 0.8033
     Batch 225 | Loss : 0.4182 | Acc : 0.8052
     Batch 250 | Loss : 0.3016 | Acc : 0.8634
     Batch 275 | Loss : 0.3926 | Acc : 0.8247
     Batch 300 | Loss : 0.3485 | Acc : 0.8408
Epoch 00017 | Train Loss : 0.3391 | Eval Loss : 0.3519 | Train acc : 0.8435 | Eval Acc : 0.8360 | Eval Log. Respected : 0.9319
     Batch 000 | Loss : 0.3470 | Acc : 0.8368
     Batch 025 | Loss : 0.4057 | Acc : 0.8070
     Batch 050 | Loss : 0.3369 | Acc : 0.8446
     Batch 075 | Loss : 0.3345 | Acc : 0.8475
     Batch 100 | Loss : 0.4390 | Acc : 0.7923
     Batch 125 | Loss : 0.4262 | Acc : 0.8114
     Batch 150 | Loss : 0.2896 | Acc : 0.8745
     Batch 175 | Loss : 0.3711 | Acc : 0.8187
     Batch 200 | Loss : 0.3286 | Acc : 0.8424
     Batch 225 | Loss : 0.3106 | Acc : 0.8559
     Batch 250 | Loss : 0.3429 | Acc : 0.8396
     Batch 275 | Loss : 0.3195 | Acc : 0.8516
     Batch 300 | Loss : 0.3154 | Acc : 0.8562
Epoch 00018 | Train Loss : 0.3394 | Eval Loss : 0.3486 | Train acc : 0.8427 | Eval Acc : 0.8387 | Eval Log. Respected : 0.9410
     Batch 000 | Loss : 0.4290 | Acc : 0.7924
     Batch 025 | Loss : 0.2999 | Acc : 0.8633
     Batch 050 | Loss : 0.3863 | Acc : 0.8136
     Batch 075 | Loss : 0.2883 | Acc : 0.8734
     Batch 100 | Loss : 0.4112 | Acc : 0.8163
     Batch 125 | Loss : 0.3113 | Acc : 0.8541
     Batch 150 | Loss : 0.2691 | Acc : 0.8798
     Batch 175 | Loss : 0.3087 | Acc : 0.8607
     Batch 200 | Loss : 0.3681 | Acc : 0.8295
     Batch 225 | Loss : 0.3621 | Acc : 0.8348
     Batch 250 | Loss : 0.3595 | Acc : 0.8263
     Batch 275 | Loss : 0.3519 | Acc : 0.8275
     Batch 300 | Loss : 0.3051 | Acc : 0.8604
Epoch 00019 | Train Loss : 0.3389 | Eval Loss : 0.3485 | Train acc : 0.8433 | Eval Acc : 0.8384 | Eval Log. Respected : 0.9345
     Batch 000 | Loss : 0.3622 | Acc : 0.8243
     Batch 025 | Loss : 0.3088 | Acc : 0.8616
     Batch 050 | Loss : 0.3413 | Acc : 0.8420
     Batch 075 | Loss : 0.3595 | Acc : 0.8254
     Batch 100 | Loss : 0.3182 | Acc : 0.8515
     Batch 125 | Loss : 0.3772 | Acc : 0.8234
     Batch 150 | Loss : 0.2948 | Acc : 0.8691
     Batch 175 | Loss : 0.2825 | Acc : 0.8746
     Batch 200 | Loss : 0.3124 | Acc : 0.8517
     Batch 225 | Loss : 0.3211 | Acc : 0.8535
     Batch 250 | Loss : 0.3470 | Acc : 0.8365
     Batch 275 | Loss : 0.3539 | Acc : 0.8295
     Batch 300 | Loss : 0.3757 | Acc : 0.8292
Epoch 00020 | Train Loss : 0.3381 | Eval Loss : 0.3443 | Train acc : 0.8438 | Eval Acc : 0.8408 | Eval Log. Respected : 0.9421
     Batch 000 | Loss : 0.3378 | Acc : 0.8368
     Batch 025 | Loss : 0.3508 | Acc : 0.8368
     Batch 050 | Loss : 0.3425 | Acc : 0.8453
     Batch 075 | Loss : 0.3791 | Acc : 0.8199
     Batch 100 | Loss : 0.3915 | Acc : 0.8185
     Batch 125 | Loss : 0.3744 | Acc : 0.8193
     Batch 150 | Loss : 0.3631 | Acc : 0.8295
     Batch 175 | Loss : 0.3926 | Acc : 0.8042
     Batch 200 | Loss : 0.3054 | Acc : 0.8588
     Batch 225 | Loss : 0.2780 | Acc : 0.8744
     Batch 250 | Loss : 0.3073 | Acc : 0.8641
     Batch 275 | Loss : 0.4571 | Acc : 0.7911
     Batch 300 | Loss : 0.3515 | Acc : 0.8366
Epoch 00021 | Train Loss : 0.3386 | Eval Loss : 0.3519 | Train acc : 0.8438 | Eval Acc : 0.8362 | Eval Log. Respected : 0.9271
     Batch 000 | Loss : 0.3561 | Acc : 0.8272
     Batch 025 | Loss : 0.3505 | Acc : 0.8388
     Batch 050 | Loss : 0.2723 | Acc : 0.8785
     Batch 075 | Loss : 0.3504 | Acc : 0.8337
     Batch 100 | Loss : 0.3523 | Acc : 0.8344
     Batch 125 | Loss : 0.2908 | Acc : 0.8696
     Batch 150 | Loss : 0.3136 | Acc : 0.8610
     Batch 175 | Loss : 0.3647 | Acc : 0.8260
     Batch 200 | Loss : 0.3194 | Acc : 0.8524
     Batch 225 | Loss : 0.3173 | Acc : 0.8561
     Batch 250 | Loss : 0.3587 | Acc : 0.8365
     Batch 275 | Loss : 0.3527 | Acc : 0.8292
     Batch 300 | Loss : 0.3277 | Acc : 0.8458
Epoch 00022 | Train Loss : 0.3367 | Eval Loss : 0.3458 | Train acc : 0.8445 | Eval Acc : 0.8395 | Eval Log. Respected : 0.9256
     Batch 000 | Loss : 0.2923 | Acc : 0.8683
     Batch 025 | Loss : 0.3787 | Acc : 0.8227
     Batch 050 | Loss : 0.2980 | Acc : 0.8659
     Batch 075 | Loss : 0.3100 | Acc : 0.8586
     Batch 100 | Loss : 0.3470 | Acc : 0.8450
     Batch 125 | Loss : 0.3158 | Acc : 0.8525
     Batch 150 | Loss : 0.3146 | Acc : 0.8573
     Batch 175 | Loss : 0.3095 | Acc : 0.8574
     Batch 200 | Loss : 0.4797 | Acc : 0.7734
     Batch 225 | Loss : 0.3012 | Acc : 0.8616
     Batch 250 | Loss : 0.3162 | Acc : 0.8551
     Batch 275 | Loss : 0.3199 | Acc : 0.8532
     Batch 300 | Loss : 0.3135 | Acc : 0.8534
Epoch 00023 | Train Loss : 0.3360 | Eval Loss : 0.3537 | Train acc : 0.8447 | Eval Acc : 0.8355 | Eval Log. Respected : 0.9357
     Batch 000 | Loss : 0.3299 | Acc : 0.8502
     Batch 025 | Loss : 0.2767 | Acc : 0.8785
     Batch 050 | Loss : 0.3487 | Acc : 0.8417
     Batch 075 | Loss : 0.2894 | Acc : 0.8709
     Batch 100 | Loss : 0.3347 | Acc : 0.8496
     Batch 125 | Loss : 0.3662 | Acc : 0.8310
     Batch 150 | Loss : 0.3713 | Acc : 0.8269
     Batch 175 | Loss : 0.3176 | Acc : 0.8551
     Batch 200 | Loss : 0.3521 | Acc : 0.8411
     Batch 225 | Loss : 0.2990 | Acc : 0.8666
     Batch 250 | Loss : 0.3474 | Acc : 0.8357
     Batch 275 | Loss : 0.2869 | Acc : 0.8691
     Batch 300 | Loss : 0.3609 | Acc : 0.8309
Epoch 00024 | Train Loss : 0.3351 | Eval Loss : 0.3414 | Train acc : 0.8452 | Eval Acc : 0.8418 | Eval Log. Respected : 0.9267
     Batch 000 | Loss : 0.2849 | Acc : 0.8672
     Batch 025 | Loss : 0.2886 | Acc : 0.8675
     Batch 050 | Loss : 0.3285 | Acc : 0.8530
     Batch 075 | Loss : 0.4245 | Acc : 0.8097
     Batch 100 | Loss : 0.3834 | Acc : 0.8280
     Batch 125 | Loss : 0.3019 | Acc : 0.8617
     Batch 150 | Loss : 0.4026 | Acc : 0.8016
     Batch 175 | Loss : 0.2802 | Acc : 0.8746
     Batch 200 | Loss : 0.3859 | Acc : 0.8161
     Batch 225 | Loss : 0.3640 | Acc : 0.8333
     Batch 250 | Loss : 0.2872 | Acc : 0.8752
     Batch 275 | Loss : 0.3347 | Acc : 0.8475
     Batch 300 | Loss : 0.3719 | Acc : 0.8219
Epoch 00025 | Train Loss : 0.3350 | Eval Loss : 0.3456 | Train acc : 0.8449 | Eval Acc : 0.8406 | Eval Log. Respected : 0.9319
     Batch 000 | Loss : 0.3129 | Acc : 0.8640
     Batch 025 | Loss : 0.2640 | Acc : 0.8849
     Batch 050 | Loss : 0.3356 | Acc : 0.8446
     Batch 075 | Loss : 0.3688 | Acc : 0.8285
     Batch 100 | Loss : 0.3019 | Acc : 0.8642
     Batch 125 | Loss : 0.2899 | Acc : 0.8667
     Batch 150 | Loss : 0.4168 | Acc : 0.7985
     Batch 175 | Loss : 0.4088 | Acc : 0.8023
     Batch 200 | Loss : 0.2675 | Acc : 0.8791
     Batch 225 | Loss : 0.3278 | Acc : 0.8463
     Batch 250 | Loss : 0.3590 | Acc : 0.8310
     Batch 275 | Loss : 0.3980 | Acc : 0.8068
     Batch 300 | Loss : 0.3273 | Acc : 0.8521
Epoch 00026 | Train Loss : 0.3342 | Eval Loss : 0.3454 | Train acc : 0.8456 | Eval Acc : 0.8399 | Eval Log. Respected : 0.9183
     Batch 000 | Loss : 0.3383 | Acc : 0.8491
     Batch 025 | Loss : 0.3421 | Acc : 0.8364
     Batch 050 | Loss : 0.3943 | Acc : 0.7999
     Batch 075 | Loss : 0.3012 | Acc : 0.8620
     Batch 100 | Loss : 0.3181 | Acc : 0.8562
     Batch 125 | Loss : 0.2913 | Acc : 0.8627
     Batch 150 | Loss : 0.3329 | Acc : 0.8585
     Batch 175 | Loss : 0.3137 | Acc : 0.8564
     Batch 200 | Loss : 0.2812 | Acc : 0.8715
     Batch 225 | Loss : 0.3029 | Acc : 0.8585
     Batch 250 | Loss : 0.3392 | Acc : 0.8414
     Batch 275 | Loss : 0.3841 | Acc : 0.8149
     Batch 300 | Loss : 0.2877 | Acc : 0.8696
Epoch 00027 | Train Loss : 0.3337 | Eval Loss : 0.3412 | Train acc : 0.8457 | Eval Acc : 0.8422 | Eval Log. Respected : 0.9271
     Batch 000 | Loss : 0.3268 | Acc : 0.8529
     Batch 025 | Loss : 0.3480 | Acc : 0.8388
     Batch 050 | Loss : 0.3733 | Acc : 0.8196
     Batch 075 | Loss : 0.2835 | Acc : 0.8781
     Batch 100 | Loss : 0.2981 | Acc : 0.8644
     Batch 125 | Loss : 0.3801 | Acc : 0.8184
     Batch 150 | Loss : 0.2951 | Acc : 0.8672
     Batch 175 | Loss : 0.3741 | Acc : 0.8239
     Batch 200 | Loss : 0.3991 | Acc : 0.8058
     Batch 225 | Loss : 0.3150 | Acc : 0.8551
     Batch 250 | Loss : 0.3274 | Acc : 0.8479
     Batch 275 | Loss : 0.3793 | Acc : 0.8242
     Batch 300 | Loss : 0.3207 | Acc : 0.8520
Epoch 00028 | Train Loss : 0.3326 | Eval Loss : 0.3428 | Train acc : 0.8463 | Eval Acc : 0.8404 | Eval Log. Respected : 0.9345
     Batch 000 | Loss : 0.3730 | Acc : 0.8278
     Batch 025 | Loss : 0.3132 | Acc : 0.8537
     Batch 050 | Loss : 0.2631 | Acc : 0.8802
     Batch 075 | Loss : 0.3307 | Acc : 0.8436
     Batch 100 | Loss : 0.3110 | Acc : 0.8554
     Batch 125 | Loss : 0.3738 | Acc : 0.8281
     Batch 150 | Loss : 0.3306 | Acc : 0.8487
     Batch 175 | Loss : 0.2909 | Acc : 0.8694
     Batch 200 | Loss : 0.3041 | Acc : 0.8594
     Batch 225 | Loss : 0.3069 | Acc : 0.8546
     Batch 250 | Loss : 0.3058 | Acc : 0.8541
     Batch 275 | Loss : 0.3761 | Acc : 0.8223
     Batch 300 | Loss : 0.3388 | Acc : 0.8373
Epoch 00029 | Train Loss : 0.3316 | Eval Loss : 0.3447 | Train acc : 0.8466 | Eval Acc : 0.8396 | Eval Log. Respected : 0.9419
     Batch 000 | Loss : 0.3438 | Acc : 0.8401
     Batch 025 | Loss : 0.2967 | Acc : 0.8669
     Batch 050 | Loss : 0.2916 | Acc : 0.8669
     Batch 075 | Loss : 0.2849 | Acc : 0.8703
     Batch 100 | Loss : 0.3344 | Acc : 0.8452
     Batch 125 | Loss : 0.3163 | Acc : 0.8543
     Batch 150 | Loss : 0.3298 | Acc : 0.8429
     Batch 175 | Loss : 0.3253 | Acc : 0.8511
     Batch 200 | Loss : 0.2990 | Acc : 0.8631
     Batch 225 | Loss : 0.3136 | Acc : 0.8631
     Batch 250 | Loss : 0.2739 | Acc : 0.8770
     Batch 275 | Loss : 0.3436 | Acc : 0.8459
     Batch 300 | Loss : 0.3395 | Acc : 0.8421
Epoch 00030 | Train Loss : 0.3310 | Eval Loss : 0.3397 | Train acc : 0.8470 | Eval Acc : 0.8418 | Eval Log. Respected : 0.9202
     Batch 000 | Loss : 0.2909 | Acc : 0.8684
     Batch 025 | Loss : 0.2866 | Acc : 0.8705
     Batch 050 | Loss : 0.3246 | Acc : 0.8474
     Batch 075 | Loss : 0.3353 | Acc : 0.8451
     Batch 100 | Loss : 0.2778 | Acc : 0.8769
     Batch 125 | Loss : 0.3426 | Acc : 0.8446
     Batch 150 | Loss : 0.3200 | Acc : 0.8550
     Batch 175 | Loss : 0.2772 | Acc : 0.8778
     Batch 200 | Loss : 0.2866 | Acc : 0.8702
     Batch 225 | Loss : 0.3503 | Acc : 0.8325
     Batch 250 | Loss : 0.3280 | Acc : 0.8490
     Batch 275 | Loss : 0.3852 | Acc : 0.8196
     Batch 300 | Loss : 0.3824 | Acc : 0.8227
Epoch 00031 | Train Loss : 0.3313 | Eval Loss : 0.3414 | Train acc : 0.8470 | Eval Acc : 0.8427 | Eval Log. Respected : 0.9329
     Batch 000 | Loss : 0.3456 | Acc : 0.8362
     Batch 025 | Loss : 0.3543 | Acc : 0.8342
     Batch 050 | Loss : 0.2691 | Acc : 0.8825
     Batch 075 | Loss : 0.3426 | Acc : 0.8392
     Batch 100 | Loss : 0.3416 | Acc : 0.8380
     Batch 125 | Loss : 0.2936 | Acc : 0.8708
     Batch 150 | Loss : 0.3438 | Acc : 0.8412
     Batch 175 | Loss : 0.2983 | Acc : 0.8718
     Batch 200 | Loss : 0.3891 | Acc : 0.8037
     Batch 225 | Loss : 0.3064 | Acc : 0.8619
     Batch 250 | Loss : 0.2773 | Acc : 0.8757
     Batch 275 | Loss : 0.3755 | Acc : 0.8261
     Batch 300 | Loss : 0.4667 | Acc : 0.7810
Epoch 00032 | Train Loss : 0.3313 | Eval Loss : 0.3378 | Train acc : 0.8468 | Eval Acc : 0.8437 | Eval Log. Respected : 0.9244
     Batch 000 | Loss : 0.3201 | Acc : 0.8506
     Batch 025 | Loss : 0.3136 | Acc : 0.8536
     Batch 050 | Loss : 0.3197 | Acc : 0.8522
     Batch 075 | Loss : 0.3227 | Acc : 0.8558
     Batch 100 | Loss : 0.3247 | Acc : 0.8438
     Batch 125 | Loss : 0.3203 | Acc : 0.8508
     Batch 150 | Loss : 0.3801 | Acc : 0.8188
     Batch 175 | Loss : 0.4019 | Acc : 0.8027
     Batch 200 | Loss : 0.3312 | Acc : 0.8492
     Batch 225 | Loss : 0.2988 | Acc : 0.8659
     Batch 250 | Loss : 0.3488 | Acc : 0.8395
     Batch 275 | Loss : 0.2944 | Acc : 0.8710
     Batch 300 | Loss : 0.4233 | Acc : 0.8061
Epoch 00033 | Train Loss : 0.3302 | Eval Loss : 0.3463 | Train acc : 0.8472 | Eval Acc : 0.8391 | Eval Log. Respected : 0.9348
     Batch 000 | Loss : 0.2859 | Acc : 0.8728
     Batch 025 | Loss : 0.3165 | Acc : 0.8541
     Batch 050 | Loss : 0.4265 | Acc : 0.8005
     Batch 075 | Loss : 0.3677 | Acc : 0.8262
     Batch 100 | Loss : 0.4200 | Acc : 0.7987
     Batch 125 | Loss : 0.3101 | Acc : 0.8589
     Batch 150 | Loss : 0.3037 | Acc : 0.8614
     Batch 175 | Loss : 0.3330 | Acc : 0.8473
     Batch 200 | Loss : 0.3501 | Acc : 0.8402
     Batch 225 | Loss : 0.3500 | Acc : 0.8378
     Batch 250 | Loss : 0.3114 | Acc : 0.8659
     Batch 275 | Loss : 0.2672 | Acc : 0.8771
     Batch 300 | Loss : 0.3061 | Acc : 0.8619
Epoch 00034 | Train Loss : 0.3312 | Eval Loss : 0.3448 | Train acc : 0.8470 | Eval Acc : 0.8392 | Eval Log. Respected : 0.9303
     Batch 000 | Loss : 0.2708 | Acc : 0.8815
     Batch 025 | Loss : 0.3000 | Acc : 0.8636
     Batch 050 | Loss : 0.2683 | Acc : 0.8811
     Batch 075 | Loss : 0.4139 | Acc : 0.8097
     Batch 100 | Loss : 0.2868 | Acc : 0.8704
     Batch 125 | Loss : 0.3438 | Acc : 0.8373
     Batch 150 | Loss : 0.2942 | Acc : 0.8658
     Batch 175 | Loss : 0.3443 | Acc : 0.8361
     Batch 200 | Loss : 0.2802 | Acc : 0.8710
     Batch 225 | Loss : 0.3699 | Acc : 0.8238
     Batch 250 | Loss : 0.3376 | Acc : 0.8496
     Batch 275 | Loss : 0.3014 | Acc : 0.8621
     Batch 300 | Loss : 0.3136 | Acc : 0.8586
Epoch 00035 | Train Loss : 0.3284 | Eval Loss : 0.3463 | Train acc : 0.8480 | Eval Acc : 0.8389 | Eval Log. Respected : 0.9397
     Batch 000 | Loss : 0.4108 | Acc : 0.7990
     Batch 025 | Loss : 0.2850 | Acc : 0.8761
     Batch 050 | Loss : 0.3486 | Acc : 0.8342
     Batch 075 | Loss : 0.2681 | Acc : 0.8770
     Batch 100 | Loss : 0.3341 | Acc : 0.8467
     Batch 125 | Loss : 0.3582 | Acc : 0.8192
     Batch 150 | Loss : 0.2708 | Acc : 0.8804
     Batch 175 | Loss : 0.4159 | Acc : 0.8099
     Batch 200 | Loss : 0.3350 | Acc : 0.8527
     Batch 225 | Loss : 0.2740 | Acc : 0.8767
     Batch 250 | Loss : 0.2726 | Acc : 0.8777
     Batch 275 | Loss : 0.3229 | Acc : 0.8550
     Batch 300 | Loss : 0.2934 | Acc : 0.8704
Epoch 00036 | Train Loss : 0.3291 | Eval Loss : 0.3377 | Train acc : 0.8479 | Eval Acc : 0.8428 | Eval Log. Respected : 0.9387
     Batch 000 | Loss : 0.3528 | Acc : 0.8405
     Batch 025 | Loss : 0.2914 | Acc : 0.8701
     Batch 050 | Loss : 0.2847 | Acc : 0.8718
     Batch 075 | Loss : 0.3006 | Acc : 0.8627
     Batch 100 | Loss : 0.3087 | Acc : 0.8568
     Batch 125 | Loss : 0.2767 | Acc : 0.8778
     Batch 150 | Loss : 0.4121 | Acc : 0.8012
     Batch 175 | Loss : 0.3559 | Acc : 0.8389
     Batch 200 | Loss : 0.3547 | Acc : 0.8279
     Batch 225 | Loss : 0.2882 | Acc : 0.8703
     Batch 250 | Loss : 0.2829 | Acc : 0.8709
     Batch 275 | Loss : 0.3303 | Acc : 0.8467
     Batch 300 | Loss : 0.2527 | Acc : 0.8885
Epoch 00037 | Train Loss : 0.3288 | Eval Loss : 0.3479 | Train acc : 0.8480 | Eval Acc : 0.8410 | Eval Log. Respected : 0.9310
     Batch 000 | Loss : 0.3715 | Acc : 0.8289
     Batch 025 | Loss : 0.3511 | Acc : 0.8405
     Batch 050 | Loss : 0.2808 | Acc : 0.8722
     Batch 075 | Loss : 0.3273 | Acc : 0.8483
     Batch 100 | Loss : 0.2685 | Acc : 0.8798
     Batch 125 | Loss : 0.2667 | Acc : 0.8801
     Batch 150 | Loss : 0.3403 | Acc : 0.8388
     Batch 175 | Loss : 0.3174 | Acc : 0.8517
     Batch 200 | Loss : 0.3668 | Acc : 0.8298
     Batch 225 | Loss : 0.3567 | Acc : 0.8342
     Batch 250 | Loss : 0.3558 | Acc : 0.8274
     Batch 275 | Loss : 0.3090 | Acc : 0.8573
     Batch 300 | Loss : 0.3487 | Acc : 0.8316
Epoch 00038 | Train Loss : 0.3275 | Eval Loss : 0.3409 | Train acc : 0.8486 | Eval Acc : 0.8424 | Eval Log. Respected : 0.9272
     Batch 000 | Loss : 0.3501 | Acc : 0.8299
     Batch 025 | Loss : 0.3229 | Acc : 0.8489
     Batch 050 | Loss : 0.2922 | Acc : 0.8659
     Batch 075 | Loss : 0.3219 | Acc : 0.8564
     Batch 100 | Loss : 0.2781 | Acc : 0.8730
     Batch 125 | Loss : 0.3680 | Acc : 0.8188
     Batch 150 | Loss : 0.2926 | Acc : 0.8650
     Batch 175 | Loss : 0.3939 | Acc : 0.8175
     Batch 200 | Loss : 0.3076 | Acc : 0.8525
     Batch 225 | Loss : 0.2894 | Acc : 0.8683
     Batch 250 | Loss : 0.3682 | Acc : 0.8236
     Batch 275 | Loss : 0.3105 | Acc : 0.8560
     Batch 300 | Loss : 0.2617 | Acc : 0.8798
Epoch 00039 | Train Loss : 0.3274 | Eval Loss : 0.3396 | Train acc : 0.8486 | Eval Acc : 0.8422 | Eval Log. Respected : 0.9380
     Batch 000 | Loss : 0.2723 | Acc : 0.8774
     Batch 025 | Loss : 0.3289 | Acc : 0.8440
     Batch 050 | Loss : 0.3604 | Acc : 0.8345
     Batch 075 | Loss : 0.3598 | Acc : 0.8288
     Batch 100 | Loss : 0.3034 | Acc : 0.8592
     Batch 125 | Loss : 0.3989 | Acc : 0.8111
     Batch 150 | Loss : 0.4112 | Acc : 0.8034
     Batch 175 | Loss : 0.3639 | Acc : 0.8216
     Batch 200 | Loss : 0.3774 | Acc : 0.8253
     Batch 225 | Loss : 0.3048 | Acc : 0.8601
     Batch 250 | Loss : 0.3227 | Acc : 0.8547
     Batch 275 | Loss : 0.3501 | Acc : 0.8348
     Batch 300 | Loss : 0.3218 | Acc : 0.8479
Epoch 00040 | Train Loss : 0.3264 | Eval Loss : 0.3370 | Train acc : 0.8487 | Eval Acc : 0.8428 | Eval Log. Respected : 0.9302
     Batch 000 | Loss : 0.3063 | Acc : 0.8585
     Batch 025 | Loss : 0.3104 | Acc : 0.8579
     Batch 050 | Loss : 0.3057 | Acc : 0.8554
     Batch 075 | Loss : 0.3576 | Acc : 0.8299
     Batch 100 | Loss : 0.3006 | Acc : 0.8566
     Batch 125 | Loss : 0.2944 | Acc : 0.8633
     Batch 150 | Loss : 0.2992 | Acc : 0.8629
     Batch 175 | Loss : 0.2771 | Acc : 0.8745
     Batch 200 | Loss : 0.2647 | Acc : 0.8827
     Batch 225 | Loss : 0.3771 | Acc : 0.8256
     Batch 250 | Loss : 0.3679 | Acc : 0.8219
     Batch 275 | Loss : 0.3356 | Acc : 0.8424
     Batch 300 | Loss : 0.2809 | Acc : 0.8755
Epoch 00041 | Train Loss : 0.3264 | Eval Loss : 0.3379 | Train acc : 0.8489 | Eval Acc : 0.8443 | Eval Log. Respected : 0.9344
     Batch 000 | Loss : 0.3128 | Acc : 0.8518
     Batch 025 | Loss : 0.3543 | Acc : 0.8329
     Batch 050 | Loss : 0.4307 | Acc : 0.7982
     Batch 075 | Loss : 0.3549 | Acc : 0.8295
     Batch 100 | Loss : 0.3219 | Acc : 0.8558
     Batch 125 | Loss : 0.3089 | Acc : 0.8584
     Batch 150 | Loss : 0.4668 | Acc : 0.7883
     Batch 175 | Loss : 0.3583 | Acc : 0.8300
     Batch 200 | Loss : 0.3051 | Acc : 0.8695
     Batch 225 | Loss : 0.3920 | Acc : 0.8135
     Batch 250 | Loss : 0.3750 | Acc : 0.8100
     Batch 275 | Loss : 0.3852 | Acc : 0.8171
     Batch 300 | Loss : 0.3488 | Acc : 0.8376
Epoch 00042 | Train Loss : 0.3254 | Eval Loss : 0.3393 | Train acc : 0.8494 | Eval Acc : 0.8433 | Eval Log. Respected : 0.9327
     Batch 000 | Loss : 0.3099 | Acc : 0.8592
     Batch 025 | Loss : 0.3390 | Acc : 0.8436
     Batch 050 | Loss : 0.2630 | Acc : 0.8830
     Batch 075 | Loss : 0.2605 | Acc : 0.8860
     Batch 100 | Loss : 0.2799 | Acc : 0.8753
     Batch 125 | Loss : 0.3321 | Acc : 0.8478
     Batch 150 | Loss : 0.2865 | Acc : 0.8684
     Batch 175 | Loss : 0.3703 | Acc : 0.8246
     Batch 200 | Loss : 0.3647 | Acc : 0.8360
     Batch 225 | Loss : 0.3376 | Acc : 0.8432
     Batch 250 | Loss : 0.2770 | Acc : 0.8753
     Batch 275 | Loss : 0.3599 | Acc : 0.8334
     Batch 300 | Loss : 0.3764 | Acc : 0.8219
Epoch 00043 | Train Loss : 0.3260 | Eval Loss : 0.3351 | Train acc : 0.8494 | Eval Acc : 0.8438 | Eval Log. Respected : 0.9294
     Batch 000 | Loss : 0.3588 | Acc : 0.8286
     Batch 025 | Loss : 0.2840 | Acc : 0.8696
     Batch 050 | Loss : 0.3921 | Acc : 0.8062
     Batch 075 | Loss : 0.2737 | Acc : 0.8723
     Batch 100 | Loss : 0.3245 | Acc : 0.8493
     Batch 125 | Loss : 0.3227 | Acc : 0.8502
     Batch 150 | Loss : 0.3138 | Acc : 0.8527
     Batch 175 | Loss : 0.3118 | Acc : 0.8547
     Batch 200 | Loss : 0.3973 | Acc : 0.8105
     Batch 225 | Loss : 0.2994 | Acc : 0.8666
     Batch 250 | Loss : 0.2904 | Acc : 0.8657
     Batch 275 | Loss : 0.2641 | Acc : 0.8823
     Batch 300 | Loss : 0.3612 | Acc : 0.8281
Epoch 00044 | Train Loss : 0.3254 | Eval Loss : 0.3337 | Train acc : 0.8496 | Eval Acc : 0.8447 | Eval Log. Respected : 0.9316
     Batch 000 | Loss : 0.2736 | Acc : 0.8750
     Batch 025 | Loss : 0.2967 | Acc : 0.8670
     Batch 050 | Loss : 0.2839 | Acc : 0.8736
     Batch 075 | Loss : 0.2580 | Acc : 0.8886
     Batch 100 | Loss : 0.3499 | Acc : 0.8365
     Batch 125 | Loss : 0.2973 | Acc : 0.8643
     Batch 150 | Loss : 0.3392 | Acc : 0.8354
     Batch 175 | Loss : 0.2984 | Acc : 0.8648
     Batch 200 | Loss : 0.3571 | Acc : 0.8324
     Batch 225 | Loss : 0.3394 | Acc : 0.8450
     Batch 250 | Loss : 0.3215 | Acc : 0.8496
     Batch 275 | Loss : 0.2703 | Acc : 0.8795
     Batch 300 | Loss : 0.4126 | Acc : 0.7994
Epoch 00045 | Train Loss : 0.3245 | Eval Loss : 0.3394 | Train acc : 0.8496 | Eval Acc : 0.8436 | Eval Log. Respected : 0.9329
     Batch 000 | Loss : 0.2977 | Acc : 0.8607
     Batch 025 | Loss : 0.3349 | Acc : 0.8434
     Batch 050 | Loss : 0.2981 | Acc : 0.8620
     Batch 075 | Loss : 0.3212 | Acc : 0.8527
     Batch 100 | Loss : 0.2868 | Acc : 0.8687
     Batch 125 | Loss : 0.2916 | Acc : 0.8677
     Batch 150 | Loss : 0.3450 | Acc : 0.8346
     Batch 175 | Loss : 0.4205 | Acc : 0.7987
     Batch 200 | Loss : 0.3289 | Acc : 0.8461
     Batch 225 | Loss : 0.3578 | Acc : 0.8329
     Batch 250 | Loss : 0.4046 | Acc : 0.8159
     Batch 275 | Loss : 0.2774 | Acc : 0.8754
     Batch 300 | Loss : 0.3263 | Acc : 0.8511
Epoch 00046 | Train Loss : 0.3250 | Eval Loss : 0.3419 | Train acc : 0.8496 | Eval Acc : 0.8402 | Eval Log. Respected : 0.9339
     Batch 000 | Loss : 0.3255 | Acc : 0.8499
     Batch 025 | Loss : 0.3631 | Acc : 0.8251
     Batch 050 | Loss : 0.3238 | Acc : 0.8459
     Batch 075 | Loss : 0.3099 | Acc : 0.8562
     Batch 100 | Loss : 0.3544 | Acc : 0.8374
     Batch 125 | Loss : 0.2453 | Acc : 0.8912
     Batch 150 | Loss : 0.3291 | Acc : 0.8465
     Batch 175 | Loss : 0.3227 | Acc : 0.8499
     Batch 200 | Loss : 0.2742 | Acc : 0.8744
     Batch 225 | Loss : 0.3923 | Acc : 0.8225
     Batch 250 | Loss : 0.3448 | Acc : 0.8372
     Batch 275 | Loss : 0.4307 | Acc : 0.7949
     Batch 300 | Loss : 0.3282 | Acc : 0.8493
Epoch 00047 | Train Loss : 0.3242 | Eval Loss : 0.3405 | Train acc : 0.8500 | Eval Acc : 0.8411 | Eval Log. Respected : 0.9513
     Batch 000 | Loss : 0.2997 | Acc : 0.8686
     Batch 025 | Loss : 0.4131 | Acc : 0.8078
     Batch 050 | Loss : 0.3194 | Acc : 0.8507
     Batch 075 | Loss : 0.3579 | Acc : 0.8295
     Batch 100 | Loss : 0.3058 | Acc : 0.8603
     Batch 125 | Loss : 0.3170 | Acc : 0.8581
     Batch 150 | Loss : 0.2757 | Acc : 0.8769
     Batch 175 | Loss : 0.3177 | Acc : 0.8565
     Batch 200 | Loss : 0.2640 | Acc : 0.8830
     Batch 225 | Loss : 0.3081 | Acc : 0.8608
     Batch 250 | Loss : 0.4030 | Acc : 0.8197
     Batch 275 | Loss : 0.3215 | Acc : 0.8549
     Batch 300 | Loss : 0.3608 | Acc : 0.8306
Epoch 00048 | Train Loss : 0.3244 | Eval Loss : 0.3353 | Train acc : 0.8501 | Eval Acc : 0.8441 | Eval Log. Respected : 0.9222
     Batch 000 | Loss : 0.3667 | Acc : 0.8326
     Batch 025 | Loss : 0.2745 | Acc : 0.8730
     Batch 050 | Loss : 0.3092 | Acc : 0.8556
     Batch 075 | Loss : 0.3735 | Acc : 0.8211
     Batch 100 | Loss : 0.3009 | Acc : 0.8625
     Batch 125 | Loss : 0.2795 | Acc : 0.8763
     Batch 150 | Loss : 0.3619 | Acc : 0.8317
     Batch 175 | Loss : 0.3646 | Acc : 0.8252
     Batch 200 | Loss : 0.3060 | Acc : 0.8624
     Batch 225 | Loss : 0.2707 | Acc : 0.8754
     Batch 250 | Loss : 0.2933 | Acc : 0.8693
     Batch 275 | Loss : 0.2856 | Acc : 0.8681
     Batch 300 | Loss : 0.3702 | Acc : 0.8244
Epoch 00049 | Train Loss : 0.3252 | Eval Loss : 0.3340 | Train acc : 0.8496 | Eval Acc : 0.8447 | Eval Log. Respected : 0.9301
     Batch 000 | Loss : 0.2691 | Acc : 0.8760
     Batch 025 | Loss : 0.2924 | Acc : 0.8655
     Batch 050 | Loss : 0.3632 | Acc : 0.8237
     Batch 075 | Loss : 0.3011 | Acc : 0.8610
     Batch 100 | Loss : 0.2557 | Acc : 0.8823
     Batch 125 | Loss : 0.3933 | Acc : 0.8198
     Batch 150 | Loss : 0.2810 | Acc : 0.8743
     Batch 175 | Loss : 0.3693 | Acc : 0.8282
     Batch 200 | Loss : 0.3000 | Acc : 0.8621
     Batch 225 | Loss : 0.2530 | Acc : 0.8888
     Batch 250 | Loss : 0.3485 | Acc : 0.8325
     Batch 275 | Loss : 0.2880 | Acc : 0.8715
     Batch 300 | Loss : 0.3198 | Acc : 0.8550
Epoch 00050 | Train Loss : 0.3225 | Eval Loss : 0.3355 | Train acc : 0.8507 | Eval Acc : 0.8440 | Eval Log. Respected : 0.9340
     Batch 000 | Loss : 0.3335 | Acc : 0.8411
     Batch 025 | Loss : 0.2717 | Acc : 0.8782
     Batch 050 | Loss : 0.3915 | Acc : 0.8123
     Batch 075 | Loss : 0.3491 | Acc : 0.8322
     Batch 100 | Loss : 0.2696 | Acc : 0.8767
     Batch 125 | Loss : 0.4717 | Acc : 0.7701
     Batch 150 | Loss : 0.2923 | Acc : 0.8683
     Batch 175 | Loss : 0.2826 | Acc : 0.8663
     Batch 200 | Loss : 0.3918 | Acc : 0.8143
     Batch 225 | Loss : 0.3428 | Acc : 0.8369
     Batch 250 | Loss : 0.3044 | Acc : 0.8601
     Batch 275 | Loss : 0.3457 | Acc : 0.8366
     Batch 300 | Loss : 0.2547 | Acc : 0.8871
Epoch 00051 | Train Loss : 0.3239 | Eval Loss : 0.3343 | Train acc : 0.8502 | Eval Acc : 0.8448 | Eval Log. Respected : 0.9335
     Batch 000 | Loss : 0.3524 | Acc : 0.8367
     Batch 025 | Loss : 0.4089 | Acc : 0.8013
     Batch 050 | Loss : 0.2730 | Acc : 0.8811
     Batch 075 | Loss : 0.2818 | Acc : 0.8748
     Batch 100 | Loss : 0.3437 | Acc : 0.8447
     Batch 125 | Loss : 0.3129 | Acc : 0.8561
     Batch 150 | Loss : 0.3263 | Acc : 0.8493
     Batch 175 | Loss : 0.3570 | Acc : 0.8276
     Batch 200 | Loss : 0.3067 | Acc : 0.8609
     Batch 225 | Loss : 0.2726 | Acc : 0.8752
     Batch 250 | Loss : 0.3663 | Acc : 0.8300
     Batch 275 | Loss : 0.3583 | Acc : 0.8293
     Batch 300 | Loss : 0.3032 | Acc : 0.8641
Epoch 00052 | Train Loss : 0.3228 | Eval Loss : 0.3378 | Train acc : 0.8505 | Eval Acc : 0.8446 | Eval Log. Respected : 0.9272
     Batch 000 | Loss : 0.3562 | Acc : 0.8400
     Batch 025 | Loss : 0.3499 | Acc : 0.8380
     Batch 050 | Loss : 0.3461 | Acc : 0.8320
     Batch 075 | Loss : 0.3330 | Acc : 0.8411
     Batch 100 | Loss : 0.3414 | Acc : 0.8481
     Batch 125 | Loss : 0.3258 | Acc : 0.8471
     Batch 150 | Loss : 0.2975 | Acc : 0.8628
     Batch 175 | Loss : 0.3073 | Acc : 0.8629
     Batch 200 | Loss : 0.2794 | Acc : 0.8775
     Batch 225 | Loss : 0.3200 | Acc : 0.8516
     Batch 250 | Loss : 0.3291 | Acc : 0.8480
     Batch 275 | Loss : 0.3751 | Acc : 0.8277
     Batch 300 | Loss : 0.3354 | Acc : 0.8470
Epoch 00053 | Train Loss : 0.3227 | Eval Loss : 0.3343 | Train acc : 0.8507 | Eval Acc : 0.8464 | Eval Log. Respected : 0.9312
     Batch 000 | Loss : 0.2867 | Acc : 0.8674
     Batch 025 | Loss : 0.3138 | Acc : 0.8513
     Batch 050 | Loss : 0.3452 | Acc : 0.8406
     Batch 075 | Loss : 0.2980 | Acc : 0.8625
     Batch 100 | Loss : 0.3586 | Acc : 0.8356
     Batch 125 | Loss : 0.3651 | Acc : 0.8228
     Batch 150 | Loss : 0.3357 | Acc : 0.8435
     Batch 175 | Loss : 0.3382 | Acc : 0.8454
     Batch 200 | Loss : 0.3192 | Acc : 0.8442
     Batch 225 | Loss : 0.3441 | Acc : 0.8422
     Batch 250 | Loss : 0.3057 | Acc : 0.8610
     Batch 275 | Loss : 0.2915 | Acc : 0.8693
     Batch 300 | Loss : 0.2848 | Acc : 0.8675
Epoch 00054 | Train Loss : 0.3227 | Eval Loss : 0.3322 | Train acc : 0.8506 | Eval Acc : 0.8446 | Eval Log. Respected : 0.9323
     Batch 000 | Loss : 0.3626 | Acc : 0.8275
     Batch 025 | Loss : 0.2575 | Acc : 0.8826
     Batch 050 | Loss : 0.2675 | Acc : 0.8784
     Batch 075 | Loss : 0.4257 | Acc : 0.8010
     Batch 100 | Loss : 0.3146 | Acc : 0.8557
     Batch 125 | Loss : 0.2782 | Acc : 0.8734
     Batch 150 | Loss : 0.3642 | Acc : 0.8254
     Batch 175 | Loss : 0.4547 | Acc : 0.7848
     Batch 200 | Loss : 0.3589 | Acc : 0.8311
     Batch 225 | Loss : 0.3232 | Acc : 0.8447
     Batch 250 | Loss : 0.3485 | Acc : 0.8276
     Batch 275 | Loss : 0.3391 | Acc : 0.8353
     Batch 300 | Loss : 0.3008 | Acc : 0.8692
Epoch 00055 | Train Loss : 0.3218 | Eval Loss : 0.3318 | Train acc : 0.8512 | Eval Acc : 0.8461 | Eval Log. Respected : 0.9371
     Batch 000 | Loss : 0.3666 | Acc : 0.8273
     Batch 025 | Loss : 0.2926 | Acc : 0.8618
     Batch 050 | Loss : 0.3997 | Acc : 0.8071
     Batch 075 | Loss : 0.2810 | Acc : 0.8742
     Batch 100 | Loss : 0.2569 | Acc : 0.8845
     Batch 125 | Loss : 0.3670 | Acc : 0.8313
     Batch 150 | Loss : 0.2584 | Acc : 0.8828
     Batch 175 | Loss : 0.3201 | Acc : 0.8517
     Batch 200 | Loss : 0.3409 | Acc : 0.8400
     Batch 225 | Loss : 0.4009 | Acc : 0.8049
     Batch 250 | Loss : 0.3533 | Acc : 0.8337
     Batch 275 | Loss : 0.2710 | Acc : 0.8728
     Batch 300 | Loss : 0.3491 | Acc : 0.8329
Epoch 00056 | Train Loss : 0.3216 | Eval Loss : 0.3351 | Train acc : 0.8513 | Eval Acc : 0.8448 | Eval Log. Respected : 0.9237
     Batch 000 | Loss : 0.3552 | Acc : 0.8271
     Batch 025 | Loss : 0.3480 | Acc : 0.8396
     Batch 050 | Loss : 0.2619 | Acc : 0.8832
     Batch 075 | Loss : 0.3448 | Acc : 0.8430
     Batch 100 | Loss : 0.3271 | Acc : 0.8503
     Batch 125 | Loss : 0.2684 | Acc : 0.8809
     Batch 150 | Loss : 0.3034 | Acc : 0.8589
     Batch 175 | Loss : 0.2991 | Acc : 0.8602
     Batch 200 | Loss : 0.2794 | Acc : 0.8721
     Batch 225 | Loss : 0.2591 | Acc : 0.8833
     Batch 250 | Loss : 0.3993 | Acc : 0.8168
     Batch 275 | Loss : 0.3373 | Acc : 0.8429
     Batch 300 | Loss : 0.2996 | Acc : 0.8613
Epoch 00057 | Train Loss : 0.3210 | Eval Loss : 0.3345 | Train acc : 0.8511 | Eval Acc : 0.8443 | Eval Log. Respected : 0.9360
     Batch 000 | Loss : 0.3023 | Acc : 0.8607
     Batch 025 | Loss : 0.3591 | Acc : 0.8305
     Batch 050 | Loss : 0.2736 | Acc : 0.8800
     Batch 075 | Loss : 0.3152 | Acc : 0.8490
     Batch 100 | Loss : 0.2990 | Acc : 0.8621
     Batch 125 | Loss : 0.2779 | Acc : 0.8714
     Batch 150 | Loss : 0.3411 | Acc : 0.8399
     Batch 175 | Loss : 0.2736 | Acc : 0.8745
     Batch 200 | Loss : 0.3403 | Acc : 0.8413
     Batch 225 | Loss : 0.3221 | Acc : 0.8524
     Batch 250 | Loss : 0.2995 | Acc : 0.8617
     Batch 275 | Loss : 0.3310 | Acc : 0.8456
     Batch 300 | Loss : 0.3089 | Acc : 0.8532
Epoch 00058 | Train Loss : 0.3224 | Eval Loss : 0.3328 | Train acc : 0.8508 | Eval Acc : 0.8450 | Eval Log. Respected : 0.9229
     Batch 000 | Loss : 0.3158 | Acc : 0.8543
     Batch 025 | Loss : 0.2982 | Acc : 0.8661
     Batch 050 | Loss : 0.2776 | Acc : 0.8709
     Batch 075 | Loss : 0.2972 | Acc : 0.8581
     Batch 100 | Loss : 0.2628 | Acc : 0.8795
     Batch 125 | Loss : 0.3292 | Acc : 0.8464
     Batch 150 | Loss : 0.3153 | Acc : 0.8544
     Batch 175 | Loss : 0.3345 | Acc : 0.8460
     Batch 200 | Loss : 0.3608 | Acc : 0.8244
     Batch 225 | Loss : 0.3222 | Acc : 0.8481
     Batch 250 | Loss : 0.2857 | Acc : 0.8693
     Batch 275 | Loss : 0.2621 | Acc : 0.8839
     Batch 300 | Loss : 0.2730 | Acc : 0.8755
Epoch 00059 | Train Loss : 0.3203 | Eval Loss : 0.3376 | Train acc : 0.8516 | Eval Acc : 0.8455 | Eval Log. Respected : 0.9234
     Batch 000 | Loss : 0.2741 | Acc : 0.8749
     Batch 025 | Loss : 0.3376 | Acc : 0.8442
     Batch 050 | Loss : 0.2998 | Acc : 0.8585
     Batch 075 | Loss : 0.2864 | Acc : 0.8737
     Batch 100 | Loss : 0.2915 | Acc : 0.8712
     Batch 125 | Loss : 0.3698 | Acc : 0.8251
     Batch 150 | Loss : 0.3351 | Acc : 0.8355
     Batch 175 | Loss : 0.2931 | Acc : 0.8690
     Batch 200 | Loss : 0.2828 | Acc : 0.8731
     Batch 225 | Loss : 0.3295 | Acc : 0.8415
     Batch 250 | Loss : 0.2514 | Acc : 0.8876
     Batch 275 | Loss : 0.2944 | Acc : 0.8667
     Batch 300 | Loss : 0.3428 | Acc : 0.8379
Epoch 00060 | Train Loss : 0.3206 | Eval Loss : 0.3343 | Train acc : 0.8515 | Eval Acc : 0.8445 | Eval Log. Respected : 0.9366
     Batch 000 | Loss : 0.3026 | Acc : 0.8609
     Batch 025 | Loss : 0.3068 | Acc : 0.8548
     Batch 050 | Loss : 0.3154 | Acc : 0.8599
     Batch 075 | Loss : 0.2733 | Acc : 0.8813
     Batch 100 | Loss : 0.2783 | Acc : 0.8721
     Batch 125 | Loss : 0.2915 | Acc : 0.8712
     Batch 150 | Loss : 0.4240 | Acc : 0.8028
     Batch 175 | Loss : 0.4114 | Acc : 0.7998
     Batch 200 | Loss : 0.3067 | Acc : 0.8623
     Batch 225 | Loss : 0.3695 | Acc : 0.8215
     Batch 250 | Loss : 0.2841 | Acc : 0.8696
     Batch 275 | Loss : 0.2961 | Acc : 0.8627
     Batch 300 | Loss : 0.3047 | Acc : 0.8591
Epoch 00061 | Train Loss : 0.3200 | Eval Loss : 0.3349 | Train acc : 0.8517 | Eval Acc : 0.8446 | Eval Log. Respected : 0.9293
     Batch 000 | Loss : 0.3557 | Acc : 0.8280
     Batch 025 | Loss : 0.3538 | Acc : 0.8347
     Batch 050 | Loss : 0.3171 | Acc : 0.8535
     Batch 075 | Loss : 0.2712 | Acc : 0.8761
     Batch 100 | Loss : 0.3635 | Acc : 0.8268
     Batch 125 | Loss : 0.3399 | Acc : 0.8419
     Batch 150 | Loss : 0.2675 | Acc : 0.8772
     Batch 175 | Loss : 0.3529 | Acc : 0.8296
     Batch 200 | Loss : 0.2845 | Acc : 0.8704
     Batch 225 | Loss : 0.3510 | Acc : 0.8353
     Batch 250 | Loss : 0.2961 | Acc : 0.8625
     Batch 275 | Loss : 0.3405 | Acc : 0.8336
     Batch 300 | Loss : 0.3339 | Acc : 0.8411
Epoch 00062 | Train Loss : 0.3194 | Eval Loss : 0.3361 | Train acc : 0.8520 | Eval Acc : 0.8429 | Eval Log. Respected : 0.9481
     Batch 000 | Loss : 0.3120 | Acc : 0.8590
     Batch 025 | Loss : 0.3372 | Acc : 0.8408
     Batch 050 | Loss : 0.2860 | Acc : 0.8672
     Batch 075 | Loss : 0.2693 | Acc : 0.8785
     Batch 100 | Loss : 0.3740 | Acc : 0.8268
     Batch 125 | Loss : 0.3295 | Acc : 0.8457
     Batch 150 | Loss : 0.3466 | Acc : 0.8424
     Batch 175 | Loss : 0.3358 | Acc : 0.8442
     Batch 200 | Loss : 0.2656 | Acc : 0.8796
     Batch 225 | Loss : 0.2830 | Acc : 0.8717
     Batch 250 | Loss : 0.2445 | Acc : 0.8903
     Batch 275 | Loss : 0.3475 | Acc : 0.8373
     Batch 300 | Loss : 0.2817 | Acc : 0.8711
Epoch 00063 | Train Loss : 0.3197 | Eval Loss : 0.3291 | Train acc : 0.8520 | Eval Acc : 0.8465 | Eval Log. Respected : 0.9361
     Batch 000 | Loss : 0.3574 | Acc : 0.8216
     Batch 025 | Loss : 0.4866 | Acc : 0.7721
     Batch 050 | Loss : 0.3366 | Acc : 0.8392
     Batch 075 | Loss : 0.3245 | Acc : 0.8499
     Batch 100 | Loss : 0.2852 | Acc : 0.8699
     Batch 125 | Loss : 0.3212 | Acc : 0.8457
     Batch 150 | Loss : 0.3428 | Acc : 0.8449
     Batch 175 | Loss : 0.4289 | Acc : 0.8003
     Batch 200 | Loss : 0.3423 | Acc : 0.8418
     Batch 225 | Loss : 0.3830 | Acc : 0.8222
     Batch 250 | Loss : 0.2650 | Acc : 0.8812
     Batch 275 | Loss : 0.2627 | Acc : 0.8830
     Batch 300 | Loss : 0.2699 | Acc : 0.8828
Epoch 00064 | Train Loss : 0.3195 | Eval Loss : 0.3273 | Train acc : 0.8522 | Eval Acc : 0.8478 | Eval Log. Respected : 0.9279
     Batch 000 | Loss : 0.2956 | Acc : 0.8693
     Batch 025 | Loss : 0.3341 | Acc : 0.8377
     Batch 050 | Loss : 0.3222 | Acc : 0.8518
     Batch 075 | Loss : 0.3909 | Acc : 0.8085
     Batch 100 | Loss : 0.2901 | Acc : 0.8669
     Batch 125 | Loss : 0.3249 | Acc : 0.8509
     Batch 150 | Loss : 0.4104 | Acc : 0.8141
     Batch 175 | Loss : 0.2650 | Acc : 0.8787
     Batch 200 | Loss : 0.2834 | Acc : 0.8706
     Batch 225 | Loss : 0.2629 | Acc : 0.8813
     Batch 250 | Loss : 0.3247 | Acc : 0.8470
     Batch 275 | Loss : 0.2623 | Acc : 0.8838
     Batch 300 | Loss : 0.3846 | Acc : 0.8171
Epoch 00065 | Train Loss : 0.3185 | Eval Loss : 0.3310 | Train acc : 0.8523 | Eval Acc : 0.8462 | Eval Log. Respected : 0.9340
     Batch 000 | Loss : 0.3480 | Acc : 0.8382
     Batch 025 | Loss : 0.3372 | Acc : 0.8444
     Batch 050 | Loss : 0.2747 | Acc : 0.8750
     Batch 075 | Loss : 0.3456 | Acc : 0.8396
     Batch 100 | Loss : 0.3904 | Acc : 0.8139
     Batch 125 | Loss : 0.3275 | Acc : 0.8503
     Batch 150 | Loss : 0.2959 | Acc : 0.8624
     Batch 175 | Loss : 0.2843 | Acc : 0.8715
     Batch 200 | Loss : 0.2799 | Acc : 0.8731
     Batch 225 | Loss : 0.3067 | Acc : 0.8679
     Batch 250 | Loss : 0.3463 | Acc : 0.8368
     Batch 275 | Loss : 0.3274 | Acc : 0.8473
     Batch 300 | Loss : 0.2969 | Acc : 0.8669
Epoch 00066 | Train Loss : 0.3189 | Eval Loss : 0.3312 | Train acc : 0.8524 | Eval Acc : 0.8465 | Eval Log. Respected : 0.9359
     Batch 000 | Loss : 0.2632 | Acc : 0.8798
     Batch 025 | Loss : 0.3021 | Acc : 0.8596
     Batch 050 | Loss : 0.3431 | Acc : 0.8369
     Batch 075 | Loss : 0.2972 | Acc : 0.8635
     Batch 100 | Loss : 0.2782 | Acc : 0.8705
     Batch 125 | Loss : 0.3284 | Acc : 0.8474
     Batch 150 | Loss : 0.2856 | Acc : 0.8698
     Batch 175 | Loss : 0.3447 | Acc : 0.8318
     Batch 200 | Loss : 0.2541 | Acc : 0.8927
     Batch 225 | Loss : 0.3138 | Acc : 0.8568
     Batch 250 | Loss : 0.2746 | Acc : 0.8709
     Batch 275 | Loss : 0.3687 | Acc : 0.8309
     Batch 300 | Loss : 0.3366 | Acc : 0.8444
Epoch 00067 | Train Loss : 0.3184 | Eval Loss : 0.3307 | Train acc : 0.8525 | Eval Acc : 0.8460 | Eval Log. Respected : 0.9314
     Batch 000 | Loss : 0.3874 | Acc : 0.8144
     Batch 025 | Loss : 0.3147 | Acc : 0.8535
     Batch 050 | Loss : 0.3464 | Acc : 0.8412
     Batch 075 | Loss : 0.3485 | Acc : 0.8267
     Batch 100 | Loss : 0.2372 | Acc : 0.8933
     Batch 125 | Loss : 0.3822 | Acc : 0.8058
     Batch 150 | Loss : 0.3131 | Acc : 0.8564
     Batch 175 | Loss : 0.3262 | Acc : 0.8475
     Batch 200 | Loss : 0.3084 | Acc : 0.8635
     Batch 225 | Loss : 0.3154 | Acc : 0.8563
     Batch 250 | Loss : 0.3161 | Acc : 0.8529
     Batch 275 | Loss : 0.2591 | Acc : 0.8824
     Batch 300 | Loss : 0.3408 | Acc : 0.8338
Epoch 00068 | Train Loss : 0.3177 | Eval Loss : 0.3356 | Train acc : 0.8527 | Eval Acc : 0.8452 | Eval Log. Respected : 0.9333
     Batch 000 | Loss : 0.4434 | Acc : 0.8037
     Batch 025 | Loss : 0.3277 | Acc : 0.8500
     Batch 050 | Loss : 0.3641 | Acc : 0.8246
     Batch 075 | Loss : 0.3867 | Acc : 0.8230
     Batch 100 | Loss : 0.3549 | Acc : 0.8277
     Batch 125 | Loss : 0.3800 | Acc : 0.8170
     Batch 150 | Loss : 0.3355 | Acc : 0.8428
     Batch 175 | Loss : 0.3794 | Acc : 0.8215
     Batch 200 | Loss : 0.3551 | Acc : 0.8315
     Batch 225 | Loss : 0.3456 | Acc : 0.8347
     Batch 250 | Loss : 0.2972 | Acc : 0.8613
     Batch 275 | Loss : 0.2629 | Acc : 0.8786
     Batch 300 | Loss : 0.2940 | Acc : 0.8652
Epoch 00069 | Train Loss : 0.3179 | Eval Loss : 0.3310 | Train acc : 0.8528 | Eval Acc : 0.8462 | Eval Log. Respected : 0.9314
     Batch 000 | Loss : 0.2612 | Acc : 0.8787
     Batch 025 | Loss : 0.3578 | Acc : 0.8349
     Batch 050 | Loss : 0.2738 | Acc : 0.8756
     Batch 075 | Loss : 0.3129 | Acc : 0.8534
     Batch 100 | Loss : 0.2679 | Acc : 0.8797
     Batch 125 | Loss : 0.3139 | Acc : 0.8526
     Batch 150 | Loss : 0.2670 | Acc : 0.8792
     Batch 175 | Loss : 0.4440 | Acc : 0.8021
     Batch 200 | Loss : 0.2558 | Acc : 0.8834
     Batch 225 | Loss : 0.2563 | Acc : 0.8872
     Batch 250 | Loss : 0.2852 | Acc : 0.8669
     Batch 275 | Loss : 0.3357 | Acc : 0.8410
     Batch 300 | Loss : 0.3245 | Acc : 0.8517
Epoch 00070 | Train Loss : 0.3169 | Eval Loss : 0.3322 | Train acc : 0.8532 | Eval Acc : 0.8465 | Eval Log. Respected : 0.9268
     Batch 000 | Loss : 0.3189 | Acc : 0.8497
     Batch 025 | Loss : 0.3496 | Acc : 0.8376
     Batch 050 | Loss : 0.2515 | Acc : 0.8871
     Batch 075 | Loss : 0.2547 | Acc : 0.8827
     Batch 100 | Loss : 0.2687 | Acc : 0.8830
     Batch 125 | Loss : 0.3204 | Acc : 0.8525
     Batch 150 | Loss : 0.3198 | Acc : 0.8556
     Batch 175 | Loss : 0.4046 | Acc : 0.8087
     Batch 200 | Loss : 0.2991 | Acc : 0.8654
     Batch 225 | Loss : 0.3466 | Acc : 0.8335
     Batch 250 | Loss : 0.3635 | Acc : 0.8231
     Batch 275 | Loss : 0.2762 | Acc : 0.8705
     Batch 300 | Loss : 0.3083 | Acc : 0.8558
Epoch 00071 | Train Loss : 0.3176 | Eval Loss : 0.3341 | Train acc : 0.8531 | Eval Acc : 0.8443 | Eval Log. Respected : 0.9358
     Batch 000 | Loss : 0.3086 | Acc : 0.8509
     Batch 025 | Loss : 0.3422 | Acc : 0.8388
     Batch 050 | Loss : 0.2504 | Acc : 0.8928
     Batch 075 | Loss : 0.3152 | Acc : 0.8485
     Batch 100 | Loss : 0.3293 | Acc : 0.8373
     Batch 125 | Loss : 0.3235 | Acc : 0.8508
     Batch 150 | Loss : 0.2772 | Acc : 0.8720
     Batch 175 | Loss : 0.3585 | Acc : 0.8302
     Batch 200 | Loss : 0.3696 | Acc : 0.8260
     Batch 225 | Loss : 0.3364 | Acc : 0.8446
     Batch 250 | Loss : 0.2742 | Acc : 0.8714
     Batch 275 | Loss : 0.3261 | Acc : 0.8451
     Batch 300 | Loss : 0.2907 | Acc : 0.8675
Epoch 00072 | Train Loss : 0.3171 | Eval Loss : 0.3274 | Train acc : 0.8530 | Eval Acc : 0.8467 | Eval Log. Respected : 0.9394
     Batch 000 | Loss : 0.2642 | Acc : 0.8821
     Batch 025 | Loss : 0.2722 | Acc : 0.8721
     Batch 050 | Loss : 0.3203 | Acc : 0.8528
     Batch 075 | Loss : 0.3401 | Acc : 0.8384
     Batch 100 | Loss : 0.4131 | Acc : 0.8020
     Batch 125 | Loss : 0.2910 | Acc : 0.8659
     Batch 150 | Loss : 0.3504 | Acc : 0.8292
     Batch 175 | Loss : 0.3544 | Acc : 0.8332
     Batch 200 | Loss : 0.3027 | Acc : 0.8627
     Batch 225 | Loss : 0.3040 | Acc : 0.8581
     Batch 250 | Loss : 0.3521 | Acc : 0.8335
     Batch 275 | Loss : 0.3369 | Acc : 0.8395
     Batch 300 | Loss : 0.2850 | Acc : 0.8712
Epoch 00073 | Train Loss : 0.3172 | Eval Loss : 0.3294 | Train acc : 0.8531 | Eval Acc : 0.8466 | Eval Log. Respected : 0.9364
     Batch 000 | Loss : 0.3282 | Acc : 0.8477
     Batch 025 | Loss : 0.2669 | Acc : 0.8745
     Batch 050 | Loss : 0.2781 | Acc : 0.8779
     Batch 075 | Loss : 0.3070 | Acc : 0.8571
     Batch 100 | Loss : 0.2710 | Acc : 0.8815
     Batch 125 | Loss : 0.3250 | Acc : 0.8452
     Batch 150 | Loss : 0.2676 | Acc : 0.8775
     Batch 175 | Loss : 0.2697 | Acc : 0.8812
     Batch 200 | Loss : 0.3157 | Acc : 0.8514
     Batch 225 | Loss : 0.2774 | Acc : 0.8751
     Batch 250 | Loss : 0.2781 | Acc : 0.8743
     Batch 275 | Loss : 0.2915 | Acc : 0.8658
     Batch 300 | Loss : 0.2712 | Acc : 0.8772
Epoch 00074 | Train Loss : 0.3164 | Eval Loss : 0.3344 | Train acc : 0.8533 | Eval Acc : 0.8437 | Eval Log. Respected : 0.9247
Early Stopping
Testing...
Test Loss 0.5879 | Test Acc 0.8435 | Test Log. Res. 0.9251
