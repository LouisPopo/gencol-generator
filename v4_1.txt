cuda is available
USING : cuda
Done loading data from cached files.
Training ...
     Batch 000 | Loss : 0.6934 | Acc : 0.4880
     Batch 025 | Loss : 0.6914 | Acc : 0.5114
     Batch 050 | Loss : 0.5950 | Acc : 0.7399
     Batch 075 | Loss : 0.5184 | Acc : 0.7601
     Batch 100 | Loss : 0.4947 | Acc : 0.7642
     Batch 125 | Loss : 0.4542 | Acc : 0.7794
     Batch 150 | Loss : 0.4575 | Acc : 0.7796
     Batch 175 | Loss : 0.3760 | Acc : 0.8290
     Batch 200 | Loss : 0.4095 | Acc : 0.8044
     Batch 225 | Loss : 0.3541 | Acc : 0.8518
     Batch 250 | Loss : 0.3755 | Acc : 0.8220
     Batch 275 | Loss : 0.4490 | Acc : 0.7790
     Batch 300 | Loss : 0.3770 | Acc : 0.8245
Epoch 00000 | Train Loss : 0.4805 | Eval Loss : 0.4110 | Train acc : 0.7549 | Eval Acc : 0.8032 | Eval Log. Respected : 0.9971
     Batch 000 | Loss : 0.3494 | Acc : 0.8404
     Batch 025 | Loss : 0.4710 | Acc : 0.7840
     Batch 050 | Loss : 0.4063 | Acc : 0.8033
     Batch 075 | Loss : 0.5125 | Acc : 0.7650
     Batch 100 | Loss : 0.3907 | Acc : 0.8148
     Batch 125 | Loss : 0.3795 | Acc : 0.8161
     Batch 150 | Loss : 0.4018 | Acc : 0.8139
     Batch 175 | Loss : 0.4374 | Acc : 0.7903
     Batch 200 | Loss : 0.4387 | Acc : 0.7838
     Batch 225 | Loss : 0.4845 | Acc : 0.7595
     Batch 250 | Loss : 0.3522 | Acc : 0.8405
     Batch 275 | Loss : 0.3352 | Acc : 0.8530
     Batch 300 | Loss : 0.3970 | Acc : 0.8167
Epoch 00001 | Train Loss : 0.4061 | Eval Loss : 0.3934 | Train acc : 0.8079 | Eval Acc : 0.8121 | Eval Log. Respected : 0.9739
     Batch 000 | Loss : 0.3643 | Acc : 0.8400
     Batch 025 | Loss : 0.5060 | Acc : 0.7746
     Batch 050 | Loss : 0.3783 | Acc : 0.8177
     Batch 075 | Loss : 0.5240 | Acc : 0.7601
     Batch 100 | Loss : 0.3645 | Acc : 0.8293
     Batch 125 | Loss : 0.4349 | Acc : 0.7834
     Batch 150 | Loss : 0.3857 | Acc : 0.8183
     Batch 175 | Loss : 0.3541 | Acc : 0.8306
     Batch 200 | Loss : 0.3416 | Acc : 0.8473
     Batch 225 | Loss : 0.3656 | Acc : 0.8241
     Batch 250 | Loss : 0.3698 | Acc : 0.8300
     Batch 275 | Loss : 0.3193 | Acc : 0.8591
     Batch 300 | Loss : 0.4047 | Acc : 0.8057
Epoch 00002 | Train Loss : 0.3846 | Eval Loss : 0.3852 | Train acc : 0.8191 | Eval Acc : 0.8167 | Eval Log. Respected : 0.9705
     Batch 000 | Loss : 0.4850 | Acc : 0.7637
     Batch 025 | Loss : 0.3335 | Acc : 0.8480
     Batch 050 | Loss : 0.3034 | Acc : 0.8662
     Batch 075 | Loss : 0.3030 | Acc : 0.8655
     Batch 100 | Loss : 0.3589 | Acc : 0.8297
     Batch 125 | Loss : 0.3056 | Acc : 0.8571
     Batch 150 | Loss : 0.3594 | Acc : 0.8346
     Batch 175 | Loss : 0.4397 | Acc : 0.7940
     Batch 200 | Loss : 0.3771 | Acc : 0.8278
     Batch 225 | Loss : 0.3120 | Acc : 0.8607
     Batch 250 | Loss : 0.4114 | Acc : 0.7979
     Batch 275 | Loss : 0.3671 | Acc : 0.8303
     Batch 300 | Loss : 0.3729 | Acc : 0.8228
Epoch 00003 | Train Loss : 0.3732 | Eval Loss : 0.3497 | Train acc : 0.8278 | Eval Acc : 0.8363 | Eval Log. Respected : 0.9656
     Batch 000 | Loss : 0.3830 | Acc : 0.8208
     Batch 025 | Loss : 0.4538 | Acc : 0.7745
     Batch 050 | Loss : 0.3993 | Acc : 0.8090
     Batch 075 | Loss : 0.4208 | Acc : 0.7950
     Batch 100 | Loss : 0.3741 | Acc : 0.8337
     Batch 125 | Loss : 0.3096 | Acc : 0.8635
     Batch 150 | Loss : 0.5167 | Acc : 0.7657
     Batch 175 | Loss : 0.2885 | Acc : 0.8711
     Batch 200 | Loss : 0.4218 | Acc : 0.8006
     Batch 225 | Loss : 0.3443 | Acc : 0.8395
     Batch 250 | Loss : 0.3478 | Acc : 0.8469
     Batch 275 | Loss : 0.4299 | Acc : 0.7989
     Batch 300 | Loss : 0.4594 | Acc : 0.7858
Epoch 00004 | Train Loss : 0.3657 | Eval Loss : 0.3685 | Train acc : 0.8321 | Eval Acc : 0.8290 | Eval Log. Respected : 0.9459
     Batch 000 | Loss : 0.3394 | Acc : 0.8433
     Batch 025 | Loss : 0.3871 | Acc : 0.8148
     Batch 050 | Loss : 0.4337 | Acc : 0.7940
     Batch 075 | Loss : 0.3914 | Acc : 0.8168
     Batch 100 | Loss : 0.2904 | Acc : 0.8722
     Batch 125 | Loss : 0.3760 | Acc : 0.8254
     Batch 150 | Loss : 0.2786 | Acc : 0.8824
     Batch 175 | Loss : 0.2845 | Acc : 0.8736
     Batch 200 | Loss : 0.3250 | Acc : 0.8594
     Batch 225 | Loss : 0.3634 | Acc : 0.8313
     Batch 250 | Loss : 0.3440 | Acc : 0.8401
     Batch 275 | Loss : 0.3015 | Acc : 0.8598
     Batch 300 | Loss : 0.3716 | Acc : 0.8227
Epoch 00005 | Train Loss : 0.3588 | Eval Loss : 0.3461 | Train acc : 0.8356 | Eval Acc : 0.8373 | Eval Log. Respected : 0.9387
     Batch 000 | Loss : 0.3409 | Acc : 0.8394
     Batch 025 | Loss : 0.3190 | Acc : 0.8600
     Batch 050 | Loss : 0.3429 | Acc : 0.8401
     Batch 075 | Loss : 0.3226 | Acc : 0.8548
     Batch 100 | Loss : 0.3111 | Acc : 0.8671
     Batch 125 | Loss : 0.3018 | Acc : 0.8618
     Batch 150 | Loss : 0.3141 | Acc : 0.8593
     Batch 175 | Loss : 0.5021 | Acc : 0.7727
     Batch 200 | Loss : 0.3722 | Acc : 0.8343
     Batch 225 | Loss : 0.3910 | Acc : 0.8098
     Batch 250 | Loss : 0.3611 | Acc : 0.8302
     Batch 275 | Loss : 0.4279 | Acc : 0.7889
     Batch 300 | Loss : 0.4006 | Acc : 0.8105
Epoch 00006 | Train Loss : 0.3534 | Eval Loss : 0.3610 | Train acc : 0.8372 | Eval Acc : 0.8384 | Eval Log. Respected : 0.9451
     Batch 000 | Loss : 0.3417 | Acc : 0.8498
     Batch 025 | Loss : 0.3731 | Acc : 0.8243
     Batch 050 | Loss : 0.3878 | Acc : 0.8262
     Batch 075 | Loss : 0.3190 | Acc : 0.8515
     Batch 100 | Loss : 0.3220 | Acc : 0.8641
     Batch 125 | Loss : 0.3035 | Acc : 0.8638
     Batch 150 | Loss : 0.4365 | Acc : 0.8028
     Batch 175 | Loss : 0.3382 | Acc : 0.8419
     Batch 200 | Loss : 0.2898 | Acc : 0.8703
     Batch 225 | Loss : 0.3152 | Acc : 0.8623
     Batch 250 | Loss : 0.3933 | Acc : 0.8134
     Batch 275 | Loss : 0.3740 | Acc : 0.8206
     Batch 300 | Loss : 0.3491 | Acc : 0.8405
Epoch 00007 | Train Loss : 0.3501 | Eval Loss : 0.3357 | Train acc : 0.8390 | Eval Acc : 0.8431 | Eval Log. Respected : 0.9261
     Batch 000 | Loss : 0.3346 | Acc : 0.8463
     Batch 025 | Loss : 0.3709 | Acc : 0.8248
     Batch 050 | Loss : 0.3819 | Acc : 0.8152
     Batch 075 | Loss : 0.3763 | Acc : 0.8219
     Batch 100 | Loss : 0.3113 | Acc : 0.8526
     Batch 125 | Loss : 0.2811 | Acc : 0.8777
     Batch 150 | Loss : 0.3989 | Acc : 0.8119
     Batch 175 | Loss : 0.3588 | Acc : 0.8306
     Batch 200 | Loss : 0.2998 | Acc : 0.8636
     Batch 225 | Loss : 0.3566 | Acc : 0.8357
     Batch 250 | Loss : 0.3422 | Acc : 0.8413
     Batch 275 | Loss : 0.4517 | Acc : 0.7816
     Batch 300 | Loss : 0.2962 | Acc : 0.8676
Epoch 00008 | Train Loss : 0.3440 | Eval Loss : 0.3333 | Train acc : 0.8414 | Eval Acc : 0.8435 | Eval Log. Respected : 0.9417
     Batch 000 | Loss : 0.2921 | Acc : 0.8708
     Batch 025 | Loss : 0.3128 | Acc : 0.8532
     Batch 050 | Loss : 0.3616 | Acc : 0.8356
     Batch 075 | Loss : 0.3290 | Acc : 0.8526
     Batch 100 | Loss : 0.3694 | Acc : 0.8281
     Batch 125 | Loss : 0.3788 | Acc : 0.8190
     Batch 150 | Loss : 0.3498 | Acc : 0.8428
     Batch 175 | Loss : 0.4411 | Acc : 0.7910
     Batch 200 | Loss : 0.3717 | Acc : 0.8230
     Batch 225 | Loss : 0.4289 | Acc : 0.7958
     Batch 250 | Loss : 0.3700 | Acc : 0.8235
     Batch 275 | Loss : 0.2827 | Acc : 0.8768
     Batch 300 | Loss : 0.4307 | Acc : 0.7836
Epoch 00009 | Train Loss : 0.3427 | Eval Loss : 0.3308 | Train acc : 0.8419 | Eval Acc : 0.8440 | Eval Log. Respected : 0.9373
     Batch 000 | Loss : 0.3440 | Acc : 0.8469
     Batch 025 | Loss : 0.4132 | Acc : 0.8156
     Batch 050 | Loss : 0.3217 | Acc : 0.8499
     Batch 075 | Loss : 0.4215 | Acc : 0.7938
     Batch 100 | Loss : 0.3387 | Acc : 0.8432
     Batch 125 | Loss : 0.3635 | Acc : 0.8237
     Batch 150 | Loss : 0.4046 | Acc : 0.8191
     Batch 175 | Loss : 0.3045 | Acc : 0.8660
     Batch 200 | Loss : 0.3037 | Acc : 0.8678
     Batch 225 | Loss : 0.2870 | Acc : 0.8697
     Batch 250 | Loss : 0.3041 | Acc : 0.8630
     Batch 275 | Loss : 0.2977 | Acc : 0.8690
     Batch 300 | Loss : 0.2976 | Acc : 0.8722
Epoch 00010 | Train Loss : 0.3436 | Eval Loss : 0.3332 | Train acc : 0.8420 | Eval Acc : 0.8432 | Eval Log. Respected : 0.9236
     Batch 000 | Loss : 0.3506 | Acc : 0.8363
     Batch 025 | Loss : 0.3425 | Acc : 0.8447
     Batch 050 | Loss : 0.3395 | Acc : 0.8419
     Batch 075 | Loss : 0.3072 | Acc : 0.8615
     Batch 100 | Loss : 0.3115 | Acc : 0.8556
     Batch 125 | Loss : 0.3440 | Acc : 0.8403
     Batch 150 | Loss : 0.2855 | Acc : 0.8701
     Batch 175 | Loss : 0.3580 | Acc : 0.8265
     Batch 200 | Loss : 0.3171 | Acc : 0.8524
     Batch 225 | Loss : 0.3570 | Acc : 0.8297
     Batch 250 | Loss : 0.2849 | Acc : 0.8696
     Batch 275 | Loss : 0.3476 | Acc : 0.8386
     Batch 300 | Loss : 0.2953 | Acc : 0.8724
Epoch 00011 | Train Loss : 0.3405 | Eval Loss : 0.3240 | Train acc : 0.8428 | Eval Acc : 0.8485 | Eval Log. Respected : 0.9295
     Batch 000 | Loss : 0.4167 | Acc : 0.8103
     Batch 025 | Loss : 0.3156 | Acc : 0.8561
     Batch 050 | Loss : 0.3171 | Acc : 0.8516
     Batch 075 | Loss : 0.4013 | Acc : 0.8154
     Batch 100 | Loss : 0.3101 | Acc : 0.8565
     Batch 125 | Loss : 0.3136 | Acc : 0.8599
     Batch 150 | Loss : 0.3594 | Acc : 0.8321
     Batch 175 | Loss : 0.3440 | Acc : 0.8355
     Batch 200 | Loss : 0.2958 | Acc : 0.8642
     Batch 225 | Loss : 0.3844 | Acc : 0.8224
     Batch 250 | Loss : 0.3901 | Acc : 0.8158
     Batch 275 | Loss : 0.3011 | Acc : 0.8619
     Batch 300 | Loss : 0.2864 | Acc : 0.8688
Epoch 00012 | Train Loss : 0.3393 | Eval Loss : 0.3345 | Train acc : 0.8439 | Eval Acc : 0.8458 | Eval Log. Respected : 0.9178
     Batch 000 | Loss : 0.3742 | Acc : 0.8350
     Batch 025 | Loss : 0.3625 | Acc : 0.8250
     Batch 050 | Loss : 0.3375 | Acc : 0.8481
     Batch 075 | Loss : 0.2895 | Acc : 0.8741
     Batch 100 | Loss : 0.2802 | Acc : 0.8755
     Batch 125 | Loss : 0.3334 | Acc : 0.8512
     Batch 150 | Loss : 0.2974 | Acc : 0.8667
     Batch 175 | Loss : 0.2954 | Acc : 0.8695
     Batch 200 | Loss : 0.3095 | Acc : 0.8576
     Batch 225 | Loss : 0.4096 | Acc : 0.8158
     Batch 250 | Loss : 0.4406 | Acc : 0.7891
     Batch 275 | Loss : 0.3344 | Acc : 0.8424
     Batch 300 | Loss : 0.3434 | Acc : 0.8390
Epoch 00013 | Train Loss : 0.3355 | Eval Loss : 0.3257 | Train acc : 0.8453 | Eval Acc : 0.8476 | Eval Log. Respected : 0.9261
     Batch 000 | Loss : 0.3003 | Acc : 0.8631
     Batch 025 | Loss : 0.3245 | Acc : 0.8485
     Batch 050 | Loss : 0.3613 | Acc : 0.8265
     Batch 075 | Loss : 0.2894 | Acc : 0.8682
     Batch 100 | Loss : 0.2784 | Acc : 0.8842
     Batch 125 | Loss : 0.3640 | Acc : 0.8291
     Batch 150 | Loss : 0.3011 | Acc : 0.8626
     Batch 175 | Loss : 0.3721 | Acc : 0.8228
     Batch 200 | Loss : 0.3857 | Acc : 0.8240
     Batch 225 | Loss : 0.3313 | Acc : 0.8464
     Batch 250 | Loss : 0.3612 | Acc : 0.8285
     Batch 275 | Loss : 0.2927 | Acc : 0.8673
     Batch 300 | Loss : 0.3643 | Acc : 0.8211
Epoch 00014 | Train Loss : 0.3347 | Eval Loss : 0.3288 | Train acc : 0.8456 | Eval Acc : 0.8476 | Eval Log. Respected : 0.9257
     Batch 000 | Loss : 0.3936 | Acc : 0.8260
     Batch 025 | Loss : 0.2940 | Acc : 0.8735
     Batch 050 | Loss : 0.3005 | Acc : 0.8639
     Batch 075 | Loss : 0.2996 | Acc : 0.8648
     Batch 100 | Loss : 0.3333 | Acc : 0.8476
     Batch 125 | Loss : 0.3135 | Acc : 0.8525
     Batch 150 | Loss : 0.3589 | Acc : 0.8469
     Batch 175 | Loss : 0.3422 | Acc : 0.8445
     Batch 200 | Loss : 0.3089 | Acc : 0.8573
     Batch 225 | Loss : 0.3428 | Acc : 0.8405
     Batch 250 | Loss : 0.3938 | Acc : 0.8204
     Batch 275 | Loss : 0.2788 | Acc : 0.8789
     Batch 300 | Loss : 0.2725 | Acc : 0.8793
Epoch 00015 | Train Loss : 0.3347 | Eval Loss : 0.3304 | Train acc : 0.8459 | Eval Acc : 0.8445 | Eval Log. Respected : 0.9195
     Batch 000 | Loss : 0.3210 | Acc : 0.8539
     Batch 025 | Loss : 0.3760 | Acc : 0.8221
     Batch 050 | Loss : 0.2924 | Acc : 0.8657
     Batch 075 | Loss : 0.3617 | Acc : 0.8322
     Batch 100 | Loss : 0.2950 | Acc : 0.8673
     Batch 125 | Loss : 0.3956 | Acc : 0.8155
     Batch 150 | Loss : 0.3455 | Acc : 0.8341
     Batch 175 | Loss : 0.4648 | Acc : 0.7942
     Batch 200 | Loss : 0.3966 | Acc : 0.8084
     Batch 225 | Loss : 0.3140 | Acc : 0.8556
     Batch 250 | Loss : 0.2952 | Acc : 0.8698
     Batch 275 | Loss : 0.3106 | Acc : 0.8595
     Batch 300 | Loss : 0.5474 | Acc : 0.7682
Epoch 00016 | Train Loss : 0.3343 | Eval Loss : 0.3364 | Train acc : 0.8458 | Eval Acc : 0.8435 | Eval Log. Respected : 0.9172
     Batch 000 | Loss : 0.3351 | Acc : 0.8508
     Batch 025 | Loss : 0.3516 | Acc : 0.8340
     Batch 050 | Loss : 0.2564 | Acc : 0.8846
     Batch 075 | Loss : 0.3247 | Acc : 0.8558
     Batch 100 | Loss : 0.3805 | Acc : 0.8202
     Batch 125 | Loss : 0.3797 | Acc : 0.8178
     Batch 150 | Loss : 0.3430 | Acc : 0.8423
     Batch 175 | Loss : 0.3412 | Acc : 0.8404
     Batch 200 | Loss : 0.3758 | Acc : 0.8325
     Batch 225 | Loss : 0.2943 | Acc : 0.8681
     Batch 250 | Loss : 0.3511 | Acc : 0.8329
     Batch 275 | Loss : 0.3726 | Acc : 0.8270
     Batch 300 | Loss : 0.3269 | Acc : 0.8544
Epoch 00017 | Train Loss : 0.3346 | Eval Loss : 0.3269 | Train acc : 0.8461 | Eval Acc : 0.8455 | Eval Log. Respected : 0.9142
     Batch 000 | Loss : 0.3291 | Acc : 0.8507
     Batch 025 | Loss : 0.3072 | Acc : 0.8585
     Batch 050 | Loss : 0.2924 | Acc : 0.8666
     Batch 075 | Loss : 0.3393 | Acc : 0.8417
     Batch 100 | Loss : 0.3234 | Acc : 0.8481
     Batch 125 | Loss : 0.2886 | Acc : 0.8704
     Batch 150 | Loss : 0.2567 | Acc : 0.8849
     Batch 175 | Loss : 0.3174 | Acc : 0.8531
     Batch 200 | Loss : 0.3648 | Acc : 0.8238
     Batch 225 | Loss : 0.2745 | Acc : 0.8835
     Batch 250 | Loss : 0.3421 | Acc : 0.8418
     Batch 275 | Loss : 0.3070 | Acc : 0.8573
     Batch 300 | Loss : 0.3502 | Acc : 0.8386
Epoch 00018 | Train Loss : 0.3315 | Eval Loss : 0.3194 | Train acc : 0.8470 | Eval Acc : 0.8499 | Eval Log. Respected : 0.9231
     Batch 000 | Loss : 0.3505 | Acc : 0.8330
     Batch 025 | Loss : 0.2754 | Acc : 0.8802
     Batch 050 | Loss : 0.2858 | Acc : 0.8721
     Batch 075 | Loss : 0.3216 | Acc : 0.8472
     Batch 100 | Loss : 0.2648 | Acc : 0.8798
     Batch 125 | Loss : 0.3106 | Acc : 0.8593
     Batch 150 | Loss : 0.2964 | Acc : 0.8635
     Batch 175 | Loss : 0.2778 | Acc : 0.8736
     Batch 200 | Loss : 0.3374 | Acc : 0.8515
     Batch 225 | Loss : 0.3794 | Acc : 0.8180
     Batch 250 | Loss : 0.3056 | Acc : 0.8603
     Batch 275 | Loss : 0.4484 | Acc : 0.7998
     Batch 300 | Loss : 0.2857 | Acc : 0.8764
Epoch 00019 | Train Loss : 0.3301 | Eval Loss : 0.3222 | Train acc : 0.8474 | Eval Acc : 0.8486 | Eval Log. Respected : 0.9257
     Batch 000 | Loss : 0.2517 | Acc : 0.8883
     Batch 025 | Loss : 0.3705 | Acc : 0.8228
     Batch 050 | Loss : 0.2893 | Acc : 0.8694
     Batch 075 | Loss : 0.3185 | Acc : 0.8497
     Batch 100 | Loss : 0.3242 | Acc : 0.8436
     Batch 125 | Loss : 0.3084 | Acc : 0.8570
     Batch 150 | Loss : 0.4113 | Acc : 0.8103
     Batch 175 | Loss : 0.2821 | Acc : 0.8734
     Batch 200 | Loss : 0.3420 | Acc : 0.8355
     Batch 225 | Loss : 0.3242 | Acc : 0.8610
     Batch 250 | Loss : 0.3844 | Acc : 0.8171
     Batch 275 | Loss : 0.4010 | Acc : 0.8012
     Batch 300 | Loss : 0.3372 | Acc : 0.8439
Epoch 00020 | Train Loss : 0.3301 | Eval Loss : 0.3203 | Train acc : 0.8476 | Eval Acc : 0.8485 | Eval Log. Respected : 0.9224
     Batch 000 | Loss : 0.3333 | Acc : 0.8393
     Batch 025 | Loss : 0.3352 | Acc : 0.8437
     Batch 050 | Loss : 0.3200 | Acc : 0.8520
     Batch 075 | Loss : 0.3285 | Acc : 0.8485
     Batch 100 | Loss : 0.2910 | Acc : 0.8715
     Batch 125 | Loss : 0.3083 | Acc : 0.8605
     Batch 150 | Loss : 0.3047 | Acc : 0.8580
     Batch 175 | Loss : 0.2652 | Acc : 0.8836
     Batch 200 | Loss : 0.3015 | Acc : 0.8657
     Batch 225 | Loss : 0.3633 | Acc : 0.8308
     Batch 250 | Loss : 0.3715 | Acc : 0.8249
     Batch 275 | Loss : 0.3406 | Acc : 0.8451
     Batch 300 | Loss : 0.2926 | Acc : 0.8689
Epoch 00021 | Train Loss : 0.3304 | Eval Loss : 0.3203 | Train acc : 0.8476 | Eval Acc : 0.8504 | Eval Log. Respected : 0.9180
     Batch 000 | Loss : 0.3452 | Acc : 0.8391
     Batch 025 | Loss : 0.3129 | Acc : 0.8577
     Batch 050 | Loss : 0.3015 | Acc : 0.8667
     Batch 075 | Loss : 0.4682 | Acc : 0.7710
     Batch 100 | Loss : 0.3410 | Acc : 0.8434
     Batch 125 | Loss : 0.3225 | Acc : 0.8489
     Batch 150 | Loss : 0.2941 | Acc : 0.8724
     Batch 175 | Loss : 0.3548 | Acc : 0.8381
     Batch 200 | Loss : 0.3417 | Acc : 0.8378
     Batch 225 | Loss : 0.3404 | Acc : 0.8362
     Batch 250 | Loss : 0.2642 | Acc : 0.8846
     Batch 275 | Loss : 0.3008 | Acc : 0.8599
     Batch 300 | Loss : 0.2667 | Acc : 0.8787
Epoch 00022 | Train Loss : 0.3297 | Eval Loss : 0.3222 | Train acc : 0.8479 | Eval Acc : 0.8483 | Eval Log. Respected : 0.9277
     Batch 000 | Loss : 0.3910 | Acc : 0.8106
     Batch 025 | Loss : 0.2796 | Acc : 0.8685
     Batch 050 | Loss : 0.4168 | Acc : 0.8167
     Batch 075 | Loss : 0.2981 | Acc : 0.8630
     Batch 100 | Loss : 0.3621 | Acc : 0.8271
     Batch 125 | Loss : 0.3342 | Acc : 0.8483
     Batch 150 | Loss : 0.2707 | Acc : 0.8800
     Batch 175 | Loss : 0.3295 | Acc : 0.8425
     Batch 200 | Loss : 0.2965 | Acc : 0.8671
     Batch 225 | Loss : 0.4161 | Acc : 0.7947
     Batch 250 | Loss : 0.3231 | Acc : 0.8531
     Batch 275 | Loss : 0.2830 | Acc : 0.8688
     Batch 300 | Loss : 0.3362 | Acc : 0.8436
Epoch 00023 | Train Loss : 0.3279 | Eval Loss : 0.3216 | Train acc : 0.8485 | Eval Acc : 0.8490 | Eval Log. Respected : 0.9196
     Batch 000 | Loss : 0.3015 | Acc : 0.8605
     Batch 025 | Loss : 0.3568 | Acc : 0.8315
     Batch 050 | Loss : 0.3080 | Acc : 0.8564
     Batch 075 | Loss : 0.2999 | Acc : 0.8624
     Batch 100 | Loss : 0.2883 | Acc : 0.8688
     Batch 125 | Loss : 0.2709 | Acc : 0.8837
     Batch 150 | Loss : 0.4185 | Acc : 0.8055
     Batch 175 | Loss : 0.3741 | Acc : 0.8201
     Batch 200 | Loss : 0.3744 | Acc : 0.8252
     Batch 225 | Loss : 0.2605 | Acc : 0.8864
     Batch 250 | Loss : 0.2931 | Acc : 0.8686
     Batch 275 | Loss : 0.3036 | Acc : 0.8555
     Batch 300 | Loss : 0.2815 | Acc : 0.8779
Epoch 00024 | Train Loss : 0.3275 | Eval Loss : 0.3232 | Train acc : 0.8489 | Eval Acc : 0.8477 | Eval Log. Respected : 0.9173
     Batch 000 | Loss : 0.4221 | Acc : 0.8015
     Batch 025 | Loss : 0.5128 | Acc : 0.7807
     Batch 050 | Loss : 0.2938 | Acc : 0.8698
     Batch 075 | Loss : 0.2521 | Acc : 0.8915
     Batch 100 | Loss : 0.3719 | Acc : 0.8274
     Batch 125 | Loss : 0.3711 | Acc : 0.8252
     Batch 150 | Loss : 0.3001 | Acc : 0.8663
     Batch 175 | Loss : 0.3264 | Acc : 0.8504
     Batch 200 | Loss : 0.3621 | Acc : 0.8259
     Batch 225 | Loss : 0.2990 | Acc : 0.8647
     Batch 250 | Loss : 0.2913 | Acc : 0.8678
     Batch 275 | Loss : 0.3065 | Acc : 0.8546
     Batch 300 | Loss : 0.2627 | Acc : 0.8836
Epoch 00025 | Train Loss : 0.3280 | Eval Loss : 0.3241 | Train acc : 0.8486 | Eval Acc : 0.8471 | Eval Log. Respected : 0.9118
     Batch 000 | Loss : 0.3286 | Acc : 0.8426
     Batch 025 | Loss : 0.3863 | Acc : 0.8220
     Batch 050 | Loss : 0.3251 | Acc : 0.8503
     Batch 075 | Loss : 0.2755 | Acc : 0.8801
     Batch 100 | Loss : 0.2742 | Acc : 0.8758
     Batch 125 | Loss : 0.3666 | Acc : 0.8351
     Batch 150 | Loss : 0.3729 | Acc : 0.8283
     Batch 175 | Loss : 0.2933 | Acc : 0.8690
     Batch 200 | Loss : 0.3128 | Acc : 0.8526
     Batch 225 | Loss : 0.2864 | Acc : 0.8708
     Batch 250 | Loss : 0.3254 | Acc : 0.8513
     Batch 275 | Loss : 0.3601 | Acc : 0.8314
     Batch 300 | Loss : 0.3710 | Acc : 0.8239
Epoch 00026 | Train Loss : 0.3260 | Eval Loss : 0.3307 | Train acc : 0.8492 | Eval Acc : 0.8439 | Eval Log. Respected : 0.9234
     Batch 000 | Loss : 0.3239 | Acc : 0.8554
     Batch 025 | Loss : 0.2774 | Acc : 0.8777
     Batch 050 | Loss : 0.2812 | Acc : 0.8732
     Batch 075 | Loss : 0.2651 | Acc : 0.8804
     Batch 100 | Loss : 0.4594 | Acc : 0.8155
     Batch 125 | Loss : 0.2883 | Acc : 0.8701
     Batch 150 | Loss : 0.3393 | Acc : 0.8354
     Batch 175 | Loss : 0.2914 | Acc : 0.8671
     Batch 200 | Loss : 0.3221 | Acc : 0.8492
     Batch 225 | Loss : 0.4123 | Acc : 0.8009
     Batch 250 | Loss : 0.2819 | Acc : 0.8703
     Batch 275 | Loss : 0.3926 | Acc : 0.8110
     Batch 300 | Loss : 0.3439 | Acc : 0.8409
Epoch 00027 | Train Loss : 0.3271 | Eval Loss : 0.3160 | Train acc : 0.8491 | Eval Acc : 0.8513 | Eval Log. Respected : 0.9235
     Batch 000 | Loss : 0.2895 | Acc : 0.8679
     Batch 025 | Loss : 0.3763 | Acc : 0.8239
     Batch 050 | Loss : 0.3833 | Acc : 0.8176
     Batch 075 | Loss : 0.3884 | Acc : 0.8266
     Batch 100 | Loss : 0.2850 | Acc : 0.8722
     Batch 125 | Loss : 0.3009 | Acc : 0.8629
     Batch 150 | Loss : 0.2684 | Acc : 0.8770
     Batch 175 | Loss : 0.3290 | Acc : 0.8475
     Batch 200 | Loss : 0.3077 | Acc : 0.8560
     Batch 225 | Loss : 0.3526 | Acc : 0.8313
     Batch 250 | Loss : 0.3462 | Acc : 0.8352
     Batch 275 | Loss : 0.3269 | Acc : 0.8511
     Batch 300 | Loss : 0.2893 | Acc : 0.8665
Epoch 00028 | Train Loss : 0.3260 | Eval Loss : 0.3142 | Train acc : 0.8495 | Eval Acc : 0.8524 | Eval Log. Respected : 0.9288
     Batch 000 | Loss : 0.3058 | Acc : 0.8579
     Batch 025 | Loss : 0.3356 | Acc : 0.8466
     Batch 050 | Loss : 0.2839 | Acc : 0.8731
     Batch 075 | Loss : 0.3488 | Acc : 0.8335
     Batch 100 | Loss : 0.3071 | Acc : 0.8586
     Batch 125 | Loss : 0.3309 | Acc : 0.8445
     Batch 150 | Loss : 0.2973 | Acc : 0.8704
     Batch 175 | Loss : 0.2925 | Acc : 0.8668
     Batch 200 | Loss : 0.4037 | Acc : 0.8169
     Batch 225 | Loss : 0.2798 | Acc : 0.8692
     Batch 250 | Loss : 0.2562 | Acc : 0.8859
     Batch 275 | Loss : 0.5439 | Acc : 0.7675
     Batch 300 | Loss : 0.2722 | Acc : 0.8722
Epoch 00029 | Train Loss : 0.3265 | Eval Loss : 0.3202 | Train acc : 0.8494 | Eval Acc : 0.8492 | Eval Log. Respected : 0.9330
     Batch 000 | Loss : 0.2706 | Acc : 0.8751
     Batch 025 | Loss : 0.2783 | Acc : 0.8731
     Batch 050 | Loss : 0.4528 | Acc : 0.7959
     Batch 075 | Loss : 0.2878 | Acc : 0.8661
     Batch 100 | Loss : 0.3650 | Acc : 0.8358
     Batch 125 | Loss : 0.2890 | Acc : 0.8715
     Batch 150 | Loss : 0.2760 | Acc : 0.8777
     Batch 175 | Loss : 0.2588 | Acc : 0.8843
     Batch 200 | Loss : 0.3941 | Acc : 0.8181
     Batch 225 | Loss : 0.2806 | Acc : 0.8787
     Batch 250 | Loss : 0.2836 | Acc : 0.8714
     Batch 275 | Loss : 0.3198 | Acc : 0.8513
     Batch 300 | Loss : 0.2740 | Acc : 0.8749
Epoch 00030 | Train Loss : 0.3254 | Eval Loss : 0.3219 | Train acc : 0.8497 | Eval Acc : 0.8493 | Eval Log. Respected : 0.9247
     Batch 000 | Loss : 0.3267 | Acc : 0.8521
     Batch 025 | Loss : 0.2878 | Acc : 0.8711
     Batch 050 | Loss : 0.2381 | Acc : 0.8958
     Batch 075 | Loss : 0.2705 | Acc : 0.8764
     Batch 100 | Loss : 0.2889 | Acc : 0.8692
     Batch 125 | Loss : 0.3125 | Acc : 0.8567
     Batch 150 | Loss : 0.2811 | Acc : 0.8755
     Batch 175 | Loss : 0.3180 | Acc : 0.8496
     Batch 200 | Loss : 0.3299 | Acc : 0.8482
     Batch 225 | Loss : 0.3456 | Acc : 0.8349
     Batch 250 | Loss : 0.3448 | Acc : 0.8416
     Batch 275 | Loss : 0.4386 | Acc : 0.7931
     Batch 300 | Loss : 0.3184 | Acc : 0.8508
Epoch 00031 | Train Loss : 0.3239 | Eval Loss : 0.3315 | Train acc : 0.8503 | Eval Acc : 0.8457 | Eval Log. Respected : 0.9246
     Batch 000 | Loss : 0.3061 | Acc : 0.8667
     Batch 025 | Loss : 0.3079 | Acc : 0.8597
     Batch 050 | Loss : 0.3531 | Acc : 0.8305
     Batch 075 | Loss : 0.3384 | Acc : 0.8392
     Batch 100 | Loss : 0.3661 | Acc : 0.8282
     Batch 125 | Loss : 0.3508 | Acc : 0.8355
     Batch 150 | Loss : 0.3492 | Acc : 0.8401
     Batch 175 | Loss : 0.4148 | Acc : 0.8123
     Batch 200 | Loss : 0.3490 | Acc : 0.8348
     Batch 225 | Loss : 0.3777 | Acc : 0.8173
     Batch 250 | Loss : 0.3029 | Acc : 0.8619
     Batch 275 | Loss : 0.3695 | Acc : 0.8210
     Batch 300 | Loss : 0.3122 | Acc : 0.8552
Epoch 00032 | Train Loss : 0.3243 | Eval Loss : 0.3284 | Train acc : 0.8502 | Eval Acc : 0.8459 | Eval Log. Respected : 0.9323
     Batch 000 | Loss : 0.3034 | Acc : 0.8603
     Batch 025 | Loss : 0.2444 | Acc : 0.8946
     Batch 050 | Loss : 0.3030 | Acc : 0.8675
     Batch 075 | Loss : 0.2955 | Acc : 0.8644
     Batch 100 | Loss : 0.2765 | Acc : 0.8720
     Batch 125 | Loss : 0.2651 | Acc : 0.8787
     Batch 150 | Loss : 0.2872 | Acc : 0.8725
     Batch 175 | Loss : 0.4242 | Acc : 0.8034
     Batch 200 | Loss : 0.2890 | Acc : 0.8666
     Batch 225 | Loss : 0.3028 | Acc : 0.8574
     Batch 250 | Loss : 0.3485 | Acc : 0.8416
     Batch 275 | Loss : 0.3174 | Acc : 0.8477
     Batch 300 | Loss : 0.3021 | Acc : 0.8602
Epoch 00033 | Train Loss : 0.3239 | Eval Loss : 0.3243 | Train acc : 0.8505 | Eval Acc : 0.8496 | Eval Log. Respected : 0.9262
     Batch 000 | Loss : 0.2640 | Acc : 0.8814
     Batch 025 | Loss : 0.3276 | Acc : 0.8415
     Batch 050 | Loss : 0.2903 | Acc : 0.8722
     Batch 075 | Loss : 0.3752 | Acc : 0.8220
     Batch 100 | Loss : 0.2662 | Acc : 0.8801
     Batch 125 | Loss : 0.2713 | Acc : 0.8722
     Batch 150 | Loss : 0.2987 | Acc : 0.8653
     Batch 175 | Loss : 0.2944 | Acc : 0.8680
     Batch 200 | Loss : 0.3792 | Acc : 0.8291
     Batch 225 | Loss : 0.3557 | Acc : 0.8359
     Batch 250 | Loss : 0.2697 | Acc : 0.8774
     Batch 275 | Loss : 0.3241 | Acc : 0.8540
     Batch 300 | Loss : 0.2802 | Acc : 0.8691
Epoch 00034 | Train Loss : 0.3235 | Eval Loss : 0.3220 | Train acc : 0.8506 | Eval Acc : 0.8516 | Eval Log. Respected : 0.9268
     Batch 000 | Loss : 0.3086 | Acc : 0.8638
     Batch 025 | Loss : 0.3523 | Acc : 0.8332
     Batch 050 | Loss : 0.3009 | Acc : 0.8593
     Batch 075 | Loss : 0.2815 | Acc : 0.8696
     Batch 100 | Loss : 0.2832 | Acc : 0.8783
     Batch 125 | Loss : 0.3743 | Acc : 0.8255
     Batch 150 | Loss : 0.2714 | Acc : 0.8793
     Batch 175 | Loss : 0.2784 | Acc : 0.8728
     Batch 200 | Loss : 0.2976 | Acc : 0.8661
     Batch 225 | Loss : 0.3731 | Acc : 0.8187
     Batch 250 | Loss : 0.3436 | Acc : 0.8357
     Batch 275 | Loss : 0.2860 | Acc : 0.8716
     Batch 300 | Loss : 0.3704 | Acc : 0.8272
Epoch 00035 | Train Loss : 0.3236 | Eval Loss : 0.3149 | Train acc : 0.8507 | Eval Acc : 0.8522 | Eval Log. Respected : 0.9346
     Batch 000 | Loss : 0.2878 | Acc : 0.8644
     Batch 025 | Loss : 0.3192 | Acc : 0.8500
     Batch 050 | Loss : 0.2961 | Acc : 0.8598
     Batch 075 | Loss : 0.2896 | Acc : 0.8662
     Batch 100 | Loss : 0.3352 | Acc : 0.8412
     Batch 125 | Loss : 0.3420 | Acc : 0.8350
     Batch 150 | Loss : 0.3734 | Acc : 0.8272
     Batch 175 | Loss : 0.2668 | Acc : 0.8813
     Batch 200 | Loss : 0.2987 | Acc : 0.8625
     Batch 225 | Loss : 0.3155 | Acc : 0.8525
     Batch 250 | Loss : 0.2812 | Acc : 0.8719
     Batch 275 | Loss : 0.3485 | Acc : 0.8405
     Batch 300 | Loss : 0.3537 | Acc : 0.8339
Epoch 00036 | Train Loss : 0.3222 | Eval Loss : 0.3291 | Train acc : 0.8511 | Eval Acc : 0.8449 | Eval Log. Respected : 0.9262
     Batch 000 | Loss : 0.3528 | Acc : 0.8291
     Batch 025 | Loss : 0.3566 | Acc : 0.8316
     Batch 050 | Loss : 0.3675 | Acc : 0.8255
     Batch 075 | Loss : 0.3217 | Acc : 0.8475
     Batch 100 | Loss : 0.2571 | Acc : 0.8843
     Batch 125 | Loss : 0.2607 | Acc : 0.8849
     Batch 150 | Loss : 0.3047 | Acc : 0.8619
     Batch 175 | Loss : 0.3434 | Acc : 0.8394
     Batch 200 | Loss : 0.2778 | Acc : 0.8779
     Batch 225 | Loss : 0.2602 | Acc : 0.8818
     Batch 250 | Loss : 0.3533 | Acc : 0.8295
     Batch 275 | Loss : 0.2736 | Acc : 0.8788
     Batch 300 | Loss : 0.3032 | Acc : 0.8582
Epoch 00037 | Train Loss : 0.3222 | Eval Loss : 0.3200 | Train acc : 0.8510 | Eval Acc : 0.8500 | Eval Log. Respected : 0.9281
     Batch 000 | Loss : 0.3509 | Acc : 0.8328
     Batch 025 | Loss : 0.3438 | Acc : 0.8357
     Batch 050 | Loss : 0.3349 | Acc : 0.8460
     Batch 075 | Loss : 0.2826 | Acc : 0.8748
     Batch 100 | Loss : 0.2974 | Acc : 0.8613
     Batch 125 | Loss : 0.5014 | Acc : 0.7630
     Batch 150 | Loss : 0.2964 | Acc : 0.8685
     Batch 175 | Loss : 0.2776 | Acc : 0.8695
     Batch 200 | Loss : 0.2999 | Acc : 0.8649
     Batch 225 | Loss : 0.2779 | Acc : 0.8729
     Batch 250 | Loss : 0.2873 | Acc : 0.8651
     Batch 275 | Loss : 0.2951 | Acc : 0.8638
     Batch 300 | Loss : 0.2545 | Acc : 0.8857
Epoch 00038 | Train Loss : 0.3221 | Eval Loss : 0.3164 | Train acc : 0.8512 | Eval Acc : 0.8507 | Eval Log. Respected : 0.9311
Early Stopping
Testing...
Test Loss 0.5873 | Test Acc 0.8352 | Test Log. Res. 0.9349
