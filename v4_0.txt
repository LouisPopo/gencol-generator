cuda is available
USING : cuda
Done loading data from cached files.
Training ...
     Batch 000 | Loss : 0.6954 | Acc : 0.5146
     Batch 025 | Loss : 0.6923 | Acc : 0.5118
     Batch 050 | Loss : 0.6283 | Acc : 0.6685
     Batch 075 | Loss : 0.5137 | Acc : 0.8034
     Batch 100 | Loss : 0.4145 | Acc : 0.8000
     Batch 125 | Loss : 0.4328 | Acc : 0.7988
     Batch 150 | Loss : 0.4219 | Acc : 0.7981
     Batch 175 | Loss : 0.3451 | Acc : 0.8449
     Batch 200 | Loss : 0.3810 | Acc : 0.8237
     Batch 225 | Loss : 0.5562 | Acc : 0.7453
     Batch 250 | Loss : 0.4082 | Acc : 0.7961
     Batch 275 | Loss : 0.5497 | Acc : 0.7448
     Batch 300 | Loss : 0.4368 | Acc : 0.7909
Epoch 00000 | Train Loss : 0.4756 | Eval Loss : 0.3865 | Train acc : 0.7583 | Eval Acc : 0.8177 | Eval Log. Respected : 0.9877
     Batch 000 | Loss : 0.4667 | Acc : 0.7839
     Batch 025 | Loss : 0.3593 | Acc : 0.8407
     Batch 050 | Loss : 0.3697 | Acc : 0.8190
     Batch 075 | Loss : 0.4630 | Acc : 0.7834
     Batch 100 | Loss : 0.3520 | Acc : 0.8409
     Batch 125 | Loss : 0.3273 | Acc : 0.8553
     Batch 150 | Loss : 0.3081 | Acc : 0.8648
     Batch 175 | Loss : 0.4223 | Acc : 0.7985
     Batch 200 | Loss : 0.3826 | Acc : 0.8239
     Batch 225 | Loss : 0.3954 | Acc : 0.8154
     Batch 250 | Loss : 0.3221 | Acc : 0.8500
     Batch 275 | Loss : 0.3558 | Acc : 0.8311
     Batch 300 | Loss : 0.3983 | Acc : 0.8071
Epoch 00001 | Train Loss : 0.3791 | Eval Loss : 0.3729 | Train acc : 0.8236 | Eval Acc : 0.8249 | Eval Log. Respected : 0.9641
     Batch 000 | Loss : 0.4370 | Acc : 0.7833
     Batch 025 | Loss : 0.4225 | Acc : 0.7966
     Batch 050 | Loss : 0.3695 | Acc : 0.8247
     Batch 075 | Loss : 0.3695 | Acc : 0.8221
     Batch 100 | Loss : 0.4123 | Acc : 0.8099
     Batch 125 | Loss : 0.3220 | Acc : 0.8546
     Batch 150 | Loss : 0.3930 | Acc : 0.8079
     Batch 175 | Loss : 0.3425 | Acc : 0.8372
     Batch 200 | Loss : 0.3595 | Acc : 0.8317
     Batch 225 | Loss : 0.4006 | Acc : 0.8151
     Batch 250 | Loss : 0.3492 | Acc : 0.8563
     Batch 275 | Loss : 0.3118 | Acc : 0.8574
     Batch 300 | Loss : 0.3083 | Acc : 0.8610
Epoch 00002 | Train Loss : 0.3621 | Eval Loss : 0.3907 | Train acc : 0.8326 | Eval Acc : 0.8085 | Eval Log. Respected : 0.9369
     Batch 000 | Loss : 0.3946 | Acc : 0.8087
     Batch 025 | Loss : 0.3059 | Acc : 0.8632
     Batch 050 | Loss : 0.3355 | Acc : 0.8446
     Batch 075 | Loss : 0.3247 | Acc : 0.8542
     Batch 100 | Loss : 0.4058 | Acc : 0.8118
     Batch 125 | Loss : 0.3259 | Acc : 0.8505
     Batch 150 | Loss : 0.3063 | Acc : 0.8579
     Batch 175 | Loss : 0.3428 | Acc : 0.8606
     Batch 200 | Loss : 0.2921 | Acc : 0.8684
     Batch 225 | Loss : 0.3351 | Acc : 0.8452
     Batch 250 | Loss : 0.3974 | Acc : 0.8194
     Batch 275 | Loss : 0.3406 | Acc : 0.8423
     Batch 300 | Loss : 0.3742 | Acc : 0.8204
Epoch 00003 | Train Loss : 0.3567 | Eval Loss : 0.3704 | Train acc : 0.8352 | Eval Acc : 0.8221 | Eval Log. Respected : 0.9495
     Batch 000 | Loss : 0.3438 | Acc : 0.8378
     Batch 025 | Loss : 0.3385 | Acc : 0.8410
     Batch 050 | Loss : 0.3159 | Acc : 0.8585
     Batch 075 | Loss : 0.3040 | Acc : 0.8624
     Batch 100 | Loss : 0.3920 | Acc : 0.8212
     Batch 125 | Loss : 0.2718 | Acc : 0.8825
     Batch 150 | Loss : 0.3236 | Acc : 0.8516
     Batch 175 | Loss : 0.3520 | Acc : 0.8327
     Batch 200 | Loss : 0.3520 | Acc : 0.8352
     Batch 225 | Loss : 0.3350 | Acc : 0.8478
     Batch 250 | Loss : 0.3449 | Acc : 0.8389
     Batch 275 | Loss : 0.3201 | Acc : 0.8546
     Batch 300 | Loss : 0.2896 | Acc : 0.8721
Epoch 00004 | Train Loss : 0.3544 | Eval Loss : 0.3480 | Train acc : 0.8366 | Eval Acc : 0.8348 | Eval Log. Respected : 0.9378
     Batch 000 | Loss : 0.4170 | Acc : 0.7966
     Batch 025 | Loss : 0.3494 | Acc : 0.8369
     Batch 050 | Loss : 0.3380 | Acc : 0.8408
     Batch 075 | Loss : 0.4221 | Acc : 0.8140
     Batch 100 | Loss : 0.3634 | Acc : 0.8255
     Batch 125 | Loss : 0.3374 | Acc : 0.8490
     Batch 150 | Loss : 0.3461 | Acc : 0.8343
     Batch 175 | Loss : 0.3175 | Acc : 0.8582
     Batch 200 | Loss : 0.3328 | Acc : 0.8503
     Batch 225 | Loss : 0.5023 | Acc : 0.7925
     Batch 250 | Loss : 0.3412 | Acc : 0.8333
     Batch 275 | Loss : 0.4113 | Acc : 0.8043
     Batch 300 | Loss : 0.3709 | Acc : 0.8293
Epoch 00005 | Train Loss : 0.3477 | Eval Loss : 0.3441 | Train acc : 0.8394 | Eval Acc : 0.8392 | Eval Log. Respected : 0.9157
     Batch 000 | Loss : 0.3091 | Acc : 0.8573
     Batch 025 | Loss : 0.3279 | Acc : 0.8515
     Batch 050 | Loss : 0.3740 | Acc : 0.8332
     Batch 075 | Loss : 0.3521 | Acc : 0.8363
     Batch 100 | Loss : 0.2817 | Acc : 0.8730
     Batch 125 | Loss : 0.3115 | Acc : 0.8562
     Batch 150 | Loss : 0.4645 | Acc : 0.7892
     Batch 175 | Loss : 0.3022 | Acc : 0.8623
     Batch 200 | Loss : 0.3552 | Acc : 0.8347
     Batch 225 | Loss : 0.4139 | Acc : 0.7927
     Batch 250 | Loss : 0.3974 | Acc : 0.8092
     Batch 275 | Loss : 0.3713 | Acc : 0.8299
     Batch 300 | Loss : 0.3493 | Acc : 0.8360
Epoch 00006 | Train Loss : 0.3467 | Eval Loss : 0.3384 | Train acc : 0.8402 | Eval Acc : 0.8440 | Eval Log. Respected : 0.9247
     Batch 000 | Loss : 0.4021 | Acc : 0.8115
     Batch 025 | Loss : 0.3728 | Acc : 0.8274
     Batch 050 | Loss : 0.3224 | Acc : 0.8464
     Batch 075 | Loss : 0.2953 | Acc : 0.8705
     Batch 100 | Loss : 0.3383 | Acc : 0.8427
     Batch 125 | Loss : 0.3334 | Acc : 0.8460
     Batch 150 | Loss : 0.3516 | Acc : 0.8356
     Batch 175 | Loss : 0.2996 | Acc : 0.8645
     Batch 200 | Loss : 0.4095 | Acc : 0.8013
     Batch 225 | Loss : 0.2841 | Acc : 0.8696
     Batch 250 | Loss : 0.3511 | Acc : 0.8383
     Batch 275 | Loss : 0.3188 | Acc : 0.8561
     Batch 300 | Loss : 0.2860 | Acc : 0.8766
Epoch 00007 | Train Loss : 0.3418 | Eval Loss : 0.3484 | Train acc : 0.8424 | Eval Acc : 0.8378 | Eval Log. Respected : 0.9004
     Batch 000 | Loss : 0.3086 | Acc : 0.8537
     Batch 025 | Loss : 0.3552 | Acc : 0.8355
     Batch 050 | Loss : 0.3423 | Acc : 0.8408
     Batch 075 | Loss : 0.3941 | Acc : 0.8213
     Batch 100 | Loss : 0.3035 | Acc : 0.8659
     Batch 125 | Loss : 0.4460 | Acc : 0.7881
     Batch 150 | Loss : 0.3870 | Acc : 0.8099
     Batch 175 | Loss : 0.3134 | Acc : 0.8544
     Batch 200 | Loss : 0.3362 | Acc : 0.8501
     Batch 225 | Loss : 0.4606 | Acc : 0.7850
     Batch 250 | Loss : 0.3572 | Acc : 0.8328
     Batch 275 | Loss : 0.3203 | Acc : 0.8519
     Batch 300 | Loss : 0.3880 | Acc : 0.8271
Epoch 00008 | Train Loss : 0.3430 | Eval Loss : 0.3412 | Train acc : 0.8415 | Eval Acc : 0.8410 | Eval Log. Respected : 0.9302
     Batch 000 | Loss : 0.3062 | Acc : 0.8597
     Batch 025 | Loss : 0.3803 | Acc : 0.8184
     Batch 050 | Loss : 0.3015 | Acc : 0.8683
     Batch 075 | Loss : 0.3025 | Acc : 0.8659
     Batch 100 | Loss : 0.3013 | Acc : 0.8664
     Batch 125 | Loss : 0.3043 | Acc : 0.8660
     Batch 150 | Loss : 0.3545 | Acc : 0.8289
     Batch 175 | Loss : 0.3161 | Acc : 0.8589
     Batch 200 | Loss : 0.3524 | Acc : 0.8323
     Batch 225 | Loss : 0.3307 | Acc : 0.8540
     Batch 250 | Loss : 0.3949 | Acc : 0.8004
     Batch 275 | Loss : 0.3315 | Acc : 0.8443
     Batch 300 | Loss : 0.3060 | Acc : 0.8580
Epoch 00009 | Train Loss : 0.3401 | Eval Loss : 0.3494 | Train acc : 0.8434 | Eval Acc : 0.8376 | Eval Log. Respected : 0.9076
     Batch 000 | Loss : 0.3779 | Acc : 0.8229
     Batch 025 | Loss : 0.2860 | Acc : 0.8702
     Batch 050 | Loss : 0.3365 | Acc : 0.8446
     Batch 075 | Loss : 0.3226 | Acc : 0.8544
     Batch 100 | Loss : 0.5683 | Acc : 0.7477
     Batch 125 | Loss : 0.3286 | Acc : 0.8451
     Batch 150 | Loss : 0.3518 | Acc : 0.8334
     Batch 175 | Loss : 0.2988 | Acc : 0.8652
     Batch 200 | Loss : 0.3043 | Acc : 0.8679
     Batch 225 | Loss : 0.3400 | Acc : 0.8398
     Batch 250 | Loss : 0.4477 | Acc : 0.7975
     Batch 275 | Loss : 0.3198 | Acc : 0.8644
     Batch 300 | Loss : 0.3286 | Acc : 0.8581
Epoch 00010 | Train Loss : 0.3392 | Eval Loss : 0.3364 | Train acc : 0.8439 | Eval Acc : 0.8418 | Eval Log. Respected : 0.9214
     Batch 000 | Loss : 0.2872 | Acc : 0.8737
     Batch 025 | Loss : 0.2877 | Acc : 0.8689
     Batch 050 | Loss : 0.2922 | Acc : 0.8697
     Batch 075 | Loss : 0.3587 | Acc : 0.8309
     Batch 100 | Loss : 0.3168 | Acc : 0.8567
     Batch 125 | Loss : 0.3626 | Acc : 0.8296
     Batch 150 | Loss : 0.3204 | Acc : 0.8565
     Batch 175 | Loss : 0.3180 | Acc : 0.8549
     Batch 200 | Loss : 0.4612 | Acc : 0.7792
     Batch 225 | Loss : 0.3170 | Acc : 0.8538
     Batch 250 | Loss : 0.3411 | Acc : 0.8401
     Batch 275 | Loss : 0.2813 | Acc : 0.8740
     Batch 300 | Loss : 0.2966 | Acc : 0.8661
Epoch 00011 | Train Loss : 0.3377 | Eval Loss : 0.3366 | Train acc : 0.8445 | Eval Acc : 0.8436 | Eval Log. Respected : 0.9132
     Batch 000 | Loss : 0.3119 | Acc : 0.8540
     Batch 025 | Loss : 0.3128 | Acc : 0.8542
     Batch 050 | Loss : 0.3021 | Acc : 0.8593
     Batch 075 | Loss : 0.2953 | Acc : 0.8688
     Batch 100 | Loss : 0.3403 | Acc : 0.8434
     Batch 125 | Loss : 0.3651 | Acc : 0.8360
     Batch 150 | Loss : 0.3081 | Acc : 0.8624
     Batch 175 | Loss : 0.3237 | Acc : 0.8476
     Batch 200 | Loss : 0.3642 | Acc : 0.8288
     Batch 225 | Loss : 0.3106 | Acc : 0.8628
     Batch 250 | Loss : 0.3668 | Acc : 0.8360
     Batch 275 | Loss : 0.3048 | Acc : 0.8631
     Batch 300 | Loss : 0.3132 | Acc : 0.8603
Epoch 00012 | Train Loss : 0.3348 | Eval Loss : 0.3347 | Train acc : 0.8457 | Eval Acc : 0.8445 | Eval Log. Respected : 0.9253
     Batch 000 | Loss : 0.2643 | Acc : 0.8833
     Batch 025 | Loss : 0.3150 | Acc : 0.8565
     Batch 050 | Loss : 0.2826 | Acc : 0.8780
     Batch 075 | Loss : 0.3224 | Acc : 0.8557
     Batch 100 | Loss : 0.3200 | Acc : 0.8545
     Batch 125 | Loss : 0.2867 | Acc : 0.8706
     Batch 150 | Loss : 0.3059 | Acc : 0.8571
     Batch 175 | Loss : 0.4432 | Acc : 0.8027
     Batch 200 | Loss : 0.3018 | Acc : 0.8602
     Batch 225 | Loss : 0.3675 | Acc : 0.8338
     Batch 250 | Loss : 0.3063 | Acc : 0.8642
     Batch 275 | Loss : 0.4016 | Acc : 0.8197
     Batch 300 | Loss : 0.3625 | Acc : 0.8338
Epoch 00013 | Train Loss : 0.3344 | Eval Loss : 0.3295 | Train acc : 0.8462 | Eval Acc : 0.8447 | Eval Log. Respected : 0.9217
     Batch 000 | Loss : 0.2970 | Acc : 0.8656
     Batch 025 | Loss : 0.2925 | Acc : 0.8747
     Batch 050 | Loss : 0.2760 | Acc : 0.8773
     Batch 075 | Loss : 0.3044 | Acc : 0.8611
     Batch 100 | Loss : 0.2729 | Acc : 0.8765
     Batch 125 | Loss : 0.3185 | Acc : 0.8540
     Batch 150 | Loss : 0.3223 | Acc : 0.8561
     Batch 175 | Loss : 0.4079 | Acc : 0.8032
     Batch 200 | Loss : 0.3576 | Acc : 0.8358
     Batch 225 | Loss : 0.2677 | Acc : 0.8809
     Batch 250 | Loss : 0.3872 | Acc : 0.8283
     Batch 275 | Loss : 0.4194 | Acc : 0.7962
     Batch 300 | Loss : 0.3430 | Acc : 0.8392
Epoch 00014 | Train Loss : 0.3347 | Eval Loss : 0.3328 | Train acc : 0.8460 | Eval Acc : 0.8453 | Eval Log. Respected : 0.9164
     Batch 000 | Loss : 0.3025 | Acc : 0.8611
     Batch 025 | Loss : 0.2888 | Acc : 0.8786
     Batch 050 | Loss : 0.3382 | Acc : 0.8431
     Batch 075 | Loss : 0.3942 | Acc : 0.7987
     Batch 100 | Loss : 0.3030 | Acc : 0.8588
     Batch 125 | Loss : 0.3694 | Acc : 0.8254
     Batch 150 | Loss : 0.3026 | Acc : 0.8697
     Batch 175 | Loss : 0.3217 | Acc : 0.8544
     Batch 200 | Loss : 0.2708 | Acc : 0.8746
     Batch 225 | Loss : 0.2822 | Acc : 0.8756
     Batch 250 | Loss : 0.3019 | Acc : 0.8619
     Batch 275 | Loss : 0.3056 | Acc : 0.8606
     Batch 300 | Loss : 0.3993 | Acc : 0.8073
Epoch 00015 | Train Loss : 0.3326 | Eval Loss : 0.3319 | Train acc : 0.8466 | Eval Acc : 0.8453 | Eval Log. Respected : 0.9079
     Batch 000 | Loss : 0.2924 | Acc : 0.8668
     Batch 025 | Loss : 0.2884 | Acc : 0.8731
     Batch 050 | Loss : 0.3582 | Acc : 0.8275
     Batch 075 | Loss : 0.3549 | Acc : 0.8284
     Batch 100 | Loss : 0.3092 | Acc : 0.8568
     Batch 125 | Loss : 0.3452 | Acc : 0.8356
     Batch 150 | Loss : 0.2557 | Acc : 0.8903
     Batch 175 | Loss : 0.2679 | Acc : 0.8840
     Batch 200 | Loss : 0.3739 | Acc : 0.8239
     Batch 225 | Loss : 0.3371 | Acc : 0.8432
     Batch 250 | Loss : 0.4292 | Acc : 0.7979
     Batch 275 | Loss : 0.2928 | Acc : 0.8705
     Batch 300 | Loss : 0.5227 | Acc : 0.7591
Epoch 00016 | Train Loss : 0.3335 | Eval Loss : 0.3310 | Train acc : 0.8463 | Eval Acc : 0.8453 | Eval Log. Respected : 0.9234
     Batch 000 | Loss : 0.3671 | Acc : 0.8226
     Batch 025 | Loss : 0.3243 | Acc : 0.8568
     Batch 050 | Loss : 0.3035 | Acc : 0.8600
     Batch 075 | Loss : 0.3674 | Acc : 0.8357
     Batch 100 | Loss : 0.3379 | Acc : 0.8411
     Batch 125 | Loss : 0.3024 | Acc : 0.8722
     Batch 150 | Loss : 0.2863 | Acc : 0.8737
     Batch 175 | Loss : 0.3532 | Acc : 0.8421
     Batch 200 | Loss : 0.3404 | Acc : 0.8425
     Batch 225 | Loss : 0.3348 | Acc : 0.8461
     Batch 250 | Loss : 0.3074 | Acc : 0.8531
     Batch 275 | Loss : 0.3565 | Acc : 0.8329
     Batch 300 | Loss : 0.2772 | Acc : 0.8713
Epoch 00017 | Train Loss : 0.3313 | Eval Loss : 0.3337 | Train acc : 0.8473 | Eval Acc : 0.8442 | Eval Log. Respected : 0.9238
     Batch 000 | Loss : 0.2929 | Acc : 0.8661
     Batch 025 | Loss : 0.3231 | Acc : 0.8553
     Batch 050 | Loss : 0.3092 | Acc : 0.8573
     Batch 075 | Loss : 0.2923 | Acc : 0.8629
     Batch 100 | Loss : 0.3484 | Acc : 0.8297
     Batch 125 | Loss : 0.2955 | Acc : 0.8699
     Batch 150 | Loss : 0.3154 | Acc : 0.8515
     Batch 175 | Loss : 0.3542 | Acc : 0.8358
     Batch 200 | Loss : 0.3165 | Acc : 0.8562
     Batch 225 | Loss : 0.2757 | Acc : 0.8758
     Batch 250 | Loss : 0.4260 | Acc : 0.8045
     Batch 275 | Loss : 0.3311 | Acc : 0.8442
     Batch 300 | Loss : 0.3420 | Acc : 0.8415
Epoch 00018 | Train Loss : 0.3295 | Eval Loss : 0.3268 | Train acc : 0.8477 | Eval Acc : 0.8469 | Eval Log. Respected : 0.9196
     Batch 000 | Loss : 0.2752 | Acc : 0.8762
     Batch 025 | Loss : 0.3002 | Acc : 0.8647
     Batch 050 | Loss : 0.2867 | Acc : 0.8667
     Batch 075 | Loss : 0.2658 | Acc : 0.8820
     Batch 100 | Loss : 0.2769 | Acc : 0.8779
     Batch 125 | Loss : 0.2873 | Acc : 0.8638
     Batch 150 | Loss : 0.3300 | Acc : 0.8393
     Batch 175 | Loss : 0.3959 | Acc : 0.8181
     Batch 200 | Loss : 0.3688 | Acc : 0.8306
     Batch 225 | Loss : 0.2742 | Acc : 0.8800
     Batch 250 | Loss : 0.3737 | Acc : 0.8216
     Batch 275 | Loss : 0.2543 | Acc : 0.8868
     Batch 300 | Loss : 0.3628 | Acc : 0.8307
Epoch 00019 | Train Loss : 0.3293 | Eval Loss : 0.3325 | Train acc : 0.8483 | Eval Acc : 0.8444 | Eval Log. Respected : 0.9183
     Batch 000 | Loss : 0.3189 | Acc : 0.8505
     Batch 025 | Loss : 0.2716 | Acc : 0.8768
     Batch 050 | Loss : 0.3040 | Acc : 0.8640
     Batch 075 | Loss : 0.3307 | Acc : 0.8455
     Batch 100 | Loss : 0.2651 | Acc : 0.8814
     Batch 125 | Loss : 0.3503 | Acc : 0.8413
     Batch 150 | Loss : 0.3161 | Acc : 0.8548
     Batch 175 | Loss : 0.3308 | Acc : 0.8458
     Batch 200 | Loss : 0.2946 | Acc : 0.8701
     Batch 225 | Loss : 0.3403 | Acc : 0.8434
     Batch 250 | Loss : 0.3617 | Acc : 0.8278
     Batch 275 | Loss : 0.2807 | Acc : 0.8779
     Batch 300 | Loss : 0.2825 | Acc : 0.8662
Epoch 00020 | Train Loss : 0.3300 | Eval Loss : 0.3266 | Train acc : 0.8478 | Eval Acc : 0.8477 | Eval Log. Respected : 0.9365
     Batch 000 | Loss : 0.2768 | Acc : 0.8744
     Batch 025 | Loss : 0.3455 | Acc : 0.8391
     Batch 050 | Loss : 0.3228 | Acc : 0.8512
     Batch 075 | Loss : 0.3044 | Acc : 0.8597
     Batch 100 | Loss : 0.3354 | Acc : 0.8398
     Batch 125 | Loss : 0.3464 | Acc : 0.8316
     Batch 150 | Loss : 0.3252 | Acc : 0.8517
     Batch 175 | Loss : 0.3199 | Acc : 0.8475
     Batch 200 | Loss : 0.2874 | Acc : 0.8700
     Batch 225 | Loss : 0.3031 | Acc : 0.8674
     Batch 250 | Loss : 0.2766 | Acc : 0.8764
     Batch 275 | Loss : 0.3513 | Acc : 0.8339
     Batch 300 | Loss : 0.3116 | Acc : 0.8601
Epoch 00021 | Train Loss : 0.3282 | Eval Loss : 0.3365 | Train acc : 0.8487 | Eval Acc : 0.8453 | Eval Log. Respected : 0.9358
     Batch 000 | Loss : 0.3322 | Acc : 0.8414
     Batch 025 | Loss : 0.3094 | Acc : 0.8602
     Batch 050 | Loss : 0.3630 | Acc : 0.8265
     Batch 075 | Loss : 0.3143 | Acc : 0.8604
     Batch 100 | Loss : 0.3266 | Acc : 0.8486
     Batch 125 | Loss : 0.2968 | Acc : 0.8711
     Batch 150 | Loss : 0.2703 | Acc : 0.8780
     Batch 175 | Loss : 0.3595 | Acc : 0.8259
     Batch 200 | Loss : 0.2947 | Acc : 0.8668
     Batch 225 | Loss : 0.3354 | Acc : 0.8442
     Batch 250 | Loss : 0.4026 | Acc : 0.8123
     Batch 275 | Loss : 0.3149 | Acc : 0.8628
     Batch 300 | Loss : 0.3459 | Acc : 0.8411
Epoch 00022 | Train Loss : 0.3279 | Eval Loss : 0.3345 | Train acc : 0.8488 | Eval Acc : 0.8422 | Eval Log. Respected : 0.9086
     Batch 000 | Loss : 0.3655 | Acc : 0.8235
     Batch 025 | Loss : 0.3594 | Acc : 0.8312
     Batch 050 | Loss : 0.2911 | Acc : 0.8631
     Batch 075 | Loss : 0.3367 | Acc : 0.8409
     Batch 100 | Loss : 0.3801 | Acc : 0.8273
     Batch 125 | Loss : 0.2986 | Acc : 0.8647
     Batch 150 | Loss : 0.3626 | Acc : 0.8302
     Batch 175 | Loss : 0.2730 | Acc : 0.8795
     Batch 200 | Loss : 0.5364 | Acc : 0.7613
     Batch 225 | Loss : 0.2842 | Acc : 0.8704
     Batch 250 | Loss : 0.3101 | Acc : 0.8606
     Batch 275 | Loss : 0.3444 | Acc : 0.8340
     Batch 300 | Loss : 0.3001 | Acc : 0.8649
Epoch 00023 | Train Loss : 0.3279 | Eval Loss : 0.3265 | Train acc : 0.8488 | Eval Acc : 0.8490 | Eval Log. Respected : 0.9220
     Batch 000 | Loss : 0.3593 | Acc : 0.8343
     Batch 025 | Loss : 0.2847 | Acc : 0.8718
     Batch 050 | Loss : 0.2786 | Acc : 0.8747
     Batch 075 | Loss : 0.2597 | Acc : 0.8872
     Batch 100 | Loss : 0.3394 | Acc : 0.8361
     Batch 125 | Loss : 0.3075 | Acc : 0.8630
     Batch 150 | Loss : 0.2797 | Acc : 0.8742
     Batch 175 | Loss : 0.3575 | Acc : 0.8305
     Batch 200 | Loss : 0.3155 | Acc : 0.8531
     Batch 225 | Loss : 0.3080 | Acc : 0.8588
     Batch 250 | Loss : 0.2960 | Acc : 0.8663
     Batch 275 | Loss : 0.3039 | Acc : 0.8656
     Batch 300 | Loss : 0.3106 | Acc : 0.8546
Epoch 00024 | Train Loss : 0.3264 | Eval Loss : 0.3262 | Train acc : 0.8494 | Eval Acc : 0.8464 | Eval Log. Respected : 0.9241
     Batch 000 | Loss : 0.2740 | Acc : 0.8819
     Batch 025 | Loss : 0.3936 | Acc : 0.8084
     Batch 050 | Loss : 0.3845 | Acc : 0.8210
     Batch 075 | Loss : 0.3674 | Acc : 0.8251
     Batch 100 | Loss : 0.3079 | Acc : 0.8549
     Batch 125 | Loss : 0.2859 | Acc : 0.8739
     Batch 150 | Loss : 0.2859 | Acc : 0.8716
     Batch 175 | Loss : 0.3344 | Acc : 0.8481
     Batch 200 | Loss : 0.3238 | Acc : 0.8509
     Batch 225 | Loss : 0.3689 | Acc : 0.8255
     Batch 250 | Loss : 0.3966 | Acc : 0.8147
     Batch 275 | Loss : 0.2870 | Acc : 0.8685
     Batch 300 | Loss : 0.2951 | Acc : 0.8615
Epoch 00025 | Train Loss : 0.3254 | Eval Loss : 0.3240 | Train acc : 0.8497 | Eval Acc : 0.8482 | Eval Log. Respected : 0.9240
     Batch 000 | Loss : 0.2686 | Acc : 0.8796
     Batch 025 | Loss : 0.3749 | Acc : 0.8198
     Batch 050 | Loss : 0.3304 | Acc : 0.8431
     Batch 075 | Loss : 0.3069 | Acc : 0.8551
     Batch 100 | Loss : 0.3389 | Acc : 0.8355
     Batch 125 | Loss : 0.3370 | Acc : 0.8343
     Batch 150 | Loss : 0.3530 | Acc : 0.8346
     Batch 175 | Loss : 0.3375 | Acc : 0.8497
     Batch 200 | Loss : 0.2929 | Acc : 0.8652
     Batch 225 | Loss : 0.3190 | Acc : 0.8500
     Batch 250 | Loss : 0.2809 | Acc : 0.8735
     Batch 275 | Loss : 0.2980 | Acc : 0.8645
     Batch 300 | Loss : 0.2642 | Acc : 0.8849
Epoch 00026 | Train Loss : 0.3251 | Eval Loss : 0.3341 | Train acc : 0.8500 | Eval Acc : 0.8425 | Eval Log. Respected : 0.9352
     Batch 000 | Loss : 0.2713 | Acc : 0.8855
     Batch 025 | Loss : 0.2994 | Acc : 0.8603
     Batch 050 | Loss : 0.3379 | Acc : 0.8383
     Batch 075 | Loss : 0.3780 | Acc : 0.8173
     Batch 100 | Loss : 0.3597 | Acc : 0.8305
     Batch 125 | Loss : 0.3334 | Acc : 0.8421
     Batch 150 | Loss : 0.2623 | Acc : 0.8830
     Batch 175 | Loss : 0.3366 | Acc : 0.8416
     Batch 200 | Loss : 0.3199 | Acc : 0.8565
     Batch 225 | Loss : 0.4245 | Acc : 0.7900
     Batch 250 | Loss : 0.4169 | Acc : 0.8125
     Batch 275 | Loss : 0.4745 | Acc : 0.7848
     Batch 300 | Loss : 0.2782 | Acc : 0.8669
Epoch 00027 | Train Loss : 0.3259 | Eval Loss : 0.3266 | Train acc : 0.8496 | Eval Acc : 0.8467 | Eval Log. Respected : 0.9194
     Batch 000 | Loss : 0.3209 | Acc : 0.8549
     Batch 025 | Loss : 0.3103 | Acc : 0.8541
     Batch 050 | Loss : 0.3069 | Acc : 0.8579
     Batch 075 | Loss : 0.3605 | Acc : 0.8270
     Batch 100 | Loss : 0.3092 | Acc : 0.8591
     Batch 125 | Loss : 0.3451 | Acc : 0.8460
     Batch 150 | Loss : 0.3551 | Acc : 0.8320
     Batch 175 | Loss : 0.3790 | Acc : 0.8216
     Batch 200 | Loss : 0.2992 | Acc : 0.8788
     Batch 225 | Loss : 0.3604 | Acc : 0.8256
     Batch 250 | Loss : 0.3474 | Acc : 0.8329
     Batch 275 | Loss : 0.2909 | Acc : 0.8686
     Batch 300 | Loss : 0.2869 | Acc : 0.8767
Epoch 00028 | Train Loss : 0.3260 | Eval Loss : 0.3223 | Train acc : 0.8498 | Eval Acc : 0.8498 | Eval Log. Respected : 0.9365
     Batch 000 | Loss : 0.3543 | Acc : 0.8348
     Batch 025 | Loss : 0.3375 | Acc : 0.8435
     Batch 050 | Loss : 0.3505 | Acc : 0.8423
     Batch 075 | Loss : 0.3081 | Acc : 0.8571
     Batch 100 | Loss : 0.3327 | Acc : 0.8470
     Batch 125 | Loss : 0.2844 | Acc : 0.8691
     Batch 150 | Loss : 0.2668 | Acc : 0.8808
     Batch 175 | Loss : 0.3901 | Acc : 0.7995
     Batch 200 | Loss : 0.3043 | Acc : 0.8648
     Batch 225 | Loss : 0.2554 | Acc : 0.8857
     Batch 250 | Loss : 0.3102 | Acc : 0.8561
     Batch 275 | Loss : 0.3578 | Acc : 0.8330
     Batch 300 | Loss : 0.3160 | Acc : 0.8588
Epoch 00029 | Train Loss : 0.3240 | Eval Loss : 0.3259 | Train acc : 0.8506 | Eval Acc : 0.8505 | Eval Log. Respected : 0.9347
     Batch 000 | Loss : 0.3954 | Acc : 0.8282
     Batch 025 | Loss : 0.3080 | Acc : 0.8627
     Batch 050 | Loss : 0.3999 | Acc : 0.7964
     Batch 075 | Loss : 0.2978 | Acc : 0.8671
     Batch 100 | Loss : 0.4898 | Acc : 0.7628
     Batch 125 | Loss : 0.2859 | Acc : 0.8679
     Batch 150 | Loss : 0.3316 | Acc : 0.8470
     Batch 175 | Loss : 0.2642 | Acc : 0.8792
     Batch 200 | Loss : 0.3744 | Acc : 0.8239
     Batch 225 | Loss : 0.2821 | Acc : 0.8736
     Batch 250 | Loss : 0.3286 | Acc : 0.8439
     Batch 275 | Loss : 0.2657 | Acc : 0.8793
     Batch 300 | Loss : 0.3252 | Acc : 0.8465
Epoch 00030 | Train Loss : 0.3256 | Eval Loss : 0.3402 | Train acc : 0.8501 | Eval Acc : 0.8380 | Eval Log. Respected : 0.9294
     Batch 000 | Loss : 0.2818 | Acc : 0.8785
     Batch 025 | Loss : 0.3769 | Acc : 0.8193
     Batch 050 | Loss : 0.3064 | Acc : 0.8574
     Batch 075 | Loss : 0.3072 | Acc : 0.8586
     Batch 100 | Loss : 0.2789 | Acc : 0.8713
     Batch 125 | Loss : 0.2547 | Acc : 0.8868
     Batch 150 | Loss : 0.3848 | Acc : 0.8227
     Batch 175 | Loss : 0.3375 | Acc : 0.8328
     Batch 200 | Loss : 0.3289 | Acc : 0.8408
     Batch 225 | Loss : 0.3521 | Acc : 0.8275
     Batch 250 | Loss : 0.3609 | Acc : 0.8279
     Batch 275 | Loss : 0.3248 | Acc : 0.8514
     Batch 300 | Loss : 0.3033 | Acc : 0.8620
Epoch 00031 | Train Loss : 0.3233 | Eval Loss : 0.3251 | Train acc : 0.8505 | Eval Acc : 0.8480 | Eval Log. Respected : 0.9339
     Batch 000 | Loss : 0.3937 | Acc : 0.8140
     Batch 025 | Loss : 0.2998 | Acc : 0.8664
     Batch 050 | Loss : 0.3545 | Acc : 0.8334
     Batch 075 | Loss : 0.3428 | Acc : 0.8341
     Batch 100 | Loss : 0.3292 | Acc : 0.8493
     Batch 125 | Loss : 0.2948 | Acc : 0.8664
     Batch 150 | Loss : 0.3436 | Acc : 0.8401
     Batch 175 | Loss : 0.3569 | Acc : 0.8316
     Batch 200 | Loss : 0.3613 | Acc : 0.8364
     Batch 225 | Loss : 0.3233 | Acc : 0.8500
     Batch 250 | Loss : 0.3083 | Acc : 0.8617
     Batch 275 | Loss : 0.3292 | Acc : 0.8448
     Batch 300 | Loss : 0.2640 | Acc : 0.8866
Epoch 00032 | Train Loss : 0.3228 | Eval Loss : 0.3195 | Train acc : 0.8510 | Eval Acc : 0.8504 | Eval Log. Respected : 0.9309
     Batch 000 | Loss : 0.3172 | Acc : 0.8556
     Batch 025 | Loss : 0.3287 | Acc : 0.8456
     Batch 050 | Loss : 0.3066 | Acc : 0.8600
     Batch 075 | Loss : 0.2778 | Acc : 0.8782
     Batch 100 | Loss : 0.2839 | Acc : 0.8703
     Batch 125 | Loss : 0.4059 | Acc : 0.8093
     Batch 150 | Loss : 0.2958 | Acc : 0.8629
     Batch 175 | Loss : 0.3473 | Acc : 0.8448
     Batch 200 | Loss : 0.3058 | Acc : 0.8517
     Batch 225 | Loss : 0.3562 | Acc : 0.8301
     Batch 250 | Loss : 0.3472 | Acc : 0.8331
     Batch 275 | Loss : 0.3207 | Acc : 0.8474
     Batch 300 | Loss : 0.3295 | Acc : 0.8489
Epoch 00033 | Train Loss : 0.3223 | Eval Loss : 0.3262 | Train acc : 0.8512 | Eval Acc : 0.8471 | Eval Log. Respected : 0.9329
     Batch 000 | Loss : 0.2748 | Acc : 0.8798
     Batch 025 | Loss : 0.2938 | Acc : 0.8639
     Batch 050 | Loss : 0.2712 | Acc : 0.8827
     Batch 075 | Loss : 0.3500 | Acc : 0.8409
     Batch 100 | Loss : 0.4281 | Acc : 0.8100
     Batch 125 | Loss : 0.2818 | Acc : 0.8834
     Batch 150 | Loss : 0.3437 | Acc : 0.8468
     Batch 175 | Loss : 0.3010 | Acc : 0.8609
     Batch 200 | Loss : 0.2806 | Acc : 0.8726
     Batch 225 | Loss : 0.3642 | Acc : 0.8265
     Batch 250 | Loss : 0.2896 | Acc : 0.8681
     Batch 275 | Loss : 0.3347 | Acc : 0.8434
     Batch 300 | Loss : 0.3269 | Acc : 0.8458
Epoch 00034 | Train Loss : 0.3224 | Eval Loss : 0.3231 | Train acc : 0.8511 | Eval Acc : 0.8500 | Eval Log. Respected : 0.9322
     Batch 000 | Loss : 0.3922 | Acc : 0.8165
     Batch 025 | Loss : 0.4937 | Acc : 0.7645
     Batch 050 | Loss : 0.3153 | Acc : 0.8543
     Batch 075 | Loss : 0.2942 | Acc : 0.8652
     Batch 100 | Loss : 0.3121 | Acc : 0.8593
     Batch 125 | Loss : 0.2976 | Acc : 0.8633
     Batch 150 | Loss : 0.2872 | Acc : 0.8729
     Batch 175 | Loss : 0.3286 | Acc : 0.8415
     Batch 200 | Loss : 0.2877 | Acc : 0.8697
     Batch 225 | Loss : 0.3330 | Acc : 0.8391
     Batch 250 | Loss : 0.2566 | Acc : 0.8831
     Batch 275 | Loss : 0.3094 | Acc : 0.8578
     Batch 300 | Loss : 0.3124 | Acc : 0.8530
Epoch 00035 | Train Loss : 0.3203 | Eval Loss : 0.3200 | Train acc : 0.8520 | Eval Acc : 0.8493 | Eval Log. Respected : 0.9247
     Batch 000 | Loss : 0.3371 | Acc : 0.8465
     Batch 025 | Loss : 0.2936 | Acc : 0.8637
     Batch 050 | Loss : 0.2809 | Acc : 0.8708
     Batch 075 | Loss : 0.3393 | Acc : 0.8406
     Batch 100 | Loss : 0.3003 | Acc : 0.8596
     Batch 125 | Loss : 0.2822 | Acc : 0.8748
     Batch 150 | Loss : 0.3240 | Acc : 0.8551
     Batch 175 | Loss : 0.3261 | Acc : 0.8482
     Batch 200 | Loss : 0.2911 | Acc : 0.8729
     Batch 225 | Loss : 0.3106 | Acc : 0.8573
     Batch 250 | Loss : 0.2688 | Acc : 0.8818
     Batch 275 | Loss : 0.3438 | Acc : 0.8425
     Batch 300 | Loss : 0.3522 | Acc : 0.8320
Epoch 00036 | Train Loss : 0.3206 | Eval Loss : 0.3232 | Train acc : 0.8522 | Eval Acc : 0.8476 | Eval Log. Respected : 0.9344
     Batch 000 | Loss : 0.2689 | Acc : 0.8820
     Batch 025 | Loss : 0.3698 | Acc : 0.8230
     Batch 050 | Loss : 0.2796 | Acc : 0.8739
     Batch 075 | Loss : 0.3645 | Acc : 0.8266
     Batch 100 | Loss : 0.2944 | Acc : 0.8689
     Batch 125 | Loss : 0.2956 | Acc : 0.8668
     Batch 150 | Loss : 0.3302 | Acc : 0.8408
     Batch 175 | Loss : 0.4748 | Acc : 0.7825
     Batch 200 | Loss : 0.3013 | Acc : 0.8615
     Batch 225 | Loss : 0.3245 | Acc : 0.8489
     Batch 250 | Loss : 0.3513 | Acc : 0.8338
     Batch 275 | Loss : 0.3162 | Acc : 0.8499
     Batch 300 | Loss : 0.2904 | Acc : 0.8736
Epoch 00037 | Train Loss : 0.3205 | Eval Loss : 0.3339 | Train acc : 0.8520 | Eval Acc : 0.8440 | Eval Log. Respected : 0.9400
     Batch 000 | Loss : 0.3443 | Acc : 0.8448
     Batch 025 | Loss : 0.3347 | Acc : 0.8440
     Batch 050 | Loss : 0.4229 | Acc : 0.7963
     Batch 075 | Loss : 0.3177 | Acc : 0.8497
     Batch 100 | Loss : 0.3257 | Acc : 0.8510
     Batch 125 | Loss : 0.2838 | Acc : 0.8734
     Batch 150 | Loss : 0.2990 | Acc : 0.8638
     Batch 175 | Loss : 0.3327 | Acc : 0.8476
     Batch 200 | Loss : 0.2840 | Acc : 0.8666
     Batch 225 | Loss : 0.2758 | Acc : 0.8760
     Batch 250 | Loss : 0.3115 | Acc : 0.8532
     Batch 275 | Loss : 0.3559 | Acc : 0.8422
     Batch 300 | Loss : 0.2936 | Acc : 0.8684
Epoch 00038 | Train Loss : 0.3201 | Eval Loss : 0.3208 | Train acc : 0.8521 | Eval Acc : 0.8496 | Eval Log. Respected : 0.9307
     Batch 000 | Loss : 0.2913 | Acc : 0.8635
     Batch 025 | Loss : 0.2953 | Acc : 0.8657
     Batch 050 | Loss : 0.2972 | Acc : 0.8596
     Batch 075 | Loss : 0.3284 | Acc : 0.8509
     Batch 100 | Loss : 0.3067 | Acc : 0.8600
     Batch 125 | Loss : 0.3494 | Acc : 0.8334
     Batch 150 | Loss : 0.3118 | Acc : 0.8566
     Batch 175 | Loss : 0.2996 | Acc : 0.8613
     Batch 200 | Loss : 0.3449 | Acc : 0.8412
     Batch 225 | Loss : 0.2550 | Acc : 0.8814
     Batch 250 | Loss : 0.3575 | Acc : 0.8341
     Batch 275 | Loss : 0.2612 | Acc : 0.8830
     Batch 300 | Loss : 0.3179 | Acc : 0.8565
Epoch 00039 | Train Loss : 0.3205 | Eval Loss : 0.3206 | Train acc : 0.8520 | Eval Acc : 0.8498 | Eval Log. Respected : 0.9279
     Batch 000 | Loss : 0.2525 | Acc : 0.8895
     Batch 025 | Loss : 0.3331 | Acc : 0.8442
     Batch 050 | Loss : 0.2696 | Acc : 0.8769
     Batch 075 | Loss : 0.3151 | Acc : 0.8545
     Batch 100 | Loss : 0.2804 | Acc : 0.8728
     Batch 125 | Loss : 0.2847 | Acc : 0.8674
     Batch 150 | Loss : 0.2838 | Acc : 0.8685
     Batch 175 | Loss : 0.3990 | Acc : 0.8057
     Batch 200 | Loss : 0.3188 | Acc : 0.8533
     Batch 225 | Loss : 0.2601 | Acc : 0.8835
     Batch 250 | Loss : 0.2830 | Acc : 0.8702
     Batch 275 | Loss : 0.3710 | Acc : 0.8230
     Batch 300 | Loss : 0.2727 | Acc : 0.8788
Epoch 00040 | Train Loss : 0.3191 | Eval Loss : 0.3216 | Train acc : 0.8524 | Eval Acc : 0.8502 | Eval Log. Respected : 0.9251
     Batch 000 | Loss : 0.3447 | Acc : 0.8354
     Batch 025 | Loss : 0.2971 | Acc : 0.8640
     Batch 050 | Loss : 0.4242 | Acc : 0.8017
     Batch 075 | Loss : 0.2736 | Acc : 0.8763
     Batch 100 | Loss : 0.3860 | Acc : 0.8128
     Batch 125 | Loss : 0.3509 | Acc : 0.8356
     Batch 150 | Loss : 0.4002 | Acc : 0.8143
     Batch 175 | Loss : 0.3420 | Acc : 0.8367
     Batch 200 | Loss : 0.3358 | Acc : 0.8393
     Batch 225 | Loss : 0.4113 | Acc : 0.8033
     Batch 250 | Loss : 0.2962 | Acc : 0.8658
     Batch 275 | Loss : 0.2635 | Acc : 0.8799
     Batch 300 | Loss : 0.3138 | Acc : 0.8575
Epoch 00041 | Train Loss : 0.3180 | Eval Loss : 0.3321 | Train acc : 0.8531 | Eval Acc : 0.8486 | Eval Log. Respected : 0.9318
     Batch 000 | Loss : 0.3420 | Acc : 0.8426
     Batch 025 | Loss : 0.3236 | Acc : 0.8453
     Batch 050 | Loss : 0.3082 | Acc : 0.8603
     Batch 075 | Loss : 0.3366 | Acc : 0.8418
     Batch 100 | Loss : 0.2461 | Acc : 0.8971
     Batch 125 | Loss : 0.3468 | Acc : 0.8386
     Batch 150 | Loss : 0.2727 | Acc : 0.8729
     Batch 175 | Loss : 0.4012 | Acc : 0.8093
     Batch 200 | Loss : 0.2923 | Acc : 0.8667
     Batch 225 | Loss : 0.3624 | Acc : 0.8280
     Batch 250 | Loss : 0.3350 | Acc : 0.8367
     Batch 275 | Loss : 0.2820 | Acc : 0.8696
     Batch 300 | Loss : 0.2696 | Acc : 0.8793
Epoch 00042 | Train Loss : 0.3187 | Eval Loss : 0.3210 | Train acc : 0.8529 | Eval Acc : 0.8497 | Eval Log. Respected : 0.9288
Early Stopping
Testing...
Test Loss 0.5850 | Test Acc 0.8471 | Test Log. Res. 0.9284
