Done loading data from cached files.
Training ...
     Batch 000 | Loss : 0.6938 | Acc : 0.5172
     Batch 025 | Loss : 0.6923 | Acc : 0.5139
     Batch 050 | Loss : 0.6814 | Acc : 0.5851
     Batch 075 | Loss : 0.6434 | Acc : 0.5990
     Batch 100 | Loss : 0.6201 | Acc : 0.6048
     Batch 125 | Loss : 0.6093 | Acc : 0.6149
     Batch 150 | Loss : 0.6155 | Acc : 0.6123
     Batch 175 | Loss : 0.6175 | Acc : 0.6136
     Batch 200 | Loss : 0.5940 | Acc : 0.6254
     Batch 225 | Loss : 0.6350 | Acc : 0.6182
     Batch 250 | Loss : 0.5913 | Acc : 0.6801
     Batch 275 | Loss : 0.4643 | Acc : 0.7542
     Batch 300 | Loss : 0.4875 | Acc : 0.7527
Epoch 00000 | Train Loss : 0.6058 | Eval Loss : 0.5023 | Train acc : 0.6260 | Eval Acc : 0.7287 | Eval Log. Respected : 0.9862
     Batch 000 | Loss : 0.5815 | Acc : 0.6865
     Batch 025 | Loss : 0.4558 | Acc : 0.7873
     Batch 050 | Loss : 0.4536 | Acc : 0.7589
     Batch 075 | Loss : 0.4629 | Acc : 0.7674
     Batch 100 | Loss : 0.4920 | Acc : 0.7391
     Batch 125 | Loss : 0.5813 | Acc : 0.7147
     Batch 150 | Loss : 0.5240 | Acc : 0.7381
     Batch 175 | Loss : 0.4413 | Acc : 0.8265
     Batch 200 | Loss : 0.5201 | Acc : 0.7202
     Batch 225 | Loss : 0.4412 | Acc : 0.7944
     Batch 250 | Loss : 0.4974 | Acc : 0.7426
     Batch 275 | Loss : 0.5236 | Acc : 0.7264
     Batch 300 | Loss : 0.4774 | Acc : 0.7635
Epoch 00001 | Train Loss : 0.4901 | Eval Loss : 0.4629 | Train acc : 0.7540 | Eval Acc : 0.7750 | Eval Log. Respected : 0.9776
     Batch 000 | Loss : 0.4467 | Acc : 0.7918
     Batch 025 | Loss : 0.4934 | Acc : 0.7509
     Batch 050 | Loss : 0.4651 | Acc : 0.7766
     Batch 075 | Loss : 0.4457 | Acc : 0.7883
     Batch 100 | Loss : 0.5721 | Acc : 0.6786
     Batch 125 | Loss : 0.4486 | Acc : 0.7752
     Batch 150 | Loss : 0.4296 | Acc : 0.7950
     Batch 175 | Loss : 0.4683 | Acc : 0.7809
     Batch 200 | Loss : 0.4916 | Acc : 0.7403
     Batch 225 | Loss : 0.4268 | Acc : 0.7921
     Batch 250 | Loss : 0.4281 | Acc : 0.8361
     Batch 275 | Loss : 0.4002 | Acc : 0.8201
     Batch 300 | Loss : 0.4879 | Acc : 0.7605
Epoch 00002 | Train Loss : 0.4646 | Eval Loss : 0.4523 | Train acc : 0.7765 | Eval Acc : 0.7854 | Eval Log. Respected : 0.9708
     Batch 000 | Loss : 0.5102 | Acc : 0.7467
     Batch 025 | Loss : 0.4490 | Acc : 0.7877
     Batch 050 | Loss : 0.4729 | Acc : 0.7715
     Batch 075 | Loss : 0.3902 | Acc : 0.8219
     Batch 100 | Loss : 0.4856 | Acc : 0.7706
     Batch 125 | Loss : 0.4685 | Acc : 0.7686
     Batch 150 | Loss : 0.4079 | Acc : 0.8109
     Batch 175 | Loss : 0.3645 | Acc : 0.8389
     Batch 200 | Loss : 0.4892 | Acc : 0.7624
     Batch 225 | Loss : 0.3443 | Acc : 0.8561
     Batch 250 | Loss : 0.3985 | Acc : 0.8149
     Batch 275 | Loss : 0.3879 | Acc : 0.8139
     Batch 300 | Loss : 0.3636 | Acc : 0.8399
Epoch 00003 | Train Loss : 0.4335 | Eval Loss : 0.4172 | Train acc : 0.7977 | Eval Acc : 0.8021 | Eval Log. Respected : 0.9392
     Batch 000 | Loss : 0.3786 | Acc : 0.8304
     Batch 025 | Loss : 0.3538 | Acc : 0.8625
     Batch 050 | Loss : 0.3246 | Acc : 0.8585
     Batch 075 | Loss : 0.3586 | Acc : 0.8464
     Batch 100 | Loss : 0.3349 | Acc : 0.8606
     Batch 125 | Loss : 0.3627 | Acc : 0.8394
     Batch 150 | Loss : 0.5259 | Acc : 0.7477
     Batch 175 | Loss : 0.4238 | Acc : 0.8086
     Batch 200 | Loss : 0.4104 | Acc : 0.7973
     Batch 225 | Loss : 0.3619 | Acc : 0.8345
     Batch 250 | Loss : 0.3137 | Acc : 0.8671
     Batch 275 | Loss : 0.3664 | Acc : 0.8333
     Batch 300 | Loss : 0.3444 | Acc : 0.8515
Epoch 00004 | Train Loss : 0.4003 | Eval Loss : 0.3931 | Train acc : 0.8150 | Eval Acc : 0.8139 | Eval Log. Respected : 0.9626
     Batch 000 | Loss : 0.3515 | Acc : 0.8430
     Batch 025 | Loss : 0.3488 | Acc : 0.8394
     Batch 050 | Loss : 0.4002 | Acc : 0.8092
     Batch 075 | Loss : 0.3260 | Acc : 0.8599
     Batch 100 | Loss : 0.3302 | Acc : 0.8617
     Batch 125 | Loss : 0.3869 | Acc : 0.8158
     Batch 150 | Loss : 0.3831 | Acc : 0.8267
     Batch 175 | Loss : 0.3764 | Acc : 0.8282
     Batch 200 | Loss : 0.3529 | Acc : 0.8421
     Batch 225 | Loss : 0.3506 | Acc : 0.8487
     Batch 250 | Loss : 0.4089 | Acc : 0.8033
     Batch 275 | Loss : 0.3391 | Acc : 0.8490
     Batch 300 | Loss : 0.3584 | Acc : 0.8381
Epoch 00005 | Train Loss : 0.3851 | Eval Loss : 0.3965 | Train acc : 0.8220 | Eval Acc : 0.8147 | Eval Log. Respected : 0.9739
     Batch 000 | Loss : 0.4358 | Acc : 0.7971
     Batch 025 | Loss : 0.3564 | Acc : 0.8439
     Batch 050 | Loss : 0.3858 | Acc : 0.8208
     Batch 075 | Loss : 0.4660 | Acc : 0.7716
     Batch 100 | Loss : 0.4099 | Acc : 0.8049
     Batch 125 | Loss : 0.3332 | Acc : 0.8519
     Batch 150 | Loss : 0.4242 | Acc : 0.7955
     Batch 175 | Loss : 0.3490 | Acc : 0.8426
     Batch 200 | Loss : 0.4501 | Acc : 0.7901
     Batch 225 | Loss : 0.3433 | Acc : 0.8498
     Batch 250 | Loss : 0.3276 | Acc : 0.8536
     Batch 275 | Loss : 0.3571 | Acc : 0.8298
     Batch 300 | Loss : 0.3132 | Acc : 0.8657
Epoch 00006 | Train Loss : 0.3795 | Eval Loss : 0.3813 | Train acc : 0.8252 | Eval Acc : 0.8185 | Eval Log. Respected : 0.9697
     Batch 000 | Loss : 0.3216 | Acc : 0.8605
     Batch 025 | Loss : 0.3977 | Acc : 0.8132
     Batch 050 | Loss : 0.5444 | Acc : 0.7509
     Batch 075 | Loss : 0.3536 | Acc : 0.8415
     Batch 100 | Loss : 0.4047 | Acc : 0.8066
     Batch 125 | Loss : 0.6355 | Acc : 0.7310
     Batch 150 | Loss : 0.3237 | Acc : 0.8549
     Batch 175 | Loss : 0.3837 | Acc : 0.8226
     Batch 200 | Loss : 0.4011 | Acc : 0.8167
     Batch 225 | Loss : 0.3387 | Acc : 0.8452
     Batch 250 | Loss : 0.3386 | Acc : 0.8449
     Batch 275 | Loss : 0.3339 | Acc : 0.8493
     Batch 300 | Loss : 0.3140 | Acc : 0.8630
Epoch 00007 | Train Loss : 0.3726 | Eval Loss : 0.3754 | Train acc : 0.8283 | Eval Acc : 0.8219 | Eval Log. Respected : 0.9523
     Batch 000 | Loss : 0.3014 | Acc : 0.8652
     Batch 025 | Loss : 0.3478 | Acc : 0.8428
     Batch 050 | Loss : 0.3280 | Acc : 0.8529
     Batch 075 | Loss : 0.3988 | Acc : 0.8126
     Batch 100 | Loss : 0.4156 | Acc : 0.8038
     Batch 125 | Loss : 0.4731 | Acc : 0.7842
     Batch 150 | Loss : 0.3105 | Acc : 0.8625
     Batch 175 | Loss : 0.4039 | Acc : 0.8087
     Batch 200 | Loss : 0.3939 | Acc : 0.8149
     Batch 225 | Loss : 0.3676 | Acc : 0.8342
     Batch 250 | Loss : 0.3278 | Acc : 0.8614
     Batch 275 | Loss : 0.2987 | Acc : 0.8719
     Batch 300 | Loss : 0.3785 | Acc : 0.8244
Epoch 00008 | Train Loss : 0.3668 | Eval Loss : 0.3742 | Train acc : 0.8313 | Eval Acc : 0.8236 | Eval Log. Respected : 0.9434
     Batch 000 | Loss : 0.3774 | Acc : 0.8210
     Batch 025 | Loss : 0.3360 | Acc : 0.8533
     Batch 050 | Loss : 0.3275 | Acc : 0.8508
     Batch 075 | Loss : 0.3390 | Acc : 0.8427
     Batch 100 | Loss : 0.3248 | Acc : 0.8506
     Batch 125 | Loss : 0.3597 | Acc : 0.8230
     Batch 150 | Loss : 0.3642 | Acc : 0.8266
     Batch 175 | Loss : 0.4247 | Acc : 0.8089
     Batch 200 | Loss : 0.3417 | Acc : 0.8409
     Batch 225 | Loss : 0.3748 | Acc : 0.8214
     Batch 250 | Loss : 0.3960 | Acc : 0.8185
     Batch 275 | Loss : 0.3432 | Acc : 0.8440
     Batch 300 | Loss : 0.3218 | Acc : 0.8548
Epoch 00009 | Train Loss : 0.3622 | Eval Loss : 0.3724 | Train acc : 0.8331 | Eval Acc : 0.8236 | Eval Log. Respected : 0.9193
     Batch 000 | Loss : 0.3489 | Acc : 0.8336
     Batch 025 | Loss : 0.3546 | Acc : 0.8345
     Batch 050 | Loss : 0.3141 | Acc : 0.8577
     Batch 075 | Loss : 0.3213 | Acc : 0.8624
     Batch 100 | Loss : 0.3789 | Acc : 0.8159
     Batch 125 | Loss : 0.3193 | Acc : 0.8545
     Batch 150 | Loss : 0.3298 | Acc : 0.8471
     Batch 175 | Loss : 0.3541 | Acc : 0.8407
     Batch 200 | Loss : 0.3239 | Acc : 0.8556
     Batch 225 | Loss : 0.2922 | Acc : 0.8759
     Batch 250 | Loss : 0.3792 | Acc : 0.8224
     Batch 275 | Loss : 0.4213 | Acc : 0.7956
     Batch 300 | Loss : 0.3978 | Acc : 0.8200
Epoch 00010 | Train Loss : 0.3600 | Eval Loss : 0.3640 | Train acc : 0.8341 | Eval Acc : 0.8291 | Eval Log. Respected : 0.9432
     Batch 000 | Loss : 0.3194 | Acc : 0.8596
     Batch 025 | Loss : 0.3915 | Acc : 0.8252
     Batch 050 | Loss : 0.3295 | Acc : 0.8470
     Batch 075 | Loss : 0.3573 | Acc : 0.8331
     Batch 100 | Loss : 0.4196 | Acc : 0.7994
     Batch 125 | Loss : 0.2650 | Acc : 0.8959
     Batch 150 | Loss : 0.3845 | Acc : 0.8150
     Batch 175 | Loss : 0.4257 | Acc : 0.7989
     Batch 200 | Loss : 0.3984 | Acc : 0.8135
     Batch 225 | Loss : 0.3054 | Acc : 0.8650
     Batch 250 | Loss : 0.3287 | Acc : 0.8490
     Batch 275 | Loss : 0.3067 | Acc : 0.8597
     Batch 300 | Loss : 0.4220 | Acc : 0.8038
Epoch 00011 | Train Loss : 0.3551 | Eval Loss : 0.3659 | Train acc : 0.8364 | Eval Acc : 0.8259 | Eval Log. Respected : 0.9148
     Batch 000 | Loss : 0.4037 | Acc : 0.8095
     Batch 025 | Loss : 0.3865 | Acc : 0.8167
     Batch 050 | Loss : 0.3547 | Acc : 0.8392
     Batch 075 | Loss : 0.3870 | Acc : 0.8163
     Batch 100 | Loss : 0.3735 | Acc : 0.8259
     Batch 125 | Loss : 0.3592 | Acc : 0.8399
     Batch 150 | Loss : 0.3070 | Acc : 0.8571
     Batch 175 | Loss : 0.4249 | Acc : 0.7978
     Batch 200 | Loss : 0.4192 | Acc : 0.8175
     Batch 225 | Loss : 0.3258 | Acc : 0.8506
     Batch 250 | Loss : 0.4160 | Acc : 0.8058
     Batch 275 | Loss : 0.4205 | Acc : 0.8119
     Batch 300 | Loss : 0.4265 | Acc : 0.7919
Epoch 00012 | Train Loss : 0.3526 | Eval Loss : 0.3566 | Train acc : 0.8373 | Eval Acc : 0.8324 | Eval Log. Respected : 0.9284
     Batch 000 | Loss : 0.2976 | Acc : 0.8634
     Batch 025 | Loss : 0.3497 | Acc : 0.8379
     Batch 050 | Loss : 0.3527 | Acc : 0.8353
     Batch 075 | Loss : 0.3472 | Acc : 0.8377
     Batch 100 | Loss : 0.3935 | Acc : 0.8165
     Batch 125 | Loss : 0.2866 | Acc : 0.8732
     Batch 150 | Loss : 0.4211 | Acc : 0.8149
     Batch 175 | Loss : 0.3848 | Acc : 0.8184
     Batch 200 | Loss : 0.3820 | Acc : 0.8161
     Batch 225 | Loss : 0.3027 | Acc : 0.8600
     Batch 250 | Loss : 0.3300 | Acc : 0.8481
     Batch 275 | Loss : 0.2983 | Acc : 0.8695
     Batch 300 | Loss : 0.3650 | Acc : 0.8261
Epoch 00013 | Train Loss : 0.3503 | Eval Loss : 0.3690 | Train acc : 0.8385 | Eval Acc : 0.8280 | Eval Log. Respected : 0.9442
     Batch 000 | Loss : 0.3595 | Acc : 0.8259
     Batch 025 | Loss : 0.3460 | Acc : 0.8367
     Batch 050 | Loss : 0.2614 | Acc : 0.8948
     Batch 075 | Loss : 0.3646 | Acc : 0.8327
     Batch 100 | Loss : 0.3313 | Acc : 0.8532
     Batch 125 | Loss : 0.3273 | Acc : 0.8573
     Batch 150 | Loss : 0.3417 | Acc : 0.8420
     Batch 175 | Loss : 0.4717 | Acc : 0.8020
     Batch 200 | Loss : 0.3516 | Acc : 0.8352
     Batch 225 | Loss : 0.3516 | Acc : 0.8310
     Batch 250 | Loss : 0.3917 | Acc : 0.8135
     Batch 275 | Loss : 0.3115 | Acc : 0.8534
     Batch 300 | Loss : 0.3044 | Acc : 0.8657
Epoch 00014 | Train Loss : 0.3472 | Eval Loss : 0.3603 | Train acc : 0.8398 | Eval Acc : 0.8302 | Eval Log. Respected : 0.9254
     Batch 000 | Loss : 0.4071 | Acc : 0.7985
     Batch 025 | Loss : 0.3718 | Acc : 0.8298
     Batch 050 | Loss : 0.4318 | Acc : 0.8046
     Batch 075 | Loss : 0.2984 | Acc : 0.8669
     Batch 100 | Loss : 0.3859 | Acc : 0.8192
     Batch 125 | Loss : 0.3036 | Acc : 0.8644
     Batch 150 | Loss : 0.2779 | Acc : 0.8744
     Batch 175 | Loss : 0.2732 | Acc : 0.8805
     Batch 200 | Loss : 0.2797 | Acc : 0.8777
     Batch 225 | Loss : 0.3261 | Acc : 0.8495
     Batch 250 | Loss : 0.3016 | Acc : 0.8599
     Batch 275 | Loss : 0.2866 | Acc : 0.8719
     Batch 300 | Loss : 0.3892 | Acc : 0.8206
Epoch 00015 | Train Loss : 0.3490 | Eval Loss : 0.3637 | Train acc : 0.8391 | Eval Acc : 0.8291 | Eval Log. Respected : 0.9462
     Batch 000 | Loss : 0.3219 | Acc : 0.8552
     Batch 025 | Loss : 0.3391 | Acc : 0.8442
     Batch 050 | Loss : 0.3670 | Acc : 0.8306
     Batch 075 | Loss : 0.3640 | Acc : 0.8300
     Batch 100 | Loss : 0.3752 | Acc : 0.8267
     Batch 125 | Loss : 0.3004 | Acc : 0.8645
     Batch 150 | Loss : 0.3874 | Acc : 0.8177
     Batch 175 | Loss : 0.3006 | Acc : 0.8689
     Batch 200 | Loss : 0.3026 | Acc : 0.8688
     Batch 225 | Loss : 0.3449 | Acc : 0.8363
     Batch 250 | Loss : 0.3709 | Acc : 0.8208
     Batch 275 | Loss : 0.3133 | Acc : 0.8531
     Batch 300 | Loss : 0.3265 | Acc : 0.8494
Epoch 00016 | Train Loss : 0.3463 | Eval Loss : 0.3551 | Train acc : 0.8401 | Eval Acc : 0.8314 | Eval Log. Respected : 0.9236
     Batch 000 | Loss : 0.3949 | Acc : 0.8173
     Batch 025 | Loss : 0.2740 | Acc : 0.8770
     Batch 050 | Loss : 0.2996 | Acc : 0.8651
     Batch 075 | Loss : 0.3199 | Acc : 0.8530
     Batch 100 | Loss : 0.3275 | Acc : 0.8541
     Batch 125 | Loss : 0.3450 | Acc : 0.8379
     Batch 150 | Loss : 0.3086 | Acc : 0.8569
     Batch 175 | Loss : 0.3322 | Acc : 0.8475
     Batch 200 | Loss : 0.3738 | Acc : 0.8227
     Batch 225 | Loss : 0.3320 | Acc : 0.8388
     Batch 250 | Loss : 0.3556 | Acc : 0.8386
     Batch 275 | Loss : 0.3943 | Acc : 0.8055
     Batch 300 | Loss : 0.3241 | Acc : 0.8523
Epoch 00017 | Train Loss : 0.3446 | Eval Loss : 0.3546 | Train acc : 0.8408 | Eval Acc : 0.8316 | Eval Log. Respected : 0.9297
     Batch 000 | Loss : 0.3132 | Acc : 0.8510
     Batch 025 | Loss : 0.3734 | Acc : 0.8208
     Batch 050 | Loss : 0.2966 | Acc : 0.8621
     Batch 075 | Loss : 0.2959 | Acc : 0.8624
     Batch 100 | Loss : 0.3157 | Acc : 0.8566
     Batch 125 | Loss : 0.3737 | Acc : 0.8293
     Batch 150 | Loss : 0.4104 | Acc : 0.8038
     Batch 175 | Loss : 0.3391 | Acc : 0.8506
     Batch 200 | Loss : 0.3339 | Acc : 0.8475
     Batch 225 | Loss : 0.4210 | Acc : 0.7954
     Batch 250 | Loss : 0.2961 | Acc : 0.8722
     Batch 275 | Loss : 0.3406 | Acc : 0.8375
     Batch 300 | Loss : 0.3580 | Acc : 0.8305
Epoch 00018 | Train Loss : 0.3446 | Eval Loss : 0.3581 | Train acc : 0.8408 | Eval Acc : 0.8309 | Eval Log. Respected : 0.9402
     Batch 000 | Loss : 0.3727 | Acc : 0.8244
     Batch 025 | Loss : 0.2846 | Acc : 0.8695
     Batch 050 | Loss : 0.4280 | Acc : 0.7971
     Batch 075 | Loss : 0.2889 | Acc : 0.8656
     Batch 100 | Loss : 0.3354 | Acc : 0.8476
     Batch 125 | Loss : 0.3680 | Acc : 0.8250
     Batch 150 | Loss : 0.4097 | Acc : 0.8041
     Batch 175 | Loss : 0.3221 | Acc : 0.8471
     Batch 200 | Loss : 0.3252 | Acc : 0.8451
     Batch 225 | Loss : 0.2936 | Acc : 0.8765
     Batch 250 | Loss : 0.3526 | Acc : 0.8362
     Batch 275 | Loss : 0.3365 | Acc : 0.8461
     Batch 300 | Loss : 0.3194 | Acc : 0.8518
Epoch 00019 | Train Loss : 0.3433 | Eval Loss : 0.3508 | Train acc : 0.8418 | Eval Acc : 0.8345 | Eval Log. Respected : 0.9358
     Batch 000 | Loss : 0.2932 | Acc : 0.8723
     Batch 025 | Loss : 0.3144 | Acc : 0.8564
     Batch 050 | Loss : 0.2983 | Acc : 0.8698
     Batch 075 | Loss : 0.3417 | Acc : 0.8416
     Batch 100 | Loss : 0.2865 | Acc : 0.8800
     Batch 125 | Loss : 0.3545 | Acc : 0.8292
     Batch 150 | Loss : 0.3416 | Acc : 0.8385
     Batch 175 | Loss : 0.3725 | Acc : 0.8255
     Batch 200 | Loss : 0.3253 | Acc : 0.8538
     Batch 225 | Loss : 0.3216 | Acc : 0.8540
     Batch 250 | Loss : 0.3451 | Acc : 0.8465
     Batch 275 | Loss : 0.3762 | Acc : 0.8204
     Batch 300 | Loss : 0.4299 | Acc : 0.7969
Epoch 00020 | Train Loss : 0.3430 | Eval Loss : 0.3549 | Train acc : 0.8418 | Eval Acc : 0.8322 | Eval Log. Respected : 0.9411
     Batch 000 | Loss : 0.2879 | Acc : 0.8754
     Batch 025 | Loss : 0.3632 | Acc : 0.8299
     Batch 050 | Loss : 0.2911 | Acc : 0.8651
     Batch 075 | Loss : 0.3358 | Acc : 0.8396
     Batch 100 | Loss : 0.3514 | Acc : 0.8310
     Batch 125 | Loss : 0.3611 | Acc : 0.8334
     Batch 150 | Loss : 0.2905 | Acc : 0.8689
     Batch 175 | Loss : 0.2827 | Acc : 0.8704
     Batch 200 | Loss : 0.3441 | Acc : 0.8397
     Batch 225 | Loss : 0.3681 | Acc : 0.8255
     Batch 250 | Loss : 0.4531 | Acc : 0.7842
     Batch 275 | Loss : 0.3566 | Acc : 0.8357
     Batch 300 | Loss : 0.2704 | Acc : 0.8801
Epoch 00021 | Train Loss : 0.3408 | Eval Loss : 0.3560 | Train acc : 0.8428 | Eval Acc : 0.8323 | Eval Log. Respected : 0.9346
     Batch 000 | Loss : 0.3807 | Acc : 0.8227
     Batch 025 | Loss : 0.3815 | Acc : 0.8225
     Batch 050 | Loss : 0.2969 | Acc : 0.8648
     Batch 075 | Loss : 0.3823 | Acc : 0.8237
     Batch 100 | Loss : 0.2890 | Acc : 0.8674
     Batch 125 | Loss : 0.3396 | Acc : 0.8418
     Batch 150 | Loss : 0.3764 | Acc : 0.8267
     Batch 175 | Loss : 0.3435 | Acc : 0.8415
     Batch 200 | Loss : 0.3407 | Acc : 0.8444
     Batch 225 | Loss : 0.3888 | Acc : 0.8168
     Batch 250 | Loss : 0.2824 | Acc : 0.8730
     Batch 275 | Loss : 0.2986 | Acc : 0.8675
     Batch 300 | Loss : 0.2750 | Acc : 0.8787
Epoch 00022 | Train Loss : 0.3399 | Eval Loss : 0.3516 | Train acc : 0.8430 | Eval Acc : 0.8333 | Eval Log. Respected : 0.9328
     Batch 000 | Loss : 0.2720 | Acc : 0.8782
     Batch 025 | Loss : 0.2972 | Acc : 0.8728
     Batch 050 | Loss : 0.4086 | Acc : 0.8095
     Batch 075 | Loss : 0.3600 | Acc : 0.8361
     Batch 100 | Loss : 0.3681 | Acc : 0.8218
     Batch 125 | Loss : 0.4352 | Acc : 0.7906
     Batch 150 | Loss : 0.2986 | Acc : 0.8594
     Batch 175 | Loss : 0.3087 | Acc : 0.8607
     Batch 200 | Loss : 0.2993 | Acc : 0.8624
     Batch 225 | Loss : 0.3758 | Acc : 0.8253
     Batch 250 | Loss : 0.3111 | Acc : 0.8640
     Batch 275 | Loss : 0.3576 | Acc : 0.8252
     Batch 300 | Loss : 0.3450 | Acc : 0.8448
Epoch 00023 | Train Loss : 0.3402 | Eval Loss : 0.3610 | Train acc : 0.8432 | Eval Acc : 0.8311 | Eval Log. Respected : 0.9201
     Batch 000 | Loss : 0.2840 | Acc : 0.8705
     Batch 025 | Loss : 0.4156 | Acc : 0.8068
     Batch 050 | Loss : 0.2985 | Acc : 0.8634
     Batch 075 | Loss : 0.2837 | Acc : 0.8723
     Batch 100 | Loss : 0.4161 | Acc : 0.8007
     Batch 125 | Loss : 0.2965 | Acc : 0.8704
     Batch 150 | Loss : 0.3657 | Acc : 0.8287
     Batch 175 | Loss : 0.3246 | Acc : 0.8523
     Batch 200 | Loss : 0.4518 | Acc : 0.7912
     Batch 225 | Loss : 0.3679 | Acc : 0.8294
     Batch 250 | Loss : 0.4153 | Acc : 0.7999
     Batch 275 | Loss : 0.4368 | Acc : 0.7939
     Batch 300 | Loss : 0.2914 | Acc : 0.8657
Epoch 00024 | Train Loss : 0.3388 | Eval Loss : 0.3537 | Train acc : 0.8435 | Eval Acc : 0.8332 | Eval Log. Respected : 0.9438
     Batch 000 | Loss : 0.3594 | Acc : 0.8382
     Batch 025 | Loss : 0.4305 | Acc : 0.8000
     Batch 050 | Loss : 0.4836 | Acc : 0.7742
     Batch 075 | Loss : 0.3649 | Acc : 0.8281
     Batch 100 | Loss : 0.3356 | Acc : 0.8421
     Batch 125 | Loss : 0.3689 | Acc : 0.8279
     Batch 150 | Loss : 0.3469 | Acc : 0.8381
     Batch 175 | Loss : 0.3104 | Acc : 0.8546
     Batch 200 | Loss : 0.2961 | Acc : 0.8626
     Batch 225 | Loss : 0.2576 | Acc : 0.8903
     Batch 250 | Loss : 0.3148 | Acc : 0.8597
     Batch 275 | Loss : 0.3585 | Acc : 0.8286
     Batch 300 | Loss : 0.4015 | Acc : 0.8139
Epoch 00025 | Train Loss : 0.3396 | Eval Loss : 0.3512 | Train acc : 0.8432 | Eval Acc : 0.8338 | Eval Log. Respected : 0.9316
     Batch 000 | Loss : 0.3137 | Acc : 0.8581
     Batch 025 | Loss : 0.3118 | Acc : 0.8578
     Batch 050 | Loss : 0.3727 | Acc : 0.8205
     Batch 075 | Loss : 0.3435 | Acc : 0.8394
     Batch 100 | Loss : 0.2834 | Acc : 0.8719
     Batch 125 | Loss : 0.3630 | Acc : 0.8255
     Batch 150 | Loss : 0.2797 | Acc : 0.8719
     Batch 175 | Loss : 0.2883 | Acc : 0.8725
     Batch 200 | Loss : 0.2995 | Acc : 0.8656
     Batch 225 | Loss : 0.3063 | Acc : 0.8617
     Batch 250 | Loss : 0.3405 | Acc : 0.8392
     Batch 275 | Loss : 0.3625 | Acc : 0.8292
     Batch 300 | Loss : 0.3687 | Acc : 0.8254
Epoch 00026 | Train Loss : 0.3382 | Eval Loss : 0.3530 | Train acc : 0.8439 | Eval Acc : 0.8335 | Eval Log. Respected : 0.9255
     Batch 000 | Loss : 0.3767 | Acc : 0.8276
     Batch 025 | Loss : 0.3342 | Acc : 0.8438
     Batch 050 | Loss : 0.3111 | Acc : 0.8565
     Batch 075 | Loss : 0.3449 | Acc : 0.8405
     Batch 100 | Loss : 0.2960 | Acc : 0.8644
     Batch 125 | Loss : 0.3352 | Acc : 0.8385
     Batch 150 | Loss : 0.3107 | Acc : 0.8543
     Batch 175 | Loss : 0.2871 | Acc : 0.8757
     Batch 200 | Loss : 0.4233 | Acc : 0.7938
     Batch 225 | Loss : 0.3102 | Acc : 0.8578
     Batch 250 | Loss : 0.2970 | Acc : 0.8661
     Batch 275 | Loss : 0.2945 | Acc : 0.8633
     Batch 300 | Loss : 0.3088 | Acc : 0.8580
Epoch 00027 | Train Loss : 0.3363 | Eval Loss : 0.3611 | Train acc : 0.8446 | Eval Acc : 0.8309 | Eval Log. Respected : 0.9466
     Batch 000 | Loss : 0.3718 | Acc : 0.8249
     Batch 025 | Loss : 0.3024 | Acc : 0.8624
     Batch 050 | Loss : 0.2956 | Acc : 0.8649
     Batch 075 | Loss : 0.3118 | Acc : 0.8540
     Batch 100 | Loss : 0.3481 | Acc : 0.8441
     Batch 125 | Loss : 0.3782 | Acc : 0.8188
     Batch 150 | Loss : 0.3836 | Acc : 0.8211
     Batch 175 | Loss : 0.3145 | Acc : 0.8614
     Batch 200 | Loss : 0.3152 | Acc : 0.8546
     Batch 225 | Loss : 0.3755 | Acc : 0.8197
     Batch 250 | Loss : 0.3830 | Acc : 0.8255
     Batch 275 | Loss : 0.3322 | Acc : 0.8476
     Batch 300 | Loss : 0.2783 | Acc : 0.8757
Epoch 00028 | Train Loss : 0.3380 | Eval Loss : 0.3464 | Train acc : 0.8441 | Eval Acc : 0.8362 | Eval Log. Respected : 0.9357
     Batch 000 | Loss : 0.2811 | Acc : 0.8766
     Batch 025 | Loss : 0.4216 | Acc : 0.8091
     Batch 050 | Loss : 0.3383 | Acc : 0.8451
     Batch 075 | Loss : 0.3106 | Acc : 0.8587
     Batch 100 | Loss : 0.2891 | Acc : 0.8673
     Batch 125 | Loss : 0.4848 | Acc : 0.7718
     Batch 150 | Loss : 0.3399 | Acc : 0.8399
     Batch 175 | Loss : 0.2675 | Acc : 0.8854
     Batch 200 | Loss : 0.2650 | Acc : 0.8787
     Batch 225 | Loss : 0.3727 | Acc : 0.8271
     Batch 250 | Loss : 0.3960 | Acc : 0.8025
     Batch 275 | Loss : 0.3127 | Acc : 0.8529
     Batch 300 | Loss : 0.3598 | Acc : 0.8320
Epoch 00029 | Train Loss : 0.3369 | Eval Loss : 0.3503 | Train acc : 0.8446 | Eval Acc : 0.8356 | Eval Log. Respected : 0.9401
     Batch 000 | Loss : 0.2875 | Acc : 0.8690
     Batch 025 | Loss : 0.3650 | Acc : 0.8303
     Batch 050 | Loss : 0.3663 | Acc : 0.8274
     Batch 075 | Loss : 0.3490 | Acc : 0.8373
     Batch 100 | Loss : 0.2784 | Acc : 0.8779
     Batch 125 | Loss : 0.2938 | Acc : 0.8688
     Batch 150 | Loss : 0.4563 | Acc : 0.7853
     Batch 175 | Loss : 0.3100 | Acc : 0.8621
     Batch 200 | Loss : 0.4064 | Acc : 0.8147
     Batch 225 | Loss : 0.2656 | Acc : 0.8799
     Batch 250 | Loss : 0.2943 | Acc : 0.8695
     Batch 275 | Loss : 0.3302 | Acc : 0.8501
     Batch 300 | Loss : 0.2855 | Acc : 0.8698
Epoch 00030 | Train Loss : 0.3374 | Eval Loss : 0.3434 | Train acc : 0.8442 | Eval Acc : 0.8398 | Eval Log. Respected : 0.9358
     Batch 000 | Loss : 0.3205 | Acc : 0.8573
     Batch 025 | Loss : 0.3581 | Acc : 0.8345
     Batch 050 | Loss : 0.2687 | Acc : 0.8813
     Batch 075 | Loss : 0.3376 | Acc : 0.8480
     Batch 100 | Loss : 0.3013 | Acc : 0.8605
     Batch 125 | Loss : 0.2772 | Acc : 0.8732
     Batch 150 | Loss : 0.3772 | Acc : 0.8202
     Batch 175 | Loss : 0.3272 | Acc : 0.8413
     Batch 200 | Loss : 0.3858 | Acc : 0.8159
     Batch 225 | Loss : 0.3708 | Acc : 0.8199
     Batch 250 | Loss : 0.4246 | Acc : 0.7973
     Batch 275 | Loss : 0.3025 | Acc : 0.8643
     Batch 300 | Loss : 0.3018 | Acc : 0.8628
Epoch 00031 | Train Loss : 0.3361 | Eval Loss : 0.3440 | Train acc : 0.8448 | Eval Acc : 0.8377 | Eval Log. Respected : 0.9244
     Batch 000 | Loss : 0.3302 | Acc : 0.8466
     Batch 025 | Loss : 0.3619 | Acc : 0.8345
     Batch 050 | Loss : 0.2835 | Acc : 0.8785
     Batch 075 | Loss : 0.3016 | Acc : 0.8655
     Batch 100 | Loss : 0.2900 | Acc : 0.8692
     Batch 125 | Loss : 0.4189 | Acc : 0.7983
     Batch 150 | Loss : 0.3160 | Acc : 0.8527
     Batch 175 | Loss : 0.3678 | Acc : 0.8315
     Batch 200 | Loss : 0.3663 | Acc : 0.8185
     Batch 225 | Loss : 0.3386 | Acc : 0.8450
     Batch 250 | Loss : 0.3659 | Acc : 0.8201
     Batch 275 | Loss : 0.3618 | Acc : 0.8245
     Batch 300 | Loss : 0.3145 | Acc : 0.8612
Epoch 00032 | Train Loss : 0.3361 | Eval Loss : 0.3535 | Train acc : 0.8448 | Eval Acc : 0.8343 | Eval Log. Respected : 0.9421
     Batch 000 | Loss : 0.2789 | Acc : 0.8754
     Batch 025 | Loss : 0.3570 | Acc : 0.8313
     Batch 050 | Loss : 0.3691 | Acc : 0.8225
     Batch 075 | Loss : 0.2973 | Acc : 0.8601
     Batch 100 | Loss : 0.3071 | Acc : 0.8525
     Batch 125 | Loss : 0.3436 | Acc : 0.8338
     Batch 150 | Loss : 0.3169 | Acc : 0.8562
     Batch 175 | Loss : 0.3426 | Acc : 0.8421
     Batch 200 | Loss : 0.3929 | Acc : 0.8168
     Batch 225 | Loss : 0.2866 | Acc : 0.8721
     Batch 250 | Loss : 0.2999 | Acc : 0.8642
     Batch 275 | Loss : 0.3001 | Acc : 0.8637
     Batch 300 | Loss : 0.3144 | Acc : 0.8553
Epoch 00033 | Train Loss : 0.3345 | Eval Loss : 0.3419 | Train acc : 0.8452 | Eval Acc : 0.8383 | Eval Log. Respected : 0.9287
     Batch 000 | Loss : 0.3759 | Acc : 0.8266
     Batch 025 | Loss : 0.3023 | Acc : 0.8627
     Batch 050 | Loss : 0.3784 | Acc : 0.8183
     Batch 075 | Loss : 0.3495 | Acc : 0.8379
     Batch 100 | Loss : 0.3374 | Acc : 0.8495
     Batch 125 | Loss : 0.3216 | Acc : 0.8559
     Batch 150 | Loss : 0.3390 | Acc : 0.8386
     Batch 175 | Loss : 0.3125 | Acc : 0.8637
     Batch 200 | Loss : 0.3159 | Acc : 0.8576
     Batch 225 | Loss : 0.2668 | Acc : 0.8795
     Batch 250 | Loss : 0.2892 | Acc : 0.8698
     Batch 275 | Loss : 0.3688 | Acc : 0.8307
     Batch 300 | Loss : 0.3742 | Acc : 0.8303
Epoch 00034 | Train Loss : 0.3350 | Eval Loss : 0.3478 | Train acc : 0.8450 | Eval Acc : 0.8354 | Eval Log. Respected : 0.9352
     Batch 000 | Loss : 0.4403 | Acc : 0.8036
     Batch 025 | Loss : 0.3647 | Acc : 0.8306
     Batch 050 | Loss : 0.3422 | Acc : 0.8435
     Batch 075 | Loss : 0.2837 | Acc : 0.8733
     Batch 100 | Loss : 0.3895 | Acc : 0.8130
     Batch 125 | Loss : 0.2930 | Acc : 0.8662
     Batch 150 | Loss : 0.3756 | Acc : 0.8240
     Batch 175 | Loss : 0.3345 | Acc : 0.8418
     Batch 200 | Loss : 0.2650 | Acc : 0.8837
     Batch 225 | Loss : 0.3178 | Acc : 0.8471
     Batch 250 | Loss : 0.2821 | Acc : 0.8773
     Batch 275 | Loss : 0.3118 | Acc : 0.8541
     Batch 300 | Loss : 0.2779 | Acc : 0.8747
Epoch 00035 | Train Loss : 0.3340 | Eval Loss : 0.3615 | Train acc : 0.8460 | Eval Acc : 0.8338 | Eval Log. Respected : 0.9376
     Batch 000 | Loss : 0.3021 | Acc : 0.8587
     Batch 025 | Loss : 0.3134 | Acc : 0.8556
     Batch 050 | Loss : 0.2801 | Acc : 0.8776
     Batch 075 | Loss : 0.3943 | Acc : 0.8089
     Batch 100 | Loss : 0.3170 | Acc : 0.8561
     Batch 125 | Loss : 0.3386 | Acc : 0.8426
     Batch 150 | Loss : 0.3401 | Acc : 0.8434
     Batch 175 | Loss : 0.3089 | Acc : 0.8526
     Batch 200 | Loss : 0.2467 | Acc : 0.8937
     Batch 225 | Loss : 0.2725 | Acc : 0.8769
     Batch 250 | Loss : 0.2850 | Acc : 0.8706
     Batch 275 | Loss : 0.3592 | Acc : 0.8276
     Batch 300 | Loss : 0.3789 | Acc : 0.8218
Epoch 00036 | Train Loss : 0.3335 | Eval Loss : 0.3525 | Train acc : 0.8461 | Eval Acc : 0.8317 | Eval Log. Respected : 0.9301
     Batch 000 | Loss : 0.3216 | Acc : 0.8533
     Batch 025 | Loss : 0.3041 | Acc : 0.8652
     Batch 050 | Loss : 0.3050 | Acc : 0.8585
     Batch 075 | Loss : 0.3011 | Acc : 0.8714
     Batch 100 | Loss : 0.3048 | Acc : 0.8645
     Batch 125 | Loss : 0.3763 | Acc : 0.8241
     Batch 150 | Loss : 0.4332 | Acc : 0.8106
     Batch 175 | Loss : 0.3389 | Acc : 0.8455
     Batch 200 | Loss : 0.3459 | Acc : 0.8380
     Batch 225 | Loss : 0.2805 | Acc : 0.8748
     Batch 250 | Loss : 0.3163 | Acc : 0.8536
     Batch 275 | Loss : 0.3203 | Acc : 0.8529
     Batch 300 | Loss : 0.3816 | Acc : 0.8283
Epoch 00037 | Train Loss : 0.3332 | Eval Loss : 0.3489 | Train acc : 0.8462 | Eval Acc : 0.8366 | Eval Log. Respected : 0.9461
     Batch 000 | Loss : 0.2679 | Acc : 0.8857
     Batch 025 | Loss : 0.3440 | Acc : 0.8406
     Batch 050 | Loss : 0.2593 | Acc : 0.8898
     Batch 075 | Loss : 0.3296 | Acc : 0.8474
     Batch 100 | Loss : 0.4552 | Acc : 0.7868
     Batch 125 | Loss : 0.3642 | Acc : 0.8228
     Batch 150 | Loss : 0.3085 | Acc : 0.8605
     Batch 175 | Loss : 0.3229 | Acc : 0.8487
     Batch 200 | Loss : 0.3000 | Acc : 0.8581
     Batch 225 | Loss : 0.3661 | Acc : 0.8309
     Batch 250 | Loss : 0.3022 | Acc : 0.8609
     Batch 275 | Loss : 0.3111 | Acc : 0.8629
     Batch 300 | Loss : 0.3694 | Acc : 0.8232
Epoch 00038 | Train Loss : 0.3324 | Eval Loss : 0.3481 | Train acc : 0.8466 | Eval Acc : 0.8357 | Eval Log. Respected : 0.9281
     Batch 000 | Loss : 0.3815 | Acc : 0.8300
     Batch 025 | Loss : 0.3818 | Acc : 0.8177
     Batch 050 | Loss : 0.3150 | Acc : 0.8541
     Batch 075 | Loss : 0.2723 | Acc : 0.8755
     Batch 100 | Loss : 0.2941 | Acc : 0.8668
     Batch 125 | Loss : 0.3643 | Acc : 0.8301
     Batch 150 | Loss : 0.2714 | Acc : 0.8749
     Batch 175 | Loss : 0.2785 | Acc : 0.8766
     Batch 200 | Loss : 0.2707 | Acc : 0.8800
     Batch 225 | Loss : 0.3683 | Acc : 0.8256
     Batch 250 | Loss : 0.2846 | Acc : 0.8708
     Batch 275 | Loss : 0.3136 | Acc : 0.8521
     Batch 300 | Loss : 0.2911 | Acc : 0.8689
Epoch 00039 | Train Loss : 0.3342 | Eval Loss : 0.3488 | Train acc : 0.8458 | Eval Acc : 0.8364 | Eval Log. Respected : 0.9263
     Batch 000 | Loss : 0.4385 | Acc : 0.7957
     Batch 025 | Loss : 0.3051 | Acc : 0.8661
     Batch 050 | Loss : 0.4403 | Acc : 0.7858
     Batch 075 | Loss : 0.4015 | Acc : 0.8022
     Batch 100 | Loss : 0.3182 | Acc : 0.8561
     Batch 125 | Loss : 0.3371 | Acc : 0.8462
     Batch 150 | Loss : 0.2982 | Acc : 0.8657
     Batch 175 | Loss : 0.2693 | Acc : 0.8793
     Batch 200 | Loss : 0.2575 | Acc : 0.8854
     Batch 225 | Loss : 0.3512 | Acc : 0.8386
     Batch 250 | Loss : 0.3031 | Acc : 0.8582
     Batch 275 | Loss : 0.3291 | Acc : 0.8494
     Batch 300 | Loss : 0.3766 | Acc : 0.8297
Epoch 00040 | Train Loss : 0.3326 | Eval Loss : 0.3474 | Train acc : 0.8466 | Eval Acc : 0.8365 | Eval Log. Respected : 0.9441
     Batch 000 | Loss : 0.2917 | Acc : 0.8684
     Batch 025 | Loss : 0.3193 | Acc : 0.8567
     Batch 050 | Loss : 0.3666 | Acc : 0.8304
     Batch 075 | Loss : 0.2950 | Acc : 0.8699
     Batch 100 | Loss : 0.3560 | Acc : 0.8341
     Batch 125 | Loss : 0.3491 | Acc : 0.8330
     Batch 150 | Loss : 0.3118 | Acc : 0.8587
     Batch 175 | Loss : 0.3039 | Acc : 0.8699
     Batch 200 | Loss : 0.3211 | Acc : 0.8502
     Batch 225 | Loss : 0.2926 | Acc : 0.8660
     Batch 250 | Loss : 0.3102 | Acc : 0.8562
     Batch 275 | Loss : 0.3115 | Acc : 0.8580
     Batch 300 | Loss : 0.3174 | Acc : 0.8505
Epoch 00041 | Train Loss : 0.3328 | Eval Loss : 0.3436 | Train acc : 0.8465 | Eval Acc : 0.8381 | Eval Log. Respected : 0.9369
     Batch 000 | Loss : 0.2903 | Acc : 0.8635
     Batch 025 | Loss : 0.4000 | Acc : 0.8103
     Batch 050 | Loss : 0.3571 | Acc : 0.8323
     Batch 075 | Loss : 0.4459 | Acc : 0.7948
     Batch 100 | Loss : 0.2659 | Acc : 0.8791
     Batch 125 | Loss : 0.2953 | Acc : 0.8656
     Batch 150 | Loss : 0.3883 | Acc : 0.8042
     Batch 175 | Loss : 0.2790 | Acc : 0.8734
     Batch 200 | Loss : 0.3809 | Acc : 0.8123
     Batch 225 | Loss : 0.3334 | Acc : 0.8463
     Batch 250 | Loss : 0.4219 | Acc : 0.7942
     Batch 275 | Loss : 0.2792 | Acc : 0.8788
     Batch 300 | Loss : 0.3563 | Acc : 0.8299
Epoch 00042 | Train Loss : 0.3305 | Eval Loss : 0.3452 | Train acc : 0.8473 | Eval Acc : 0.8373 | Eval Log. Respected : 0.9307
     Batch 000 | Loss : 0.3288 | Acc : 0.8502
     Batch 025 | Loss : 0.2938 | Acc : 0.8639
     Batch 050 | Loss : 0.3785 | Acc : 0.8201
     Batch 075 | Loss : 0.2739 | Acc : 0.8769
     Batch 100 | Loss : 0.4236 | Acc : 0.7908
     Batch 125 | Loss : 0.4020 | Acc : 0.8109
     Batch 150 | Loss : 0.2703 | Acc : 0.8757
     Batch 175 | Loss : 0.3269 | Acc : 0.8517
     Batch 200 | Loss : 0.3049 | Acc : 0.8662
     Batch 225 | Loss : 0.3492 | Acc : 0.8343
     Batch 250 | Loss : 0.2859 | Acc : 0.8668
     Batch 275 | Loss : 0.3712 | Acc : 0.8237
     Batch 300 | Loss : 0.3386 | Acc : 0.8345
Epoch 00043 | Train Loss : 0.3291 | Eval Loss : 0.3463 | Train acc : 0.8479 | Eval Acc : 0.8362 | Eval Log. Respected : 0.9264
Early Stopping
Testing...
Test Loss 0.5877 | Test Acc 0.8431 | Test Log. Res. 0.9287
